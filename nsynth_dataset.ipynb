{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyO/sbhlr1ftNmGgGeMRVQhn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "07827526c8fa44739d2172f7a3b6e868": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d3c5dc1725cf400c9b19531143128948",
              "IPY_MODEL_7cec02406ff646fba05361109899ee4b",
              "IPY_MODEL_37f6dfbd4df14ba8a188859aed67470f"
            ],
            "layout": "IPY_MODEL_c24dc3d7cd104da2a841bd1545f1d68c"
          }
        },
        "d3c5dc1725cf400c9b19531143128948": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c880399aa1f4a0db9cf889d019fe7dc",
            "placeholder": "​",
            "style": "IPY_MODEL_f84f26eefe0d48af88f98a589794c0ca",
            "value": "Dl Completed...: 100%"
          }
        },
        "7cec02406ff646fba05361109899ee4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_010632b66b5d4d0ba74df0fee67a35e2",
            "max": 229,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cc06bed0b1404631a7e5c40573ffce8d",
            "value": 229
          }
        },
        "37f6dfbd4df14ba8a188859aed67470f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df6dafb834bc4ee29855a68909cee457",
            "placeholder": "​",
            "style": "IPY_MODEL_5395627ef29e4ec197526077adce51b6",
            "value": " 229/229 [01:58&lt;00:00,  2.09 file/s]"
          }
        },
        "c24dc3d7cd104da2a841bd1545f1d68c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c880399aa1f4a0db9cf889d019fe7dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f84f26eefe0d48af88f98a589794c0ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "010632b66b5d4d0ba74df0fee67a35e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc06bed0b1404631a7e5c40573ffce8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "df6dafb834bc4ee29855a68909cee457": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5395627ef29e4ec197526077adce51b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fireHedgehog/music-intrument-OvA-model/blob/main/nsynth_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "x2ZIzLNyO-En"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import librosa\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from tensorflow.keras.backend import clear_session\n",
        "from google.colab import drive\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: Load the NSynth Dataset\n",
        "TensorFlow Datasets (TFDS) provides a convenient way to load the NSynth dataset. The following code snippet demonstrates how to load the dataset. Note that the NSynth dataset is large, and loading it might take some time."
      ],
      "metadata": {
        "id": "nx53LisdPnGS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "dataset_save_path = '/content/drive/My Drive/datasets/'\n",
        "\n",
        "if not os.path.exists(dataset_save_path):\n",
        "    os.makedirs(dataset_save_path)\n",
        "    print(f\"Directory created at {dataset_save_path}\")\n",
        "else:\n",
        "    print(f\"Directory already exists at {dataset_save_path}\")\n",
        "\n",
        "\n",
        "# Example saving function\n",
        "def save_dataset(dataset, save_path):\n",
        "    tf.data.experimental.save(dataset, save_path)\n",
        "\n",
        "# Example loading function\n",
        "def load_dataset(load_path):\n",
        "    return tf.data.experimental.load(load_path)\n",
        "\n",
        "\n",
        "# Define the path where you expect the dataset to be stored\n",
        "dataset_path = os.path.join(tfds.core.constants.DATA_DIR, 'nsynth/gansynth_subset')\n",
        "\n",
        "# Check if the dataset already exists on disk\n",
        "if os.path.exists(dataset_path):\n",
        "    print(\"Loading dataset from disk...\")\n",
        "    nsynth_dataset = tfds.load('nsynth/gansynth_subset', split='train', shuffle_files=True, data_dir=dataset_path)\n",
        "else:\n",
        "    print(\"Downloading and preparing dataset...\")\n",
        "    nsynth_builder = tfds.builder('nsynth/gansynth_subset')\n",
        "    nsynth_builder.download_and_prepare()\n",
        "    nsynth_dataset = nsynth_builder.as_dataset(split='train', shuffle_files=True)\n",
        "    print(\"Dataset ready.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188,
          "referenced_widgets": [
            "07827526c8fa44739d2172f7a3b6e868",
            "d3c5dc1725cf400c9b19531143128948",
            "7cec02406ff646fba05361109899ee4b",
            "37f6dfbd4df14ba8a188859aed67470f",
            "c24dc3d7cd104da2a841bd1545f1d68c",
            "5c880399aa1f4a0db9cf889d019fe7dc",
            "f84f26eefe0d48af88f98a589794c0ca",
            "010632b66b5d4d0ba74df0fee67a35e2",
            "cc06bed0b1404631a7e5c40573ffce8d",
            "df6dafb834bc4ee29855a68909cee457",
            "5395627ef29e4ec197526077adce51b6"
          ]
        },
        "id": "vxTqigLuPqev",
        "outputId": "779cf6e5-bc4d-4856-f89c-95e5137ce30c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You use TensorFlow DType <dtype: 'string'> in tfds.features This will soon be deprecated in favor of NumPy DTypes. In the meantime it was converted to object.\n",
            "WARNING:absl:You use TensorFlow DType <dtype: 'bool'> in tfds.features This will soon be deprecated in favor of NumPy DTypes. In the meantime it was converted to bool.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Directory already exists at /content/drive/My Drive/datasets/\n",
            "Downloading and preparing dataset...\n",
            "Downloading and preparing dataset 73.08 GiB (download: 73.08 GiB, generated: 20.73 GiB, total: 93.80 GiB) to /root/tensorflow_datasets/nsynth/gansynth_subset/2.3.3...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Dl Completed...:   0%|          | 0/229 [00:00<?, ? file/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "07827526c8fa44739d2172f7a3b6e868"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset nsynth downloaded and prepared to /root/tensorflow_datasets/nsynth/gansynth_subset/2.3.3. Subsequent calls will reuse this data.\n",
            "Dataset ready.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3: Preprocess the Audio Data\n",
        "You'll need to preprocess the audio data by converting the audio samples into spectrograms. This involves iterating over the dataset, extracting audio samples, and using librosa to convert these samples into spectrogram"
      ],
      "metadata": {
        "id": "0lEI21-gPs9W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mapping from numerical labels to string names\n",
        "label_map = {\n",
        "    0: 'bass',\n",
        "    1: 'brass',\n",
        "    2: 'flute',\n",
        "    3: 'guitar',\n",
        "    4: 'keyboard',\n",
        "    5: 'mallet',\n",
        "    6: 'organ',\n",
        "    7: 'reed',\n",
        "    8: 'string',\n",
        "    9: 'synth_lead',\n",
        "    10: 'vocal',\n",
        "}\n",
        "\n",
        "def audio_to_spectrogram(audio_sample, sr=16000, n_fft=2048, hop_length=512):\n",
        "    \"\"\"Convert audio to spectrogram.\"\"\"\n",
        "    spectrogram = librosa.stft(audio_sample, n_fft=n_fft, hop_length=hop_length)\n",
        "    spectrogram_db = librosa.amplitude_to_db(abs(spectrogram))\n",
        "    return spectrogram_db\n",
        "\n",
        "def preprocess_dataset(nsynth_dataset):\n",
        "    spectrograms = []\n",
        "    labels = []\n",
        "    processed_families = set()\n",
        "\n",
        "    # for example in nsynth_dataset.take(100):  # Taking only 100 samples for demonstration\n",
        "    for example in nsynth_dataset:\n",
        "        family_id = example['instrument']['family'].numpy()\n",
        "        # Skip if the family has already been processed\n",
        "        if family_id in processed_families:\n",
        "            continue\n",
        "        processed_families.add(family_id)\n",
        "\n",
        "        audio_sample = example['audio']\n",
        "        label = label_map[family_id]\n",
        "\n",
        "        spectrogram = audio_to_spectrogram(audio_sample.numpy())\n",
        "        spectrograms.append(spectrogram)\n",
        "        labels.append(label)\n",
        "\n",
        "         # Stop if we have processed one example per family\n",
        "        if len(processed_families) == 11:\n",
        "            break\n",
        "\n",
        "    return np.array(spectrograms), np.array(labels)\n"
      ],
      "metadata": {
        "id": "hgn1v0ZTP17X"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 4: Convert Audio Samples to Spectrograms\n",
        "Use the preprocess_dataset function to convert your audio samples in the dataset to spectrograms. (comment out, for background running)"
      ],
      "metadata": {
        "id": "p9pmNAoCP4Gn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"spectrograms, labels = preprocess_dataset(nsynth_dataset)\"\"\"\n"
      ],
      "metadata": {
        "id": "Kvd2XFJDP8la"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 5: Visualizing a Spectrogram\n",
        "To ensure that your spectrograms are correctly generated, visualize one using matplotlib. (comment out, for background running)"
      ],
      "metadata": {
        "id": "UUT7Q0s0P_Mp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import librosa.display\n",
        "\n",
        "def plot_and_save_spectrograms(spectrograms, labels):\n",
        "    # Ensure the directory for spectrograms exists\n",
        "    os.makedirs('./spectrograms', exist_ok=True)\n",
        "\n",
        "    for i, (spectrogram, label) in enumerate(zip(spectrograms, labels)):\n",
        "        plt.figure(figsize=(10, 4))\n",
        "        librosa.display.specshow(spectrogram, y_axis='log', x_axis='time')\n",
        "        plt.title(f'Label: {label}')\n",
        "        plt.colorbar(format='%+2.0f dB')\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f'./spectrograms/spectrogram_{label}.png')  # Save the spectrogram as a PNG file\n",
        "        plt.close()  # Close the plot to free memory\n",
        "        plt.show()\n",
        "\n",
        "plot_and_save_spectrograms(spectrograms, labels)\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "Lh9STxspP_rj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "subplots to a big plot (comment out, for background running)\n"
      ],
      "metadata": {
        "id": "GGtive-_bzsU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import librosa.display\n",
        "\n",
        "def plot_and_save_combined_spectrograms(spectrograms, labels):\n",
        "    # Ensure the directory for spectrograms exists\n",
        "    os.makedirs('./spectrograms', exist_ok=True)\n",
        "\n",
        "    # Create a figure with subplots\n",
        "    fig, axs = plt.subplots(5, 2, figsize=(15, 25))\n",
        "    axs = axs.flatten()  # Flatten the array for easy indexing\n",
        "\n",
        "    for i, (spectrogram, label) in enumerate(zip(spectrograms, labels)):\n",
        "        ax = axs[i]\n",
        "        img = librosa.display.specshow(spectrogram, y_axis='log', x_axis='time', ax=ax)\n",
        "        ax.set_title(f'Label: {label}')\n",
        "        fig.colorbar(img, ax=ax, format='%+2.0f dB')\n",
        "\n",
        "    # Adjust layout\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Save the combined figure as a PNG file\n",
        "    plt.savefig('./spectrograms/combined_spectrograms.png')\n",
        "    plt.close(fig)  # Close the figure to free memory\n",
        "\n",
        "# Example usage:\n",
        "# plot_and_save_combined_spectrograms(spectrograms[:11], labels[:11])\n",
        "\n",
        "plot_and_save_combined_spectrograms(spectrograms, labels)\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "sBbdVSCtb2Tp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 6: Define the Model Architecture\n",
        "Use the CNN architecture you've established or any variations you prefer. Ensure it's suitable for binary classification."
      ],
      "metadata": {
        "id": "NleraOi6eg2W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(input_shape):\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape, padding='same'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "        tf.keras.layers.Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "        tf.keras.layers.Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(128, activation='relu'),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "O4TLKKpCenhE"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "load data\n"
      ],
      "metadata": {
        "id": "s5VGD0eRiS1_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nsynth_train = tfds.load('nsynth/gansynth_subset', split='train', shuffle_files=True)\n",
        "nsynth_valid = tfds.load('nsynth/gansynth_subset', split='valid', shuffle_files=True)  # Assuming 'test' as validation\n",
        "nsynth_test = tfds.load('nsynth/gansynth_subset', split='test', shuffle_files=True)"
      ],
      "metadata": {
        "id": "0YHhgEaNiURO"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "save to google drive"
      ],
      "metadata": {
        "id": "VcCAgIjirvd8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# save_dataset(nsynth_train, os.path.join(dataset_save_path, 'nsynth_train'))\n",
        "# save_dataset(nsynth_valid, os.path.join(dataset_save_path, 'nsynth_valid'))\n",
        "# save_dataset(nsynth_test, os.path.join(dataset_save_path, 'nsynth_test'))\n",
        "# save_dataset(fuss_dataset, os.path.join(dataset_save_path, 'fuss_dataset'))"
      ],
      "metadata": {
        "id": "aMvdxaIfrzJ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocess the Data\n",
        "Convert audio files to spectrograms, normalize, and prepare binary labels. Here's a simplified preprocessing function:"
      ],
      "metadata": {
        "id": "ic-SKpCvifWP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def audio_to_spectrogram(audio_sample, sr=16000, n_fft=2048, hop_length=512):\n",
        "    \"\"\"Convert audio to spectrogram.\"\"\"\n",
        "    spectrogram = librosa.stft(audio_sample, n_fft=n_fft, hop_length=hop_length)\n",
        "    spectrogram_db = librosa.amplitude_to_db(abs(spectrogram))\n",
        "    return spectrogram_db\n"
      ],
      "metadata": {
        "id": "-UJaFkaJieqS"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "get 11 array for each instrument\n"
      ],
      "metadata": {
        "id": "WqP82Y_coX9Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dictionary to hold the spectrogram arrays for each instrument family\n",
        "x_train_dict = {}\n",
        "y_train_dict = {}\n",
        "\n",
        "# Loop through each family ID\n",
        "for family_id in range(11):\n",
        "\n",
        "    if family_id == 9:\n",
        "        continue\n",
        "\n",
        "    family_name = label_map.get(family_id, None)\n",
        "    if not family_name:\n",
        "        continue  # Skip if the family is not in the adjusted label_map\n",
        "\n",
        "    # Initialize arrays to hold data and labels for the current family\n",
        "    x_train_family = []\n",
        "    y_train_family = []\n",
        "\n",
        "\n",
        "    sample_counter = 0\n",
        "    # Iterate through the dataset to filter examples for the current family\n",
        "    # for example in nsynth_dataset.take(20000):\n",
        "    for example in nsynth_train:\n",
        "         # Initialize a counter for samples per family\n",
        "\n",
        "        if example['instrument']['family'].numpy() == family_id:\n",
        "            # Convert the audio sample to a spectrogram\n",
        "            spectrogram = audio_to_spectrogram(example['audio'].numpy())\n",
        "            x_train_family.append(spectrogram)\n",
        "\n",
        "            # Add a label indicating presence of the family's instrument\n",
        "            y_train_family.append(1)\n",
        "            # Increment the sample counter\n",
        "            sample_counter += 1\n",
        "            if sample_counter >= 1000:  # Break after collecting 500 samples\n",
        "                break\n",
        "\n",
        "    # Convert lists to numpy arrays and store them in the dictionaries\n",
        "    x_train_dict[family_name] = np.array(x_train_family)\n",
        "    y_train_dict[family_name] = np.array(y_train_family)\n",
        "\n",
        "# Now, x_train_dict and y_train_dict contain the training data and labels for each family\n",
        "# For example, to access the bass training data and labels:\n",
        "# x_train_bass = x_train_dict['bass']\n",
        "# y_train_bass = y_train_dict['bass']\n"
      ],
      "metadata": {
        "id": "cRGhNGbqoavY"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Augmenting Data: The function augment_with_negative_examples takes positive examples for the current family and combines them with a sampled set of negative examples from other families.\n",
        "Balancing Classes: It aims to balance the number of positive and negative examples. Adjust the sampling logic as necessary based on your dataset's specifics and desired class balance.\n",
        "Shuffling: It's crucial to shuffle the combined dataset to ensure the model doesn't learn the order of examples.\n",
        "Model Input Shape: Ensure the input shape for create_model is derived from the augmented dataset's shape."
      ],
      "metadata": {
        "id": "BxBOBKb3v-J4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming x_train_dict and y_train_dict are already populated with positive examples\n",
        "\n",
        "def augment_with_negative_examples(x_train, y_train, family_name, x_train_dict, sample_size):\n",
        "    # Gather negative samples from other families\n",
        "    x_negatives = []\n",
        "    for other_family in x_train_dict:\n",
        "        if other_family != family_name:\n",
        "            x_negatives.extend(x_train_dict[other_family][:sample_size])\n",
        "\n",
        "    # Create negative labels\n",
        "    y_negatives = [0] * len(x_negatives)\n",
        "\n",
        "    # Combine positive and negative examples\n",
        "    x_train_augmented = np.concatenate((x_train, np.array(x_negatives)), axis=0)\n",
        "    y_train_augmented = np.concatenate((y_train, y_negatives), axis=0)\n",
        "\n",
        "    # Shuffle the combined dataset to mix positive and negative examples\n",
        "    permutation = np.random.permutation(len(x_train_augmented))\n",
        "    x_train_augmented = x_train_augmented[permutation]\n",
        "    y_train_augmented = y_train_augmented[permutation]\n",
        "\n",
        "    return x_train_augmented, y_train_augmented\n"
      ],
      "metadata": {
        "id": "AhnnLejvv-kW"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train Each Classifier\n",
        "Loop through each instrument family, create a binary classification dataset, and train a model:"
      ],
      "metadata": {
        "id": "tC-VJjtlijUn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the base directory within Google Drive to save the models and metrics\n",
        "base_dir = '/content/drive/MyDrive/output/'\n",
        "\n",
        "models_dir = os.path.join(base_dir, 'models')\n",
        "metrics_dir = os.path.join(base_dir, 'metrics')\n",
        "\n",
        "# Create the directories if they do not exist\n",
        "os.makedirs(models_dir, exist_ok=True)\n",
        "os.makedirs(metrics_dir, exist_ok=True)\n",
        "\n",
        "\n",
        "import gc\n",
        "\n",
        "# Explicitly set TensorFlow to use dynamic GPU memory allocation\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "    except RuntimeError as e:\n",
        "        print(e)\n",
        "\n",
        "def clear_gpu_memory():\n",
        "    \"\"\"\n",
        "    Clear GPU memory by explicitly deleting models and objects and then\n",
        "    collecting garbage.\n",
        "    \"\"\"\n",
        "    # Attempt to clear session\n",
        "    clear_session()\n",
        "\n",
        "    # Manually collect garbage\n",
        "    gc.collect()\n",
        "\n",
        "    # If necessary, additional manual deletion of variables can be done here\n",
        "    # del model, x_train, y_train, etc.\n",
        "\n",
        "\n",
        "\n",
        "for family_id in range(11):\n",
        "\n",
        "    if family_id == 9:\n",
        "        continue\n",
        "\n",
        "    family_name = label_map[family_id]\n",
        "\n",
        "    x_train = x_train_dict[family_name]\n",
        "    y_train = y_train_dict[family_name]\n",
        "\n",
        "    # Determine sample size for negative examples\n",
        "    positive_sample_size = len(x_train)\n",
        "    x_train_augmented, y_train_augmented = augment_with_negative_examples(x_train, y_train, family_name, x_train_dict, positive_sample_size)\n",
        "\n",
        "    x_train_augmented = np.array([np.expand_dims(x, -1) for x in x_train_augmented])\n",
        "    model = create_model(input_shape=x_train_augmented[0].shape)\n",
        "    history = model.fit(x_train_augmented, y_train_augmented, validation_split=0.2, epochs=1000)\n",
        "\n",
        "    # Save model\n",
        "    # model.save(f'./models/family_{family_name}_classifier.h5')\n",
        "    # Save model to google drive\n",
        "    model_save_path = os.path.join(models_dir, f'family_{family_name}_classifier.h5')\n",
        "    model.save(model_save_path)\n",
        "\n",
        "    # Save training metrics\n",
        "    #with open(f'./metrics/{family_name}_train_loss.txt', 'w') as f_loss, \\\n",
        "    #     open(f'./metrics/{family_name}_train_acc.txt', 'w') as f_acc:\n",
        "    #    for loss, acc in zip(history.history['loss'], history.history['accuracy']):\n",
        "    #        f_loss.write(f\"{loss}\\n\")\n",
        "    #        f_acc.write(f\"{acc}\\n\")\n",
        "\n",
        "    # Save training metrics to google drive\n",
        "    loss_file_path = os.path.join(metrics_dir, f'{family_name}_train_loss.txt')\n",
        "    acc_file_path = os.path.join(metrics_dir, f'{family_name}_train_acc.txt')\n",
        "\n",
        "    with open(loss_file_path, 'w') as f_loss, open(acc_file_path, 'w') as f_acc:\n",
        "        for loss, acc in zip(history.history['loss'], history.history['accuracy']):\n",
        "          f_loss.write(f\"{loss}\\n\")\n",
        "          f_acc.write(f\"{acc}\\n\")\n",
        "\n",
        "    # Clear the current TensorFlow graph and create a new one\n",
        "    # Useful to ensure the GPU memory is freed\n",
        "    # Call clear_gpu_memory at the end of each loop iteration\n",
        "    clear_gpu_memory()\n",
        "\n",
        "    # Optionally, you can also manually set the TensorFlow device to CPU\n",
        "    # to ensure that GPU memory is completely cleared. This might not be necessary,\n",
        "    # but you can uncomment the following lines if you want to be extra sure.\n",
        "    # with tf.device('/cpu:0'):\n",
        "    #     model = create_model()\n",
        "    #     train_model(model)\n",
        "\n",
        "    # Define the directory within Google Drive to save the plots\n",
        "    plots_dir = os.path.join(base_dir, 'plots')\n",
        "\n",
        "    # Create the directory if it does not exist\n",
        "    os.makedirs(plots_dir, exist_ok=True)\n",
        "\n",
        "    # Generate and save the plots\n",
        "    fig, axs = plt.subplots(1, 2, figsize=(12, 4))\n",
        "    axs[0].plot(history.history['accuracy'], label='Accuracy')\n",
        "    axs[0].set_title(f'{family_name} Accuracy')\n",
        "    axs[0].set_xlabel('Epochs')\n",
        "    axs[0].set_ylabel('Accuracy')\n",
        "\n",
        "    axs[1].plot(history.history['loss'], label='Loss')\n",
        "    axs[1].set_title(f'{family_name} Loss')\n",
        "    axs[1].set_xlabel('Epochs')\n",
        "    axs[1].set_ylabel('Loss')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    # Important: plt.show() is moved after plt.savefig() to ensure the plot is saved before being displayed\n",
        "    plot_save_path = os.path.join(plots_dir, f'{family_name}_curve.png')\n",
        "    plt.savefig(plot_save_path)\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pRaxwG-GiqyR",
        "outputId": "2263836c-a2d0-42c6-81eb-4e73eecc4281"
      },
      "execution_count": 9,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Physical devices cannot be modified after being initialized\n",
            "Epoch 1/1000\n",
            "33/33 [==============================] - 11s 91ms/step - loss: 3.8289 - accuracy: 0.8760 - val_loss: 76.5137 - val_accuracy: 0.9198\n",
            "Epoch 2/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.2368 - accuracy: 0.8912 - val_loss: 15.1322 - val_accuracy: 0.9198\n",
            "Epoch 3/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.1709 - accuracy: 0.8931 - val_loss: 0.9397 - val_accuracy: 0.9198\n",
            "Epoch 4/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.1527 - accuracy: 0.9227 - val_loss: 0.1835 - val_accuracy: 0.9580\n",
            "Epoch 5/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.1132 - accuracy: 0.9513 - val_loss: 0.2059 - val_accuracy: 0.9618\n",
            "Epoch 6/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.1095 - accuracy: 0.9542 - val_loss: 0.0683 - val_accuracy: 0.9962\n",
            "Epoch 7/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.1363 - accuracy: 0.9332 - val_loss: 0.0619 - val_accuracy: 1.0000\n",
            "Epoch 8/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.1219 - accuracy: 0.9370 - val_loss: 0.0675 - val_accuracy: 0.9924\n",
            "Epoch 9/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.1084 - accuracy: 0.9552 - val_loss: 0.0636 - val_accuracy: 0.9733\n",
            "Epoch 10/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.1230 - accuracy: 0.9466 - val_loss: 0.0521 - val_accuracy: 1.0000\n",
            "Epoch 11/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.1088 - accuracy: 0.9571 - val_loss: 0.0642 - val_accuracy: 1.0000\n",
            "Epoch 12/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.1148 - accuracy: 0.9418 - val_loss: 0.0544 - val_accuracy: 1.0000\n",
            "Epoch 13/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.1148 - accuracy: 0.9494 - val_loss: 0.0533 - val_accuracy: 0.9962\n",
            "Epoch 14/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.1088 - accuracy: 0.9494 - val_loss: 0.0510 - val_accuracy: 1.0000\n",
            "Epoch 15/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.1067 - accuracy: 0.9494 - val_loss: 0.0502 - val_accuracy: 1.0000\n",
            "Epoch 16/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.1114 - accuracy: 0.9456 - val_loss: 0.0497 - val_accuracy: 1.0000\n",
            "Epoch 17/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0953 - accuracy: 0.9676 - val_loss: 0.0483 - val_accuracy: 1.0000\n",
            "Epoch 18/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.1208 - accuracy: 0.9561 - val_loss: 0.0502 - val_accuracy: 1.0000\n",
            "Epoch 19/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.1076 - accuracy: 0.9571 - val_loss: 0.0520 - val_accuracy: 0.9847\n",
            "Epoch 20/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.1129 - accuracy: 0.9447 - val_loss: 0.0881 - val_accuracy: 0.9656\n",
            "Epoch 21/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.1018 - accuracy: 0.9676 - val_loss: 0.0815 - val_accuracy: 0.9656\n",
            "Epoch 22/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.1321 - accuracy: 0.9609 - val_loss: 0.7096 - val_accuracy: 0.9542\n",
            "Epoch 23/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.1268 - accuracy: 0.9418 - val_loss: 64.7272 - val_accuracy: 0.9198\n",
            "Epoch 24/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.1912 - accuracy: 0.9590 - val_loss: 10.4161 - val_accuracy: 0.9198\n",
            "Epoch 25/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.2031 - accuracy: 0.9027 - val_loss: 0.1693 - val_accuracy: 0.9504\n",
            "Epoch 26/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.1363 - accuracy: 0.9151 - val_loss: 0.5095 - val_accuracy: 0.9580\n",
            "Epoch 27/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.1160 - accuracy: 0.9561 - val_loss: 0.0650 - val_accuracy: 0.9847\n",
            "Epoch 28/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.1143 - accuracy: 0.9418 - val_loss: 0.0649 - val_accuracy: 0.9771\n",
            "Epoch 29/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.1022 - accuracy: 0.9513 - val_loss: 0.0439 - val_accuracy: 1.0000\n",
            "Epoch 30/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0885 - accuracy: 0.9656 - val_loss: 0.0454 - val_accuracy: 1.0000\n",
            "Epoch 31/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0880 - accuracy: 0.9685 - val_loss: 0.0447 - val_accuracy: 1.0000\n",
            "Epoch 32/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0867 - accuracy: 0.9695 - val_loss: 0.0420 - val_accuracy: 1.0000\n",
            "Epoch 33/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0901 - accuracy: 0.9628 - val_loss: 0.0415 - val_accuracy: 1.0000\n",
            "Epoch 34/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0818 - accuracy: 0.9742 - val_loss: 0.0407 - val_accuracy: 1.0000\n",
            "Epoch 35/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0893 - accuracy: 0.9647 - val_loss: 0.0495 - val_accuracy: 0.9885\n",
            "Epoch 36/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.1053 - accuracy: 0.9637 - val_loss: 26.8199 - val_accuracy: 0.9237\n",
            "Epoch 37/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0849 - accuracy: 0.9676 - val_loss: 1.5160 - val_accuracy: 0.9618\n",
            "Epoch 38/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0885 - accuracy: 0.9647 - val_loss: 0.0545 - val_accuracy: 0.9885\n",
            "Epoch 39/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0808 - accuracy: 0.9733 - val_loss: 0.1734 - val_accuracy: 0.9771\n",
            "Epoch 40/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.1865 - accuracy: 0.9800 - val_loss: 0.0428 - val_accuracy: 0.9962\n",
            "Epoch 41/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0681 - accuracy: 0.9819 - val_loss: 0.0372 - val_accuracy: 1.0000\n",
            "Epoch 42/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0673 - accuracy: 0.9809 - val_loss: 0.0363 - val_accuracy: 1.0000\n",
            "Epoch 43/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0724 - accuracy: 0.9771 - val_loss: 0.0357 - val_accuracy: 1.0000\n",
            "Epoch 44/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0809 - accuracy: 0.9733 - val_loss: 0.0354 - val_accuracy: 1.0000\n",
            "Epoch 45/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0800 - accuracy: 0.9695 - val_loss: 0.0398 - val_accuracy: 0.9924\n",
            "Epoch 46/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.1510 - accuracy: 0.9609 - val_loss: 0.0356 - val_accuracy: 1.0000\n",
            "Epoch 47/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0802 - accuracy: 0.9704 - val_loss: 0.0342 - val_accuracy: 1.0000\n",
            "Epoch 48/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.1248 - accuracy: 0.9656 - val_loss: 0.3800 - val_accuracy: 0.9618\n",
            "Epoch 49/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0999 - accuracy: 0.9609 - val_loss: 0.0667 - val_accuracy: 0.9962\n",
            "Epoch 50/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.1097 - accuracy: 0.9637 - val_loss: 0.8259 - val_accuracy: 0.9962\n",
            "Epoch 51/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0878 - accuracy: 0.9714 - val_loss: 0.0317 - val_accuracy: 1.0000\n",
            "Epoch 52/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0858 - accuracy: 0.9723 - val_loss: 0.0417 - val_accuracy: 0.9924\n",
            "Epoch 53/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0757 - accuracy: 0.9704 - val_loss: 0.0309 - val_accuracy: 1.0000\n",
            "Epoch 54/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0684 - accuracy: 0.9714 - val_loss: 2.6134 - val_accuracy: 0.9427\n",
            "Epoch 55/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0751 - accuracy: 0.9695 - val_loss: 1.6263 - val_accuracy: 0.9733\n",
            "Epoch 56/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0829 - accuracy: 0.9666 - val_loss: 0.3424 - val_accuracy: 0.9924\n",
            "Epoch 57/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0667 - accuracy: 0.9790 - val_loss: 0.1517 - val_accuracy: 0.9885\n",
            "Epoch 58/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.1230 - accuracy: 0.9609 - val_loss: 0.0300 - val_accuracy: 1.0000\n",
            "Epoch 59/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0633 - accuracy: 0.9800 - val_loss: 0.0345 - val_accuracy: 0.9962\n",
            "Epoch 60/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0652 - accuracy: 0.9790 - val_loss: 0.0298 - val_accuracy: 1.0000\n",
            "Epoch 61/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0856 - accuracy: 0.9656 - val_loss: 0.1127 - val_accuracy: 0.9504\n",
            "Epoch 62/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0963 - accuracy: 0.9628 - val_loss: 0.0508 - val_accuracy: 0.9847\n",
            "Epoch 63/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0756 - accuracy: 0.9685 - val_loss: 0.0342 - val_accuracy: 0.9924\n",
            "Epoch 64/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0798 - accuracy: 0.9733 - val_loss: 0.0543 - val_accuracy: 0.9924\n",
            "Epoch 65/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0889 - accuracy: 0.9761 - val_loss: 0.1006 - val_accuracy: 0.9733\n",
            "Epoch 66/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0745 - accuracy: 0.9695 - val_loss: 0.0868 - val_accuracy: 0.9924\n",
            "Epoch 67/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0622 - accuracy: 0.9771 - val_loss: 44.9446 - val_accuracy: 0.9198\n",
            "Epoch 68/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0643 - accuracy: 0.9723 - val_loss: 0.0161 - val_accuracy: 0.9924\n",
            "Epoch 69/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0775 - accuracy: 0.9742 - val_loss: 0.0582 - val_accuracy: 0.9924\n",
            "Epoch 70/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.1106 - accuracy: 0.9809 - val_loss: 6.4528 - val_accuracy: 0.9427\n",
            "Epoch 71/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.1729 - accuracy: 0.9800 - val_loss: 0.5651 - val_accuracy: 0.9924\n",
            "Epoch 72/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0670 - accuracy: 0.9809 - val_loss: 0.0158 - val_accuracy: 1.0000\n",
            "Epoch 73/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0507 - accuracy: 0.9809 - val_loss: 0.0256 - val_accuracy: 0.9962\n",
            "Epoch 74/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0564 - accuracy: 0.9819 - val_loss: 0.0175 - val_accuracy: 1.0000\n",
            "Epoch 75/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0361 - accuracy: 0.9905 - val_loss: 0.0135 - val_accuracy: 1.0000\n",
            "Epoch 76/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0573 - accuracy: 0.9895 - val_loss: 0.0230 - val_accuracy: 1.0000\n",
            "Epoch 77/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0947 - accuracy: 0.9790 - val_loss: 71.9455 - val_accuracy: 0.9198\n",
            "Epoch 78/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0863 - accuracy: 0.9733 - val_loss: 2.0230 - val_accuracy: 0.9618\n",
            "Epoch 79/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0840 - accuracy: 0.9637 - val_loss: 0.0409 - val_accuracy: 0.9847\n",
            "Epoch 80/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0672 - accuracy: 0.9752 - val_loss: 0.0221 - val_accuracy: 1.0000\n",
            "Epoch 81/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0816 - accuracy: 0.9800 - val_loss: 0.0303 - val_accuracy: 0.9924\n",
            "Epoch 82/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0857 - accuracy: 0.9781 - val_loss: 0.0240 - val_accuracy: 1.0000\n",
            "Epoch 83/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0557 - accuracy: 0.9790 - val_loss: 0.0164 - val_accuracy: 1.0000\n",
            "Epoch 84/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0501 - accuracy: 0.9790 - val_loss: 0.0079 - val_accuracy: 1.0000\n",
            "Epoch 85/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0514 - accuracy: 0.9809 - val_loss: 0.0134 - val_accuracy: 1.0000\n",
            "Epoch 86/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0497 - accuracy: 0.9781 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 87/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0514 - accuracy: 0.9847 - val_loss: 0.0220 - val_accuracy: 0.9885\n",
            "Epoch 88/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0375 - accuracy: 0.9847 - val_loss: 3.7691e-04 - val_accuracy: 1.0000\n",
            "Epoch 89/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0370 - accuracy: 0.9847 - val_loss: 2.5024e-07 - val_accuracy: 1.0000\n",
            "Epoch 90/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0394 - accuracy: 0.9847 - val_loss: 1.8499e-04 - val_accuracy: 1.0000\n",
            "Epoch 91/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0349 - accuracy: 0.9895 - val_loss: 9.1858e-05 - val_accuracy: 1.0000\n",
            "Epoch 92/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.1949 - accuracy: 0.9733 - val_loss: 0.0136 - val_accuracy: 0.9962\n",
            "Epoch 93/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0552 - accuracy: 0.9819 - val_loss: 0.0103 - val_accuracy: 1.0000\n",
            "Epoch 94/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.1757 - accuracy: 0.9752 - val_loss: 6.5629e-04 - val_accuracy: 1.0000\n",
            "Epoch 95/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0558 - accuracy: 0.9838 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
            "Epoch 96/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0476 - accuracy: 0.9838 - val_loss: 4.8175e-04 - val_accuracy: 1.0000\n",
            "Epoch 97/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0422 - accuracy: 0.9819 - val_loss: 8.2939e-04 - val_accuracy: 1.0000\n",
            "Epoch 98/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0543 - accuracy: 0.9838 - val_loss: 0.0168 - val_accuracy: 1.0000\n",
            "Epoch 99/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0420 - accuracy: 0.9876 - val_loss: 0.0120 - val_accuracy: 1.0000\n",
            "Epoch 100/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0468 - accuracy: 0.9857 - val_loss: 5.1588e-06 - val_accuracy: 1.0000\n",
            "Epoch 101/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0860 - accuracy: 0.9752 - val_loss: 0.0215 - val_accuracy: 0.9924\n",
            "Epoch 102/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0507 - accuracy: 0.9781 - val_loss: 0.0068 - val_accuracy: 0.9962\n",
            "Epoch 103/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0442 - accuracy: 0.9819 - val_loss: 0.4812 - val_accuracy: 0.9847\n",
            "Epoch 104/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0397 - accuracy: 0.9895 - val_loss: 0.0150 - val_accuracy: 1.0000\n",
            "Epoch 105/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0476 - accuracy: 0.9828 - val_loss: 0.0086 - val_accuracy: 1.0000\n",
            "Epoch 106/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0331 - accuracy: 0.9895 - val_loss: 6.3650e-05 - val_accuracy: 1.0000\n",
            "Epoch 107/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0354 - accuracy: 0.9876 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 108/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0486 - accuracy: 0.9857 - val_loss: 0.0133 - val_accuracy: 1.0000\n",
            "Epoch 109/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0415 - accuracy: 0.9847 - val_loss: 0.0123 - val_accuracy: 1.0000\n",
            "Epoch 110/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0408 - accuracy: 0.9857 - val_loss: 0.0118 - val_accuracy: 1.0000\n",
            "Epoch 111/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0365 - accuracy: 0.9895 - val_loss: 0.0084 - val_accuracy: 1.0000\n",
            "Epoch 112/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0262 - accuracy: 0.9933 - val_loss: 0.0080 - val_accuracy: 1.0000\n",
            "Epoch 113/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0290 - accuracy: 0.9905 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
            "Epoch 114/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0360 - accuracy: 0.9866 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
            "Epoch 115/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0269 - accuracy: 0.9905 - val_loss: 6.2840e-05 - val_accuracy: 1.0000\n",
            "Epoch 116/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0306 - accuracy: 0.9885 - val_loss: 6.5210e-06 - val_accuracy: 1.0000\n",
            "Epoch 117/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0244 - accuracy: 0.9943 - val_loss: 4.6446e-06 - val_accuracy: 1.0000\n",
            "Epoch 118/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0204 - accuracy: 0.9962 - val_loss: 5.5863e-06 - val_accuracy: 1.0000\n",
            "Epoch 119/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0183 - accuracy: 0.9962 - val_loss: 6.0847e-06 - val_accuracy: 1.0000\n",
            "Epoch 120/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0252 - accuracy: 0.9933 - val_loss: 6.4659e-06 - val_accuracy: 1.0000\n",
            "Epoch 121/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0293 - accuracy: 0.9905 - val_loss: 7.6036e-06 - val_accuracy: 1.0000\n",
            "Epoch 122/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0296 - accuracy: 0.9895 - val_loss: 7.9833e-06 - val_accuracy: 1.0000\n",
            "Epoch 123/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0227 - accuracy: 0.9924 - val_loss: 8.2404e-06 - val_accuracy: 1.0000\n",
            "Epoch 124/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0240 - accuracy: 0.9933 - val_loss: 6.4416e-06 - val_accuracy: 1.0000\n",
            "Epoch 125/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0247 - accuracy: 0.9924 - val_loss: 6.4873e-06 - val_accuracy: 1.0000\n",
            "Epoch 126/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0234 - accuracy: 0.9914 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 127/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0261 - accuracy: 0.9914 - val_loss: 8.0011e-05 - val_accuracy: 1.0000\n",
            "Epoch 128/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0180 - accuracy: 0.9962 - val_loss: 2.2829e-04 - val_accuracy: 1.0000\n",
            "Epoch 129/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0217 - accuracy: 0.9933 - val_loss: 3.1683e-06 - val_accuracy: 1.0000\n",
            "Epoch 130/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0213 - accuracy: 0.9943 - val_loss: 2.1954e-06 - val_accuracy: 1.0000\n",
            "Epoch 131/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0212 - accuracy: 0.9952 - val_loss: 1.7574e-06 - val_accuracy: 1.0000\n",
            "Epoch 132/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0217 - accuracy: 0.9943 - val_loss: 1.4227e-06 - val_accuracy: 1.0000\n",
            "Epoch 133/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0314 - accuracy: 0.9905 - val_loss: 0.0085 - val_accuracy: 0.9962\n",
            "Epoch 134/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0245 - accuracy: 0.9914 - val_loss: 3.4678e-08 - val_accuracy: 1.0000\n",
            "Epoch 135/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0183 - accuracy: 0.9962 - val_loss: 7.0589e-08 - val_accuracy: 1.0000\n",
            "Epoch 136/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0204 - accuracy: 0.9952 - val_loss: 1.2176e-07 - val_accuracy: 1.0000\n",
            "Epoch 137/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0165 - accuracy: 0.9971 - val_loss: 1.8903e-07 - val_accuracy: 1.0000\n",
            "Epoch 138/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0132 - accuracy: 0.9990 - val_loss: 2.3270e-07 - val_accuracy: 1.0000\n",
            "Epoch 139/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0280 - accuracy: 0.9905 - val_loss: 2.1350e-07 - val_accuracy: 1.0000\n",
            "Epoch 140/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0207 - accuracy: 0.9943 - val_loss: 1.8801e-07 - val_accuracy: 1.0000\n",
            "Epoch 141/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0254 - accuracy: 0.9924 - val_loss: 1.4260 - val_accuracy: 0.9542\n",
            "Epoch 142/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.2764 - accuracy: 0.9857 - val_loss: 14.4236 - val_accuracy: 0.9389\n",
            "Epoch 143/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0326 - accuracy: 0.9924 - val_loss: 0.0143 - val_accuracy: 1.0000\n",
            "Epoch 144/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0300 - accuracy: 0.9933 - val_loss: 0.0113 - val_accuracy: 1.0000\n",
            "Epoch 145/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0234 - accuracy: 0.9962 - val_loss: 0.0107 - val_accuracy: 1.0000\n",
            "Epoch 146/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0210 - accuracy: 0.9971 - val_loss: 0.0096 - val_accuracy: 1.0000\n",
            "Epoch 147/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0298 - accuracy: 0.9905 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
            "Epoch 148/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0276 - accuracy: 0.9905 - val_loss: 6.3538e-04 - val_accuracy: 1.0000\n",
            "Epoch 149/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0214 - accuracy: 0.9933 - val_loss: 0.2922 - val_accuracy: 0.9771\n",
            "Epoch 150/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0364 - accuracy: 0.9924 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
            "Epoch 151/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0486 - accuracy: 0.9885 - val_loss: 2.6405e-05 - val_accuracy: 1.0000\n",
            "Epoch 152/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0411 - accuracy: 0.9924 - val_loss: 2.7862e-05 - val_accuracy: 1.0000\n",
            "Epoch 153/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0244 - accuracy: 0.9924 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
            "Epoch 154/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0262 - accuracy: 0.9924 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
            "Epoch 155/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0343 - accuracy: 0.9885 - val_loss: 0.0089 - val_accuracy: 1.0000\n",
            "Epoch 156/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0396 - accuracy: 0.9828 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 157/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0297 - accuracy: 0.9885 - val_loss: 8.7868e-04 - val_accuracy: 1.0000\n",
            "Epoch 158/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0162 - accuracy: 0.9962 - val_loss: 5.9890e-04 - val_accuracy: 1.0000\n",
            "Epoch 159/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0188 - accuracy: 0.9943 - val_loss: 1.6461e-04 - val_accuracy: 1.0000\n",
            "Epoch 160/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0195 - accuracy: 0.9943 - val_loss: 1.2391e-04 - val_accuracy: 1.0000\n",
            "Epoch 161/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0187 - accuracy: 0.9952 - val_loss: 1.9248e-04 - val_accuracy: 1.0000\n",
            "Epoch 162/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0201 - accuracy: 0.9943 - val_loss: 0.0061 - val_accuracy: 0.9962\n",
            "Epoch 163/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0157 - accuracy: 0.9971 - val_loss: 0.0085 - val_accuracy: 0.9962\n",
            "Epoch 164/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0229 - accuracy: 0.9933 - val_loss: 3.2013e-04 - val_accuracy: 1.0000\n",
            "Epoch 165/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0190 - accuracy: 0.9952 - val_loss: 4.7914e-06 - val_accuracy: 1.0000\n",
            "Epoch 166/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0355 - accuracy: 0.9943 - val_loss: 3.6561e-05 - val_accuracy: 1.0000\n",
            "Epoch 167/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0267 - accuracy: 0.9914 - val_loss: 1.5079e-04 - val_accuracy: 1.0000\n",
            "Epoch 168/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0373 - accuracy: 0.9885 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 169/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0232 - accuracy: 0.9952 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
            "Epoch 170/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0382 - accuracy: 0.9895 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
            "Epoch 171/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0267 - accuracy: 0.9914 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 172/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0225 - accuracy: 0.9943 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 173/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0253 - accuracy: 0.9914 - val_loss: 9.2132e-04 - val_accuracy: 1.0000\n",
            "Epoch 174/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0203 - accuracy: 0.9933 - val_loss: 6.8439e-05 - val_accuracy: 1.0000\n",
            "Epoch 175/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0168 - accuracy: 0.9952 - val_loss: 3.4008e-05 - val_accuracy: 1.0000\n",
            "Epoch 176/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0167 - accuracy: 0.9952 - val_loss: 3.4364e-04 - val_accuracy: 1.0000\n",
            "Epoch 177/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0230 - accuracy: 0.9924 - val_loss: 1.6470e-04 - val_accuracy: 1.0000\n",
            "Epoch 178/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0222 - accuracy: 0.9962 - val_loss: 0.0124 - val_accuracy: 0.9962\n",
            "Epoch 179/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0290 - accuracy: 0.9952 - val_loss: 0.0066 - val_accuracy: 0.9962\n",
            "Epoch 180/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0157 - accuracy: 0.9952 - val_loss: 6.7522e-05 - val_accuracy: 1.0000\n",
            "Epoch 181/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0396 - accuracy: 0.9914 - val_loss: 2.6344e-06 - val_accuracy: 1.0000\n",
            "Epoch 182/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0380 - accuracy: 0.9952 - val_loss: 0.0101 - val_accuracy: 0.9962\n",
            "Epoch 183/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0176 - accuracy: 0.9952 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
            "Epoch 184/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0242 - accuracy: 0.9933 - val_loss: 0.0057 - val_accuracy: 0.9962\n",
            "Epoch 185/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0262 - accuracy: 0.9905 - val_loss: 0.0132 - val_accuracy: 0.9924\n",
            "Epoch 186/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0277 - accuracy: 0.9914 - val_loss: 0.1369 - val_accuracy: 0.9733\n",
            "Epoch 187/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0387 - accuracy: 0.9924 - val_loss: 0.0482 - val_accuracy: 0.9885\n",
            "Epoch 188/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0970 - accuracy: 0.9876 - val_loss: 9.1282e-04 - val_accuracy: 1.0000\n",
            "Epoch 189/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.1658 - accuracy: 0.9895 - val_loss: 4.0233 - val_accuracy: 0.9427\n",
            "Epoch 190/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.7674 - accuracy: 0.9733 - val_loss: 772.4193 - val_accuracy: 0.9198\n",
            "Epoch 191/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.4598 - accuracy: 0.9523 - val_loss: 34.4867 - val_accuracy: 0.9198\n",
            "Epoch 192/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0401 - accuracy: 0.9828 - val_loss: 3.9208 - val_accuracy: 0.9618\n",
            "Epoch 193/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0651 - accuracy: 0.9866 - val_loss: 1.1999 - val_accuracy: 0.9733\n",
            "Epoch 194/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.2066 - accuracy: 0.9838 - val_loss: 3.0246 - val_accuracy: 0.9618\n",
            "Epoch 195/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0604 - accuracy: 0.9809 - val_loss: 0.0167 - val_accuracy: 0.9962\n",
            "Epoch 196/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0858 - accuracy: 0.9723 - val_loss: 0.0151 - val_accuracy: 0.9962\n",
            "Epoch 197/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0801 - accuracy: 0.9733 - val_loss: 0.0075 - val_accuracy: 1.0000\n",
            "Epoch 198/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0866 - accuracy: 0.9809 - val_loss: 0.0069 - val_accuracy: 1.0000\n",
            "Epoch 199/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0470 - accuracy: 0.9809 - val_loss: 0.0123 - val_accuracy: 0.9962\n",
            "Epoch 200/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0418 - accuracy: 0.9828 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
            "Epoch 201/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0499 - accuracy: 0.9800 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 202/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0319 - accuracy: 0.9876 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "Epoch 203/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0249 - accuracy: 0.9914 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
            "Epoch 204/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0200 - accuracy: 0.9952 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
            "Epoch 205/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0243 - accuracy: 0.9914 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 206/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0227 - accuracy: 0.9924 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 207/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0310 - accuracy: 0.9895 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 208/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0219 - accuracy: 0.9933 - val_loss: 4.5544e-06 - val_accuracy: 1.0000\n",
            "Epoch 209/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0253 - accuracy: 0.9914 - val_loss: 1.0568e-08 - val_accuracy: 1.0000\n",
            "Epoch 210/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0303 - accuracy: 0.9943 - val_loss: 5.2433e-11 - val_accuracy: 1.0000\n",
            "Epoch 211/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.1161 - accuracy: 0.9895 - val_loss: 5.0438e-11 - val_accuracy: 1.0000\n",
            "Epoch 212/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0728 - accuracy: 0.9885 - val_loss: 0.0052 - val_accuracy: 1.0000\n",
            "Epoch 213/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0295 - accuracy: 0.9905 - val_loss: 0.0062 - val_accuracy: 1.0000\n",
            "Epoch 214/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0340 - accuracy: 0.9876 - val_loss: 0.0062 - val_accuracy: 1.0000\n",
            "Epoch 215/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0269 - accuracy: 0.9924 - val_loss: 0.0062 - val_accuracy: 1.0000\n",
            "Epoch 216/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0230 - accuracy: 0.9933 - val_loss: 0.0055 - val_accuracy: 1.0000\n",
            "Epoch 217/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0287 - accuracy: 0.9905 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
            "Epoch 218/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0213 - accuracy: 0.9943 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
            "Epoch 219/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0356 - accuracy: 0.9905 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
            "Epoch 220/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0248 - accuracy: 0.9914 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 221/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0231 - accuracy: 0.9924 - val_loss: 4.6442e-04 - val_accuracy: 1.0000\n",
            "Epoch 222/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0260 - accuracy: 0.9914 - val_loss: 4.2655e-05 - val_accuracy: 1.0000\n",
            "Epoch 223/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0243 - accuracy: 0.9924 - val_loss: 9.3217e-05 - val_accuracy: 1.0000\n",
            "Epoch 224/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0190 - accuracy: 0.9952 - val_loss: 1.2649e-04 - val_accuracy: 1.0000\n",
            "Epoch 225/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0217 - accuracy: 0.9952 - val_loss: 2.2786e-05 - val_accuracy: 1.0000\n",
            "Epoch 226/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0216 - accuracy: 0.9933 - val_loss: 5.6164e-06 - val_accuracy: 1.0000\n",
            "Epoch 227/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0319 - accuracy: 0.9885 - val_loss: 9.2428e-05 - val_accuracy: 1.0000\n",
            "Epoch 228/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0512 - accuracy: 0.9781 - val_loss: 8.0884e-05 - val_accuracy: 1.0000\n",
            "Epoch 229/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0398 - accuracy: 0.9838 - val_loss: 1.9346e-08 - val_accuracy: 1.0000\n",
            "Epoch 230/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0262 - accuracy: 0.9914 - val_loss: 4.5715e-08 - val_accuracy: 1.0000\n",
            "Epoch 231/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0247 - accuracy: 0.9924 - val_loss: 2.5831e-07 - val_accuracy: 1.0000\n",
            "Epoch 232/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0414 - accuracy: 0.9828 - val_loss: 2.8239e-07 - val_accuracy: 1.0000\n",
            "Epoch 233/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0216 - accuracy: 0.9933 - val_loss: 3.8660e-08 - val_accuracy: 1.0000\n",
            "Epoch 234/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0260 - accuracy: 0.9914 - val_loss: 1.0286e-08 - val_accuracy: 1.0000\n",
            "Epoch 235/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0506 - accuracy: 0.9914 - val_loss: 7.1477e-08 - val_accuracy: 1.0000\n",
            "Epoch 236/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0205 - accuracy: 0.9943 - val_loss: 1.3646e-07 - val_accuracy: 1.0000\n",
            "Epoch 237/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0240 - accuracy: 0.9924 - val_loss: 2.6208e-07 - val_accuracy: 1.0000\n",
            "Epoch 238/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0284 - accuracy: 0.9905 - val_loss: 2.6097e-07 - val_accuracy: 1.0000\n",
            "Epoch 239/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0207 - accuracy: 0.9933 - val_loss: 2.5998e-07 - val_accuracy: 1.0000\n",
            "Epoch 240/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0175 - accuracy: 0.9952 - val_loss: 2.4832e-07 - val_accuracy: 1.0000\n",
            "Epoch 241/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.1000 - accuracy: 0.9914 - val_loss: 1.0520e-09 - val_accuracy: 1.0000\n",
            "Epoch 242/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0479 - accuracy: 0.9933 - val_loss: 0.0122 - val_accuracy: 1.0000\n",
            "Epoch 243/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0275 - accuracy: 0.9943 - val_loss: 0.0120 - val_accuracy: 1.0000\n",
            "Epoch 244/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0276 - accuracy: 0.9943 - val_loss: 0.0118 - val_accuracy: 1.0000\n",
            "Epoch 245/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0314 - accuracy: 0.9924 - val_loss: 0.0115 - val_accuracy: 1.0000\n",
            "Epoch 246/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0398 - accuracy: 0.9943 - val_loss: 0.0113 - val_accuracy: 1.0000\n",
            "Epoch 247/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0256 - accuracy: 0.9943 - val_loss: 0.0082 - val_accuracy: 1.0000\n",
            "Epoch 248/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0301 - accuracy: 0.9905 - val_loss: 0.0065 - val_accuracy: 1.0000\n",
            "Epoch 249/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0148 - accuracy: 0.9981 - val_loss: 0.0063 - val_accuracy: 1.0000\n",
            "Epoch 250/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0189 - accuracy: 0.9962 - val_loss: 0.0130 - val_accuracy: 0.9962\n",
            "Epoch 251/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0235 - accuracy: 0.9943 - val_loss: 0.0061 - val_accuracy: 1.0000\n",
            "Epoch 252/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0166 - accuracy: 0.9971 - val_loss: 0.0060 - val_accuracy: 1.0000\n",
            "Epoch 253/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0311 - accuracy: 0.9943 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
            "Epoch 254/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.1406 - accuracy: 0.9847 - val_loss: 0.0067 - val_accuracy: 1.0000\n",
            "Epoch 255/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0382 - accuracy: 0.9866 - val_loss: 0.0065 - val_accuracy: 1.0000\n",
            "Epoch 256/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0314 - accuracy: 0.9905 - val_loss: 0.0065 - val_accuracy: 1.0000\n",
            "Epoch 257/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0229 - accuracy: 0.9943 - val_loss: 0.0065 - val_accuracy: 1.0000\n",
            "Epoch 258/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0328 - accuracy: 0.9895 - val_loss: 0.0065 - val_accuracy: 1.0000\n",
            "Epoch 259/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0212 - accuracy: 0.9952 - val_loss: 0.0060 - val_accuracy: 1.0000\n",
            "Epoch 260/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0360 - accuracy: 0.9876 - val_loss: 0.0059 - val_accuracy: 1.0000\n",
            "Epoch 261/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0305 - accuracy: 0.9914 - val_loss: 0.0059 - val_accuracy: 1.0000\n",
            "Epoch 262/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0225 - accuracy: 0.9933 - val_loss: 0.0054 - val_accuracy: 1.0000\n",
            "Epoch 263/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0288 - accuracy: 0.9924 - val_loss: 0.0050 - val_accuracy: 1.0000\n",
            "Epoch 264/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0358 - accuracy: 0.9866 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
            "Epoch 265/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0241 - accuracy: 0.9924 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
            "Epoch 266/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0214 - accuracy: 0.9943 - val_loss: 0.2443 - val_accuracy: 0.9771\n",
            "Epoch 267/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0249 - accuracy: 0.9914 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
            "Epoch 268/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0147 - accuracy: 0.9971 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
            "Epoch 269/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0131 - accuracy: 0.9981 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
            "Epoch 270/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0133 - accuracy: 0.9971 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
            "Epoch 271/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0151 - accuracy: 0.9962 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
            "Epoch 272/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
            "Epoch 273/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0118 - accuracy: 0.9981 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
            "Epoch 274/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0155 - accuracy: 0.9962 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
            "Epoch 275/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0388 - accuracy: 0.9933 - val_loss: 0.0047 - val_accuracy: 0.9962\n",
            "Epoch 276/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0189 - accuracy: 0.9952 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
            "Epoch 277/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0185 - accuracy: 0.9943 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
            "Epoch 278/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0229 - accuracy: 0.9943 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 279/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0134 - accuracy: 0.9971 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 280/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0101 - accuracy: 0.9981 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 281/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0214 - accuracy: 0.9933 - val_loss: 7.6829e-04 - val_accuracy: 1.0000\n",
            "Epoch 282/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0230 - accuracy: 0.9924 - val_loss: 6.0051e-04 - val_accuracy: 1.0000\n",
            "Epoch 283/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0126 - accuracy: 0.9971 - val_loss: 4.5287e-04 - val_accuracy: 1.0000\n",
            "Epoch 284/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0138 - accuracy: 0.9962 - val_loss: 4.2935e-04 - val_accuracy: 1.0000\n",
            "Epoch 285/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0124 - accuracy: 0.9971 - val_loss: 4.7014e-04 - val_accuracy: 1.0000\n",
            "Epoch 286/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0225 - accuracy: 0.9962 - val_loss: 5.2558e-04 - val_accuracy: 1.0000\n",
            "Epoch 287/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0121 - accuracy: 0.9971 - val_loss: 4.2959e-04 - val_accuracy: 1.0000\n",
            "Epoch 288/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0128 - accuracy: 0.9971 - val_loss: 4.2845e-04 - val_accuracy: 1.0000\n",
            "Epoch 289/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0164 - accuracy: 0.9952 - val_loss: 4.4095e-04 - val_accuracy: 1.0000\n",
            "Epoch 290/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0154 - accuracy: 0.9962 - val_loss: 4.7925e-04 - val_accuracy: 1.0000\n",
            "Epoch 291/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0102 - accuracy: 0.9981 - val_loss: 5.1617e-04 - val_accuracy: 1.0000\n",
            "Epoch 292/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0179 - accuracy: 0.9952 - val_loss: 5.3402e-04 - val_accuracy: 1.0000\n",
            "Epoch 293/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0147 - accuracy: 0.9962 - val_loss: 8.9077e-04 - val_accuracy: 1.0000\n",
            "Epoch 294/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0146 - accuracy: 0.9962 - val_loss: 5.2910e-04 - val_accuracy: 1.0000\n",
            "Epoch 295/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0144 - accuracy: 0.9962 - val_loss: 4.6916e-04 - val_accuracy: 1.0000\n",
            "Epoch 296/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0153 - accuracy: 0.9962 - val_loss: 4.8441e-04 - val_accuracy: 1.0000\n",
            "Epoch 297/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0125 - accuracy: 0.9971 - val_loss: 6.8476e-04 - val_accuracy: 1.0000\n",
            "Epoch 298/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0148 - accuracy: 0.9962 - val_loss: 5.8800e-04 - val_accuracy: 1.0000\n",
            "Epoch 299/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 5.6913e-04 - val_accuracy: 1.0000\n",
            "Epoch 300/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0100 - accuracy: 0.9981 - val_loss: 4.8645e-04 - val_accuracy: 1.0000\n",
            "Epoch 301/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0113 - accuracy: 0.9971 - val_loss: 4.5757e-04 - val_accuracy: 1.0000\n",
            "Epoch 302/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0101 - accuracy: 0.9981 - val_loss: 1.6156e-04 - val_accuracy: 1.0000\n",
            "Epoch 303/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0124 - accuracy: 0.9971 - val_loss: 9.8395e-05 - val_accuracy: 1.0000\n",
            "Epoch 304/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0080 - accuracy: 0.9990 - val_loss: 3.5453e-05 - val_accuracy: 1.0000\n",
            "Epoch 305/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0102 - accuracy: 0.9981 - val_loss: 6.7689e-06 - val_accuracy: 1.0000\n",
            "Epoch 306/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 4.1207e-07 - val_accuracy: 1.0000\n",
            "Epoch 307/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 3.2689e-07 - val_accuracy: 1.0000\n",
            "Epoch 308/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0511 - accuracy: 0.9971 - val_loss: 0.5277 - val_accuracy: 0.9924\n",
            "Epoch 309/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0213 - accuracy: 0.9981 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 310/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0152 - accuracy: 0.9962 - val_loss: 7.0527e-04 - val_accuracy: 1.0000\n",
            "Epoch 311/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0112 - accuracy: 0.9971 - val_loss: 6.9485e-04 - val_accuracy: 1.0000\n",
            "Epoch 312/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0123 - accuracy: 0.9971 - val_loss: 4.2327e-04 - val_accuracy: 1.0000\n",
            "Epoch 313/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0103 - accuracy: 0.9981 - val_loss: 6.7742e-04 - val_accuracy: 1.0000\n",
            "Epoch 314/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0079 - accuracy: 0.9990 - val_loss: 6.7121e-04 - val_accuracy: 1.0000\n",
            "Epoch 315/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0115 - accuracy: 0.9971 - val_loss: 6.6692e-04 - val_accuracy: 1.0000\n",
            "Epoch 316/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0078 - accuracy: 0.9990 - val_loss: 6.6045e-04 - val_accuracy: 1.0000\n",
            "Epoch 317/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0090 - accuracy: 0.9981 - val_loss: 6.5637e-04 - val_accuracy: 1.0000\n",
            "Epoch 318/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0093 - accuracy: 0.9981 - val_loss: 3.2726e-04 - val_accuracy: 1.0000\n",
            "Epoch 319/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0068 - accuracy: 0.9990 - val_loss: 3.2798e-04 - val_accuracy: 1.0000\n",
            "Epoch 320/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0094 - accuracy: 0.9981 - val_loss: 3.2233e-04 - val_accuracy: 1.0000\n",
            "Epoch 321/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 3.1822e-04 - val_accuracy: 1.0000\n",
            "Epoch 322/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 3.1503e-04 - val_accuracy: 1.0000\n",
            "Epoch 323/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0081 - accuracy: 0.9981 - val_loss: 3.1228e-04 - val_accuracy: 1.0000\n",
            "Epoch 324/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0057 - accuracy: 0.9990 - val_loss: 2.0285e-04 - val_accuracy: 1.0000\n",
            "Epoch 325/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0423 - accuracy: 0.9962 - val_loss: 5.7542e-10 - val_accuracy: 1.0000\n",
            "Epoch 326/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.1538 - accuracy: 0.9905 - val_loss: 0.0116 - val_accuracy: 0.9962\n",
            "Epoch 327/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0403 - accuracy: 0.9933 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 328/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0172 - accuracy: 0.9952 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 329/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0212 - accuracy: 0.9933 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 330/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0122 - accuracy: 0.9971 - val_loss: 8.4105e-04 - val_accuracy: 1.0000\n",
            "Epoch 331/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0094 - accuracy: 0.9981 - val_loss: 8.0146e-04 - val_accuracy: 1.0000\n",
            "Epoch 332/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0197 - accuracy: 0.9952 - val_loss: 8.0690e-04 - val_accuracy: 1.0000\n",
            "Epoch 333/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0172 - accuracy: 0.9952 - val_loss: 6.9371e-04 - val_accuracy: 1.0000\n",
            "Epoch 334/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0152 - accuracy: 0.9962 - val_loss: 5.2161e-04 - val_accuracy: 1.0000\n",
            "Epoch 335/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0129 - accuracy: 0.9962 - val_loss: 9.6260e-04 - val_accuracy: 1.0000\n",
            "Epoch 336/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0074 - accuracy: 0.9990 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 337/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0069 - accuracy: 0.9990 - val_loss: 9.5021e-04 - val_accuracy: 1.0000\n",
            "Epoch 338/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0121 - accuracy: 0.9971 - val_loss: 7.5010e-04 - val_accuracy: 1.0000\n",
            "Epoch 339/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0175 - accuracy: 0.9952 - val_loss: 4.4322e-04 - val_accuracy: 1.0000\n",
            "Epoch 340/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0128 - accuracy: 0.9962 - val_loss: 0.0037 - val_accuracy: 0.9962\n",
            "Epoch 341/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0142 - accuracy: 0.9952 - val_loss: 2.9700e-04 - val_accuracy: 1.0000\n",
            "Epoch 342/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0074 - accuracy: 0.9990 - val_loss: 1.5188e-04 - val_accuracy: 1.0000\n",
            "Epoch 343/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0092 - accuracy: 0.9981 - val_loss: 9.1814e-05 - val_accuracy: 1.0000\n",
            "Epoch 344/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0152 - accuracy: 0.9952 - val_loss: 3.3431e-05 - val_accuracy: 1.0000\n",
            "Epoch 345/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0218 - accuracy: 0.9933 - val_loss: 2.8871e-05 - val_accuracy: 1.0000\n",
            "Epoch 346/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0137 - accuracy: 0.9962 - val_loss: 2.6985e-05 - val_accuracy: 1.0000\n",
            "Epoch 347/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0111 - accuracy: 0.9971 - val_loss: 2.5970e-05 - val_accuracy: 1.0000\n",
            "Epoch 348/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0120 - accuracy: 0.9962 - val_loss: 2.0790e-05 - val_accuracy: 1.0000\n",
            "Epoch 349/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0387 - accuracy: 0.9952 - val_loss: 1.1466e-04 - val_accuracy: 1.0000\n",
            "Epoch 350/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0142 - accuracy: 0.9962 - val_loss: 0.0214 - val_accuracy: 0.9962\n",
            "Epoch 351/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.1061 - accuracy: 0.9943 - val_loss: 0.1040 - val_accuracy: 0.9885\n",
            "Epoch 352/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.5659 - accuracy: 0.9914 - val_loss: 8.5861 - val_accuracy: 0.9580\n",
            "Epoch 353/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0829 - accuracy: 0.9885 - val_loss: 3.2420 - val_accuracy: 0.9389\n",
            "Epoch 354/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0130 - accuracy: 0.9971 - val_loss: 0.6147 - val_accuracy: 0.9809\n",
            "Epoch 355/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0228 - accuracy: 0.9924 - val_loss: 0.0386 - val_accuracy: 0.9924\n",
            "Epoch 356/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0079 - accuracy: 0.9981 - val_loss: 0.0881 - val_accuracy: 0.9924\n",
            "Epoch 357/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0141 - accuracy: 0.9962 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 358/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0089 - accuracy: 0.9981 - val_loss: 7.4196e-04 - val_accuracy: 1.0000\n",
            "Epoch 359/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.1452 - accuracy: 0.9943 - val_loss: 1.5578e-06 - val_accuracy: 1.0000\n",
            "Epoch 360/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0619 - accuracy: 0.9943 - val_loss: 0.0708 - val_accuracy: 0.9962\n",
            "Epoch 361/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0063 - accuracy: 0.9990 - val_loss: 9.6966e-08 - val_accuracy: 1.0000\n",
            "Epoch 362/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0188 - accuracy: 0.9952 - val_loss: 2.1609e-07 - val_accuracy: 1.0000\n",
            "Epoch 363/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0129 - accuracy: 0.9962 - val_loss: 6.4996e-05 - val_accuracy: 1.0000\n",
            "Epoch 364/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0089 - accuracy: 0.9981 - val_loss: 4.6420e-04 - val_accuracy: 1.0000\n",
            "Epoch 365/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0088 - accuracy: 0.9981 - val_loss: 5.9748e-04 - val_accuracy: 1.0000\n",
            "Epoch 366/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0090 - accuracy: 0.9981 - val_loss: 6.3963e-04 - val_accuracy: 1.0000\n",
            "Epoch 367/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0065 - accuracy: 0.9990 - val_loss: 6.5924e-04 - val_accuracy: 1.0000\n",
            "Epoch 368/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0119 - accuracy: 0.9971 - val_loss: 6.6417e-04 - val_accuracy: 1.0000\n",
            "Epoch 369/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0167 - accuracy: 0.9952 - val_loss: 6.9040e-04 - val_accuracy: 1.0000\n",
            "Epoch 370/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0146 - accuracy: 0.9962 - val_loss: 5.9593e-04 - val_accuracy: 1.0000\n",
            "Epoch 371/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0076 - accuracy: 0.9990 - val_loss: 5.7075e-04 - val_accuracy: 1.0000\n",
            "Epoch 372/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0143 - accuracy: 0.9962 - val_loss: 5.6294e-04 - val_accuracy: 1.0000\n",
            "Epoch 373/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0113 - accuracy: 0.9971 - val_loss: 3.5613e-04 - val_accuracy: 1.0000\n",
            "Epoch 374/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0094 - accuracy: 0.9981 - val_loss: 2.3917e-05 - val_accuracy: 1.0000\n",
            "Epoch 375/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0140 - accuracy: 0.9962 - val_loss: 1.9377e-05 - val_accuracy: 1.0000\n",
            "Epoch 376/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0145 - accuracy: 0.9962 - val_loss: 2.7383e-05 - val_accuracy: 1.0000\n",
            "Epoch 377/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0109 - accuracy: 0.9971 - val_loss: 3.6867e-05 - val_accuracy: 1.0000\n",
            "Epoch 378/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0108 - accuracy: 0.9971 - val_loss: 3.3153e-05 - val_accuracy: 1.0000\n",
            "Epoch 379/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0133 - accuracy: 0.9962 - val_loss: 6.4697e-05 - val_accuracy: 1.0000\n",
            "Epoch 380/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0117 - accuracy: 0.9971 - val_loss: 5.7426e-05 - val_accuracy: 1.0000\n",
            "Epoch 381/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0079 - accuracy: 0.9981 - val_loss: 3.5607e-05 - val_accuracy: 1.0000\n",
            "Epoch 382/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0193 - accuracy: 0.9962 - val_loss: 4.4476e-10 - val_accuracy: 1.0000\n",
            "Epoch 383/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0085 - accuracy: 0.9981 - val_loss: 5.2949e-11 - val_accuracy: 1.0000\n",
            "Epoch 384/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0192 - accuracy: 0.9943 - val_loss: 8.9946e-11 - val_accuracy: 1.0000\n",
            "Epoch 385/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0183 - accuracy: 0.9943 - val_loss: 1.2914e-10 - val_accuracy: 1.0000\n",
            "Epoch 386/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0477 - accuracy: 0.9943 - val_loss: 2.8318e-09 - val_accuracy: 1.0000\n",
            "Epoch 387/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0114 - accuracy: 0.9971 - val_loss: 2.6034e-09 - val_accuracy: 1.0000\n",
            "Epoch 388/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0141 - accuracy: 0.9962 - val_loss: 1.4801e-08 - val_accuracy: 1.0000\n",
            "Epoch 389/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0157 - accuracy: 0.9952 - val_loss: 1.5757e-08 - val_accuracy: 1.0000\n",
            "Epoch 390/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0191 - accuracy: 0.9943 - val_loss: 5.8955e-09 - val_accuracy: 1.0000\n",
            "Epoch 391/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0101 - accuracy: 0.9971 - val_loss: 3.5930e-09 - val_accuracy: 1.0000\n",
            "Epoch 392/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0116 - accuracy: 0.9971 - val_loss: 6.3388e-09 - val_accuracy: 1.0000\n",
            "Epoch 393/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0142 - accuracy: 0.9962 - val_loss: 1.0951e-08 - val_accuracy: 1.0000\n",
            "Epoch 394/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.5590e-08 - val_accuracy: 1.0000\n",
            "Epoch 395/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0062 - accuracy: 0.9990 - val_loss: 2.3248e-08 - val_accuracy: 1.0000\n",
            "Epoch 396/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 3.0015e-08 - val_accuracy: 1.0000\n",
            "Epoch 397/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0189 - accuracy: 0.9952 - val_loss: 2.2025e-10 - val_accuracy: 1.0000\n",
            "Epoch 398/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0167 - accuracy: 0.9952 - val_loss: 6.0187e-11 - val_accuracy: 1.0000\n",
            "Epoch 399/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0061 - accuracy: 0.9990 - val_loss: 2.3019e-11 - val_accuracy: 1.0000\n",
            "Epoch 400/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0111 - accuracy: 0.9971 - val_loss: 2.6175e-11 - val_accuracy: 1.0000\n",
            "Epoch 401/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0060 - accuracy: 0.9990 - val_loss: 2.7807e-11 - val_accuracy: 1.0000\n",
            "Epoch 402/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0201 - accuracy: 0.9943 - val_loss: 2.5999e-11 - val_accuracy: 1.0000\n",
            "Epoch 403/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0092 - accuracy: 0.9981 - val_loss: 2.5601e-11 - val_accuracy: 1.0000\n",
            "Epoch 404/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0138 - accuracy: 0.9962 - val_loss: 2.6316e-11 - val_accuracy: 1.0000\n",
            "Epoch 405/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0113 - accuracy: 0.9962 - val_loss: 1.1172e-07 - val_accuracy: 1.0000\n",
            "Epoch 406/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0136 - accuracy: 0.9962 - val_loss: 3.6524e-08 - val_accuracy: 1.0000\n",
            "Epoch 407/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0088 - accuracy: 0.9981 - val_loss: 6.9090e-10 - val_accuracy: 1.0000\n",
            "Epoch 408/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0183 - accuracy: 0.9943 - val_loss: 3.2179e-11 - val_accuracy: 1.0000\n",
            "Epoch 409/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0114 - accuracy: 0.9971 - val_loss: 5.2917e-12 - val_accuracy: 1.0000\n",
            "Epoch 410/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0116 - accuracy: 0.9971 - val_loss: 1.3410e-12 - val_accuracy: 1.0000\n",
            "Epoch 411/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0060 - accuracy: 0.9990 - val_loss: 6.2572e-13 - val_accuracy: 1.0000\n",
            "Epoch 412/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 3.5344e-13 - val_accuracy: 1.0000\n",
            "Epoch 413/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0081 - accuracy: 0.9981 - val_loss: 2.3322e-13 - val_accuracy: 1.0000\n",
            "Epoch 414/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0111 - accuracy: 0.9971 - val_loss: 1.9009e-13 - val_accuracy: 1.0000\n",
            "Epoch 415/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0108 - accuracy: 0.9971 - val_loss: 2.2473e-12 - val_accuracy: 1.0000\n",
            "Epoch 416/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0138 - accuracy: 0.9962 - val_loss: 3.4031e-12 - val_accuracy: 1.0000\n",
            "Epoch 417/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0142 - accuracy: 0.9962 - val_loss: 3.7629e-12 - val_accuracy: 1.0000\n",
            "Epoch 418/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0088 - accuracy: 0.9981 - val_loss: 4.8531e-13 - val_accuracy: 1.0000\n",
            "Epoch 419/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0139 - accuracy: 0.9962 - val_loss: 9.4550e-14 - val_accuracy: 1.0000\n",
            "Epoch 420/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0723 - accuracy: 0.9933 - val_loss: 0.2132 - val_accuracy: 0.9885\n",
            "Epoch 421/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0505 - accuracy: 0.9962 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 422/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0236 - accuracy: 0.9943 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 423/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0074 - accuracy: 0.9990 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
            "Epoch 424/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0073 - accuracy: 0.9990 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
            "Epoch 425/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0100 - accuracy: 0.9981 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
            "Epoch 426/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0070 - accuracy: 0.9990 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
            "Epoch 427/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0055 - accuracy: 0.9990 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
            "Epoch 428/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0124 - accuracy: 0.9990 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
            "Epoch 429/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0065 - accuracy: 0.9990 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
            "Epoch 430/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0309 - accuracy: 0.9971 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 431/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 432/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0135 - accuracy: 0.9981 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 433/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0090 - accuracy: 0.9981 - val_loss: 6.5332e-04 - val_accuracy: 1.0000\n",
            "Epoch 434/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0064 - accuracy: 0.9990 - val_loss: 5.7672e-04 - val_accuracy: 1.0000\n",
            "Epoch 435/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 3.9990e-04 - val_accuracy: 1.0000\n",
            "Epoch 436/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 3.3078e-04 - val_accuracy: 1.0000\n",
            "Epoch 437/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.7728e-04 - val_accuracy: 1.0000\n",
            "Epoch 438/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.4245e-04 - val_accuracy: 1.0000\n",
            "Epoch 439/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0058 - accuracy: 0.9990 - val_loss: 2.2352e-04 - val_accuracy: 1.0000\n",
            "Epoch 440/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 2.1199e-04 - val_accuracy: 1.0000\n",
            "Epoch 441/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.0930e-04 - val_accuracy: 1.0000\n",
            "Epoch 442/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0051 - accuracy: 0.9990 - val_loss: 2.0625e-04 - val_accuracy: 1.0000\n",
            "Epoch 443/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0081 - accuracy: 0.9981 - val_loss: 2.2920e-04 - val_accuracy: 1.0000\n",
            "Epoch 444/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0075 - accuracy: 0.9981 - val_loss: 2.6898e-04 - val_accuracy: 1.0000\n",
            "Epoch 445/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0084 - accuracy: 0.9981 - val_loss: 2.7856e-04 - val_accuracy: 1.0000\n",
            "Epoch 446/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.5371e-04 - val_accuracy: 1.0000\n",
            "Epoch 447/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.9542e-04 - val_accuracy: 1.0000\n",
            "Epoch 448/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0053 - accuracy: 0.9990 - val_loss: 1.9261e-04 - val_accuracy: 1.0000\n",
            "Epoch 449/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0057 - accuracy: 0.9990 - val_loss: 2.1176e-04 - val_accuracy: 1.0000\n",
            "Epoch 450/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0150 - accuracy: 0.9971 - val_loss: 2.1109e-08 - val_accuracy: 1.0000\n",
            "Epoch 451/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.0478e-09 - val_accuracy: 1.0000\n",
            "Epoch 452/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0108 - accuracy: 0.9971 - val_loss: 1.4981e-10 - val_accuracy: 1.0000\n",
            "Epoch 453/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0111 - accuracy: 0.9971 - val_loss: 1.8145e-11 - val_accuracy: 1.0000\n",
            "Epoch 454/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0085 - accuracy: 0.9981 - val_loss: 5.0148e-12 - val_accuracy: 1.0000\n",
            "Epoch 455/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0085 - accuracy: 0.9981 - val_loss: 2.8171e-12 - val_accuracy: 1.0000\n",
            "Epoch 456/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0088 - accuracy: 0.9981 - val_loss: 2.3348e-12 - val_accuracy: 1.0000\n",
            "Epoch 457/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 3.0278e-12 - val_accuracy: 1.0000\n",
            "Epoch 458/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0083 - accuracy: 0.9981 - val_loss: 3.4948e-12 - val_accuracy: 1.0000\n",
            "Epoch 459/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 3.8173e-12 - val_accuracy: 1.0000\n",
            "Epoch 460/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0086 - accuracy: 0.9981 - val_loss: 4.2633e-12 - val_accuracy: 1.0000\n",
            "Epoch 461/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 4.4843e-12 - val_accuracy: 1.0000\n",
            "Epoch 462/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 4.4687e-12 - val_accuracy: 1.0000\n",
            "Epoch 463/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 4.4707e-12 - val_accuracy: 1.0000\n",
            "Epoch 464/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0056 - accuracy: 0.9990 - val_loss: 2.2662e-11 - val_accuracy: 1.0000\n",
            "Epoch 465/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.2101e-11 - val_accuracy: 1.0000\n",
            "Epoch 466/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 7.4928e-12 - val_accuracy: 1.0000\n",
            "Epoch 467/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 4.9424e-12 - val_accuracy: 1.0000\n",
            "Epoch 468/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0057 - accuracy: 0.9990 - val_loss: 3.5620e-11 - val_accuracy: 1.0000\n",
            "Epoch 469/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.8272e-11 - val_accuracy: 1.0000\n",
            "Epoch 470/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.2465e-11 - val_accuracy: 1.0000\n",
            "Epoch 471/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0054 - accuracy: 0.9990 - val_loss: 1.7998e-11 - val_accuracy: 1.0000\n",
            "Epoch 472/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.5809e-11 - val_accuracy: 1.0000\n",
            "Epoch 473/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0053 - accuracy: 0.9990 - val_loss: 1.2764e-11 - val_accuracy: 1.0000\n",
            "Epoch 474/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0054 - accuracy: 0.9990 - val_loss: 1.2335e-11 - val_accuracy: 1.0000\n",
            "Epoch 475/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0105 - accuracy: 0.9971 - val_loss: 29.6730 - val_accuracy: 0.9198\n",
            "Epoch 476/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0718 - accuracy: 0.9943 - val_loss: 3.1104e-04 - val_accuracy: 1.0000\n",
            "Epoch 477/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0218 - accuracy: 0.9943 - val_loss: 3.2380e-04 - val_accuracy: 1.0000\n",
            "Epoch 478/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0427 - accuracy: 0.9924 - val_loss: 0.4596 - val_accuracy: 0.9771\n",
            "Epoch 479/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0472 - accuracy: 0.9952 - val_loss: 3.7843e-04 - val_accuracy: 1.0000\n",
            "Epoch 480/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0149 - accuracy: 0.9962 - val_loss: 1.5993e-04 - val_accuracy: 1.0000\n",
            "Epoch 481/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0149 - accuracy: 0.9962 - val_loss: 1.6680e-04 - val_accuracy: 1.0000\n",
            "Epoch 482/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0146 - accuracy: 0.9981 - val_loss: 1.5728e-04 - val_accuracy: 1.0000\n",
            "Epoch 483/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0147 - accuracy: 0.9962 - val_loss: 1.5878e-04 - val_accuracy: 1.0000\n",
            "Epoch 484/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0131 - accuracy: 0.9962 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "Epoch 485/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0770 - accuracy: 0.9952 - val_loss: 4.1992e-06 - val_accuracy: 1.0000\n",
            "Epoch 486/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0161 - accuracy: 0.9952 - val_loss: 3.6901e-07 - val_accuracy: 1.0000\n",
            "Epoch 487/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0084 - accuracy: 0.9981 - val_loss: 1.3266e-07 - val_accuracy: 1.0000\n",
            "Epoch 488/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0084 - accuracy: 0.9981 - val_loss: 1.4773e-07 - val_accuracy: 1.0000\n",
            "Epoch 489/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0142 - accuracy: 0.9962 - val_loss: 1.3180e-07 - val_accuracy: 1.0000\n",
            "Epoch 490/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0055 - accuracy: 0.9990 - val_loss: 1.3862e-07 - val_accuracy: 1.0000\n",
            "Epoch 491/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0108 - accuracy: 0.9971 - val_loss: 4.5733e-08 - val_accuracy: 1.0000\n",
            "Epoch 492/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 4.4205e-08 - val_accuracy: 1.0000\n",
            "Epoch 493/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0358 - accuracy: 0.9952 - val_loss: 8.8999e-05 - val_accuracy: 1.0000\n",
            "Epoch 494/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0105 - accuracy: 0.9971 - val_loss: 1.9292e-04 - val_accuracy: 1.0000\n",
            "Epoch 495/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0083 - accuracy: 0.9981 - val_loss: 1.4406e-04 - val_accuracy: 1.0000\n",
            "Epoch 496/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0102 - accuracy: 0.9971 - val_loss: 3.7909e-04 - val_accuracy: 1.0000\n",
            "Epoch 497/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0168 - accuracy: 0.9952 - val_loss: 1.6942e-04 - val_accuracy: 1.0000\n",
            "Epoch 498/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0059 - accuracy: 0.9990 - val_loss: 9.5867e-05 - val_accuracy: 1.0000\n",
            "Epoch 499/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0085 - accuracy: 0.9981 - val_loss: 4.4000e-05 - val_accuracy: 1.0000\n",
            "Epoch 500/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.2419e-05 - val_accuracy: 1.0000\n",
            "Epoch 501/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0083 - accuracy: 0.9981 - val_loss: 1.2476e-05 - val_accuracy: 1.0000\n",
            "Epoch 502/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0060 - accuracy: 0.9990 - val_loss: 6.1691e-06 - val_accuracy: 1.0000\n",
            "Epoch 503/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0051 - accuracy: 0.9990 - val_loss: 2.9368e-06 - val_accuracy: 1.0000\n",
            "Epoch 504/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0114 - accuracy: 0.9990 - val_loss: 1.0909e-06 - val_accuracy: 1.0000\n",
            "Epoch 505/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0146 - accuracy: 0.9990 - val_loss: 1.4756e-06 - val_accuracy: 1.0000\n",
            "Epoch 506/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0059 - accuracy: 0.9981 - val_loss: 9.3511e-07 - val_accuracy: 1.0000\n",
            "Epoch 507/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0083 - accuracy: 0.9981 - val_loss: 7.5333e-07 - val_accuracy: 1.0000\n",
            "Epoch 508/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0084 - accuracy: 0.9981 - val_loss: 6.3968e-07 - val_accuracy: 1.0000\n",
            "Epoch 509/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0132 - accuracy: 0.9962 - val_loss: 1.0658e-06 - val_accuracy: 1.0000\n",
            "Epoch 510/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0129 - accuracy: 0.9962 - val_loss: 1.2530e-06 - val_accuracy: 1.0000\n",
            "Epoch 511/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.2026 - accuracy: 0.9971 - val_loss: 0.0229 - val_accuracy: 0.9962\n",
            "Epoch 512/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 3.6817e-06 - val_accuracy: 1.0000\n",
            "Epoch 513/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0086 - accuracy: 0.9981 - val_loss: 7.4719e-07 - val_accuracy: 1.0000\n",
            "Epoch 514/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0066 - accuracy: 0.9981 - val_loss: 9.9020e-07 - val_accuracy: 1.0000\n",
            "Epoch 515/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0047 - accuracy: 0.9990 - val_loss: 2.1522e-06 - val_accuracy: 1.0000\n",
            "Epoch 516/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0056 - accuracy: 0.9981 - val_loss: 1.1499e-06 - val_accuracy: 1.0000\n",
            "Epoch 517/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0052 - accuracy: 0.9990 - val_loss: 9.1918e-07 - val_accuracy: 1.0000\n",
            "Epoch 518/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0085 - accuracy: 0.9981 - val_loss: 7.1319e-07 - val_accuracy: 1.0000\n",
            "Epoch 519/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0062 - accuracy: 0.9990 - val_loss: 6.8873e-07 - val_accuracy: 1.0000\n",
            "Epoch 520/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0115 - accuracy: 0.9971 - val_loss: 1.4495e-06 - val_accuracy: 1.0000\n",
            "Epoch 521/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0050 - accuracy: 0.9990 - val_loss: 1.2407e-06 - val_accuracy: 1.0000\n",
            "Epoch 522/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0147 - accuracy: 0.9962 - val_loss: 1.1083e-06 - val_accuracy: 1.0000\n",
            "Epoch 523/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 6.8537e-07 - val_accuracy: 1.0000\n",
            "Epoch 524/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0061 - accuracy: 0.9981 - val_loss: 3.5499e-07 - val_accuracy: 1.0000\n",
            "Epoch 525/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.2032e-07 - val_accuracy: 1.0000\n",
            "Epoch 526/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0060 - accuracy: 0.9981 - val_loss: 3.2850e-08 - val_accuracy: 1.0000\n",
            "Epoch 527/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0045 - accuracy: 0.9990 - val_loss: 1.4080e-07 - val_accuracy: 1.0000\n",
            "Epoch 528/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0082 - accuracy: 0.9981 - val_loss: 1.2998e-07 - val_accuracy: 1.0000\n",
            "Epoch 529/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0054 - accuracy: 0.9990 - val_loss: 9.6186e-08 - val_accuracy: 1.0000\n",
            "Epoch 530/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0083 - accuracy: 0.9981 - val_loss: 7.0884e-08 - val_accuracy: 1.0000\n",
            "Epoch 531/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0052 - accuracy: 0.9990 - val_loss: 6.4629e-08 - val_accuracy: 1.0000\n",
            "Epoch 532/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0052 - accuracy: 0.9990 - val_loss: 5.9411e-08 - val_accuracy: 1.0000\n",
            "Epoch 533/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0051 - accuracy: 0.9990 - val_loss: 5.3115e-08 - val_accuracy: 1.0000\n",
            "Epoch 534/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 5.1138e-08 - val_accuracy: 1.0000\n",
            "Epoch 535/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0085 - accuracy: 0.9981 - val_loss: 4.9338e-08 - val_accuracy: 1.0000\n",
            "Epoch 536/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0052 - accuracy: 0.9990 - val_loss: 4.9899e-08 - val_accuracy: 1.0000\n",
            "Epoch 537/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 4.8042e-08 - val_accuracy: 1.0000\n",
            "Epoch 538/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 4.7351e-08 - val_accuracy: 1.0000\n",
            "Epoch 539/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0179 - accuracy: 0.9952 - val_loss: 4.7921e-08 - val_accuracy: 1.0000\n",
            "Epoch 540/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 5.0008e-08 - val_accuracy: 1.0000\n",
            "Epoch 541/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0100 - accuracy: 0.9971 - val_loss: 8.4913e-06 - val_accuracy: 1.0000\n",
            "Epoch 542/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0053 - accuracy: 0.9990 - val_loss: 2.2229e-05 - val_accuracy: 1.0000\n",
            "Epoch 543/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0037 - accuracy: 0.9990 - val_loss: 2.5049e-05 - val_accuracy: 1.0000\n",
            "Epoch 544/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0094 - accuracy: 0.9981 - val_loss: 7.4947e-06 - val_accuracy: 1.0000\n",
            "Epoch 545/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0050 - accuracy: 0.9990 - val_loss: 8.7686e-06 - val_accuracy: 1.0000\n",
            "Epoch 546/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0053 - accuracy: 0.9990 - val_loss: 1.3717e-05 - val_accuracy: 1.0000\n",
            "Epoch 547/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0052 - accuracy: 0.9990 - val_loss: 1.2004e-05 - val_accuracy: 1.0000\n",
            "Epoch 548/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0054 - accuracy: 0.9990 - val_loss: 9.5398e-05 - val_accuracy: 1.0000\n",
            "Epoch 549/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0258 - accuracy: 0.9971 - val_loss: 1.8714e-06 - val_accuracy: 1.0000\n",
            "Epoch 550/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0089 - accuracy: 0.9990 - val_loss: 5.6136e-05 - val_accuracy: 1.0000\n",
            "Epoch 551/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 6.2382e-05 - val_accuracy: 1.0000\n",
            "Epoch 552/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0426 - accuracy: 0.9981 - val_loss: 1.1793e-05 - val_accuracy: 1.0000\n",
            "Epoch 553/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0022 - accuracy: 0.9990 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
            "Epoch 554/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.2003 - accuracy: 0.9952 - val_loss: 2.2309e-10 - val_accuracy: 1.0000\n",
            "Epoch 555/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0082 - accuracy: 0.9981 - val_loss: 4.5933e-11 - val_accuracy: 1.0000\n",
            "Epoch 556/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0071 - accuracy: 0.9981 - val_loss: 5.3150e-12 - val_accuracy: 1.0000\n",
            "Epoch 557/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0049 - accuracy: 0.9990 - val_loss: 3.0219e-12 - val_accuracy: 1.0000\n",
            "Epoch 558/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.4265e-12 - val_accuracy: 1.0000\n",
            "Epoch 559/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0117 - accuracy: 0.9971 - val_loss: 1.9999e-12 - val_accuracy: 1.0000\n",
            "Epoch 560/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0086 - accuracy: 0.9981 - val_loss: 1.8728e-12 - val_accuracy: 1.0000\n",
            "Epoch 561/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0048 - accuracy: 0.9990 - val_loss: 1.8859e-12 - val_accuracy: 1.0000\n",
            "Epoch 562/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0052 - accuracy: 0.9990 - val_loss: 1.3038e-12 - val_accuracy: 1.0000\n",
            "Epoch 563/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0052 - accuracy: 0.9990 - val_loss: 1.1213e-12 - val_accuracy: 1.0000\n",
            "Epoch 564/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0082 - accuracy: 0.9981 - val_loss: 9.7650e-13 - val_accuracy: 1.0000\n",
            "Epoch 565/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0051 - accuracy: 0.9990 - val_loss: 9.2517e-13 - val_accuracy: 1.0000\n",
            "Epoch 566/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0056 - accuracy: 0.9990 - val_loss: 2.2882e-12 - val_accuracy: 1.0000\n",
            "Epoch 567/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.5082e-12 - val_accuracy: 1.0000\n",
            "Epoch 568/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0050 - accuracy: 0.9990 - val_loss: 2.4847e-12 - val_accuracy: 1.0000\n",
            "Epoch 569/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0051 - accuracy: 0.9990 - val_loss: 2.4567e-12 - val_accuracy: 1.0000\n",
            "Epoch 570/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0052 - accuracy: 0.9990 - val_loss: 2.3564e-12 - val_accuracy: 1.0000\n",
            "Epoch 571/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 2.6644e-12 - val_accuracy: 1.0000\n",
            "Epoch 572/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 5.3181e-13 - val_accuracy: 1.0000\n",
            "Epoch 573/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0049 - accuracy: 0.9990 - val_loss: 1.9652e-13 - val_accuracy: 1.0000\n",
            "Epoch 574/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0049 - accuracy: 0.9990 - val_loss: 1.1356e-13 - val_accuracy: 1.0000\n",
            "Epoch 575/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0051 - accuracy: 0.9990 - val_loss: 7.6586e-14 - val_accuracy: 1.0000\n",
            "Epoch 576/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 5.6693e-14 - val_accuracy: 1.0000\n",
            "Epoch 577/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0767 - accuracy: 0.9943 - val_loss: 0.0886 - val_accuracy: 0.9885\n",
            "Epoch 578/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0102 - accuracy: 0.9971 - val_loss: 0.0134 - val_accuracy: 0.9962\n",
            "Epoch 579/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0195 - accuracy: 0.9962 - val_loss: 0.2517 - val_accuracy: 0.9695\n",
            "Epoch 580/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0254 - accuracy: 0.9981 - val_loss: 8.9714e-04 - val_accuracy: 1.0000\n",
            "Epoch 581/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0075 - accuracy: 0.9981 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 582/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0097 - accuracy: 0.9971 - val_loss: 8.4423e-04 - val_accuracy: 1.0000\n",
            "Epoch 583/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 7.5539e-04 - val_accuracy: 1.0000\n",
            "Epoch 584/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0094 - accuracy: 0.9971 - val_loss: 3.2527e-05 - val_accuracy: 1.0000\n",
            "Epoch 585/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 7.7872e-06 - val_accuracy: 1.0000\n",
            "Epoch 586/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0342 - accuracy: 0.9981 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 587/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0048 - accuracy: 0.9990 - val_loss: 3.4938e-04 - val_accuracy: 1.0000\n",
            "Epoch 588/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 3.7482e-04 - val_accuracy: 1.0000\n",
            "Epoch 589/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0070 - accuracy: 0.9981 - val_loss: 1.5329 - val_accuracy: 0.9733\n",
            "Epoch 590/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0102 - accuracy: 0.9971 - val_loss: 3.3795e-05 - val_accuracy: 1.0000\n",
            "Epoch 591/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0050 - accuracy: 0.9990 - val_loss: 5.0529e-08 - val_accuracy: 1.0000\n",
            "Epoch 592/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0148 - accuracy: 0.9981 - val_loss: 7.9721e-08 - val_accuracy: 1.0000\n",
            "Epoch 593/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0083 - accuracy: 0.9981 - val_loss: 1.7442e-07 - val_accuracy: 1.0000\n",
            "Epoch 594/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0051 - accuracy: 0.9990 - val_loss: 3.4137e-07 - val_accuracy: 1.0000\n",
            "Epoch 595/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 5.0559e-07 - val_accuracy: 1.0000\n",
            "Epoch 596/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 5.7612e-07 - val_accuracy: 1.0000\n",
            "Epoch 597/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0049 - accuracy: 0.9990 - val_loss: 5.7212e-07 - val_accuracy: 1.0000\n",
            "Epoch 598/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0048 - accuracy: 0.9990 - val_loss: 5.7067e-07 - val_accuracy: 1.0000\n",
            "Epoch 599/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0084 - accuracy: 0.9981 - val_loss: 5.5253e-07 - val_accuracy: 1.0000\n",
            "Epoch 600/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 5.6903e-07 - val_accuracy: 1.0000\n",
            "Epoch 601/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0082 - accuracy: 0.9981 - val_loss: 5.7585e-07 - val_accuracy: 1.0000\n",
            "Epoch 602/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 5.4815e-07 - val_accuracy: 1.0000\n",
            "Epoch 603/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 5.4331e-07 - val_accuracy: 1.0000\n",
            "Epoch 604/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0117 - accuracy: 0.9971 - val_loss: 5.5091e-07 - val_accuracy: 1.0000\n",
            "Epoch 605/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0048 - accuracy: 0.9990 - val_loss: 5.3456e-07 - val_accuracy: 1.0000\n",
            "Epoch 606/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0051 - accuracy: 0.9990 - val_loss: 5.4369e-07 - val_accuracy: 1.0000\n",
            "Epoch 607/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 5.0860e-07 - val_accuracy: 1.0000\n",
            "Epoch 608/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0049 - accuracy: 0.9990 - val_loss: 4.4059e-07 - val_accuracy: 1.0000\n",
            "Epoch 609/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0085 - accuracy: 0.9981 - val_loss: 4.4106e-07 - val_accuracy: 1.0000\n",
            "Epoch 610/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0049 - accuracy: 0.9990 - val_loss: 4.5606e-07 - val_accuracy: 1.0000\n",
            "Epoch 611/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0049 - accuracy: 0.9990 - val_loss: 4.6412e-07 - val_accuracy: 1.0000\n",
            "Epoch 612/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 4.3988e-07 - val_accuracy: 1.0000\n",
            "Epoch 613/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0083 - accuracy: 0.9981 - val_loss: 4.2709e-07 - val_accuracy: 1.0000\n",
            "Epoch 614/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0049 - accuracy: 0.9990 - val_loss: 3.9961e-07 - val_accuracy: 1.0000\n",
            "Epoch 615/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 4.0547e-07 - val_accuracy: 1.0000\n",
            "Epoch 616/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0048 - accuracy: 0.9990 - val_loss: 3.8730e-07 - val_accuracy: 1.0000\n",
            "Epoch 617/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 3.7847e-07 - val_accuracy: 1.0000\n",
            "Epoch 618/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0048 - accuracy: 0.9990 - val_loss: 6.6909e-07 - val_accuracy: 1.0000\n",
            "Epoch 619/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 6.9598e-07 - val_accuracy: 1.0000\n",
            "Epoch 620/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 6.5586e-07 - val_accuracy: 1.0000\n",
            "Epoch 621/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 5.6672e-07 - val_accuracy: 1.0000\n",
            "Epoch 622/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0049 - accuracy: 0.9990 - val_loss: 5.3911e-07 - val_accuracy: 1.0000\n",
            "Epoch 623/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 4.8578e-07 - val_accuracy: 1.0000\n",
            "Epoch 624/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0050 - accuracy: 0.9990 - val_loss: 4.3834e-07 - val_accuracy: 1.0000\n",
            "Epoch 625/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0048 - accuracy: 0.9990 - val_loss: 3.9725e-07 - val_accuracy: 1.0000\n",
            "Epoch 626/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0047 - accuracy: 0.9990 - val_loss: 2.6067e-07 - val_accuracy: 1.0000\n",
            "Epoch 627/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0045 - accuracy: 0.9990 - val_loss: 1.3343e-07 - val_accuracy: 1.0000\n",
            "Epoch 628/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 9.0714e-04 - accuracy: 1.0000 - val_loss: 4.0501e-08 - val_accuracy: 1.0000\n",
            "Epoch 629/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 8.4533e-04 - accuracy: 1.0000 - val_loss: 2.1388e-08 - val_accuracy: 1.0000\n",
            "Epoch 630/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0044 - accuracy: 0.9990 - val_loss: 1.3839e-08 - val_accuracy: 1.0000\n",
            "Epoch 631/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0041 - accuracy: 0.9990 - val_loss: 1.1157e-08 - val_accuracy: 1.0000\n",
            "Epoch 632/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 8.2049e-04 - accuracy: 1.0000 - val_loss: 7.3787e-09 - val_accuracy: 1.0000\n",
            "Epoch 633/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 8.5641e-04 - accuracy: 1.0000 - val_loss: 5.9647e-09 - val_accuracy: 1.0000\n",
            "Epoch 634/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0041 - accuracy: 0.9990 - val_loss: 4.4269e-09 - val_accuracy: 1.0000\n",
            "Epoch 635/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 7.5771e-04 - accuracy: 1.0000 - val_loss: 4.0228e-09 - val_accuracy: 1.0000\n",
            "Epoch 636/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 6.5855e-04 - accuracy: 1.0000 - val_loss: 3.2356e-09 - val_accuracy: 1.0000\n",
            "Epoch 637/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0078 - accuracy: 0.9981 - val_loss: 3.0006e-09 - val_accuracy: 1.0000\n",
            "Epoch 638/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 7.2599e-04 - accuracy: 1.0000 - val_loss: 2.6453e-09 - val_accuracy: 1.0000\n",
            "Epoch 639/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0226 - accuracy: 0.9981 - val_loss: 9.7310e-05 - val_accuracy: 1.0000\n",
            "Epoch 640/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0049 - accuracy: 0.9990 - val_loss: 1.0073e-04 - val_accuracy: 1.0000\n",
            "Epoch 641/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0084 - accuracy: 0.9981 - val_loss: 9.9357e-05 - val_accuracy: 1.0000\n",
            "Epoch 642/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 9.7975e-05 - val_accuracy: 1.0000\n",
            "Epoch 643/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0119 - accuracy: 0.9971 - val_loss: 9.7460e-05 - val_accuracy: 1.0000\n",
            "Epoch 644/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0056 - accuracy: 0.9981 - val_loss: 1.0708e-04 - val_accuracy: 1.0000\n",
            "Epoch 645/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0049 - accuracy: 0.9990 - val_loss: 1.1042e-04 - val_accuracy: 1.0000\n",
            "Epoch 646/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0047 - accuracy: 0.9990 - val_loss: 1.1147e-04 - val_accuracy: 1.0000\n",
            "Epoch 647/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0128 - accuracy: 0.9981 - val_loss: 3.0066e-05 - val_accuracy: 1.0000\n",
            "Epoch 648/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0050 - accuracy: 0.9990 - val_loss: 1.2001e-06 - val_accuracy: 1.0000\n",
            "Epoch 649/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0030 - accuracy: 0.9990 - val_loss: 7.9819e-07 - val_accuracy: 1.0000\n",
            "Epoch 650/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 5.0301e-07 - val_accuracy: 1.0000\n",
            "Epoch 651/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 3.2104e-07 - val_accuracy: 1.0000\n",
            "Epoch 652/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.3861e-07 - val_accuracy: 1.0000\n",
            "Epoch 653/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.9390e-07 - val_accuracy: 1.0000\n",
            "Epoch 654/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 4.7706e-07 - val_accuracy: 1.0000\n",
            "Epoch 655/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0022 - accuracy: 0.9990 - val_loss: 1.6764e-06 - val_accuracy: 1.0000\n",
            "Epoch 656/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0129 - accuracy: 0.9962 - val_loss: 9.1018e-05 - val_accuracy: 1.0000\n",
            "Epoch 657/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0310 - accuracy: 0.9981 - val_loss: 7.8833e-06 - val_accuracy: 1.0000\n",
            "Epoch 658/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0085 - accuracy: 0.9981 - val_loss: 7.0371e-07 - val_accuracy: 1.0000\n",
            "Epoch 659/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 3.2052e-07 - val_accuracy: 1.0000\n",
            "Epoch 660/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0084 - accuracy: 0.9981 - val_loss: 2.5222e-07 - val_accuracy: 1.0000\n",
            "Epoch 661/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0048 - accuracy: 0.9990 - val_loss: 2.1384e-07 - val_accuracy: 1.0000\n",
            "Epoch 662/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0083 - accuracy: 0.9981 - val_loss: 1.9616e-07 - val_accuracy: 1.0000\n",
            "Epoch 663/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0088 - accuracy: 0.9981 - val_loss: 1.0437e-06 - val_accuracy: 1.0000\n",
            "Epoch 664/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0050 - accuracy: 0.9990 - val_loss: 1.0342e-06 - val_accuracy: 1.0000\n",
            "Epoch 665/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 8.6531e-07 - val_accuracy: 1.0000\n",
            "Epoch 666/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0087 - accuracy: 0.9981 - val_loss: 7.7531e-07 - val_accuracy: 1.0000\n",
            "Epoch 667/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0091 - accuracy: 0.9981 - val_loss: 0.0712 - val_accuracy: 0.9885\n",
            "Epoch 668/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.1767 - accuracy: 0.9914 - val_loss: 1.3643e-05 - val_accuracy: 1.0000\n",
            "Epoch 669/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0051 - accuracy: 0.9990 - val_loss: 1.3055e-04 - val_accuracy: 1.0000\n",
            "Epoch 670/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0158 - accuracy: 0.9962 - val_loss: 1.8547e-04 - val_accuracy: 1.0000\n",
            "Epoch 671/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0153 - accuracy: 0.9962 - val_loss: 1.8998e-04 - val_accuracy: 1.0000\n",
            "Epoch 672/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.9137e-04 - val_accuracy: 1.0000\n",
            "Epoch 673/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0116 - accuracy: 0.9971 - val_loss: 1.0549e-04 - val_accuracy: 1.0000\n",
            "Epoch 674/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 7.5383e-05 - val_accuracy: 1.0000\n",
            "Epoch 675/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0138 - accuracy: 0.9962 - val_loss: 7.6360e-05 - val_accuracy: 1.0000\n",
            "Epoch 676/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0048 - accuracy: 0.9990 - val_loss: 1.2327e-04 - val_accuracy: 1.0000\n",
            "Epoch 677/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0048 - accuracy: 0.9990 - val_loss: 1.1469e-04 - val_accuracy: 1.0000\n",
            "Epoch 678/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.0913e-04 - val_accuracy: 1.0000\n",
            "Epoch 679/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0120 - accuracy: 0.9971 - val_loss: 9.9453e-05 - val_accuracy: 1.0000\n",
            "Epoch 680/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0026 - accuracy: 0.9990 - val_loss: 1.1593e-04 - val_accuracy: 1.0000\n",
            "Epoch 681/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0049 - accuracy: 0.9990 - val_loss: 0.0139 - val_accuracy: 0.9962\n",
            "Epoch 682/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0092 - val_accuracy: 0.9962\n",
            "Epoch 683/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0142 - accuracy: 0.9981 - val_loss: 9.7155e-05 - val_accuracy: 1.0000\n",
            "Epoch 684/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 9.3654e-05 - val_accuracy: 1.0000\n",
            "Epoch 685/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 9.2233e-05 - val_accuracy: 1.0000\n",
            "Epoch 686/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0052 - accuracy: 0.9990 - val_loss: 9.1149e-05 - val_accuracy: 1.0000\n",
            "Epoch 687/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0122 - accuracy: 0.9971 - val_loss: 9.1328e-05 - val_accuracy: 1.0000\n",
            "Epoch 688/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 9.0624e-05 - val_accuracy: 1.0000\n",
            "Epoch 689/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0049 - accuracy: 0.9990 - val_loss: 9.0142e-05 - val_accuracy: 1.0000\n",
            "Epoch 690/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0048 - accuracy: 0.9990 - val_loss: 9.0038e-05 - val_accuracy: 1.0000\n",
            "Epoch 691/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0051 - accuracy: 0.9990 - val_loss: 8.9648e-05 - val_accuracy: 1.0000\n",
            "Epoch 692/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0049 - accuracy: 0.9990 - val_loss: 8.9382e-05 - val_accuracy: 1.0000\n",
            "Epoch 693/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0048 - accuracy: 0.9990 - val_loss: 8.6855e-05 - val_accuracy: 1.0000\n",
            "Epoch 694/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 8.5863e-05 - val_accuracy: 1.0000\n",
            "Epoch 695/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0047 - accuracy: 0.9990 - val_loss: 8.0137e-05 - val_accuracy: 1.0000\n",
            "Epoch 696/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 7.4367e-05 - val_accuracy: 1.0000\n",
            "Epoch 697/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 7.3811e-05 - val_accuracy: 1.0000\n",
            "Epoch 698/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0083 - accuracy: 0.9981 - val_loss: 7.3508e-05 - val_accuracy: 1.0000\n",
            "Epoch 699/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0048 - accuracy: 0.9990 - val_loss: 7.1763e-05 - val_accuracy: 1.0000\n",
            "Epoch 700/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 6.8322e-05 - val_accuracy: 1.0000\n",
            "Epoch 701/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 6.9415e-05 - val_accuracy: 1.0000\n",
            "Epoch 702/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0049 - accuracy: 0.9990 - val_loss: 6.6087e-05 - val_accuracy: 1.0000\n",
            "Epoch 703/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0161 - accuracy: 0.9971 - val_loss: 3.4342e-05 - val_accuracy: 1.0000\n",
            "Epoch 704/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0049 - accuracy: 0.9990 - val_loss: 4.1918e-06 - val_accuracy: 1.0000\n",
            "Epoch 705/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.8069e-06 - val_accuracy: 1.0000\n",
            "Epoch 706/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.6588e-06 - val_accuracy: 1.0000\n",
            "Epoch 707/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0049 - accuracy: 0.9990 - val_loss: 1.7001e-06 - val_accuracy: 1.0000\n",
            "Epoch 708/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.7178e-06 - val_accuracy: 1.0000\n",
            "Epoch 709/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0049 - accuracy: 0.9990 - val_loss: 1.7417e-06 - val_accuracy: 1.0000\n",
            "Epoch 710/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.7728e-06 - val_accuracy: 1.0000\n",
            "Epoch 711/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.8186e-06 - val_accuracy: 1.0000\n",
            "Epoch 712/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0091 - accuracy: 0.9981 - val_loss: 3.1624e-06 - val_accuracy: 1.0000\n",
            "Epoch 713/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0048 - accuracy: 0.9990 - val_loss: 3.4706e-06 - val_accuracy: 1.0000\n",
            "Epoch 714/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 4.2283e-06 - val_accuracy: 1.0000\n",
            "Epoch 715/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 5.4957e-06 - val_accuracy: 1.0000\n",
            "Epoch 716/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 6.8919e-06 - val_accuracy: 1.0000\n",
            "Epoch 717/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0047 - accuracy: 0.9990 - val_loss: 8.1136e-06 - val_accuracy: 1.0000\n",
            "Epoch 718/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 9.1145e-06 - val_accuracy: 1.0000\n",
            "Epoch 719/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 9.1395e-06 - val_accuracy: 1.0000\n",
            "Epoch 720/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 9.6723e-06 - val_accuracy: 1.0000\n",
            "Epoch 721/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0048 - accuracy: 0.9990 - val_loss: 1.0206e-05 - val_accuracy: 1.0000\n",
            "Epoch 722/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.0452e-05 - val_accuracy: 1.0000\n",
            "Epoch 723/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.0484e-05 - val_accuracy: 1.0000\n",
            "Epoch 724/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.0930e-05 - val_accuracy: 1.0000\n",
            "Epoch 725/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0034 - accuracy: 0.9990 - val_loss: 1.1846e-05 - val_accuracy: 1.0000\n",
            "Epoch 726/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 9.6059e-04 - accuracy: 1.0000 - val_loss: 1.6957e-05 - val_accuracy: 1.0000\n",
            "Epoch 727/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0048 - accuracy: 0.9990 - val_loss: 1.6545e-05 - val_accuracy: 1.0000\n",
            "Epoch 728/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.7382e-05 - val_accuracy: 1.0000\n",
            "Epoch 729/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.6822e-05 - val_accuracy: 1.0000\n",
            "Epoch 730/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.5891e-05 - val_accuracy: 1.0000\n",
            "Epoch 731/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0087 - accuracy: 0.9981 - val_loss: 1.5241e-05 - val_accuracy: 1.0000\n",
            "Epoch 732/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0048 - accuracy: 0.9990 - val_loss: 1.5599e-05 - val_accuracy: 1.0000\n",
            "Epoch 733/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.5463e-05 - val_accuracy: 1.0000\n",
            "Epoch 734/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 8.8436e-04 - accuracy: 1.0000 - val_loss: 1.5332e-05 - val_accuracy: 1.0000\n",
            "Epoch 735/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 9.9595e-04 - accuracy: 1.0000 - val_loss: 1.6752e-05 - val_accuracy: 1.0000\n",
            "Epoch 736/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0048 - accuracy: 0.9990 - val_loss: 1.7732e-05 - val_accuracy: 1.0000\n",
            "Epoch 737/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0049 - accuracy: 0.9990 - val_loss: 1.6975e-05 - val_accuracy: 1.0000\n",
            "Epoch 738/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0086 - accuracy: 0.9981 - val_loss: 1.6482e-05 - val_accuracy: 1.0000\n",
            "Epoch 739/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 9.5056e-04 - accuracy: 1.0000 - val_loss: 1.6407e-05 - val_accuracy: 1.0000\n",
            "Epoch 740/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0048 - accuracy: 0.9990 - val_loss: 1.6233e-05 - val_accuracy: 1.0000\n",
            "Epoch 741/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0049 - accuracy: 0.9990 - val_loss: 1.5835e-05 - val_accuracy: 1.0000\n",
            "Epoch 742/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.5702e-05 - val_accuracy: 1.0000\n",
            "Epoch 743/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0047 - accuracy: 0.9990 - val_loss: 1.5215e-05 - val_accuracy: 1.0000\n",
            "Epoch 744/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0085 - accuracy: 0.9981 - val_loss: 1.5226e-05 - val_accuracy: 1.0000\n",
            "Epoch 745/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 8.3241e-04 - accuracy: 1.0000 - val_loss: 1.5425e-05 - val_accuracy: 1.0000\n",
            "Epoch 746/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0049 - accuracy: 0.9990 - val_loss: 1.5118e-05 - val_accuracy: 1.0000\n",
            "Epoch 747/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0047 - accuracy: 0.9990 - val_loss: 1.5425e-05 - val_accuracy: 1.0000\n",
            "Epoch 748/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.5454e-05 - val_accuracy: 1.0000\n",
            "Epoch 749/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.5564e-05 - val_accuracy: 1.0000\n",
            "Epoch 750/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.5505e-05 - val_accuracy: 1.0000\n",
            "Epoch 751/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0048 - accuracy: 0.9990 - val_loss: 1.5492e-05 - val_accuracy: 1.0000\n",
            "Epoch 752/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.5332e-05 - val_accuracy: 1.0000\n",
            "Epoch 753/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0627 - accuracy: 0.9962 - val_loss: 7.0768e-05 - val_accuracy: 1.0000\n",
            "Epoch 754/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0048 - accuracy: 0.9990 - val_loss: 7.1561e-05 - val_accuracy: 1.0000\n",
            "Epoch 755/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 9.6848e-04 - accuracy: 1.0000 - val_loss: 7.1238e-05 - val_accuracy: 1.0000\n",
            "Epoch 756/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0048 - accuracy: 0.9990 - val_loss: 6.4896e-05 - val_accuracy: 1.0000\n",
            "Epoch 757/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0048 - accuracy: 0.9990 - val_loss: 5.6379e-05 - val_accuracy: 1.0000\n",
            "Epoch 758/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0048 - accuracy: 0.9990 - val_loss: 5.0101e-05 - val_accuracy: 1.0000\n",
            "Epoch 759/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 9.7862e-04 - accuracy: 1.0000 - val_loss: 4.6990e-05 - val_accuracy: 1.0000\n",
            "Epoch 760/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0050 - accuracy: 0.9990 - val_loss: 4.2662e-05 - val_accuracy: 1.0000\n",
            "Epoch 761/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0049 - accuracy: 0.9990 - val_loss: 3.6869e-05 - val_accuracy: 1.0000\n",
            "Epoch 762/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 9.5231e-04 - accuracy: 1.0000 - val_loss: 3.3958e-05 - val_accuracy: 1.0000\n",
            "Epoch 763/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 9.4683e-04 - accuracy: 1.0000 - val_loss: 3.2719e-05 - val_accuracy: 1.0000\n",
            "Epoch 764/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0056 - accuracy: 0.9990 - val_loss: 2.2757e-05 - val_accuracy: 1.0000\n",
            "Epoch 765/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0036 - accuracy: 0.9990 - val_loss: 0.2703 - val_accuracy: 0.9771\n",
            "Epoch 766/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0221 - accuracy: 0.9971 - val_loss: 13.5388 - val_accuracy: 0.9389\n",
            "Epoch 767/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0089 - accuracy: 0.9981 - val_loss: 2.1187e-04 - val_accuracy: 1.0000\n",
            "Epoch 768/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0048 - accuracy: 0.9990 - val_loss: 1.5130e-04 - val_accuracy: 1.0000\n",
            "Epoch 769/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0088 - accuracy: 0.9981 - val_loss: 1.5031e-04 - val_accuracy: 1.0000\n",
            "Epoch 770/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0056 - accuracy: 0.9981 - val_loss: 1.9801e-04 - val_accuracy: 1.0000\n",
            "Epoch 771/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.3480e-04 - val_accuracy: 1.0000\n",
            "Epoch 772/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.0905e-04 - val_accuracy: 1.0000\n",
            "Epoch 773/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 9.4013e-05 - val_accuracy: 1.0000\n",
            "Epoch 774/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0089 - accuracy: 0.9981 - val_loss: 8.2600e-05 - val_accuracy: 1.0000\n",
            "Epoch 775/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 9.8879e-05 - val_accuracy: 1.0000\n",
            "Epoch 776/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0050 - accuracy: 0.9990 - val_loss: 9.1733e-05 - val_accuracy: 1.0000\n",
            "Epoch 777/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 9.3169e-04 - accuracy: 1.0000 - val_loss: 8.4421e-05 - val_accuracy: 1.0000\n",
            "Epoch 778/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 9.7040e-04 - accuracy: 1.0000 - val_loss: 7.9818e-05 - val_accuracy: 1.0000\n",
            "Epoch 779/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0165 - accuracy: 0.9990 - val_loss: 6.8018e-05 - val_accuracy: 1.0000\n",
            "Epoch 780/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 8.6612e-04 - accuracy: 1.0000 - val_loss: 6.5491e-05 - val_accuracy: 1.0000\n",
            "Epoch 781/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0064 - accuracy: 0.9981 - val_loss: 0.0115 - val_accuracy: 0.9962\n",
            "Epoch 782/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0151 - accuracy: 0.9981 - val_loss: 2.7145e-14 - val_accuracy: 1.0000\n",
            "Epoch 783/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0203 - accuracy: 0.9952 - val_loss: 1.4048e-18 - val_accuracy: 1.0000\n",
            "Epoch 784/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0204 - accuracy: 0.9952 - val_loss: 3.5973e-19 - val_accuracy: 1.0000\n",
            "Epoch 785/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0130 - accuracy: 0.9981 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 786/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0102 - accuracy: 0.9971 - val_loss: 4.3658e-04 - val_accuracy: 1.0000\n",
            "Epoch 787/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0087 - accuracy: 0.9981 - val_loss: 2.4883e-04 - val_accuracy: 1.0000\n",
            "Epoch 788/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0124 - accuracy: 0.9971 - val_loss: 2.3415e-04 - val_accuracy: 1.0000\n",
            "Epoch 789/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0047 - accuracy: 0.9990 - val_loss: 1.9501e-04 - val_accuracy: 1.0000\n",
            "Epoch 790/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0087 - accuracy: 0.9981 - val_loss: 1.6425e-04 - val_accuracy: 1.0000\n",
            "Epoch 791/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0929 - accuracy: 0.9962 - val_loss: 3.3460e-04 - val_accuracy: 1.0000\n",
            "Epoch 792/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0067 - accuracy: 0.9981 - val_loss: 4.2968e-04 - val_accuracy: 1.0000\n",
            "Epoch 793/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0127 - accuracy: 0.9971 - val_loss: 7.0869e-05 - val_accuracy: 1.0000\n",
            "Epoch 794/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0061 - accuracy: 0.9990 - val_loss: 6.7453e-05 - val_accuracy: 1.0000\n",
            "Epoch 795/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0034 - accuracy: 0.9990 - val_loss: 7.1300e-05 - val_accuracy: 1.0000\n",
            "Epoch 796/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0219 - accuracy: 0.9981 - val_loss: 9.0808e-05 - val_accuracy: 1.0000\n",
            "Epoch 797/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0048 - accuracy: 0.9990 - val_loss: 9.5483e-05 - val_accuracy: 1.0000\n",
            "Epoch 798/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0088 - accuracy: 0.9981 - val_loss: 8.8801e-05 - val_accuracy: 1.0000\n",
            "Epoch 799/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 8.2918e-05 - val_accuracy: 1.0000\n",
            "Epoch 800/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 9.5649e-05 - val_accuracy: 1.0000\n",
            "Epoch 801/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0050 - accuracy: 0.9990 - val_loss: 1.1663e-04 - val_accuracy: 1.0000\n",
            "Epoch 802/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0050 - accuracy: 0.9990 - val_loss: 1.3975e-04 - val_accuracy: 1.0000\n",
            "Epoch 803/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0048 - accuracy: 0.9990 - val_loss: 1.4142e-04 - val_accuracy: 1.0000\n",
            "Epoch 804/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0142 - accuracy: 0.9990 - val_loss: 6.9738e-05 - val_accuracy: 1.0000\n",
            "Epoch 805/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0057 - accuracy: 0.9990 - val_loss: 1.8396e-07 - val_accuracy: 1.0000\n",
            "Epoch 806/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 8.6385e-04 - accuracy: 1.0000 - val_loss: 6.4288e-05 - val_accuracy: 1.0000\n",
            "Epoch 807/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0049 - accuracy: 0.9990 - val_loss: 2.0951e-05 - val_accuracy: 1.0000\n",
            "Epoch 808/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 8.6105e-04 - accuracy: 1.0000 - val_loss: 1.0519e-05 - val_accuracy: 1.0000\n",
            "Epoch 809/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0048 - accuracy: 0.9990 - val_loss: 6.6997e-06 - val_accuracy: 1.0000\n",
            "Epoch 810/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 8.3965e-04 - accuracy: 1.0000 - val_loss: 4.8373e-06 - val_accuracy: 1.0000\n",
            "Epoch 811/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 9.7169e-04 - accuracy: 1.0000 - val_loss: 3.7903e-06 - val_accuracy: 1.0000\n",
            "Epoch 812/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0210 - accuracy: 0.9971 - val_loss: 2.1174e-05 - val_accuracy: 1.0000\n",
            "Epoch 813/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 3.4566e-05 - val_accuracy: 1.0000\n",
            "Epoch 814/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 2.3910e-05 - val_accuracy: 1.0000\n",
            "Epoch 815/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0094 - accuracy: 0.9981 - val_loss: 6.9489e-05 - val_accuracy: 1.0000\n",
            "Epoch 816/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 8.6362e-04 - accuracy: 1.0000 - val_loss: 7.3053e-05 - val_accuracy: 1.0000\n",
            "Epoch 817/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0423 - accuracy: 0.9952 - val_loss: 6.9800e-05 - val_accuracy: 1.0000\n",
            "Epoch 818/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 9.8700e-04 - accuracy: 1.0000 - val_loss: 6.8876e-05 - val_accuracy: 1.0000\n",
            "Epoch 819/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 9.1678e-04 - accuracy: 1.0000 - val_loss: 6.8504e-05 - val_accuracy: 1.0000\n",
            "Epoch 820/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 8.6152e-04 - accuracy: 1.0000 - val_loss: 6.8240e-05 - val_accuracy: 1.0000\n",
            "Epoch 821/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 6.7987e-05 - val_accuracy: 1.0000\n",
            "Epoch 822/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0049 - accuracy: 0.9990 - val_loss: 6.8077e-05 - val_accuracy: 1.0000\n",
            "Epoch 823/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0052 - accuracy: 0.9990 - val_loss: 6.8181e-05 - val_accuracy: 1.0000\n",
            "Epoch 824/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0050 - accuracy: 0.9990 - val_loss: 6.8800e-05 - val_accuracy: 1.0000\n",
            "Epoch 825/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 8.8533e-04 - accuracy: 1.0000 - val_loss: 6.8268e-05 - val_accuracy: 1.0000\n",
            "Epoch 826/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 8.6514e-04 - accuracy: 1.0000 - val_loss: 6.7768e-05 - val_accuracy: 1.0000\n",
            "Epoch 827/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0048 - accuracy: 0.9990 - val_loss: 6.7487e-05 - val_accuracy: 1.0000\n",
            "Epoch 828/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 8.9844e-04 - accuracy: 1.0000 - val_loss: 6.6948e-05 - val_accuracy: 1.0000\n",
            "Epoch 829/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 7.7713e-04 - accuracy: 1.0000 - val_loss: 6.6532e-05 - val_accuracy: 1.0000\n",
            "Epoch 830/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 8.9923e-04 - accuracy: 1.0000 - val_loss: 6.6163e-05 - val_accuracy: 1.0000\n",
            "Epoch 831/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 9.5807e-04 - accuracy: 1.0000 - val_loss: 6.5732e-05 - val_accuracy: 1.0000\n",
            "Epoch 832/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0047 - accuracy: 0.9990 - val_loss: 6.5731e-05 - val_accuracy: 1.0000\n",
            "Epoch 833/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0176 - accuracy: 0.9981 - val_loss: 6.4195e-05 - val_accuracy: 1.0000\n",
            "Epoch 834/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0086 - accuracy: 0.9981 - val_loss: 6.4406e-05 - val_accuracy: 1.0000\n",
            "Epoch 835/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0050 - accuracy: 0.9990 - val_loss: 6.5191e-05 - val_accuracy: 1.0000\n",
            "Epoch 836/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0054 - accuracy: 0.9990 - val_loss: 6.6664e-05 - val_accuracy: 1.0000\n",
            "Epoch 837/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 7.6644e-04 - accuracy: 1.0000 - val_loss: 6.5891e-05 - val_accuracy: 1.0000\n",
            "Epoch 838/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 8.8916e-04 - accuracy: 1.0000 - val_loss: 6.5126e-05 - val_accuracy: 1.0000\n",
            "Epoch 839/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 6.4511e-05 - val_accuracy: 1.0000\n",
            "Epoch 840/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 6.4590e-05 - val_accuracy: 1.0000\n",
            "Epoch 841/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 8.5919e-04 - accuracy: 1.0000 - val_loss: 6.4035e-05 - val_accuracy: 1.0000\n",
            "Epoch 842/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 9.9313e-04 - accuracy: 1.0000 - val_loss: 6.3570e-05 - val_accuracy: 1.0000\n",
            "Epoch 843/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 9.8639e-04 - accuracy: 1.0000 - val_loss: 6.3090e-05 - val_accuracy: 1.0000\n",
            "Epoch 844/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0049 - accuracy: 0.9990 - val_loss: 6.2945e-05 - val_accuracy: 1.0000\n",
            "Epoch 845/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 7.6612e-04 - accuracy: 1.0000 - val_loss: 6.2601e-05 - val_accuracy: 1.0000\n",
            "Epoch 846/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 9.1382e-04 - accuracy: 1.0000 - val_loss: 6.2148e-05 - val_accuracy: 1.0000\n",
            "Epoch 847/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 9.2325e-04 - accuracy: 1.0000 - val_loss: 6.1731e-05 - val_accuracy: 1.0000\n",
            "Epoch 848/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 8.4208e-04 - accuracy: 1.0000 - val_loss: 6.1317e-05 - val_accuracy: 1.0000\n",
            "Epoch 849/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 8.6911e-04 - accuracy: 1.0000 - val_loss: 6.0869e-05 - val_accuracy: 1.0000\n",
            "Epoch 850/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 7.8702e-04 - accuracy: 1.0000 - val_loss: 6.0475e-05 - val_accuracy: 1.0000\n",
            "Epoch 851/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 8.8604e-04 - accuracy: 1.0000 - val_loss: 6.0046e-05 - val_accuracy: 1.0000\n",
            "Epoch 852/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 9.2378e-04 - accuracy: 1.0000 - val_loss: 5.9631e-05 - val_accuracy: 1.0000\n",
            "Epoch 853/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0047 - accuracy: 0.9990 - val_loss: 5.9628e-05 - val_accuracy: 1.0000\n",
            "Epoch 854/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 7.1471e-04 - accuracy: 1.0000 - val_loss: 5.9355e-05 - val_accuracy: 1.0000\n",
            "Epoch 855/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0048 - accuracy: 0.9990 - val_loss: 5.9177e-05 - val_accuracy: 1.0000\n",
            "Epoch 856/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 8.4137e-04 - accuracy: 1.0000 - val_loss: 5.8996e-05 - val_accuracy: 1.0000\n",
            "Epoch 857/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 8.6539e-04 - accuracy: 1.0000 - val_loss: 5.8653e-05 - val_accuracy: 1.0000\n",
            "Epoch 858/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 8.5978e-04 - accuracy: 1.0000 - val_loss: 5.8260e-05 - val_accuracy: 1.0000\n",
            "Epoch 859/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 8.2636e-04 - accuracy: 1.0000 - val_loss: 5.7318e-05 - val_accuracy: 1.0000\n",
            "Epoch 860/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 8.9183e-04 - accuracy: 1.0000 - val_loss: 5.4019e-05 - val_accuracy: 1.0000\n",
            "Epoch 861/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0048 - accuracy: 0.9990 - val_loss: 5.4235e-05 - val_accuracy: 1.0000\n",
            "Epoch 862/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 8.2810e-04 - accuracy: 1.0000 - val_loss: 5.3504e-05 - val_accuracy: 1.0000\n",
            "Epoch 863/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0047 - accuracy: 0.9990 - val_loss: 5.3203e-05 - val_accuracy: 1.0000\n",
            "Epoch 864/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 7.8259e-04 - accuracy: 1.0000 - val_loss: 5.1678e-05 - val_accuracy: 1.0000\n",
            "Epoch 865/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 7.7773e-04 - accuracy: 1.0000 - val_loss: 5.1915e-05 - val_accuracy: 1.0000\n",
            "Epoch 866/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0048 - accuracy: 0.9990 - val_loss: 5.1881e-05 - val_accuracy: 1.0000\n",
            "Epoch 867/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 6.7718e-04 - accuracy: 1.0000 - val_loss: 5.1745e-05 - val_accuracy: 1.0000\n",
            "Epoch 868/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 7.7141e-04 - accuracy: 1.0000 - val_loss: 5.2068e-05 - val_accuracy: 1.0000\n",
            "Epoch 869/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0048 - accuracy: 0.9990 - val_loss: 5.1805e-05 - val_accuracy: 1.0000\n",
            "Epoch 870/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0049 - accuracy: 0.9990 - val_loss: 5.1438e-05 - val_accuracy: 1.0000\n",
            "Epoch 871/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 6.8547e-04 - accuracy: 1.0000 - val_loss: 5.2078e-05 - val_accuracy: 1.0000\n",
            "Epoch 872/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0048 - accuracy: 0.9990 - val_loss: 5.0861e-05 - val_accuracy: 1.0000\n",
            "Epoch 873/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0049 - accuracy: 0.9990 - val_loss: 4.9704e-05 - val_accuracy: 1.0000\n",
            "Epoch 874/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 6.8269e-04 - accuracy: 1.0000 - val_loss: 4.9861e-05 - val_accuracy: 1.0000\n",
            "Epoch 875/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 8.2867e-04 - accuracy: 1.0000 - val_loss: 4.9864e-05 - val_accuracy: 1.0000\n",
            "Epoch 876/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0048 - accuracy: 0.9990 - val_loss: 4.9771e-05 - val_accuracy: 1.0000\n",
            "Epoch 877/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 7.4391e-04 - accuracy: 1.0000 - val_loss: 4.9783e-05 - val_accuracy: 1.0000\n",
            "Epoch 878/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 5.9214e-04 - accuracy: 1.0000 - val_loss: 4.8294e-05 - val_accuracy: 1.0000\n",
            "Epoch 879/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 8.1554e-04 - accuracy: 1.0000 - val_loss: 4.7310e-05 - val_accuracy: 1.0000\n",
            "Epoch 880/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0048 - accuracy: 0.9990 - val_loss: 4.7201e-05 - val_accuracy: 1.0000\n",
            "Epoch 881/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0048 - accuracy: 0.9990 - val_loss: 4.6802e-05 - val_accuracy: 1.0000\n",
            "Epoch 882/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0049 - accuracy: 0.9990 - val_loss: 4.6788e-05 - val_accuracy: 1.0000\n",
            "Epoch 883/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 6.9327e-04 - accuracy: 1.0000 - val_loss: 4.6477e-05 - val_accuracy: 1.0000\n",
            "Epoch 884/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 8.2278e-04 - accuracy: 1.0000 - val_loss: 4.6875e-05 - val_accuracy: 1.0000\n",
            "Epoch 885/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 7.6449e-04 - accuracy: 1.0000 - val_loss: 4.6390e-05 - val_accuracy: 1.0000\n",
            "Epoch 886/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 6.2875e-04 - accuracy: 1.0000 - val_loss: 4.6100e-05 - val_accuracy: 1.0000\n",
            "Epoch 887/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0048 - accuracy: 0.9990 - val_loss: 4.5654e-05 - val_accuracy: 1.0000\n",
            "Epoch 888/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 6.5877e-04 - accuracy: 1.0000 - val_loss: 4.2623e-05 - val_accuracy: 1.0000\n",
            "Epoch 889/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 5.9711e-04 - accuracy: 1.0000 - val_loss: 3.5756e-05 - val_accuracy: 1.0000\n",
            "Epoch 890/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0048 - accuracy: 0.9990 - val_loss: 3.5966e-05 - val_accuracy: 1.0000\n",
            "Epoch 891/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 7.8875e-04 - accuracy: 1.0000 - val_loss: 3.5370e-05 - val_accuracy: 1.0000\n",
            "Epoch 892/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 7.3261e-04 - accuracy: 1.0000 - val_loss: 3.5264e-05 - val_accuracy: 1.0000\n",
            "Epoch 893/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 5.7519e-04 - accuracy: 1.0000 - val_loss: 3.3723e-05 - val_accuracy: 1.0000\n",
            "Epoch 894/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 6.0981e-04 - accuracy: 1.0000 - val_loss: 3.2988e-05 - val_accuracy: 1.0000\n",
            "Epoch 895/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0050 - accuracy: 0.9990 - val_loss: 3.2188e-05 - val_accuracy: 1.0000\n",
            "Epoch 896/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 7.5674e-04 - accuracy: 1.0000 - val_loss: 3.1911e-05 - val_accuracy: 1.0000\n",
            "Epoch 897/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 6.5253e-04 - accuracy: 1.0000 - val_loss: 3.1364e-05 - val_accuracy: 1.0000\n",
            "Epoch 898/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 7.6039e-04 - accuracy: 1.0000 - val_loss: 3.1370e-05 - val_accuracy: 1.0000\n",
            "Epoch 899/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0048 - accuracy: 0.9990 - val_loss: 3.1527e-05 - val_accuracy: 1.0000\n",
            "Epoch 900/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 5.9607e-04 - accuracy: 1.0000 - val_loss: 3.0793e-05 - val_accuracy: 1.0000\n",
            "Epoch 901/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0049 - accuracy: 0.9990 - val_loss: 3.0757e-05 - val_accuracy: 1.0000\n",
            "Epoch 902/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0048 - accuracy: 0.9990 - val_loss: 3.0560e-05 - val_accuracy: 1.0000\n",
            "Epoch 903/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0049 - accuracy: 0.9990 - val_loss: 3.0593e-05 - val_accuracy: 1.0000\n",
            "Epoch 904/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 7.4512e-04 - accuracy: 1.0000 - val_loss: 2.9839e-05 - val_accuracy: 1.0000\n",
            "Epoch 905/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 7.2791e-04 - accuracy: 1.0000 - val_loss: 2.9501e-05 - val_accuracy: 1.0000\n",
            "Epoch 906/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0091 - accuracy: 0.9981 - val_loss: 2.9658e-05 - val_accuracy: 1.0000\n",
            "Epoch 907/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 7.1626e-04 - accuracy: 1.0000 - val_loss: 2.9930e-05 - val_accuracy: 1.0000\n",
            "Epoch 908/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 7.9914e-04 - accuracy: 1.0000 - val_loss: 2.9372e-05 - val_accuracy: 1.0000\n",
            "Epoch 909/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0329 - accuracy: 0.9971 - val_loss: 5.0421e-05 - val_accuracy: 1.0000\n",
            "Epoch 910/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0117 - accuracy: 0.9971 - val_loss: 1.8022e-05 - val_accuracy: 1.0000\n",
            "Epoch 911/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0049 - accuracy: 0.9990 - val_loss: 1.5453e-05 - val_accuracy: 1.0000\n",
            "Epoch 912/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 6.1437e-04 - accuracy: 1.0000 - val_loss: 1.3466e-05 - val_accuracy: 1.0000\n",
            "Epoch 913/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0084 - accuracy: 0.9981 - val_loss: 2.1348e-04 - val_accuracy: 1.0000\n",
            "Epoch 914/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 6.3696e-04 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 915/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0237 - accuracy: 0.9990 - val_loss: 3.4475e-05 - val_accuracy: 1.0000\n",
            "Epoch 916/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0049 - accuracy: 0.9990 - val_loss: 5.0611e-05 - val_accuracy: 1.0000\n",
            "Epoch 917/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0116 - accuracy: 0.9962 - val_loss: 1.0617e-05 - val_accuracy: 1.0000\n",
            "Epoch 918/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0048 - accuracy: 0.9990 - val_loss: 5.0211e-08 - val_accuracy: 1.0000\n",
            "Epoch 919/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 6.4459e-04 - accuracy: 1.0000 - val_loss: 1.7518e-07 - val_accuracy: 1.0000\n",
            "Epoch 920/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 6.5520e-04 - accuracy: 1.0000 - val_loss: 5.5636e-07 - val_accuracy: 1.0000\n",
            "Epoch 921/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0137 - accuracy: 0.9981 - val_loss: 1.1921e-06 - val_accuracy: 1.0000\n",
            "Epoch 922/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0364 - accuracy: 0.9990 - val_loss: 0.2898 - val_accuracy: 0.9924\n",
            "Epoch 923/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0098 - accuracy: 0.9981 - val_loss: 2.2425e-09 - val_accuracy: 1.0000\n",
            "Epoch 924/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0360 - accuracy: 0.9981 - val_loss: 6.2916e-18 - val_accuracy: 1.0000\n",
            "Epoch 925/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0288 - accuracy: 0.9990 - val_loss: 1.9742 - val_accuracy: 0.9962\n",
            "Epoch 926/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 7.1712e-04 - accuracy: 1.0000 - val_loss: 4.2817e-07 - val_accuracy: 1.0000\n",
            "Epoch 927/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0049 - accuracy: 0.9990 - val_loss: 3.4619e-07 - val_accuracy: 1.0000\n",
            "Epoch 928/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 7.0862e-04 - accuracy: 1.0000 - val_loss: 2.0533e-07 - val_accuracy: 1.0000\n",
            "Epoch 929/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 7.4646e-04 - accuracy: 1.0000 - val_loss: 1.0577e-07 - val_accuracy: 1.0000\n",
            "Epoch 930/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 6.7216e-04 - accuracy: 1.0000 - val_loss: 6.3219e-08 - val_accuracy: 1.0000\n",
            "Epoch 931/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.8360e-07 - val_accuracy: 1.0000\n",
            "Epoch 932/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 7.1442e-04 - accuracy: 1.0000 - val_loss: 1.1222e-07 - val_accuracy: 1.0000\n",
            "Epoch 933/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 6.4014e-04 - accuracy: 1.0000 - val_loss: 5.4313e-08 - val_accuracy: 1.0000\n",
            "Epoch 934/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 7.1788e-04 - accuracy: 1.0000 - val_loss: 1.5915e-08 - val_accuracy: 1.0000\n",
            "Epoch 935/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 7.3666e-04 - accuracy: 1.0000 - val_loss: 9.5036e-09 - val_accuracy: 1.0000\n",
            "Epoch 936/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 5.1095e-04 - accuracy: 1.0000 - val_loss: 6.0392e-09 - val_accuracy: 1.0000\n",
            "Epoch 937/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0089 - accuracy: 0.9981 - val_loss: 4.9228e-09 - val_accuracy: 1.0000\n",
            "Epoch 938/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0047 - accuracy: 0.9990 - val_loss: 4.2686e-09 - val_accuracy: 1.0000\n",
            "Epoch 939/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0047 - accuracy: 0.9990 - val_loss: 4.0359e-09 - val_accuracy: 1.0000\n",
            "Epoch 940/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 5.8473e-04 - accuracy: 1.0000 - val_loss: 3.5144e-09 - val_accuracy: 1.0000\n",
            "Epoch 941/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 5.5073e-04 - accuracy: 1.0000 - val_loss: 3.3242e-09 - val_accuracy: 1.0000\n",
            "Epoch 942/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 4.6007e-04 - accuracy: 1.0000 - val_loss: 3.0731e-09 - val_accuracy: 1.0000\n",
            "Epoch 943/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 4.9334e-04 - accuracy: 1.0000 - val_loss: 2.8846e-09 - val_accuracy: 1.0000\n",
            "Epoch 944/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 4.1295e-04 - accuracy: 1.0000 - val_loss: 2.7739e-09 - val_accuracy: 1.0000\n",
            "Epoch 945/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 5.7491e-04 - accuracy: 1.0000 - val_loss: 2.5820e-09 - val_accuracy: 1.0000\n",
            "Epoch 946/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 4.7185e-04 - accuracy: 1.0000 - val_loss: 2.6203e-09 - val_accuracy: 1.0000\n",
            "Epoch 947/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 5.1787e-04 - accuracy: 1.0000 - val_loss: 1.7949e-09 - val_accuracy: 1.0000\n",
            "Epoch 948/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 7.7270e-04 - accuracy: 1.0000 - val_loss: 1.1737e-09 - val_accuracy: 1.0000\n",
            "Epoch 949/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 5.5589e-04 - accuracy: 1.0000 - val_loss: 1.6550e-09 - val_accuracy: 1.0000\n",
            "Epoch 950/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 6.0741e-04 - accuracy: 1.0000 - val_loss: 1.9931e-09 - val_accuracy: 1.0000\n",
            "Epoch 951/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0176 - accuracy: 0.9981 - val_loss: 1.3678e-19 - val_accuracy: 1.0000\n",
            "Epoch 952/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 5.2949e-04 - accuracy: 1.0000 - val_loss: 1.9996e-18 - val_accuracy: 1.0000\n",
            "Epoch 953/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 4.5174e-04 - accuracy: 1.0000 - val_loss: 3.6287e-17 - val_accuracy: 1.0000\n",
            "Epoch 954/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 3.4805e-04 - accuracy: 1.0000 - val_loss: 6.2660e-17 - val_accuracy: 1.0000\n",
            "Epoch 955/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0046 - accuracy: 0.9990 - val_loss: 1.0446e-16 - val_accuracy: 1.0000\n",
            "Epoch 956/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0047 - accuracy: 0.9990 - val_loss: 1.4958e-16 - val_accuracy: 1.0000\n",
            "Epoch 957/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 5.6191e-04 - accuracy: 1.0000 - val_loss: 1.9708e-16 - val_accuracy: 1.0000\n",
            "Epoch 958/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0046 - accuracy: 0.9990 - val_loss: 2.2379e-16 - val_accuracy: 1.0000\n",
            "Epoch 959/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0041 - accuracy: 0.9990 - val_loss: 4.4302e-16 - val_accuracy: 1.0000\n",
            "Epoch 960/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 3.7597e-04 - accuracy: 1.0000 - val_loss: 4.7877e-13 - val_accuracy: 1.0000\n",
            "Epoch 961/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0027 - accuracy: 0.9990 - val_loss: 1.9054e-14 - val_accuracy: 1.0000\n",
            "Epoch 962/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 3.4841e-04 - accuracy: 1.0000 - val_loss: 5.9963e-15 - val_accuracy: 1.0000\n",
            "Epoch 963/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 3.7637e-04 - accuracy: 1.0000 - val_loss: 2.9974e-15 - val_accuracy: 1.0000\n",
            "Epoch 964/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 3.7213e-04 - accuracy: 1.0000 - val_loss: 2.0248e-15 - val_accuracy: 1.0000\n",
            "Epoch 965/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0040 - accuracy: 0.9990 - val_loss: 2.7964e-15 - val_accuracy: 1.0000\n",
            "Epoch 966/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0036 - accuracy: 0.9990 - val_loss: 2.8442e-15 - val_accuracy: 1.0000\n",
            "Epoch 967/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 3.3059e-04 - accuracy: 1.0000 - val_loss: 5.6415e-15 - val_accuracy: 1.0000\n",
            "Epoch 968/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 3.0293e-04 - accuracy: 1.0000 - val_loss: 4.3975e-15 - val_accuracy: 1.0000\n",
            "Epoch 969/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 4.0249e-04 - accuracy: 1.0000 - val_loss: 3.8557e-15 - val_accuracy: 1.0000\n",
            "Epoch 970/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 2.8461e-04 - accuracy: 1.0000 - val_loss: 3.6423e-15 - val_accuracy: 1.0000\n",
            "Epoch 971/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 4.4448e-04 - accuracy: 1.0000 - val_loss: 3.3579e-15 - val_accuracy: 1.0000\n",
            "Epoch 972/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 7.3805e-04 - accuracy: 1.0000 - val_loss: 7.9394e-15 - val_accuracy: 1.0000\n",
            "Epoch 973/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 3.0968e-04 - accuracy: 1.0000 - val_loss: 6.0177e-15 - val_accuracy: 1.0000\n",
            "Epoch 974/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 2.9817e-04 - accuracy: 1.0000 - val_loss: 2.9001e-15 - val_accuracy: 1.0000\n",
            "Epoch 975/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 2.7729e-04 - accuracy: 1.0000 - val_loss: 2.3819e-15 - val_accuracy: 1.0000\n",
            "Epoch 976/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 2.6375e-04 - accuracy: 1.0000 - val_loss: 2.2246e-15 - val_accuracy: 1.0000\n",
            "Epoch 977/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 3.7900e-04 - accuracy: 1.0000 - val_loss: 1.6719e-15 - val_accuracy: 1.0000\n",
            "Epoch 978/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0047 - accuracy: 0.9990 - val_loss: 1.6502e-15 - val_accuracy: 1.0000\n",
            "Epoch 979/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 3.9822e-04 - accuracy: 1.0000 - val_loss: 1.6092e-15 - val_accuracy: 1.0000\n",
            "Epoch 980/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 3.6056e-04 - accuracy: 1.0000 - val_loss: 1.7921e-15 - val_accuracy: 1.0000\n",
            "Epoch 981/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 3.7022e-04 - accuracy: 1.0000 - val_loss: 1.7713e-15 - val_accuracy: 1.0000\n",
            "Epoch 982/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0046 - accuracy: 0.9990 - val_loss: 1.7096e-15 - val_accuracy: 1.0000\n",
            "Epoch 983/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 4.1481e-04 - accuracy: 1.0000 - val_loss: 1.6474e-15 - val_accuracy: 1.0000\n",
            "Epoch 984/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 3.4773e-04 - accuracy: 1.0000 - val_loss: 1.6580e-15 - val_accuracy: 1.0000\n",
            "Epoch 985/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 3.3943e-04 - accuracy: 1.0000 - val_loss: 1.6493e-15 - val_accuracy: 1.0000\n",
            "Epoch 986/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 0.0046 - accuracy: 0.9990 - val_loss: 1.7320e-15 - val_accuracy: 1.0000\n",
            "Epoch 987/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 4.1248e-04 - accuracy: 1.0000 - val_loss: 1.7492e-15 - val_accuracy: 1.0000\n",
            "Epoch 988/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 2.3975e-04 - accuracy: 1.0000 - val_loss: 1.7416e-15 - val_accuracy: 1.0000\n",
            "Epoch 989/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 3.2366e-04 - accuracy: 1.0000 - val_loss: 1.7601e-15 - val_accuracy: 1.0000\n",
            "Epoch 990/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 3.5472e-04 - accuracy: 1.0000 - val_loss: 1.6873e-15 - val_accuracy: 1.0000\n",
            "Epoch 991/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 2.7927e-04 - accuracy: 1.0000 - val_loss: 1.6209e-15 - val_accuracy: 1.0000\n",
            "Epoch 992/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 2.8832e-04 - accuracy: 1.0000 - val_loss: 1.7061e-15 - val_accuracy: 1.0000\n",
            "Epoch 993/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 3.4067e-04 - accuracy: 1.0000 - val_loss: 1.6560e-15 - val_accuracy: 1.0000\n",
            "Epoch 994/1000\n",
            "33/33 [==============================] - 1s 41ms/step - loss: 3.1817e-04 - accuracy: 1.0000 - val_loss: 1.6019e-15 - val_accuracy: 1.0000\n",
            "Epoch 995/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 0.0047 - accuracy: 0.9990 - val_loss: 1.6448e-15 - val_accuracy: 1.0000\n",
            "Epoch 996/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 1.8058e-04 - accuracy: 1.0000 - val_loss: 1.6477e-15 - val_accuracy: 1.0000\n",
            "Epoch 997/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 2.8700e-04 - accuracy: 1.0000 - val_loss: 1.7106e-15 - val_accuracy: 1.0000\n",
            "Epoch 998/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 2.8567e-04 - accuracy: 1.0000 - val_loss: 1.6366e-15 - val_accuracy: 1.0000\n",
            "Epoch 999/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 3.6129e-04 - accuracy: 1.0000 - val_loss: 1.6691e-15 - val_accuracy: 1.0000\n",
            "Epoch 1000/1000\n",
            "33/33 [==============================] - 1s 42ms/step - loss: 3.7820e-04 - accuracy: 1.0000 - val_loss: 1.6595e-15 - val_accuracy: 1.0000\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1200x400 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "206/206 [==============================] - 13s 53ms/step - loss: 2.6274 - accuracy: 0.8622 - val_loss: 0.2606 - val_accuracy: 0.8950\n",
            "Epoch 2/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.3425 - accuracy: 0.8865 - val_loss: 0.2092 - val_accuracy: 0.9132\n",
            "Epoch 3/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.2304 - accuracy: 0.8880 - val_loss: 0.2859 - val_accuracy: 0.8841\n",
            "Epoch 4/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.2014 - accuracy: 0.8948 - val_loss: 0.1314 - val_accuracy: 0.9405\n",
            "Epoch 5/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.2183 - accuracy: 0.8917 - val_loss: 0.1595 - val_accuracy: 0.9017\n",
            "Epoch 6/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1727 - accuracy: 0.9049 - val_loss: 0.1042 - val_accuracy: 0.9478\n",
            "Epoch 7/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.2965 - accuracy: 0.8900 - val_loss: 0.2196 - val_accuracy: 0.8914\n",
            "Epoch 8/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.2010 - accuracy: 0.9035 - val_loss: 0.1921 - val_accuracy: 0.8865\n",
            "Epoch 9/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1745 - accuracy: 0.9041 - val_loss: 0.1449 - val_accuracy: 0.9363\n",
            "Epoch 10/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1628 - accuracy: 0.9102 - val_loss: 0.1045 - val_accuracy: 0.9478\n",
            "Epoch 11/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1820 - accuracy: 0.9086 - val_loss: 0.3865 - val_accuracy: 0.8956\n",
            "Epoch 12/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1403 - accuracy: 0.9132 - val_loss: 0.1065 - val_accuracy: 0.9502\n",
            "Epoch 13/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1192 - accuracy: 0.9212 - val_loss: 0.0991 - val_accuracy: 0.9666\n",
            "Epoch 14/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1552 - accuracy: 0.9214 - val_loss: 0.2325 - val_accuracy: 0.9454\n",
            "Epoch 15/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1621 - accuracy: 0.9171 - val_loss: 0.0733 - val_accuracy: 0.9660\n",
            "Epoch 16/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1284 - accuracy: 0.9238 - val_loss: 0.1461 - val_accuracy: 0.9490\n",
            "Epoch 17/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.2511 - accuracy: 0.9323 - val_loss: 0.5205 - val_accuracy: 0.9114\n",
            "Epoch 18/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.2042 - accuracy: 0.8979 - val_loss: 0.2611 - val_accuracy: 0.8896\n",
            "Epoch 19/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1465 - accuracy: 0.9165 - val_loss: 0.1695 - val_accuracy: 0.9472\n",
            "Epoch 20/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1089 - accuracy: 0.9445 - val_loss: 0.1842 - val_accuracy: 0.9600\n",
            "Epoch 21/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1441 - accuracy: 0.9370 - val_loss: 0.1013 - val_accuracy: 0.9612\n",
            "Epoch 22/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1168 - accuracy: 0.9436 - val_loss: 0.1002 - val_accuracy: 0.9672\n",
            "Epoch 23/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1016 - accuracy: 0.9528 - val_loss: 0.0627 - val_accuracy: 0.9763\n",
            "Epoch 24/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0981 - accuracy: 0.9487 - val_loss: 0.1423 - val_accuracy: 0.9666\n",
            "Epoch 25/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1094 - accuracy: 0.9489 - val_loss: 0.1613 - val_accuracy: 0.9672\n",
            "Epoch 26/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.5241 - accuracy: 0.8724 - val_loss: 0.4806 - val_accuracy: 0.9339\n",
            "Epoch 27/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.2275 - accuracy: 0.8580 - val_loss: 0.1362 - val_accuracy: 0.9636\n",
            "Epoch 28/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.2279 - accuracy: 0.9191 - val_loss: 0.4301 - val_accuracy: 0.9581\n",
            "Epoch 29/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1991 - accuracy: 0.8962 - val_loss: 0.1621 - val_accuracy: 0.8883\n",
            "Epoch 30/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1364 - accuracy: 0.9127 - val_loss: 0.1104 - val_accuracy: 0.9533\n",
            "Epoch 31/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1072 - accuracy: 0.9288 - val_loss: 0.1015 - val_accuracy: 0.9642\n",
            "Epoch 32/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0959 - accuracy: 0.9379 - val_loss: 0.2488 - val_accuracy: 0.9527\n",
            "Epoch 33/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1084 - accuracy: 0.9499 - val_loss: 0.1039 - val_accuracy: 0.9715\n",
            "Epoch 34/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1097 - accuracy: 0.9534 - val_loss: 0.1310 - val_accuracy: 0.9448\n",
            "Epoch 35/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0974 - accuracy: 0.9511 - val_loss: 0.1142 - val_accuracy: 0.9703\n",
            "Epoch 36/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0893 - accuracy: 0.9602 - val_loss: 0.0688 - val_accuracy: 0.9745\n",
            "Epoch 37/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0942 - accuracy: 0.9577 - val_loss: 0.1129 - val_accuracy: 0.9782\n",
            "Epoch 38/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0794 - accuracy: 0.9625 - val_loss: 0.1089 - val_accuracy: 0.9757\n",
            "Epoch 39/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0818 - accuracy: 0.9627 - val_loss: 0.0819 - val_accuracy: 0.9684\n",
            "Epoch 40/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0745 - accuracy: 0.9653 - val_loss: 0.1393 - val_accuracy: 0.9672\n",
            "Epoch 41/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0823 - accuracy: 0.9604 - val_loss: 0.0653 - val_accuracy: 0.9824\n",
            "Epoch 42/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0817 - accuracy: 0.9631 - val_loss: 0.0874 - val_accuracy: 0.9769\n",
            "Epoch 43/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0874 - accuracy: 0.9574 - val_loss: 0.0540 - val_accuracy: 0.9763\n",
            "Epoch 44/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0854 - accuracy: 0.9587 - val_loss: 0.0897 - val_accuracy: 0.9800\n",
            "Epoch 45/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0885 - accuracy: 0.9569 - val_loss: 0.2968 - val_accuracy: 0.9169\n",
            "Epoch 46/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1019 - accuracy: 0.9487 - val_loss: 0.1623 - val_accuracy: 0.9363\n",
            "Epoch 47/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0812 - accuracy: 0.9618 - val_loss: 0.1266 - val_accuracy: 0.9751\n",
            "Epoch 48/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0776 - accuracy: 0.9637 - val_loss: 0.2798 - val_accuracy: 0.9672\n",
            "Epoch 49/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0674 - accuracy: 0.9675 - val_loss: 0.0789 - val_accuracy: 0.9721\n",
            "Epoch 50/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0666 - accuracy: 0.9678 - val_loss: 0.0850 - val_accuracy: 0.9800\n",
            "Epoch 51/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0747 - accuracy: 0.9646 - val_loss: 0.1452 - val_accuracy: 0.9587\n",
            "Epoch 52/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0730 - accuracy: 0.9680 - val_loss: 0.0592 - val_accuracy: 0.9818\n",
            "Epoch 53/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0759 - accuracy: 0.9643 - val_loss: 0.1616 - val_accuracy: 0.9684\n",
            "Epoch 54/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0739 - accuracy: 0.9645 - val_loss: 0.0938 - val_accuracy: 0.9836\n",
            "Epoch 55/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0761 - accuracy: 0.9648 - val_loss: 0.0700 - val_accuracy: 0.9794\n",
            "Epoch 56/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0866 - accuracy: 0.9709 - val_loss: 3.5239 - val_accuracy: 0.9581\n",
            "Epoch 57/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0722 - accuracy: 0.9718 - val_loss: 0.4149 - val_accuracy: 0.9545\n",
            "Epoch 58/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0915 - accuracy: 0.9651 - val_loss: 0.7373 - val_accuracy: 0.9587\n",
            "Epoch 59/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1637 - accuracy: 0.9331 - val_loss: 0.1885 - val_accuracy: 0.9672\n",
            "Epoch 60/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1084 - accuracy: 0.9546 - val_loss: 0.0585 - val_accuracy: 0.9782\n",
            "Epoch 61/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0633 - accuracy: 0.9703 - val_loss: 0.0662 - val_accuracy: 0.9830\n",
            "Epoch 62/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0623 - accuracy: 0.9721 - val_loss: 0.0560 - val_accuracy: 0.9800\n",
            "Epoch 63/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0569 - accuracy: 0.9741 - val_loss: 0.0962 - val_accuracy: 0.9824\n",
            "Epoch 64/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0931 - accuracy: 0.9689 - val_loss: 0.2302 - val_accuracy: 0.9709\n",
            "Epoch 65/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0979 - accuracy: 0.9561 - val_loss: 0.0658 - val_accuracy: 0.9745\n",
            "Epoch 66/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1236 - accuracy: 0.9428 - val_loss: 65.8904 - val_accuracy: 0.8817\n",
            "Epoch 67/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.2050 - accuracy: 0.9138 - val_loss: 0.0680 - val_accuracy: 0.9697\n",
            "Epoch 68/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0846 - accuracy: 0.9577 - val_loss: 0.0964 - val_accuracy: 0.9715\n",
            "Epoch 69/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0752 - accuracy: 0.9636 - val_loss: 0.0904 - val_accuracy: 0.9775\n",
            "Epoch 70/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0668 - accuracy: 0.9681 - val_loss: 0.0828 - val_accuracy: 0.9794\n",
            "Epoch 71/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0722 - accuracy: 0.9689 - val_loss: 0.1012 - val_accuracy: 0.9794\n",
            "Epoch 72/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0639 - accuracy: 0.9742 - val_loss: 0.0763 - val_accuracy: 0.9733\n",
            "Epoch 73/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0611 - accuracy: 0.9734 - val_loss: 0.0812 - val_accuracy: 0.9775\n",
            "Epoch 74/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0574 - accuracy: 0.9750 - val_loss: 0.1134 - val_accuracy: 0.9727\n",
            "Epoch 75/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0661 - accuracy: 0.9734 - val_loss: 0.1169 - val_accuracy: 0.9812\n",
            "Epoch 76/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0596 - accuracy: 0.9725 - val_loss: 0.1263 - val_accuracy: 0.9836\n",
            "Epoch 77/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0584 - accuracy: 0.9794 - val_loss: 0.1029 - val_accuracy: 0.9818\n",
            "Epoch 78/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0913 - accuracy: 0.9760 - val_loss: 0.0986 - val_accuracy: 0.9581\n",
            "Epoch 79/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0597 - accuracy: 0.9747 - val_loss: 0.0992 - val_accuracy: 0.9782\n",
            "Epoch 80/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0618 - accuracy: 0.9728 - val_loss: 0.0761 - val_accuracy: 0.9678\n",
            "Epoch 81/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0484 - accuracy: 0.9794 - val_loss: 0.1696 - val_accuracy: 0.9788\n",
            "Epoch 82/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0492 - accuracy: 0.9827 - val_loss: 0.0473 - val_accuracy: 0.9824\n",
            "Epoch 83/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0803 - accuracy: 0.9703 - val_loss: 0.1357 - val_accuracy: 0.9757\n",
            "Epoch 84/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0624 - accuracy: 0.9756 - val_loss: 0.0723 - val_accuracy: 0.9800\n",
            "Epoch 85/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0541 - accuracy: 0.9785 - val_loss: 0.1799 - val_accuracy: 0.9788\n",
            "Epoch 86/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0649 - accuracy: 0.9750 - val_loss: 0.1415 - val_accuracy: 0.9775\n",
            "Epoch 87/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0507 - accuracy: 0.9803 - val_loss: 0.0803 - val_accuracy: 0.9788\n",
            "Epoch 88/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0458 - accuracy: 0.9807 - val_loss: 0.1165 - val_accuracy: 0.9824\n",
            "Epoch 89/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0480 - accuracy: 0.9804 - val_loss: 0.1299 - val_accuracy: 0.9824\n",
            "Epoch 90/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0483 - accuracy: 0.9809 - val_loss: 0.0874 - val_accuracy: 0.9830\n",
            "Epoch 91/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0505 - accuracy: 0.9795 - val_loss: 0.0634 - val_accuracy: 0.9697\n",
            "Epoch 92/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0498 - accuracy: 0.9797 - val_loss: 0.1143 - val_accuracy: 0.9794\n",
            "Epoch 93/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0432 - accuracy: 0.9839 - val_loss: 0.0683 - val_accuracy: 0.9812\n",
            "Epoch 94/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0475 - accuracy: 0.9795 - val_loss: 0.0790 - val_accuracy: 0.9848\n",
            "Epoch 95/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0512 - accuracy: 0.9800 - val_loss: 0.3082 - val_accuracy: 0.9703\n",
            "Epoch 96/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0611 - accuracy: 0.9753 - val_loss: 0.1198 - val_accuracy: 0.9824\n",
            "Epoch 97/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0513 - accuracy: 0.9819 - val_loss: 0.0563 - val_accuracy: 0.9830\n",
            "Epoch 98/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0517 - accuracy: 0.9800 - val_loss: 0.1955 - val_accuracy: 0.9739\n",
            "Epoch 99/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0613 - accuracy: 0.9754 - val_loss: 0.2402 - val_accuracy: 0.9684\n",
            "Epoch 100/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0646 - accuracy: 0.9771 - val_loss: 0.0630 - val_accuracy: 0.9842\n",
            "Epoch 101/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0524 - accuracy: 0.9789 - val_loss: 0.1369 - val_accuracy: 0.9848\n",
            "Epoch 102/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0423 - accuracy: 0.9851 - val_loss: 0.3011 - val_accuracy: 0.9836\n",
            "Epoch 103/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0542 - accuracy: 0.9818 - val_loss: 0.0677 - val_accuracy: 0.9727\n",
            "Epoch 104/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0366 - accuracy: 0.9856 - val_loss: 0.1330 - val_accuracy: 0.9848\n",
            "Epoch 105/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0371 - accuracy: 0.9868 - val_loss: 0.1364 - val_accuracy: 0.9860\n",
            "Epoch 106/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0466 - accuracy: 0.9835 - val_loss: 0.0594 - val_accuracy: 0.9782\n",
            "Epoch 107/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0390 - accuracy: 0.9873 - val_loss: 0.1445 - val_accuracy: 0.9672\n",
            "Epoch 108/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0443 - accuracy: 0.9829 - val_loss: 0.1072 - val_accuracy: 0.9879\n",
            "Epoch 109/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0456 - accuracy: 0.9865 - val_loss: 0.0681 - val_accuracy: 0.9818\n",
            "Epoch 110/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0502 - accuracy: 0.9821 - val_loss: 0.1008 - val_accuracy: 0.9836\n",
            "Epoch 111/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0863 - accuracy: 0.9759 - val_loss: 0.0797 - val_accuracy: 0.9824\n",
            "Epoch 112/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0579 - accuracy: 0.9816 - val_loss: 0.1036 - val_accuracy: 0.9824\n",
            "Epoch 113/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0440 - accuracy: 0.9842 - val_loss: 0.0586 - val_accuracy: 0.9794\n",
            "Epoch 114/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0487 - accuracy: 0.9804 - val_loss: 0.0939 - val_accuracy: 0.9830\n",
            "Epoch 115/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0525 - accuracy: 0.9815 - val_loss: 0.0851 - val_accuracy: 0.9848\n",
            "Epoch 116/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0557 - accuracy: 0.9827 - val_loss: 1.2046 - val_accuracy: 0.9393\n",
            "Epoch 117/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0539 - accuracy: 0.9824 - val_loss: 0.0490 - val_accuracy: 0.9885\n",
            "Epoch 118/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0364 - accuracy: 0.9860 - val_loss: 0.1847 - val_accuracy: 0.9854\n",
            "Epoch 119/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0342 - accuracy: 0.9869 - val_loss: 0.0847 - val_accuracy: 0.9885\n",
            "Epoch 120/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0319 - accuracy: 0.9888 - val_loss: 0.0663 - val_accuracy: 0.9812\n",
            "Epoch 121/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0339 - accuracy: 0.9882 - val_loss: 0.0692 - val_accuracy: 0.9885\n",
            "Epoch 122/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0357 - accuracy: 0.9879 - val_loss: 0.1198 - val_accuracy: 0.9860\n",
            "Epoch 123/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0629 - accuracy: 0.9838 - val_loss: 0.0683 - val_accuracy: 0.9812\n",
            "Epoch 124/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0466 - accuracy: 0.9838 - val_loss: 0.0838 - val_accuracy: 0.9873\n",
            "Epoch 125/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0441 - accuracy: 0.9886 - val_loss: 0.1089 - val_accuracy: 0.9775\n",
            "Epoch 126/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0381 - accuracy: 0.9876 - val_loss: 0.1043 - val_accuracy: 0.9873\n",
            "Epoch 127/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0554 - accuracy: 0.9856 - val_loss: 0.4397 - val_accuracy: 0.9806\n",
            "Epoch 128/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0508 - accuracy: 0.9835 - val_loss: 0.0785 - val_accuracy: 0.9909\n",
            "Epoch 129/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0375 - accuracy: 0.9882 - val_loss: 0.1496 - val_accuracy: 0.9891\n",
            "Epoch 130/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0328 - accuracy: 0.9897 - val_loss: 0.2078 - val_accuracy: 0.9848\n",
            "Epoch 131/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0473 - accuracy: 0.9860 - val_loss: 0.1763 - val_accuracy: 0.9842\n",
            "Epoch 132/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0407 - accuracy: 0.9885 - val_loss: 0.0520 - val_accuracy: 0.9897\n",
            "Epoch 133/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1059 - accuracy: 0.9772 - val_loss: 0.1112 - val_accuracy: 0.9733\n",
            "Epoch 134/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1070 - accuracy: 0.9695 - val_loss: 0.0603 - val_accuracy: 0.9848\n",
            "Epoch 135/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0341 - accuracy: 0.9883 - val_loss: 0.0896 - val_accuracy: 0.9897\n",
            "Epoch 136/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0397 - accuracy: 0.9865 - val_loss: 0.0541 - val_accuracy: 0.9885\n",
            "Epoch 137/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0317 - accuracy: 0.9895 - val_loss: 0.1323 - val_accuracy: 0.9903\n",
            "Epoch 138/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0350 - accuracy: 0.9912 - val_loss: 0.1023 - val_accuracy: 0.9848\n",
            "Epoch 139/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0401 - accuracy: 0.9886 - val_loss: 0.0710 - val_accuracy: 0.9873\n",
            "Epoch 140/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0346 - accuracy: 0.9889 - val_loss: 0.1574 - val_accuracy: 0.9460\n",
            "Epoch 141/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0397 - accuracy: 0.9889 - val_loss: 0.0711 - val_accuracy: 0.9867\n",
            "Epoch 142/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0514 - accuracy: 0.9869 - val_loss: 0.1025 - val_accuracy: 0.9818\n",
            "Epoch 143/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0415 - accuracy: 0.9877 - val_loss: 0.0496 - val_accuracy: 0.9879\n",
            "Epoch 144/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0363 - accuracy: 0.9910 - val_loss: 0.1385 - val_accuracy: 0.9848\n",
            "Epoch 145/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0319 - accuracy: 0.9904 - val_loss: 0.3028 - val_accuracy: 0.9763\n",
            "Epoch 146/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0250 - accuracy: 0.9927 - val_loss: 0.0646 - val_accuracy: 0.9903\n",
            "Epoch 147/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0378 - accuracy: 0.9894 - val_loss: 0.1130 - val_accuracy: 0.9891\n",
            "Epoch 148/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0266 - accuracy: 0.9924 - val_loss: 0.1022 - val_accuracy: 0.9897\n",
            "Epoch 149/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0242 - accuracy: 0.9947 - val_loss: 0.1353 - val_accuracy: 0.9879\n",
            "Epoch 150/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0271 - accuracy: 0.9938 - val_loss: 0.0534 - val_accuracy: 0.9879\n",
            "Epoch 151/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0342 - accuracy: 0.9904 - val_loss: 0.1710 - val_accuracy: 0.9854\n",
            "Epoch 152/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0264 - accuracy: 0.9918 - val_loss: 0.0795 - val_accuracy: 0.9897\n",
            "Epoch 153/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0258 - accuracy: 0.9932 - val_loss: 0.0864 - val_accuracy: 0.9879\n",
            "Epoch 154/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0251 - accuracy: 0.9929 - val_loss: 0.1046 - val_accuracy: 0.9867\n",
            "Epoch 155/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0191 - accuracy: 0.9945 - val_loss: 0.1167 - val_accuracy: 0.9891\n",
            "Epoch 156/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0261 - accuracy: 0.9924 - val_loss: 0.0646 - val_accuracy: 0.9891\n",
            "Epoch 157/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0237 - accuracy: 0.9935 - val_loss: 0.0700 - val_accuracy: 0.9745\n",
            "Epoch 158/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0273 - accuracy: 0.9918 - val_loss: 0.2208 - val_accuracy: 0.9800\n",
            "Epoch 159/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0451 - accuracy: 0.9873 - val_loss: 0.0809 - val_accuracy: 0.9891\n",
            "Epoch 160/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0306 - accuracy: 0.9912 - val_loss: 0.1022 - val_accuracy: 0.9879\n",
            "Epoch 161/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0239 - accuracy: 0.9927 - val_loss: 0.0778 - val_accuracy: 0.9885\n",
            "Epoch 162/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0325 - accuracy: 0.9915 - val_loss: 0.0736 - val_accuracy: 0.9860\n",
            "Epoch 163/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0267 - accuracy: 0.9923 - val_loss: 0.1071 - val_accuracy: 0.9697\n",
            "Epoch 164/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0348 - accuracy: 0.9891 - val_loss: 0.0941 - val_accuracy: 0.9879\n",
            "Epoch 165/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0322 - accuracy: 0.9907 - val_loss: 0.1131 - val_accuracy: 0.9569\n",
            "Epoch 166/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0307 - accuracy: 0.9898 - val_loss: 0.0870 - val_accuracy: 0.9860\n",
            "Epoch 167/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0310 - accuracy: 0.9920 - val_loss: 0.0632 - val_accuracy: 0.9891\n",
            "Epoch 168/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0232 - accuracy: 0.9927 - val_loss: 0.0462 - val_accuracy: 0.9909\n",
            "Epoch 169/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0265 - accuracy: 0.9920 - val_loss: 0.1235 - val_accuracy: 0.9842\n",
            "Epoch 170/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0197 - accuracy: 0.9947 - val_loss: 0.0590 - val_accuracy: 0.9897\n",
            "Epoch 171/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0219 - accuracy: 0.9935 - val_loss: 0.0957 - val_accuracy: 0.9873\n",
            "Epoch 172/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0260 - accuracy: 0.9927 - val_loss: 0.1638 - val_accuracy: 0.9860\n",
            "Epoch 173/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0324 - accuracy: 0.9918 - val_loss: 0.0695 - val_accuracy: 0.9879\n",
            "Epoch 174/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0421 - accuracy: 0.9900 - val_loss: 0.0881 - val_accuracy: 0.9739\n",
            "Epoch 175/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0346 - accuracy: 0.9897 - val_loss: 0.1913 - val_accuracy: 0.9818\n",
            "Epoch 176/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0235 - accuracy: 0.9927 - val_loss: 0.0829 - val_accuracy: 0.9867\n",
            "Epoch 177/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0370 - accuracy: 0.9929 - val_loss: 0.1933 - val_accuracy: 0.9775\n",
            "Epoch 178/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0364 - accuracy: 0.9882 - val_loss: 0.0597 - val_accuracy: 0.9842\n",
            "Epoch 179/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0314 - accuracy: 0.9907 - val_loss: 0.1101 - val_accuracy: 0.9854\n",
            "Epoch 180/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0321 - accuracy: 0.9933 - val_loss: 0.4485 - val_accuracy: 0.8392\n",
            "Epoch 181/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0444 - accuracy: 0.9888 - val_loss: 0.1667 - val_accuracy: 0.9788\n",
            "Epoch 182/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0186 - accuracy: 0.9951 - val_loss: 0.0543 - val_accuracy: 0.9891\n",
            "Epoch 183/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0242 - accuracy: 0.9924 - val_loss: 0.0487 - val_accuracy: 0.9909\n",
            "Epoch 184/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0199 - accuracy: 0.9942 - val_loss: 0.0562 - val_accuracy: 0.9885\n",
            "Epoch 185/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0174 - accuracy: 0.9953 - val_loss: 0.1872 - val_accuracy: 0.9873\n",
            "Epoch 186/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0293 - accuracy: 0.9927 - val_loss: 0.1035 - val_accuracy: 0.9873\n",
            "Epoch 187/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0303 - accuracy: 0.9921 - val_loss: 0.0821 - val_accuracy: 0.9848\n",
            "Epoch 188/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0277 - accuracy: 0.9912 - val_loss: 0.0995 - val_accuracy: 0.9854\n",
            "Epoch 189/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0247 - accuracy: 0.9918 - val_loss: 0.0948 - val_accuracy: 0.9867\n",
            "Epoch 190/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0195 - accuracy: 0.9948 - val_loss: 0.1803 - val_accuracy: 0.9867\n",
            "Epoch 191/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0210 - accuracy: 0.9945 - val_loss: 0.1972 - val_accuracy: 0.9800\n",
            "Epoch 192/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0267 - accuracy: 0.9924 - val_loss: 0.1461 - val_accuracy: 0.9891\n",
            "Epoch 193/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0295 - accuracy: 0.9929 - val_loss: 0.2650 - val_accuracy: 0.9842\n",
            "Epoch 194/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0277 - accuracy: 0.9914 - val_loss: 0.0439 - val_accuracy: 0.9927\n",
            "Epoch 195/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0288 - accuracy: 0.9933 - val_loss: 0.0757 - val_accuracy: 0.9763\n",
            "Epoch 196/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0173 - accuracy: 0.9956 - val_loss: 0.1168 - val_accuracy: 0.9879\n",
            "Epoch 197/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0201 - accuracy: 0.9941 - val_loss: 0.1998 - val_accuracy: 0.9836\n",
            "Epoch 198/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0310 - accuracy: 0.9909 - val_loss: 0.0905 - val_accuracy: 0.9824\n",
            "Epoch 199/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0606 - accuracy: 0.9865 - val_loss: 1.2960 - val_accuracy: 0.9551\n",
            "Epoch 200/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0331 - accuracy: 0.9918 - val_loss: 0.2339 - val_accuracy: 0.9812\n",
            "Epoch 201/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0186 - accuracy: 0.9951 - val_loss: 0.0978 - val_accuracy: 0.9860\n",
            "Epoch 202/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0207 - accuracy: 0.9938 - val_loss: 0.1004 - val_accuracy: 0.9909\n",
            "Epoch 203/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0227 - accuracy: 0.9948 - val_loss: 0.0416 - val_accuracy: 0.9848\n",
            "Epoch 204/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0177 - accuracy: 0.9956 - val_loss: 0.0393 - val_accuracy: 0.9897\n",
            "Epoch 205/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0191 - accuracy: 0.9951 - val_loss: 0.1213 - val_accuracy: 0.9885\n",
            "Epoch 206/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0156 - accuracy: 0.9958 - val_loss: 0.0947 - val_accuracy: 0.9885\n",
            "Epoch 207/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0140 - accuracy: 0.9965 - val_loss: 0.1854 - val_accuracy: 0.9757\n",
            "Epoch 208/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0299 - accuracy: 0.9939 - val_loss: 0.1009 - val_accuracy: 0.9842\n",
            "Epoch 209/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0236 - accuracy: 0.9929 - val_loss: 0.1613 - val_accuracy: 0.9848\n",
            "Epoch 210/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0278 - accuracy: 0.9935 - val_loss: 0.3091 - val_accuracy: 0.9836\n",
            "Epoch 211/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0308 - accuracy: 0.9924 - val_loss: 0.1641 - val_accuracy: 0.9879\n",
            "Epoch 212/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0351 - accuracy: 0.9936 - val_loss: 0.4474 - val_accuracy: 0.9630\n",
            "Epoch 213/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0317 - accuracy: 0.9927 - val_loss: 0.0593 - val_accuracy: 0.9903\n",
            "Epoch 214/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0178 - accuracy: 0.9959 - val_loss: 0.0695 - val_accuracy: 0.9915\n",
            "Epoch 215/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0210 - accuracy: 0.9950 - val_loss: 0.1015 - val_accuracy: 0.9873\n",
            "Epoch 216/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0148 - accuracy: 0.9964 - val_loss: 0.0744 - val_accuracy: 0.9885\n",
            "Epoch 217/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0210 - accuracy: 0.9933 - val_loss: 0.0760 - val_accuracy: 0.9860\n",
            "Epoch 218/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0180 - accuracy: 0.9958 - val_loss: 0.0284 - val_accuracy: 0.9915\n",
            "Epoch 219/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0209 - accuracy: 0.9944 - val_loss: 0.0499 - val_accuracy: 0.9879\n",
            "Epoch 220/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0235 - accuracy: 0.9944 - val_loss: 0.1237 - val_accuracy: 0.9909\n",
            "Epoch 221/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0167 - accuracy: 0.9965 - val_loss: 0.0886 - val_accuracy: 0.9939\n",
            "Epoch 222/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0129 - accuracy: 0.9971 - val_loss: 0.1094 - val_accuracy: 0.9903\n",
            "Epoch 223/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0190 - accuracy: 0.9950 - val_loss: 0.0901 - val_accuracy: 0.9860\n",
            "Epoch 224/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0170 - accuracy: 0.9954 - val_loss: 0.0504 - val_accuracy: 0.9915\n",
            "Epoch 225/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0119 - accuracy: 0.9971 - val_loss: 0.0738 - val_accuracy: 0.9915\n",
            "Epoch 226/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0117 - accuracy: 0.9971 - val_loss: 0.2505 - val_accuracy: 0.9891\n",
            "Epoch 227/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0246 - accuracy: 0.9942 - val_loss: 0.1815 - val_accuracy: 0.9818\n",
            "Epoch 228/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0176 - accuracy: 0.9953 - val_loss: 0.0791 - val_accuracy: 0.9842\n",
            "Epoch 229/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0170 - accuracy: 0.9954 - val_loss: 0.0660 - val_accuracy: 0.9921\n",
            "Epoch 230/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0109 - accuracy: 0.9974 - val_loss: 0.0689 - val_accuracy: 0.9927\n",
            "Epoch 231/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0151 - accuracy: 0.9964 - val_loss: 0.1407 - val_accuracy: 0.9873\n",
            "Epoch 232/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0216 - accuracy: 0.9951 - val_loss: 0.1106 - val_accuracy: 0.9885\n",
            "Epoch 233/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0130 - accuracy: 0.9970 - val_loss: 0.1983 - val_accuracy: 0.9854\n",
            "Epoch 234/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0200 - accuracy: 0.9951 - val_loss: 0.0542 - val_accuracy: 0.9891\n",
            "Epoch 235/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0162 - accuracy: 0.9959 - val_loss: 0.0470 - val_accuracy: 0.9897\n",
            "Epoch 236/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0079 - accuracy: 0.9986 - val_loss: 0.0535 - val_accuracy: 0.9921\n",
            "Epoch 237/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0169 - accuracy: 0.9953 - val_loss: 0.1387 - val_accuracy: 0.9848\n",
            "Epoch 238/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0246 - accuracy: 0.9967 - val_loss: 0.0970 - val_accuracy: 0.9794\n",
            "Epoch 239/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0284 - accuracy: 0.9939 - val_loss: 0.1433 - val_accuracy: 0.9854\n",
            "Epoch 240/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0225 - accuracy: 0.9938 - val_loss: 0.0486 - val_accuracy: 0.9909\n",
            "Epoch 241/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0249 - accuracy: 0.9944 - val_loss: 0.5601 - val_accuracy: 0.9678\n",
            "Epoch 242/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0172 - accuracy: 0.9959 - val_loss: 0.2274 - val_accuracy: 0.9873\n",
            "Epoch 243/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0143 - accuracy: 0.9967 - val_loss: 0.0776 - val_accuracy: 0.9897\n",
            "Epoch 244/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0288 - accuracy: 0.9958 - val_loss: 0.1165 - val_accuracy: 0.9867\n",
            "Epoch 245/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0446 - accuracy: 0.9935 - val_loss: 0.1255 - val_accuracy: 0.9848\n",
            "Epoch 246/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0121 - accuracy: 0.9968 - val_loss: 0.1793 - val_accuracy: 0.9848\n",
            "Epoch 247/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0214 - accuracy: 0.9958 - val_loss: 0.0694 - val_accuracy: 0.9860\n",
            "Epoch 248/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0379 - accuracy: 0.9935 - val_loss: 0.1400 - val_accuracy: 0.9830\n",
            "Epoch 249/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0320 - accuracy: 0.9942 - val_loss: 0.0941 - val_accuracy: 0.9867\n",
            "Epoch 250/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0146 - accuracy: 0.9964 - val_loss: 0.6128 - val_accuracy: 0.9800\n",
            "Epoch 251/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0202 - accuracy: 0.9968 - val_loss: 0.0567 - val_accuracy: 0.9909\n",
            "Epoch 252/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0213 - accuracy: 0.9962 - val_loss: 0.1102 - val_accuracy: 0.9885\n",
            "Epoch 253/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0239 - accuracy: 0.9954 - val_loss: 0.0442 - val_accuracy: 0.9873\n",
            "Epoch 254/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0202 - accuracy: 0.9961 - val_loss: 0.0712 - val_accuracy: 0.9909\n",
            "Epoch 255/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0088 - accuracy: 0.9980 - val_loss: 0.1636 - val_accuracy: 0.9879\n",
            "Epoch 256/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0319 - accuracy: 0.9956 - val_loss: 0.1834 - val_accuracy: 0.9879\n",
            "Epoch 257/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0286 - accuracy: 0.9968 - val_loss: 0.2703 - val_accuracy: 0.9830\n",
            "Epoch 258/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0370 - accuracy: 0.9941 - val_loss: 0.2672 - val_accuracy: 0.9800\n",
            "Epoch 259/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0205 - accuracy: 0.9956 - val_loss: 0.0850 - val_accuracy: 0.9854\n",
            "Epoch 260/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0200 - accuracy: 0.9951 - val_loss: 0.1244 - val_accuracy: 0.9867\n",
            "Epoch 261/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0194 - accuracy: 0.9961 - val_loss: 0.0724 - val_accuracy: 0.9897\n",
            "Epoch 262/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0152 - accuracy: 0.9976 - val_loss: 0.1241 - val_accuracy: 0.9848\n",
            "Epoch 263/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0148 - accuracy: 0.9968 - val_loss: 0.0701 - val_accuracy: 0.9873\n",
            "Epoch 264/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0190 - accuracy: 0.9959 - val_loss: 0.2686 - val_accuracy: 0.9830\n",
            "Epoch 265/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0188 - accuracy: 0.9959 - val_loss: 0.2036 - val_accuracy: 0.9903\n",
            "Epoch 266/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0083 - accuracy: 0.9983 - val_loss: 0.2511 - val_accuracy: 0.9854\n",
            "Epoch 267/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0116 - accuracy: 0.9974 - val_loss: 0.2659 - val_accuracy: 0.9879\n",
            "Epoch 268/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0172 - accuracy: 0.9961 - val_loss: 0.1969 - val_accuracy: 0.9666\n",
            "Epoch 269/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0136 - accuracy: 0.9973 - val_loss: 0.0965 - val_accuracy: 0.9897\n",
            "Epoch 270/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0111 - accuracy: 0.9974 - val_loss: 0.4421 - val_accuracy: 0.9854\n",
            "Epoch 271/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0071 - accuracy: 0.9985 - val_loss: 0.3822 - val_accuracy: 0.9854\n",
            "Epoch 272/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0278 - accuracy: 0.9958 - val_loss: 0.0515 - val_accuracy: 0.9885\n",
            "Epoch 273/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0112 - accuracy: 0.9976 - val_loss: 0.0540 - val_accuracy: 0.9891\n",
            "Epoch 274/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0106 - accuracy: 0.9982 - val_loss: 0.1398 - val_accuracy: 0.9897\n",
            "Epoch 275/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0107 - accuracy: 0.9973 - val_loss: 0.0803 - val_accuracy: 0.9897\n",
            "Epoch 276/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0392 - accuracy: 0.9951 - val_loss: 0.2797 - val_accuracy: 0.9867\n",
            "Epoch 277/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0188 - accuracy: 0.9962 - val_loss: 0.1574 - val_accuracy: 0.9885\n",
            "Epoch 278/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0160 - accuracy: 0.9970 - val_loss: 0.1760 - val_accuracy: 0.9885\n",
            "Epoch 279/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0141 - accuracy: 0.9970 - val_loss: 0.1173 - val_accuracy: 0.9842\n",
            "Epoch 280/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0162 - accuracy: 0.9956 - val_loss: 0.1085 - val_accuracy: 0.9909\n",
            "Epoch 281/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0096 - accuracy: 0.9979 - val_loss: 0.1176 - val_accuracy: 0.9915\n",
            "Epoch 282/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0073 - accuracy: 0.9985 - val_loss: 0.1005 - val_accuracy: 0.9909\n",
            "Epoch 283/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0295 - accuracy: 0.9953 - val_loss: 0.0729 - val_accuracy: 0.9873\n",
            "Epoch 284/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0149 - accuracy: 0.9967 - val_loss: 0.1665 - val_accuracy: 0.9897\n",
            "Epoch 285/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0150 - accuracy: 0.9958 - val_loss: 0.1432 - val_accuracy: 0.9885\n",
            "Epoch 286/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0118 - accuracy: 0.9973 - val_loss: 0.1815 - val_accuracy: 0.9915\n",
            "Epoch 287/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0101 - accuracy: 0.9976 - val_loss: 0.1805 - val_accuracy: 0.9897\n",
            "Epoch 288/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0119 - accuracy: 0.9977 - val_loss: 0.2055 - val_accuracy: 0.9867\n",
            "Epoch 289/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0139 - accuracy: 0.9967 - val_loss: 0.3985 - val_accuracy: 0.9806\n",
            "Epoch 290/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0139 - accuracy: 0.9968 - val_loss: 0.0511 - val_accuracy: 0.9879\n",
            "Epoch 291/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0162 - accuracy: 0.9965 - val_loss: 0.0390 - val_accuracy: 0.9933\n",
            "Epoch 292/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0138 - accuracy: 0.9979 - val_loss: 0.0526 - val_accuracy: 0.9891\n",
            "Epoch 293/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0266 - accuracy: 0.9965 - val_loss: 1.6249 - val_accuracy: 0.9727\n",
            "Epoch 294/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0622 - accuracy: 0.9948 - val_loss: 0.4998 - val_accuracy: 0.9854\n",
            "Epoch 295/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0101 - accuracy: 0.9977 - val_loss: 0.2051 - val_accuracy: 0.9860\n",
            "Epoch 296/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0158 - accuracy: 0.9967 - val_loss: 0.1096 - val_accuracy: 0.9891\n",
            "Epoch 297/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0126 - accuracy: 0.9982 - val_loss: 0.0502 - val_accuracy: 0.9897\n",
            "Epoch 298/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0293 - accuracy: 0.9956 - val_loss: 0.0908 - val_accuracy: 0.9800\n",
            "Epoch 299/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0138 - accuracy: 0.9968 - val_loss: 0.1927 - val_accuracy: 0.9915\n",
            "Epoch 300/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0167 - accuracy: 0.9976 - val_loss: 0.1131 - val_accuracy: 0.9873\n",
            "Epoch 301/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0089 - accuracy: 0.9982 - val_loss: 0.0788 - val_accuracy: 0.9879\n",
            "Epoch 302/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0071 - accuracy: 0.9985 - val_loss: 0.0739 - val_accuracy: 0.9903\n",
            "Epoch 303/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0123 - accuracy: 0.9974 - val_loss: 0.0721 - val_accuracy: 0.9818\n",
            "Epoch 304/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0154 - accuracy: 0.9973 - val_loss: 0.0867 - val_accuracy: 0.9897\n",
            "Epoch 305/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0077 - accuracy: 0.9983 - val_loss: 0.0391 - val_accuracy: 0.9891\n",
            "Epoch 306/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0092 - accuracy: 0.9977 - val_loss: 0.0396 - val_accuracy: 0.9891\n",
            "Epoch 307/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0110 - accuracy: 0.9976 - val_loss: 0.0651 - val_accuracy: 0.9909\n",
            "Epoch 308/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0153 - accuracy: 0.9970 - val_loss: 0.0620 - val_accuracy: 0.9915\n",
            "Epoch 309/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0097 - accuracy: 0.9977 - val_loss: 0.1382 - val_accuracy: 0.9654\n",
            "Epoch 310/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0114 - accuracy: 0.9977 - val_loss: 0.2409 - val_accuracy: 0.9830\n",
            "Epoch 311/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0149 - accuracy: 0.9962 - val_loss: 0.1003 - val_accuracy: 0.9897\n",
            "Epoch 312/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0215 - accuracy: 0.9983 - val_loss: 0.0997 - val_accuracy: 0.9897\n",
            "Epoch 313/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0244 - accuracy: 0.9976 - val_loss: 1.0588 - val_accuracy: 0.9612\n",
            "Epoch 314/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0209 - accuracy: 0.9953 - val_loss: 0.1485 - val_accuracy: 0.9854\n",
            "Epoch 315/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0132 - accuracy: 0.9968 - val_loss: 0.1040 - val_accuracy: 0.9879\n",
            "Epoch 316/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0094 - accuracy: 0.9979 - val_loss: 0.1005 - val_accuracy: 0.9915\n",
            "Epoch 317/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0063 - accuracy: 0.9986 - val_loss: 0.0924 - val_accuracy: 0.9891\n",
            "Epoch 318/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0253 - accuracy: 0.9961 - val_loss: 0.1188 - val_accuracy: 0.9842\n",
            "Epoch 319/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0123 - accuracy: 0.9973 - val_loss: 0.0745 - val_accuracy: 0.9860\n",
            "Epoch 320/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0070 - accuracy: 0.9988 - val_loss: 0.0927 - val_accuracy: 0.9885\n",
            "Epoch 321/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0136 - accuracy: 0.9980 - val_loss: 0.0531 - val_accuracy: 0.9879\n",
            "Epoch 322/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0087 - accuracy: 0.9979 - val_loss: 0.1602 - val_accuracy: 0.9879\n",
            "Epoch 323/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0100 - accuracy: 0.9985 - val_loss: 0.0550 - val_accuracy: 0.9921\n",
            "Epoch 324/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0129 - accuracy: 0.9976 - val_loss: 0.0328 - val_accuracy: 0.9915\n",
            "Epoch 325/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0093 - accuracy: 0.9980 - val_loss: 0.0601 - val_accuracy: 0.9903\n",
            "Epoch 326/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0126 - accuracy: 0.9974 - val_loss: 0.0569 - val_accuracy: 0.9915\n",
            "Epoch 327/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0087 - accuracy: 0.9982 - val_loss: 0.1599 - val_accuracy: 0.9909\n",
            "Epoch 328/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0082 - accuracy: 0.9982 - val_loss: 0.0457 - val_accuracy: 0.9921\n",
            "Epoch 329/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0059 - accuracy: 0.9988 - val_loss: 0.0558 - val_accuracy: 0.9933\n",
            "Epoch 330/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0116 - accuracy: 0.9982 - val_loss: 0.0741 - val_accuracy: 0.9891\n",
            "Epoch 331/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0135 - accuracy: 0.9973 - val_loss: 0.0686 - val_accuracy: 0.9897\n",
            "Epoch 332/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0106 - accuracy: 0.9976 - val_loss: 0.0993 - val_accuracy: 0.9915\n",
            "Epoch 333/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0120 - accuracy: 0.9974 - val_loss: 0.1064 - val_accuracy: 0.9672\n",
            "Epoch 334/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0149 - accuracy: 0.9971 - val_loss: 0.1106 - val_accuracy: 0.9812\n",
            "Epoch 335/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0298 - accuracy: 0.9967 - val_loss: 0.0867 - val_accuracy: 0.9885\n",
            "Epoch 336/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0111 - accuracy: 0.9974 - val_loss: 0.0989 - val_accuracy: 0.9885\n",
            "Epoch 337/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0076 - accuracy: 0.9983 - val_loss: 0.0693 - val_accuracy: 0.9891\n",
            "Epoch 338/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0082 - accuracy: 0.9986 - val_loss: 0.2556 - val_accuracy: 0.9867\n",
            "Epoch 339/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0124 - accuracy: 0.9973 - val_loss: 0.3250 - val_accuracy: 0.9867\n",
            "Epoch 340/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0149 - accuracy: 0.9970 - val_loss: 0.4720 - val_accuracy: 0.9260\n",
            "Epoch 341/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0130 - accuracy: 0.9965 - val_loss: 0.0660 - val_accuracy: 0.9903\n",
            "Epoch 342/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0122 - accuracy: 0.9974 - val_loss: 0.0822 - val_accuracy: 0.9909\n",
            "Epoch 343/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0147 - accuracy: 0.9977 - val_loss: 0.0783 - val_accuracy: 0.9842\n",
            "Epoch 344/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0106 - accuracy: 0.9983 - val_loss: 0.0438 - val_accuracy: 0.9879\n",
            "Epoch 345/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0070 - accuracy: 0.9980 - val_loss: 0.0613 - val_accuracy: 0.9915\n",
            "Epoch 346/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0029 - accuracy: 0.9997 - val_loss: 0.0494 - val_accuracy: 0.9921\n",
            "Epoch 347/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0062 - accuracy: 0.9986 - val_loss: 0.0866 - val_accuracy: 0.9909\n",
            "Epoch 348/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0099 - accuracy: 0.9985 - val_loss: 0.2643 - val_accuracy: 0.9636\n",
            "Epoch 349/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0141 - accuracy: 0.9983 - val_loss: 0.0550 - val_accuracy: 0.9909\n",
            "Epoch 350/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0100 - accuracy: 0.9979 - val_loss: 0.1427 - val_accuracy: 0.9891\n",
            "Epoch 351/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0064 - accuracy: 0.9988 - val_loss: 0.0746 - val_accuracy: 0.9879\n",
            "Epoch 352/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0071 - accuracy: 0.9985 - val_loss: 0.0426 - val_accuracy: 0.9927\n",
            "Epoch 353/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0181 - accuracy: 0.9974 - val_loss: 0.3171 - val_accuracy: 0.9891\n",
            "Epoch 354/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0081 - accuracy: 0.9982 - val_loss: 0.0633 - val_accuracy: 0.9897\n",
            "Epoch 355/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0071 - accuracy: 0.9985 - val_loss: 0.2215 - val_accuracy: 0.9873\n",
            "Epoch 356/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0185 - accuracy: 0.9970 - val_loss: 0.1284 - val_accuracy: 0.9909\n",
            "Epoch 357/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0178 - accuracy: 0.9967 - val_loss: 0.1013 - val_accuracy: 0.9800\n",
            "Epoch 358/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0368 - accuracy: 0.9939 - val_loss: 0.1249 - val_accuracy: 0.9921\n",
            "Epoch 359/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0105 - accuracy: 0.9976 - val_loss: 0.3761 - val_accuracy: 0.9848\n",
            "Epoch 360/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0074 - accuracy: 0.9985 - val_loss: 0.2329 - val_accuracy: 0.9891\n",
            "Epoch 361/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0065 - accuracy: 0.9986 - val_loss: 0.1480 - val_accuracy: 0.9909\n",
            "Epoch 362/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0111 - accuracy: 0.9985 - val_loss: 0.0295 - val_accuracy: 0.9915\n",
            "Epoch 363/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0066 - accuracy: 0.9988 - val_loss: 0.0653 - val_accuracy: 0.9933\n",
            "Epoch 364/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0070 - accuracy: 0.9985 - val_loss: 0.3785 - val_accuracy: 0.9860\n",
            "Epoch 365/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0056 - accuracy: 0.9991 - val_loss: 0.1079 - val_accuracy: 0.9915\n",
            "Epoch 366/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0116 - accuracy: 0.9980 - val_loss: 0.0761 - val_accuracy: 0.9909\n",
            "Epoch 367/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0162 - accuracy: 0.9977 - val_loss: 0.0686 - val_accuracy: 0.9921\n",
            "Epoch 368/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0375 - accuracy: 0.9956 - val_loss: 0.1781 - val_accuracy: 0.9867\n",
            "Epoch 369/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0292 - accuracy: 0.9935 - val_loss: 0.0742 - val_accuracy: 0.9885\n",
            "Epoch 370/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0105 - accuracy: 0.9976 - val_loss: 0.1922 - val_accuracy: 0.9873\n",
            "Epoch 371/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0092 - accuracy: 0.9977 - val_loss: 0.0939 - val_accuracy: 0.9915\n",
            "Epoch 372/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0080 - accuracy: 0.9985 - val_loss: 0.2957 - val_accuracy: 0.9854\n",
            "Epoch 373/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0039 - accuracy: 0.9991 - val_loss: 0.0492 - val_accuracy: 0.9915\n",
            "Epoch 374/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0072 - accuracy: 0.9985 - val_loss: 0.1475 - val_accuracy: 0.9915\n",
            "Epoch 375/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0223 - accuracy: 0.9977 - val_loss: 0.0368 - val_accuracy: 0.9915\n",
            "Epoch 376/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0104 - accuracy: 0.9979 - val_loss: 0.1174 - val_accuracy: 0.9897\n",
            "Epoch 377/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0102 - accuracy: 0.9977 - val_loss: 0.0442 - val_accuracy: 0.9903\n",
            "Epoch 378/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0024 - accuracy: 0.9997 - val_loss: 0.3037 - val_accuracy: 0.9842\n",
            "Epoch 379/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0073 - accuracy: 0.9985 - val_loss: 0.0742 - val_accuracy: 0.9921\n",
            "Epoch 380/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0173 - accuracy: 0.9986 - val_loss: 0.0568 - val_accuracy: 0.9885\n",
            "Epoch 381/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0225 - accuracy: 0.9959 - val_loss: 0.0737 - val_accuracy: 0.9867\n",
            "Epoch 382/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0165 - accuracy: 0.9974 - val_loss: 0.0351 - val_accuracy: 0.9921\n",
            "Epoch 383/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0108 - accuracy: 0.9979 - val_loss: 0.0332 - val_accuracy: 0.9933\n",
            "Epoch 384/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0112 - accuracy: 0.9979 - val_loss: 0.0469 - val_accuracy: 0.9915\n",
            "Epoch 385/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0142 - accuracy: 0.9974 - val_loss: 0.0867 - val_accuracy: 0.9909\n",
            "Epoch 386/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0099 - accuracy: 0.9979 - val_loss: 0.1481 - val_accuracy: 0.9885\n",
            "Epoch 387/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0060 - accuracy: 0.9988 - val_loss: 0.1520 - val_accuracy: 0.9885\n",
            "Epoch 388/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0057 - accuracy: 0.9991 - val_loss: 0.2157 - val_accuracy: 0.9891\n",
            "Epoch 389/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0063 - accuracy: 0.9989 - val_loss: 0.1411 - val_accuracy: 0.9915\n",
            "Epoch 390/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0056 - accuracy: 0.9991 - val_loss: 0.1369 - val_accuracy: 0.9915\n",
            "Epoch 391/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0045 - accuracy: 0.9992 - val_loss: 0.1142 - val_accuracy: 0.9921\n",
            "Epoch 392/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0056 - accuracy: 0.9991 - val_loss: 0.2106 - val_accuracy: 0.9915\n",
            "Epoch 393/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0063 - accuracy: 0.9989 - val_loss: 0.1509 - val_accuracy: 0.9915\n",
            "Epoch 394/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0110 - accuracy: 0.9980 - val_loss: 0.1182 - val_accuracy: 0.9891\n",
            "Epoch 395/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0103 - accuracy: 0.9979 - val_loss: 0.1162 - val_accuracy: 0.9885\n",
            "Epoch 396/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0131 - accuracy: 0.9973 - val_loss: 0.5185 - val_accuracy: 0.9782\n",
            "Epoch 397/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0172 - accuracy: 0.9967 - val_loss: 0.1232 - val_accuracy: 0.9897\n",
            "Epoch 398/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0189 - accuracy: 0.9965 - val_loss: 0.0808 - val_accuracy: 0.9806\n",
            "Epoch 399/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0269 - accuracy: 0.9948 - val_loss: 0.0639 - val_accuracy: 0.9909\n",
            "Epoch 400/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0082 - accuracy: 0.9982 - val_loss: 0.0924 - val_accuracy: 0.9927\n",
            "Epoch 401/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0108 - accuracy: 0.9977 - val_loss: 0.1020 - val_accuracy: 0.9927\n",
            "Epoch 402/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0188 - accuracy: 0.9973 - val_loss: 0.1194 - val_accuracy: 0.9939\n",
            "Epoch 403/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0456 - accuracy: 0.9971 - val_loss: 0.0655 - val_accuracy: 0.9903\n",
            "Epoch 404/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0148 - accuracy: 0.9970 - val_loss: 0.2601 - val_accuracy: 0.9891\n",
            "Epoch 405/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0129 - accuracy: 0.9979 - val_loss: 0.0375 - val_accuracy: 0.9909\n",
            "Epoch 406/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0164 - accuracy: 0.9968 - val_loss: 0.0414 - val_accuracy: 0.9909\n",
            "Epoch 407/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0129 - accuracy: 0.9976 - val_loss: 0.0978 - val_accuracy: 0.9921\n",
            "Epoch 408/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0200 - accuracy: 0.9968 - val_loss: 0.0893 - val_accuracy: 0.9945\n",
            "Epoch 409/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0339 - accuracy: 0.9964 - val_loss: 0.0345 - val_accuracy: 0.9909\n",
            "Epoch 410/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0233 - accuracy: 0.9974 - val_loss: 0.3187 - val_accuracy: 0.9879\n",
            "Epoch 411/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0076 - accuracy: 0.9985 - val_loss: 0.2875 - val_accuracy: 0.9879\n",
            "Epoch 412/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0075 - accuracy: 0.9986 - val_loss: 0.1986 - val_accuracy: 0.9873\n",
            "Epoch 413/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0275 - accuracy: 0.9976 - val_loss: 0.0541 - val_accuracy: 0.9885\n",
            "Epoch 414/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0038 - accuracy: 0.9992 - val_loss: 0.1059 - val_accuracy: 0.9909\n",
            "Epoch 415/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0249 - accuracy: 0.9974 - val_loss: 0.1258 - val_accuracy: 0.9909\n",
            "Epoch 416/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0176 - accuracy: 0.9971 - val_loss: 0.1637 - val_accuracy: 0.9915\n",
            "Epoch 417/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0077 - accuracy: 0.9986 - val_loss: 0.1114 - val_accuracy: 0.9903\n",
            "Epoch 418/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0114 - accuracy: 0.9977 - val_loss: 0.0912 - val_accuracy: 0.9915\n",
            "Epoch 419/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0076 - accuracy: 0.9985 - val_loss: 0.0952 - val_accuracy: 0.9915\n",
            "Epoch 420/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0147 - accuracy: 0.9980 - val_loss: 0.0877 - val_accuracy: 0.9921\n",
            "Epoch 421/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0144 - accuracy: 0.9976 - val_loss: 0.6155 - val_accuracy: 0.9788\n",
            "Epoch 422/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0157 - accuracy: 0.9964 - val_loss: 0.4828 - val_accuracy: 0.9830\n",
            "Epoch 423/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0170 - accuracy: 0.9962 - val_loss: 0.7585 - val_accuracy: 0.9769\n",
            "Epoch 424/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0301 - accuracy: 0.9938 - val_loss: 0.0507 - val_accuracy: 0.9848\n",
            "Epoch 425/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0093 - accuracy: 0.9977 - val_loss: 0.0651 - val_accuracy: 0.9915\n",
            "Epoch 426/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0071 - accuracy: 0.9986 - val_loss: 0.0753 - val_accuracy: 0.9927\n",
            "Epoch 427/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0039 - accuracy: 0.9994 - val_loss: 0.0986 - val_accuracy: 0.9921\n",
            "Epoch 428/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0099 - accuracy: 0.9980 - val_loss: 0.1258 - val_accuracy: 0.9915\n",
            "Epoch 429/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0099 - accuracy: 0.9977 - val_loss: 0.0435 - val_accuracy: 0.9909\n",
            "Epoch 430/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0035 - accuracy: 0.9994 - val_loss: 0.1274 - val_accuracy: 0.9909\n",
            "Epoch 431/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0044 - accuracy: 0.9992 - val_loss: 0.1167 - val_accuracy: 0.9915\n",
            "Epoch 432/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0372 - accuracy: 0.9961 - val_loss: 0.1843 - val_accuracy: 0.9860\n",
            "Epoch 433/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0069 - accuracy: 0.9986 - val_loss: 0.1099 - val_accuracy: 0.9903\n",
            "Epoch 434/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0214 - accuracy: 0.9958 - val_loss: 0.0986 - val_accuracy: 0.9842\n",
            "Epoch 435/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0212 - accuracy: 0.9961 - val_loss: 0.1343 - val_accuracy: 0.9891\n",
            "Epoch 436/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0093 - accuracy: 0.9985 - val_loss: 0.0285 - val_accuracy: 0.9939\n",
            "Epoch 437/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0039 - accuracy: 0.9994 - val_loss: 0.0860 - val_accuracy: 0.9915\n",
            "Epoch 438/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0105 - accuracy: 0.9982 - val_loss: 0.0394 - val_accuracy: 0.9891\n",
            "Epoch 439/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0096 - accuracy: 0.9980 - val_loss: 0.0471 - val_accuracy: 0.9945\n",
            "Epoch 440/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0059 - accuracy: 0.9989 - val_loss: 0.0796 - val_accuracy: 0.9933\n",
            "Epoch 441/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0064 - accuracy: 0.9988 - val_loss: 0.0804 - val_accuracy: 0.9933\n",
            "Epoch 442/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0060 - accuracy: 0.9988 - val_loss: 0.1194 - val_accuracy: 0.9903\n",
            "Epoch 443/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0063 - accuracy: 0.9985 - val_loss: 0.2504 - val_accuracy: 0.9867\n",
            "Epoch 444/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0069 - accuracy: 0.9985 - val_loss: 0.0402 - val_accuracy: 0.9945\n",
            "Epoch 445/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0099 - accuracy: 0.9988 - val_loss: 0.0543 - val_accuracy: 0.9915\n",
            "Epoch 446/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0066 - accuracy: 0.9988 - val_loss: 0.1660 - val_accuracy: 0.9903\n",
            "Epoch 447/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0031 - accuracy: 0.9992 - val_loss: 0.2687 - val_accuracy: 0.9879\n",
            "Epoch 448/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0053 - accuracy: 0.9992 - val_loss: 0.1071 - val_accuracy: 0.9939\n",
            "Epoch 449/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0060 - accuracy: 0.9985 - val_loss: 0.0254 - val_accuracy: 0.9921\n",
            "Epoch 450/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0130 - accuracy: 0.9992 - val_loss: 0.0996 - val_accuracy: 0.9921\n",
            "Epoch 451/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0062 - accuracy: 0.9989 - val_loss: 0.0466 - val_accuracy: 0.9951\n",
            "Epoch 452/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0058 - accuracy: 0.9989 - val_loss: 0.0384 - val_accuracy: 0.9933\n",
            "Epoch 453/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0039 - accuracy: 0.9994 - val_loss: 0.1267 - val_accuracy: 0.9915\n",
            "Epoch 454/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0109 - accuracy: 0.9988 - val_loss: 0.0702 - val_accuracy: 0.9909\n",
            "Epoch 455/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0039 - accuracy: 0.9994 - val_loss: 0.0907 - val_accuracy: 0.9891\n",
            "Epoch 456/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0027 - accuracy: 0.9995 - val_loss: 0.1114 - val_accuracy: 0.9885\n",
            "Epoch 457/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0046 - accuracy: 0.9992 - val_loss: 0.1069 - val_accuracy: 0.9897\n",
            "Epoch 458/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0147 - accuracy: 0.9973 - val_loss: 0.1302 - val_accuracy: 0.9915\n",
            "Epoch 459/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0169 - accuracy: 0.9974 - val_loss: 0.0853 - val_accuracy: 0.9873\n",
            "Epoch 460/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0194 - accuracy: 0.9979 - val_loss: 0.1540 - val_accuracy: 0.9897\n",
            "Epoch 461/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0080 - accuracy: 0.9982 - val_loss: 0.1255 - val_accuracy: 0.9897\n",
            "Epoch 462/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0163 - accuracy: 0.9971 - val_loss: 0.0886 - val_accuracy: 0.9909\n",
            "Epoch 463/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0107 - accuracy: 0.9976 - val_loss: 0.0832 - val_accuracy: 0.9921\n",
            "Epoch 464/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0074 - accuracy: 0.9983 - val_loss: 0.0735 - val_accuracy: 0.9915\n",
            "Epoch 465/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0082 - accuracy: 0.9983 - val_loss: 0.0941 - val_accuracy: 0.9867\n",
            "Epoch 466/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0093 - accuracy: 0.9982 - val_loss: 0.0689 - val_accuracy: 0.9915\n",
            "Epoch 467/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0088 - accuracy: 0.9982 - val_loss: 0.0641 - val_accuracy: 0.9915\n",
            "Epoch 468/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0060 - accuracy: 0.9988 - val_loss: 0.3466 - val_accuracy: 0.9794\n",
            "Epoch 469/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0044 - accuracy: 0.9992 - val_loss: 0.1394 - val_accuracy: 0.9891\n",
            "Epoch 470/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0070 - accuracy: 0.9995 - val_loss: 0.0855 - val_accuracy: 0.9921\n",
            "Epoch 471/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0082 - accuracy: 0.9982 - val_loss: 0.4229 - val_accuracy: 0.9879\n",
            "Epoch 472/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0260 - accuracy: 0.9988 - val_loss: 0.0713 - val_accuracy: 0.9897\n",
            "Epoch 473/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0065 - accuracy: 0.9986 - val_loss: 0.3220 - val_accuracy: 0.9885\n",
            "Epoch 474/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0230 - accuracy: 0.9976 - val_loss: 0.3604 - val_accuracy: 0.9836\n",
            "Epoch 475/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0076 - accuracy: 0.9980 - val_loss: 0.1198 - val_accuracy: 0.9897\n",
            "Epoch 476/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0106 - accuracy: 0.9982 - val_loss: 0.2350 - val_accuracy: 0.9897\n",
            "Epoch 477/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0065 - accuracy: 0.9985 - val_loss: 0.0642 - val_accuracy: 0.9891\n",
            "Epoch 478/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0061 - accuracy: 0.9988 - val_loss: 0.0909 - val_accuracy: 0.9921\n",
            "Epoch 479/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0097 - accuracy: 0.9980 - val_loss: 0.0671 - val_accuracy: 0.9860\n",
            "Epoch 480/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0104 - accuracy: 0.9983 - val_loss: 0.0565 - val_accuracy: 0.9927\n",
            "Epoch 481/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0079 - accuracy: 0.9986 - val_loss: 0.1174 - val_accuracy: 0.9927\n",
            "Epoch 482/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0057 - accuracy: 0.9988 - val_loss: 0.0975 - val_accuracy: 0.9939\n",
            "Epoch 483/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0355 - accuracy: 0.9967 - val_loss: 0.1051 - val_accuracy: 0.9709\n",
            "Epoch 484/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0115 - accuracy: 0.9977 - val_loss: 0.0915 - val_accuracy: 0.9921\n",
            "Epoch 485/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0274 - accuracy: 0.9985 - val_loss: 0.0981 - val_accuracy: 0.9897\n",
            "Epoch 486/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0194 - accuracy: 0.9974 - val_loss: 0.1828 - val_accuracy: 0.9915\n",
            "Epoch 487/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0070 - accuracy: 0.9986 - val_loss: 0.0544 - val_accuracy: 0.9921\n",
            "Epoch 488/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0068 - accuracy: 0.9988 - val_loss: 0.0615 - val_accuracy: 0.9945\n",
            "Epoch 489/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0062 - accuracy: 0.9988 - val_loss: 0.0767 - val_accuracy: 0.9927\n",
            "Epoch 490/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.0577 - val_accuracy: 0.9951\n",
            "Epoch 491/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0040 - accuracy: 0.9992 - val_loss: 0.1252 - val_accuracy: 0.9897\n",
            "Epoch 492/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0061 - accuracy: 0.9989 - val_loss: 0.1221 - val_accuracy: 0.9939\n",
            "Epoch 493/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0067 - accuracy: 0.9991 - val_loss: 0.6698 - val_accuracy: 0.9794\n",
            "Epoch 494/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0113 - accuracy: 0.9976 - val_loss: 0.0936 - val_accuracy: 0.9897\n",
            "Epoch 495/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0093 - accuracy: 0.9985 - val_loss: 0.0561 - val_accuracy: 0.9915\n",
            "Epoch 496/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0019 - accuracy: 0.9997 - val_loss: 0.0599 - val_accuracy: 0.9921\n",
            "Epoch 497/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0028 - accuracy: 0.9995 - val_loss: 0.0431 - val_accuracy: 0.9933\n",
            "Epoch 498/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0039 - accuracy: 0.9994 - val_loss: 0.0797 - val_accuracy: 0.9915\n",
            "Epoch 499/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0048 - accuracy: 0.9991 - val_loss: 0.1231 - val_accuracy: 0.9885\n",
            "Epoch 500/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0108 - accuracy: 0.9983 - val_loss: 0.1777 - val_accuracy: 0.9824\n",
            "Epoch 501/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0350 - accuracy: 0.9962 - val_loss: 0.3479 - val_accuracy: 0.9903\n",
            "Epoch 502/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0073 - accuracy: 0.9988 - val_loss: 0.0626 - val_accuracy: 0.9915\n",
            "Epoch 503/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0110 - accuracy: 0.9983 - val_loss: 0.0466 - val_accuracy: 0.9885\n",
            "Epoch 504/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0080 - accuracy: 0.9985 - val_loss: 0.0586 - val_accuracy: 0.9897\n",
            "Epoch 505/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0061 - accuracy: 0.9989 - val_loss: 0.0631 - val_accuracy: 0.9927\n",
            "Epoch 506/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0118 - accuracy: 0.9983 - val_loss: 0.0717 - val_accuracy: 0.9909\n",
            "Epoch 507/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0032 - accuracy: 0.9995 - val_loss: 0.1028 - val_accuracy: 0.9903\n",
            "Epoch 508/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0031 - accuracy: 0.9995 - val_loss: 0.1065 - val_accuracy: 0.9897\n",
            "Epoch 509/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.1034 - val_accuracy: 0.9915\n",
            "Epoch 510/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0088 - accuracy: 0.9986 - val_loss: 0.2014 - val_accuracy: 0.9879\n",
            "Epoch 511/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0125 - accuracy: 0.9974 - val_loss: 0.0778 - val_accuracy: 0.9927\n",
            "Epoch 512/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0061 - accuracy: 0.9989 - val_loss: 0.0589 - val_accuracy: 0.9927\n",
            "Epoch 513/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.1546 - val_accuracy: 0.9891\n",
            "Epoch 514/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0088 - accuracy: 0.9988 - val_loss: 0.3281 - val_accuracy: 0.9867\n",
            "Epoch 515/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0374 - accuracy: 0.9968 - val_loss: 2.0612 - val_accuracy: 0.9466\n",
            "Epoch 516/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0421 - accuracy: 0.9947 - val_loss: 0.2069 - val_accuracy: 0.9879\n",
            "Epoch 517/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0192 - accuracy: 0.9979 - val_loss: 0.0596 - val_accuracy: 0.9848\n",
            "Epoch 518/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0232 - accuracy: 0.9970 - val_loss: 0.1533 - val_accuracy: 0.9915\n",
            "Epoch 519/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0201 - accuracy: 0.9983 - val_loss: 0.4506 - val_accuracy: 0.9848\n",
            "Epoch 520/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0178 - accuracy: 0.9982 - val_loss: 0.2310 - val_accuracy: 0.9909\n",
            "Epoch 521/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0300 - accuracy: 0.9976 - val_loss: 0.0806 - val_accuracy: 0.9885\n",
            "Epoch 522/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0115 - accuracy: 0.9992 - val_loss: 0.0816 - val_accuracy: 0.9909\n",
            "Epoch 523/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0147 - accuracy: 0.9982 - val_loss: 0.1028 - val_accuracy: 0.9897\n",
            "Epoch 524/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0144 - accuracy: 0.9974 - val_loss: 0.0593 - val_accuracy: 0.9879\n",
            "Epoch 525/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0063 - accuracy: 0.9986 - val_loss: 0.1193 - val_accuracy: 0.9921\n",
            "Epoch 526/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0060 - accuracy: 0.9988 - val_loss: 0.1754 - val_accuracy: 0.9903\n",
            "Epoch 527/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0053 - accuracy: 0.9991 - val_loss: 0.1364 - val_accuracy: 0.9909\n",
            "Epoch 528/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0048 - accuracy: 0.9989 - val_loss: 0.0846 - val_accuracy: 0.9927\n",
            "Epoch 529/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0054 - accuracy: 0.9988 - val_loss: 0.0673 - val_accuracy: 0.9909\n",
            "Epoch 530/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0082 - accuracy: 0.9985 - val_loss: 0.5633 - val_accuracy: 0.9769\n",
            "Epoch 531/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0056 - accuracy: 0.9992 - val_loss: 0.0595 - val_accuracy: 0.9933\n",
            "Epoch 532/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0062 - accuracy: 0.9986 - val_loss: 0.0738 - val_accuracy: 0.9921\n",
            "Epoch 533/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0046 - accuracy: 0.9995 - val_loss: 0.0507 - val_accuracy: 0.9939\n",
            "Epoch 534/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.1277 - val_accuracy: 0.9897\n",
            "Epoch 535/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0068 - accuracy: 0.9992 - val_loss: 0.0475 - val_accuracy: 0.9939\n",
            "Epoch 536/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0063 - accuracy: 0.9988 - val_loss: 0.0434 - val_accuracy: 0.9927\n",
            "Epoch 537/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0039 - accuracy: 0.9992 - val_loss: 0.0615 - val_accuracy: 0.9909\n",
            "Epoch 538/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0062 - accuracy: 0.9989 - val_loss: 0.1588 - val_accuracy: 0.9903\n",
            "Epoch 539/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0077 - accuracy: 0.9983 - val_loss: 0.0796 - val_accuracy: 0.9873\n",
            "Epoch 540/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0070 - accuracy: 0.9986 - val_loss: 0.0811 - val_accuracy: 0.9897\n",
            "Epoch 541/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0048 - accuracy: 0.9992 - val_loss: 0.0914 - val_accuracy: 0.9927\n",
            "Epoch 542/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0087 - accuracy: 0.9986 - val_loss: 0.3231 - val_accuracy: 0.9818\n",
            "Epoch 543/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0064 - accuracy: 0.9986 - val_loss: 0.0262 - val_accuracy: 0.9951\n",
            "Epoch 544/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0069 - accuracy: 0.9986 - val_loss: 0.0922 - val_accuracy: 0.9915\n",
            "Epoch 545/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.0815 - val_accuracy: 0.9927\n",
            "Epoch 546/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0185 - accuracy: 0.9985 - val_loss: 0.1823 - val_accuracy: 0.9885\n",
            "Epoch 547/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0134 - accuracy: 0.9971 - val_loss: 0.2512 - val_accuracy: 0.9897\n",
            "Epoch 548/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0146 - accuracy: 0.9980 - val_loss: 0.1301 - val_accuracy: 0.9951\n",
            "Epoch 549/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0227 - accuracy: 0.9977 - val_loss: 8.5151 - val_accuracy: 0.9102\n",
            "Epoch 550/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0237 - accuracy: 0.9959 - val_loss: 0.0894 - val_accuracy: 0.9915\n",
            "Epoch 551/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0095 - accuracy: 0.9986 - val_loss: 0.3667 - val_accuracy: 0.9885\n",
            "Epoch 552/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0058 - accuracy: 0.9989 - val_loss: 0.3541 - val_accuracy: 0.9782\n",
            "Epoch 553/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0104 - accuracy: 0.9983 - val_loss: 0.0487 - val_accuracy: 0.9903\n",
            "Epoch 554/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0069 - accuracy: 0.9986 - val_loss: 0.0701 - val_accuracy: 0.9921\n",
            "Epoch 555/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0053 - accuracy: 0.9992 - val_loss: 0.0634 - val_accuracy: 0.9933\n",
            "Epoch 556/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0065 - accuracy: 0.9991 - val_loss: 0.0757 - val_accuracy: 0.9945\n",
            "Epoch 557/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0125 - accuracy: 0.9988 - val_loss: 0.0666 - val_accuracy: 0.9927\n",
            "Epoch 558/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0050 - accuracy: 0.9991 - val_loss: 0.0729 - val_accuracy: 0.9915\n",
            "Epoch 559/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0026 - accuracy: 0.9995 - val_loss: 0.0860 - val_accuracy: 0.9933\n",
            "Epoch 560/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0073 - accuracy: 0.9986 - val_loss: 0.0841 - val_accuracy: 0.9939\n",
            "Epoch 561/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0034 - accuracy: 0.9997 - val_loss: 0.0557 - val_accuracy: 0.9933\n",
            "Epoch 562/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0132 - accuracy: 0.9985 - val_loss: 0.4794 - val_accuracy: 0.9867\n",
            "Epoch 563/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0159 - accuracy: 0.9968 - val_loss: 0.0851 - val_accuracy: 0.9891\n",
            "Epoch 564/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0259 - accuracy: 0.9976 - val_loss: 0.0780 - val_accuracy: 0.9873\n",
            "Epoch 565/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0103 - accuracy: 0.9980 - val_loss: 0.0951 - val_accuracy: 0.9903\n",
            "Epoch 566/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0078 - accuracy: 0.9983 - val_loss: 0.1715 - val_accuracy: 0.9897\n",
            "Epoch 567/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0104 - accuracy: 0.9982 - val_loss: 0.0781 - val_accuracy: 0.9903\n",
            "Epoch 568/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0078 - accuracy: 0.9985 - val_loss: 0.1465 - val_accuracy: 0.9903\n",
            "Epoch 569/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0054 - accuracy: 0.9989 - val_loss: 0.1284 - val_accuracy: 0.9933\n",
            "Epoch 570/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0071 - accuracy: 0.9992 - val_loss: 0.1677 - val_accuracy: 0.9891\n",
            "Epoch 571/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0206 - accuracy: 0.9992 - val_loss: 0.2360 - val_accuracy: 0.9867\n",
            "Epoch 572/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0078 - accuracy: 0.9985 - val_loss: 0.0421 - val_accuracy: 0.9915\n",
            "Epoch 573/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0043 - accuracy: 0.9989 - val_loss: 0.2556 - val_accuracy: 0.9885\n",
            "Epoch 574/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0072 - accuracy: 0.9989 - val_loss: 0.0554 - val_accuracy: 0.9933\n",
            "Epoch 575/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0041 - accuracy: 0.9992 - val_loss: 0.0961 - val_accuracy: 0.9915\n",
            "Epoch 576/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0053 - accuracy: 0.9991 - val_loss: 0.0977 - val_accuracy: 0.9909\n",
            "Epoch 577/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0023 - accuracy: 0.9995 - val_loss: 0.1327 - val_accuracy: 0.9921\n",
            "Epoch 578/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0083 - accuracy: 0.9983 - val_loss: 0.2663 - val_accuracy: 0.9879\n",
            "Epoch 579/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0070 - accuracy: 0.9988 - val_loss: 0.1079 - val_accuracy: 0.9921\n",
            "Epoch 580/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0091 - accuracy: 0.9985 - val_loss: 0.2176 - val_accuracy: 0.9897\n",
            "Epoch 581/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0050 - accuracy: 0.9991 - val_loss: 0.1133 - val_accuracy: 0.9915\n",
            "Epoch 582/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0144 - accuracy: 0.9980 - val_loss: 0.1256 - val_accuracy: 0.9806\n",
            "Epoch 583/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0119 - accuracy: 0.9988 - val_loss: 0.0626 - val_accuracy: 0.9927\n",
            "Epoch 584/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0066 - accuracy: 0.9989 - val_loss: 0.0591 - val_accuracy: 0.9909\n",
            "Epoch 585/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0076 - accuracy: 0.9985 - val_loss: 0.1504 - val_accuracy: 0.9897\n",
            "Epoch 586/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0093 - accuracy: 0.9989 - val_loss: 0.1669 - val_accuracy: 0.9903\n",
            "Epoch 587/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 0.1439 - val_accuracy: 0.9903\n",
            "Epoch 588/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0044 - accuracy: 0.9991 - val_loss: 0.0989 - val_accuracy: 0.9933\n",
            "Epoch 589/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0106 - accuracy: 0.9986 - val_loss: 0.1124 - val_accuracy: 0.9939\n",
            "Epoch 590/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0075 - accuracy: 0.9986 - val_loss: 0.0755 - val_accuracy: 0.9915\n",
            "Epoch 591/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0124 - accuracy: 0.9983 - val_loss: 0.1104 - val_accuracy: 0.9891\n",
            "Epoch 592/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0145 - accuracy: 0.9979 - val_loss: 0.1002 - val_accuracy: 0.9836\n",
            "Epoch 593/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0041 - accuracy: 0.9991 - val_loss: 0.0907 - val_accuracy: 0.9915\n",
            "Epoch 594/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0144 - accuracy: 0.9989 - val_loss: 0.8210 - val_accuracy: 0.9763\n",
            "Epoch 595/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0224 - accuracy: 0.9965 - val_loss: 0.1133 - val_accuracy: 0.9891\n",
            "Epoch 596/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0089 - accuracy: 0.9983 - val_loss: 0.1841 - val_accuracy: 0.9921\n",
            "Epoch 597/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0064 - accuracy: 0.9989 - val_loss: 0.1858 - val_accuracy: 0.9921\n",
            "Epoch 598/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0049 - accuracy: 0.9991 - val_loss: 0.0858 - val_accuracy: 0.9921\n",
            "Epoch 599/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0038 - accuracy: 0.9994 - val_loss: 0.0857 - val_accuracy: 0.9921\n",
            "Epoch 600/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0062 - accuracy: 0.9986 - val_loss: 0.0870 - val_accuracy: 0.9933\n",
            "Epoch 601/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0025 - accuracy: 0.9995 - val_loss: 0.0963 - val_accuracy: 0.9939\n",
            "Epoch 602/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0088 - accuracy: 0.9991 - val_loss: 0.0536 - val_accuracy: 0.9927\n",
            "Epoch 603/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0053 - accuracy: 0.9991 - val_loss: 0.0540 - val_accuracy: 0.9909\n",
            "Epoch 604/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0040 - accuracy: 0.9989 - val_loss: 0.0969 - val_accuracy: 0.9909\n",
            "Epoch 605/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0088 - accuracy: 0.9982 - val_loss: 0.0698 - val_accuracy: 0.9848\n",
            "Epoch 606/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0151 - accuracy: 0.9974 - val_loss: 0.2430 - val_accuracy: 0.9860\n",
            "Epoch 607/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0094 - accuracy: 0.9982 - val_loss: 0.2806 - val_accuracy: 0.9836\n",
            "Epoch 608/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0086 - accuracy: 0.9983 - val_loss: 0.1719 - val_accuracy: 0.9854\n",
            "Epoch 609/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0087 - accuracy: 0.9985 - val_loss: 0.1902 - val_accuracy: 0.9769\n",
            "Epoch 610/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0042 - accuracy: 0.9991 - val_loss: 0.1545 - val_accuracy: 0.9885\n",
            "Epoch 611/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0038 - accuracy: 0.9991 - val_loss: 0.1125 - val_accuracy: 0.9897\n",
            "Epoch 612/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0040 - accuracy: 0.9992 - val_loss: 0.1979 - val_accuracy: 0.9879\n",
            "Epoch 613/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0053 - accuracy: 0.9991 - val_loss: 0.1732 - val_accuracy: 0.9915\n",
            "Epoch 614/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0076 - accuracy: 0.9983 - val_loss: 0.2083 - val_accuracy: 0.9879\n",
            "Epoch 615/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0153 - accuracy: 0.9979 - val_loss: 0.1116 - val_accuracy: 0.9903\n",
            "Epoch 616/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0063 - accuracy: 0.9986 - val_loss: 0.1290 - val_accuracy: 0.9915\n",
            "Epoch 617/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0030 - accuracy: 0.9991 - val_loss: 0.1586 - val_accuracy: 0.9903\n",
            "Epoch 618/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0078 - accuracy: 0.9986 - val_loss: 0.1457 - val_accuracy: 0.9897\n",
            "Epoch 619/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0038 - accuracy: 0.9994 - val_loss: 0.1428 - val_accuracy: 0.9891\n",
            "Epoch 620/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0079 - accuracy: 0.9991 - val_loss: 0.2284 - val_accuracy: 0.9885\n",
            "Epoch 621/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0047 - accuracy: 0.9992 - val_loss: 0.1794 - val_accuracy: 0.9909\n",
            "Epoch 622/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0024 - accuracy: 0.9997 - val_loss: 0.1878 - val_accuracy: 0.9909\n",
            "Epoch 623/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0032 - accuracy: 0.9995 - val_loss: 0.1342 - val_accuracy: 0.9903\n",
            "Epoch 624/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0022 - accuracy: 0.9997 - val_loss: 0.1915 - val_accuracy: 0.9897\n",
            "Epoch 625/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0050 - accuracy: 0.9992 - val_loss: 0.1191 - val_accuracy: 0.9897\n",
            "Epoch 626/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0054 - accuracy: 0.9991 - val_loss: 0.3807 - val_accuracy: 0.9897\n",
            "Epoch 627/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0123 - accuracy: 0.9988 - val_loss: 1.9864 - val_accuracy: 0.9624\n",
            "Epoch 628/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0049 - accuracy: 0.9991 - val_loss: 0.5316 - val_accuracy: 0.9836\n",
            "Epoch 629/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0108 - accuracy: 0.9991 - val_loss: 0.9060 - val_accuracy: 0.9763\n",
            "Epoch 630/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0076 - accuracy: 0.9986 - val_loss: 0.2334 - val_accuracy: 0.9867\n",
            "Epoch 631/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0077 - accuracy: 0.9991 - val_loss: 0.0933 - val_accuracy: 0.9915\n",
            "Epoch 632/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0015 - accuracy: 0.9998 - val_loss: 0.0749 - val_accuracy: 0.9933\n",
            "Epoch 633/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 0.0721 - val_accuracy: 0.9933\n",
            "Epoch 634/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0044 - accuracy: 0.9991 - val_loss: 0.4204 - val_accuracy: 0.9848\n",
            "Epoch 635/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0025 - accuracy: 0.9995 - val_loss: 0.0730 - val_accuracy: 0.9836\n",
            "Epoch 636/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0093 - accuracy: 0.9985 - val_loss: 0.5873 - val_accuracy: 0.9757\n",
            "Epoch 637/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0071 - accuracy: 0.9992 - val_loss: 0.2048 - val_accuracy: 0.9873\n",
            "Epoch 638/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0034 - accuracy: 0.9994 - val_loss: 0.0586 - val_accuracy: 0.9927\n",
            "Epoch 639/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0045 - accuracy: 0.9992 - val_loss: 0.0587 - val_accuracy: 0.9933\n",
            "Epoch 640/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0164 - accuracy: 0.9980 - val_loss: 0.0499 - val_accuracy: 0.9915\n",
            "Epoch 641/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0172 - accuracy: 0.9980 - val_loss: 0.1364 - val_accuracy: 0.9903\n",
            "Epoch 642/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0059 - accuracy: 0.9989 - val_loss: 0.1548 - val_accuracy: 0.9921\n",
            "Epoch 643/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1383 - accuracy: 0.9965 - val_loss: 0.1309 - val_accuracy: 0.9812\n",
            "Epoch 644/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0092 - accuracy: 0.9982 - val_loss: 0.1035 - val_accuracy: 0.9903\n",
            "Epoch 645/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0070 - accuracy: 0.9985 - val_loss: 0.1495 - val_accuracy: 0.9927\n",
            "Epoch 646/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0065 - accuracy: 0.9989 - val_loss: 0.1177 - val_accuracy: 0.9909\n",
            "Epoch 647/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.1380 - val_accuracy: 0.9909\n",
            "Epoch 648/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0064 - accuracy: 0.9989 - val_loss: 0.1360 - val_accuracy: 0.9903\n",
            "Epoch 649/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.1121 - val_accuracy: 0.9915\n",
            "Epoch 650/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0081 - accuracy: 0.9986 - val_loss: 0.0862 - val_accuracy: 0.9915\n",
            "Epoch 651/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0068 - accuracy: 0.9988 - val_loss: 0.0847 - val_accuracy: 0.9945\n",
            "Epoch 652/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0106 - accuracy: 0.9985 - val_loss: 0.0967 - val_accuracy: 0.9939\n",
            "Epoch 653/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0049 - accuracy: 0.9989 - val_loss: 0.1734 - val_accuracy: 0.9903\n",
            "Epoch 654/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0039 - accuracy: 0.9992 - val_loss: 0.0971 - val_accuracy: 0.9933\n",
            "Epoch 655/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0047 - accuracy: 0.9992 - val_loss: 0.1041 - val_accuracy: 0.9921\n",
            "Epoch 656/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0043 - accuracy: 0.9992 - val_loss: 0.1177 - val_accuracy: 0.9927\n",
            "Epoch 657/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 6.3531e-04 - accuracy: 1.0000 - val_loss: 0.1136 - val_accuracy: 0.9933\n",
            "Epoch 658/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0022 - accuracy: 0.9997 - val_loss: 0.1148 - val_accuracy: 0.9933\n",
            "Epoch 659/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0039 - accuracy: 0.9991 - val_loss: 0.1122 - val_accuracy: 0.9933\n",
            "Epoch 660/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0085 - accuracy: 0.9989 - val_loss: 0.1545 - val_accuracy: 0.9915\n",
            "Epoch 661/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0061 - accuracy: 0.9989 - val_loss: 0.1047 - val_accuracy: 0.9903\n",
            "Epoch 662/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0142 - accuracy: 0.9976 - val_loss: 0.1786 - val_accuracy: 0.9915\n",
            "Epoch 663/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0076 - accuracy: 0.9985 - val_loss: 0.1751 - val_accuracy: 0.9903\n",
            "Epoch 664/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0038 - accuracy: 0.9994 - val_loss: 0.2053 - val_accuracy: 0.9891\n",
            "Epoch 665/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0085 - accuracy: 0.9989 - val_loss: 0.1333 - val_accuracy: 0.9903\n",
            "Epoch 666/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0127 - accuracy: 0.9986 - val_loss: 0.1155 - val_accuracy: 0.9879\n",
            "Epoch 667/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0104 - accuracy: 0.9982 - val_loss: 0.1690 - val_accuracy: 0.9897\n",
            "Epoch 668/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0142 - accuracy: 0.9976 - val_loss: 0.1034 - val_accuracy: 0.9885\n",
            "Epoch 669/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0070 - accuracy: 0.9985 - val_loss: 0.1010 - val_accuracy: 0.9873\n",
            "Epoch 670/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0037 - accuracy: 0.9989 - val_loss: 0.2800 - val_accuracy: 0.9891\n",
            "Epoch 671/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0590 - accuracy: 0.9974 - val_loss: 0.0221 - val_accuracy: 0.9945\n",
            "Epoch 672/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0065 - accuracy: 0.9988 - val_loss: 0.0409 - val_accuracy: 0.9933\n",
            "Epoch 673/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0016 - accuracy: 0.9998 - val_loss: 0.0661 - val_accuracy: 0.9921\n",
            "Epoch 674/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0130 - accuracy: 0.9980 - val_loss: 1.2357 - val_accuracy: 0.9727\n",
            "Epoch 675/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0143 - accuracy: 0.9976 - val_loss: 0.0591 - val_accuracy: 0.9860\n",
            "Epoch 676/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0114 - accuracy: 0.9980 - val_loss: 0.1038 - val_accuracy: 0.9921\n",
            "Epoch 677/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0068 - accuracy: 0.9986 - val_loss: 0.1263 - val_accuracy: 0.9921\n",
            "Epoch 678/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.0927 - val_accuracy: 0.9927\n",
            "Epoch 679/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 8.9395e-04 - accuracy: 0.9998 - val_loss: 0.1448 - val_accuracy: 0.9903\n",
            "Epoch 680/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.1360 - val_accuracy: 0.9915\n",
            "Epoch 681/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0035 - accuracy: 0.9997 - val_loss: 0.2138 - val_accuracy: 0.9897\n",
            "Epoch 682/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0034 - accuracy: 0.9994 - val_loss: 0.0705 - val_accuracy: 0.9927\n",
            "Epoch 683/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0331 - accuracy: 0.9971 - val_loss: 0.0994 - val_accuracy: 0.9891\n",
            "Epoch 684/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0176 - accuracy: 0.9982 - val_loss: 0.0956 - val_accuracy: 0.9921\n",
            "Epoch 685/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0084 - accuracy: 0.9983 - val_loss: 0.1189 - val_accuracy: 0.9951\n",
            "Epoch 686/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0017 - accuracy: 0.9997 - val_loss: 0.1761 - val_accuracy: 0.9927\n",
            "Epoch 687/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0029 - accuracy: 0.9995 - val_loss: 0.1560 - val_accuracy: 0.9927\n",
            "Epoch 688/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0139 - accuracy: 0.9983 - val_loss: 0.0938 - val_accuracy: 0.9909\n",
            "Epoch 689/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0037 - accuracy: 0.9994 - val_loss: 0.1255 - val_accuracy: 0.9921\n",
            "Epoch 690/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0435 - accuracy: 0.9970 - val_loss: 0.5430 - val_accuracy: 0.9842\n",
            "Epoch 691/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0064 - accuracy: 0.9986 - val_loss: 0.1161 - val_accuracy: 0.9921\n",
            "Epoch 692/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0237 - accuracy: 0.9982 - val_loss: 0.4216 - val_accuracy: 0.9794\n",
            "Epoch 693/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0086 - accuracy: 0.9982 - val_loss: 0.1668 - val_accuracy: 0.9903\n",
            "Epoch 694/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0045 - accuracy: 0.9992 - val_loss: 0.1377 - val_accuracy: 0.9909\n",
            "Epoch 695/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0097 - accuracy: 0.9983 - val_loss: 0.2591 - val_accuracy: 0.9921\n",
            "Epoch 696/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0057 - accuracy: 0.9994 - val_loss: 0.1350 - val_accuracy: 0.9927\n",
            "Epoch 697/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0053 - accuracy: 0.9991 - val_loss: 0.1563 - val_accuracy: 0.9903\n",
            "Epoch 698/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0205 - accuracy: 0.9985 - val_loss: 0.0810 - val_accuracy: 0.9891\n",
            "Epoch 699/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.6813 - val_accuracy: 0.9824\n",
            "Epoch 700/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.4086 - val_accuracy: 0.9873\n",
            "Epoch 701/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0039 - accuracy: 0.9991 - val_loss: 0.1233 - val_accuracy: 0.9891\n",
            "Epoch 702/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0073 - accuracy: 0.9992 - val_loss: 0.1329 - val_accuracy: 0.9891\n",
            "Epoch 703/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0105 - accuracy: 0.9980 - val_loss: 0.2202 - val_accuracy: 0.9915\n",
            "Epoch 704/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0038 - accuracy: 0.9994 - val_loss: 0.1926 - val_accuracy: 0.9921\n",
            "Epoch 705/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0049 - accuracy: 0.9991 - val_loss: 0.0748 - val_accuracy: 0.9867\n",
            "Epoch 706/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0183 - accuracy: 0.9982 - val_loss: 0.2203 - val_accuracy: 0.9903\n",
            "Epoch 707/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0052 - accuracy: 0.9991 - val_loss: 0.0965 - val_accuracy: 0.9830\n",
            "Epoch 708/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0096 - accuracy: 0.9985 - val_loss: 0.1624 - val_accuracy: 0.9909\n",
            "Epoch 709/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0235 - accuracy: 0.9989 - val_loss: 0.0682 - val_accuracy: 0.9909\n",
            "Epoch 710/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0077 - accuracy: 0.9986 - val_loss: 0.1434 - val_accuracy: 0.9909\n",
            "Epoch 711/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0067 - accuracy: 0.9988 - val_loss: 0.1432 - val_accuracy: 0.9915\n",
            "Epoch 712/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0045 - accuracy: 0.9992 - val_loss: 0.1447 - val_accuracy: 0.9921\n",
            "Epoch 713/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0129 - accuracy: 0.9977 - val_loss: 0.1022 - val_accuracy: 0.9915\n",
            "Epoch 714/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0081 - accuracy: 0.9982 - val_loss: 0.1320 - val_accuracy: 0.9939\n",
            "Epoch 715/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0049 - accuracy: 0.9988 - val_loss: 0.4393 - val_accuracy: 0.9891\n",
            "Epoch 716/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0084 - accuracy: 0.9985 - val_loss: 0.1704 - val_accuracy: 0.9939\n",
            "Epoch 717/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 0.1321 - val_accuracy: 0.9945\n",
            "Epoch 718/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0032 - accuracy: 0.9992 - val_loss: 0.0876 - val_accuracy: 0.9909\n",
            "Epoch 719/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0133 - accuracy: 0.9992 - val_loss: 0.0573 - val_accuracy: 0.9927\n",
            "Epoch 720/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0036 - accuracy: 0.9994 - val_loss: 0.6237 - val_accuracy: 0.9848\n",
            "Epoch 721/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0022 - accuracy: 0.9997 - val_loss: 0.1875 - val_accuracy: 0.9927\n",
            "Epoch 722/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.1263 - val_accuracy: 0.9915\n",
            "Epoch 723/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0015 - accuracy: 0.9998 - val_loss: 0.1052 - val_accuracy: 0.9927\n",
            "Epoch 724/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0022 - accuracy: 0.9997 - val_loss: 0.1168 - val_accuracy: 0.9927\n",
            "Epoch 725/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 0.1195 - val_accuracy: 0.9915\n",
            "Epoch 726/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0048 - accuracy: 0.9992 - val_loss: 0.3569 - val_accuracy: 0.9842\n",
            "Epoch 727/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0278 - accuracy: 0.9970 - val_loss: 0.2355 - val_accuracy: 0.9927\n",
            "Epoch 728/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0132 - accuracy: 0.9977 - val_loss: 0.3801 - val_accuracy: 0.9897\n",
            "Epoch 729/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0134 - accuracy: 0.9979 - val_loss: 0.1324 - val_accuracy: 0.9897\n",
            "Epoch 730/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0147 - accuracy: 0.9974 - val_loss: 0.1486 - val_accuracy: 0.9897\n",
            "Epoch 731/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0100 - accuracy: 0.9979 - val_loss: 0.1715 - val_accuracy: 0.9891\n",
            "Epoch 732/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0041 - accuracy: 0.9991 - val_loss: 0.1388 - val_accuracy: 0.9909\n",
            "Epoch 733/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0096 - accuracy: 0.9985 - val_loss: 0.0757 - val_accuracy: 0.9915\n",
            "Epoch 734/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0388 - accuracy: 0.9971 - val_loss: 0.2088 - val_accuracy: 0.9842\n",
            "Epoch 735/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0156 - accuracy: 0.9983 - val_loss: 0.0583 - val_accuracy: 0.9854\n",
            "Epoch 736/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0045 - accuracy: 0.9989 - val_loss: 0.0666 - val_accuracy: 0.9927\n",
            "Epoch 737/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0097 - accuracy: 0.9985 - val_loss: 0.0772 - val_accuracy: 0.9915\n",
            "Epoch 738/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.0571 - val_accuracy: 0.9897\n",
            "Epoch 739/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0046 - accuracy: 0.9992 - val_loss: 0.0577 - val_accuracy: 0.9897\n",
            "Epoch 740/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0038 - accuracy: 0.9994 - val_loss: 0.0567 - val_accuracy: 0.9903\n",
            "Epoch 741/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 0.0729 - val_accuracy: 0.9897\n",
            "Epoch 742/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0050 - accuracy: 0.9992 - val_loss: 0.1958 - val_accuracy: 0.9885\n",
            "Epoch 743/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0015 - accuracy: 0.9998 - val_loss: 0.0991 - val_accuracy: 0.9921\n",
            "Epoch 744/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0082 - accuracy: 0.9992 - val_loss: 0.0678 - val_accuracy: 0.9939\n",
            "Epoch 745/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0111 - accuracy: 0.9982 - val_loss: 0.2036 - val_accuracy: 0.9854\n",
            "Epoch 746/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0181 - accuracy: 0.9974 - val_loss: 0.0395 - val_accuracy: 0.9921\n",
            "Epoch 747/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0023 - accuracy: 0.9995 - val_loss: 0.0527 - val_accuracy: 0.9933\n",
            "Epoch 748/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0437 - accuracy: 0.9973 - val_loss: 0.1191 - val_accuracy: 0.9903\n",
            "Epoch 749/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0119 - accuracy: 0.9976 - val_loss: 0.0610 - val_accuracy: 0.9951\n",
            "Epoch 750/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0110 - accuracy: 0.9983 - val_loss: 0.2209 - val_accuracy: 0.9903\n",
            "Epoch 751/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0148 - accuracy: 0.9983 - val_loss: 0.0318 - val_accuracy: 0.9939\n",
            "Epoch 752/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0062 - accuracy: 0.9989 - val_loss: 0.1127 - val_accuracy: 0.9909\n",
            "Epoch 753/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0112 - accuracy: 0.9989 - val_loss: 0.1012 - val_accuracy: 0.9921\n",
            "Epoch 754/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0037 - accuracy: 0.9995 - val_loss: 0.2864 - val_accuracy: 0.9885\n",
            "Epoch 755/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0069 - accuracy: 0.9988 - val_loss: 0.0621 - val_accuracy: 0.9927\n",
            "Epoch 756/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0086 - accuracy: 0.9983 - val_loss: 0.1561 - val_accuracy: 0.9891\n",
            "Epoch 757/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0103 - accuracy: 0.9986 - val_loss: 0.0612 - val_accuracy: 0.9933\n",
            "Epoch 758/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0080 - accuracy: 0.9983 - val_loss: 0.0891 - val_accuracy: 0.9945\n",
            "Epoch 759/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0100 - accuracy: 0.9983 - val_loss: 0.0601 - val_accuracy: 0.9939\n",
            "Epoch 760/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0075 - accuracy: 0.9985 - val_loss: 0.1055 - val_accuracy: 0.9903\n",
            "Epoch 761/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0036 - accuracy: 0.9994 - val_loss: 0.1599 - val_accuracy: 0.9909\n",
            "Epoch 762/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.0833 - val_accuracy: 0.9927\n",
            "Epoch 763/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0042 - accuracy: 0.9994 - val_loss: 0.0955 - val_accuracy: 0.9915\n",
            "Epoch 764/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0040 - accuracy: 0.9992 - val_loss: 0.4938 - val_accuracy: 0.9733\n",
            "Epoch 765/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0041 - accuracy: 0.9991 - val_loss: 0.0576 - val_accuracy: 0.9921\n",
            "Epoch 766/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0050 - accuracy: 0.9992 - val_loss: 0.6746 - val_accuracy: 0.9836\n",
            "Epoch 767/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0040 - accuracy: 0.9992 - val_loss: 0.2574 - val_accuracy: 0.9885\n",
            "Epoch 768/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0016 - accuracy: 0.9998 - val_loss: 0.0868 - val_accuracy: 0.9915\n",
            "Epoch 769/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0023 - accuracy: 0.9997 - val_loss: 0.1442 - val_accuracy: 0.9903\n",
            "Epoch 770/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0096 - accuracy: 0.9977 - val_loss: 0.4585 - val_accuracy: 0.9848\n",
            "Epoch 771/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0039 - accuracy: 0.9994 - val_loss: 0.1088 - val_accuracy: 0.9927\n",
            "Epoch 772/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0022 - accuracy: 0.9997 - val_loss: 0.0990 - val_accuracy: 0.9921\n",
            "Epoch 773/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0130 - accuracy: 0.9979 - val_loss: 0.0361 - val_accuracy: 0.9927\n",
            "Epoch 774/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0079 - accuracy: 0.9992 - val_loss: 0.1070 - val_accuracy: 0.9921\n",
            "Epoch 775/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0120 - accuracy: 0.9979 - val_loss: 0.1184 - val_accuracy: 0.9800\n",
            "Epoch 776/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0099 - accuracy: 0.9992 - val_loss: 0.1491 - val_accuracy: 0.9909\n",
            "Epoch 777/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0056 - accuracy: 0.9989 - val_loss: 0.3646 - val_accuracy: 0.9860\n",
            "Epoch 778/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0187 - accuracy: 0.9983 - val_loss: 0.1272 - val_accuracy: 0.9909\n",
            "Epoch 779/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0054 - accuracy: 0.9991 - val_loss: 0.1634 - val_accuracy: 0.9927\n",
            "Epoch 780/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0038 - accuracy: 0.9994 - val_loss: 0.1773 - val_accuracy: 0.9933\n",
            "Epoch 781/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.2819 - val_accuracy: 0.9927\n",
            "Epoch 782/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0039 - accuracy: 0.9994 - val_loss: 0.4252 - val_accuracy: 0.9903\n",
            "Epoch 783/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0074 - accuracy: 0.9994 - val_loss: 0.3750 - val_accuracy: 0.9903\n",
            "Epoch 784/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0018 - accuracy: 0.9997 - val_loss: 0.1472 - val_accuracy: 0.9927\n",
            "Epoch 785/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0022 - accuracy: 0.9997 - val_loss: 0.1717 - val_accuracy: 0.9933\n",
            "Epoch 786/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0108 - accuracy: 0.9982 - val_loss: 0.1098 - val_accuracy: 0.9945\n",
            "Epoch 787/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 0.1813 - val_accuracy: 0.9933\n",
            "Epoch 788/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0051 - accuracy: 0.9991 - val_loss: 0.1992 - val_accuracy: 0.9933\n",
            "Epoch 789/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0039 - accuracy: 0.9995 - val_loss: 0.1106 - val_accuracy: 0.9939\n",
            "Epoch 790/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0073 - accuracy: 0.9989 - val_loss: 0.2243 - val_accuracy: 0.9927\n",
            "Epoch 791/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0094 - accuracy: 0.9980 - val_loss: 0.1221 - val_accuracy: 0.9903\n",
            "Epoch 792/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0077 - accuracy: 0.9994 - val_loss: 0.1507 - val_accuracy: 0.9909\n",
            "Epoch 793/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0050 - accuracy: 0.9989 - val_loss: 0.0525 - val_accuracy: 0.9945\n",
            "Epoch 794/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0136 - accuracy: 0.9986 - val_loss: 0.0989 - val_accuracy: 0.9879\n",
            "Epoch 795/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0118 - accuracy: 0.9980 - val_loss: 0.0517 - val_accuracy: 0.9915\n",
            "Epoch 796/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0045 - accuracy: 0.9992 - val_loss: 0.0660 - val_accuracy: 0.9921\n",
            "Epoch 797/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0073 - accuracy: 0.9988 - val_loss: 0.0466 - val_accuracy: 0.9933\n",
            "Epoch 798/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0075 - accuracy: 0.9991 - val_loss: 0.0420 - val_accuracy: 0.9915\n",
            "Epoch 799/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0086 - accuracy: 0.9991 - val_loss: 0.0553 - val_accuracy: 0.9951\n",
            "Epoch 800/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0025 - accuracy: 0.9995 - val_loss: 0.0677 - val_accuracy: 0.9933\n",
            "Epoch 801/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0034 - accuracy: 0.9997 - val_loss: 0.1977 - val_accuracy: 0.9945\n",
            "Epoch 802/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0028 - accuracy: 0.9995 - val_loss: 0.2666 - val_accuracy: 0.9891\n",
            "Epoch 803/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.0697 - val_accuracy: 0.9945\n",
            "Epoch 804/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0069 - accuracy: 0.9989 - val_loss: 0.8485 - val_accuracy: 0.9848\n",
            "Epoch 805/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0016 - accuracy: 0.9998 - val_loss: 0.0993 - val_accuracy: 0.9933\n",
            "Epoch 806/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.0443 - val_accuracy: 0.9897\n",
            "Epoch 807/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0051 - accuracy: 0.9991 - val_loss: 0.0485 - val_accuracy: 0.9927\n",
            "Epoch 808/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0110 - accuracy: 0.9988 - val_loss: 0.0534 - val_accuracy: 0.9909\n",
            "Epoch 809/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0065 - accuracy: 0.9985 - val_loss: 0.1954 - val_accuracy: 0.9903\n",
            "Epoch 810/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0165 - accuracy: 0.9979 - val_loss: 0.1880 - val_accuracy: 0.9921\n",
            "Epoch 811/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0069 - accuracy: 0.9988 - val_loss: 0.3979 - val_accuracy: 0.9830\n",
            "Epoch 812/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0060 - accuracy: 0.9985 - val_loss: 0.0852 - val_accuracy: 0.9903\n",
            "Epoch 813/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0060 - accuracy: 0.9988 - val_loss: 0.1253 - val_accuracy: 0.9897\n",
            "Epoch 814/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0031 - accuracy: 0.9995 - val_loss: 0.1391 - val_accuracy: 0.9915\n",
            "Epoch 815/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0090 - accuracy: 0.9986 - val_loss: 0.1074 - val_accuracy: 0.9873\n",
            "Epoch 816/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0062 - accuracy: 0.9988 - val_loss: 0.2330 - val_accuracy: 0.9885\n",
            "Epoch 817/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0042 - accuracy: 0.9992 - val_loss: 0.1237 - val_accuracy: 0.9915\n",
            "Epoch 818/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0028 - accuracy: 0.9995 - val_loss: 0.0924 - val_accuracy: 0.9927\n",
            "Epoch 819/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 0.1362 - val_accuracy: 0.9951\n",
            "Epoch 820/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0086 - accuracy: 0.9985 - val_loss: 0.1818 - val_accuracy: 0.9909\n",
            "Epoch 821/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 0.1358 - val_accuracy: 0.9915\n",
            "Epoch 822/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0035 - accuracy: 0.9994 - val_loss: 0.1283 - val_accuracy: 0.9909\n",
            "Epoch 823/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0056 - accuracy: 0.9992 - val_loss: 0.0524 - val_accuracy: 0.9885\n",
            "Epoch 824/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0084 - accuracy: 0.9989 - val_loss: 0.0522 - val_accuracy: 0.9909\n",
            "Epoch 825/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0108 - accuracy: 0.9982 - val_loss: 0.1012 - val_accuracy: 0.9879\n",
            "Epoch 826/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0064 - accuracy: 0.9994 - val_loss: 0.0666 - val_accuracy: 0.9885\n",
            "Epoch 827/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0050 - accuracy: 0.9989 - val_loss: 0.1530 - val_accuracy: 0.9945\n",
            "Epoch 828/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0022 - accuracy: 0.9997 - val_loss: 0.1367 - val_accuracy: 0.9933\n",
            "Epoch 829/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.1782 - val_accuracy: 0.9939\n",
            "Epoch 830/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.3143 - val_accuracy: 0.9794\n",
            "Epoch 831/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0156 - accuracy: 0.9982 - val_loss: 0.0731 - val_accuracy: 0.9927\n",
            "Epoch 832/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0093 - accuracy: 0.9982 - val_loss: 0.1065 - val_accuracy: 0.9927\n",
            "Epoch 833/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0052 - accuracy: 0.9992 - val_loss: 0.2695 - val_accuracy: 0.9885\n",
            "Epoch 834/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0189 - accuracy: 0.9991 - val_loss: 0.2032 - val_accuracy: 0.9836\n",
            "Epoch 835/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0257 - accuracy: 0.9967 - val_loss: 0.1004 - val_accuracy: 0.9848\n",
            "Epoch 836/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0086 - accuracy: 0.9985 - val_loss: 0.2150 - val_accuracy: 0.9763\n",
            "Epoch 837/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0200 - accuracy: 0.9964 - val_loss: 0.0889 - val_accuracy: 0.9879\n",
            "Epoch 838/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0053 - accuracy: 0.9988 - val_loss: 0.1891 - val_accuracy: 0.9873\n",
            "Epoch 839/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0050 - accuracy: 0.9989 - val_loss: 0.0883 - val_accuracy: 0.9909\n",
            "Epoch 840/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 0.0750 - val_accuracy: 0.9909\n",
            "Epoch 841/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 0.0663 - val_accuracy: 0.9909\n",
            "Epoch 842/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0189 - accuracy: 0.9980 - val_loss: 0.2036 - val_accuracy: 0.9897\n",
            "Epoch 843/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.1265 - val_accuracy: 0.9891\n",
            "Epoch 844/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0106 - accuracy: 0.9980 - val_loss: 0.0981 - val_accuracy: 0.9909\n",
            "Epoch 845/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.0901 - val_accuracy: 0.9915\n",
            "Epoch 846/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0054 - accuracy: 0.9992 - val_loss: 0.0662 - val_accuracy: 0.9873\n",
            "Epoch 847/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0074 - accuracy: 0.9994 - val_loss: 0.1267 - val_accuracy: 0.9927\n",
            "Epoch 848/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0079 - accuracy: 0.9997 - val_loss: 0.1835 - val_accuracy: 0.9891\n",
            "Epoch 849/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.1390 - val_accuracy: 0.9915\n",
            "Epoch 850/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.1039 - val_accuracy: 0.9903\n",
            "Epoch 851/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 0.0763 - val_accuracy: 0.9909\n",
            "Epoch 852/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0064 - accuracy: 0.9989 - val_loss: 0.0844 - val_accuracy: 0.9927\n",
            "Epoch 853/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0039 - accuracy: 0.9994 - val_loss: 0.0429 - val_accuracy: 0.9939\n",
            "Epoch 854/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 5.3398e-04 - accuracy: 1.0000 - val_loss: 0.0563 - val_accuracy: 0.9939\n",
            "Epoch 855/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.0587 - val_accuracy: 0.9939\n",
            "Epoch 856/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.0553 - val_accuracy: 0.9909\n",
            "Epoch 857/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0047 - accuracy: 0.9992 - val_loss: 0.0672 - val_accuracy: 0.9933\n",
            "Epoch 858/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 0.0659 - val_accuracy: 0.9933\n",
            "Epoch 859/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.0685 - val_accuracy: 0.9927\n",
            "Epoch 860/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0022 - accuracy: 0.9997 - val_loss: 0.0685 - val_accuracy: 0.9927\n",
            "Epoch 861/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0022 - accuracy: 0.9997 - val_loss: 0.0692 - val_accuracy: 0.9933\n",
            "Epoch 862/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 4.7505e-04 - accuracy: 1.0000 - val_loss: 0.0719 - val_accuracy: 0.9933\n",
            "Epoch 863/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 0.0713 - val_accuracy: 0.9933\n",
            "Epoch 864/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0067 - accuracy: 0.9991 - val_loss: 0.1895 - val_accuracy: 0.9915\n",
            "Epoch 865/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0021 - accuracy: 0.9997 - val_loss: 0.1490 - val_accuracy: 0.9897\n",
            "Epoch 866/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.0969 - val_accuracy: 0.9921\n",
            "Epoch 867/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0070 - accuracy: 0.9986 - val_loss: 0.1234 - val_accuracy: 0.9915\n",
            "Epoch 868/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0038 - accuracy: 0.9994 - val_loss: 0.0799 - val_accuracy: 0.9921\n",
            "Epoch 869/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0053 - accuracy: 0.9989 - val_loss: 0.0838 - val_accuracy: 0.9915\n",
            "Epoch 870/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.3816 - val_accuracy: 0.9854\n",
            "Epoch 871/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0057 - accuracy: 0.9989 - val_loss: 0.2527 - val_accuracy: 0.9897\n",
            "Epoch 872/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0047 - accuracy: 0.9992 - val_loss: 0.2847 - val_accuracy: 0.9891\n",
            "Epoch 873/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0069 - accuracy: 0.9986 - val_loss: 1.2439 - val_accuracy: 0.9806\n",
            "Epoch 874/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0245 - accuracy: 0.9967 - val_loss: 0.1306 - val_accuracy: 0.9903\n",
            "Epoch 875/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0113 - accuracy: 0.9977 - val_loss: 0.0709 - val_accuracy: 0.9909\n",
            "Epoch 876/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0268 - accuracy: 0.9988 - val_loss: 0.1850 - val_accuracy: 0.9921\n",
            "Epoch 877/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0042 - accuracy: 0.9991 - val_loss: 0.2045 - val_accuracy: 0.9909\n",
            "Epoch 878/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0055 - accuracy: 0.9991 - val_loss: 0.3102 - val_accuracy: 0.9860\n",
            "Epoch 879/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0042 - accuracy: 0.9992 - val_loss: 0.0405 - val_accuracy: 0.9921\n",
            "Epoch 880/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0169 - accuracy: 0.9986 - val_loss: 0.2255 - val_accuracy: 0.9873\n",
            "Epoch 881/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0050 - accuracy: 0.9991 - val_loss: 0.0673 - val_accuracy: 0.9903\n",
            "Epoch 882/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0176 - accuracy: 0.9986 - val_loss: 0.1873 - val_accuracy: 0.9939\n",
            "Epoch 883/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0103 - accuracy: 0.9985 - val_loss: 0.0842 - val_accuracy: 0.9915\n",
            "Epoch 884/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0034 - accuracy: 0.9992 - val_loss: 0.0956 - val_accuracy: 0.9945\n",
            "Epoch 885/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0047 - accuracy: 0.9991 - val_loss: 0.1522 - val_accuracy: 0.9909\n",
            "Epoch 886/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0025 - accuracy: 0.9995 - val_loss: 0.1967 - val_accuracy: 0.9891\n",
            "Epoch 887/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0066 - accuracy: 0.9997 - val_loss: 0.1587 - val_accuracy: 0.9921\n",
            "Epoch 888/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0041 - accuracy: 0.9994 - val_loss: 0.5780 - val_accuracy: 0.9806\n",
            "Epoch 889/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0105 - accuracy: 0.9982 - val_loss: 0.1517 - val_accuracy: 0.9897\n",
            "Epoch 890/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 0.1534 - val_accuracy: 0.9909\n",
            "Epoch 891/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0065 - accuracy: 0.9988 - val_loss: 0.1623 - val_accuracy: 0.9891\n",
            "Epoch 892/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0045 - accuracy: 0.9991 - val_loss: 0.1290 - val_accuracy: 0.9909\n",
            "Epoch 893/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0039 - accuracy: 0.9991 - val_loss: 0.1211 - val_accuracy: 0.9915\n",
            "Epoch 894/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0084 - accuracy: 0.9991 - val_loss: 0.0979 - val_accuracy: 0.9921\n",
            "Epoch 895/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0049 - accuracy: 0.9991 - val_loss: 0.2252 - val_accuracy: 0.9903\n",
            "Epoch 896/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0040 - accuracy: 0.9994 - val_loss: 0.2035 - val_accuracy: 0.9921\n",
            "Epoch 897/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0034 - accuracy: 0.9994 - val_loss: 0.2293 - val_accuracy: 0.9921\n",
            "Epoch 898/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0021 - accuracy: 0.9997 - val_loss: 0.3230 - val_accuracy: 0.9879\n",
            "Epoch 899/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 0.2281 - val_accuracy: 0.9915\n",
            "Epoch 900/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0022 - accuracy: 0.9997 - val_loss: 0.2401 - val_accuracy: 0.9915\n",
            "Epoch 901/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0023 - accuracy: 0.9997 - val_loss: 0.1874 - val_accuracy: 0.9933\n",
            "Epoch 902/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 8.0041e-04 - accuracy: 0.9998 - val_loss: 0.1322 - val_accuracy: 0.9939\n",
            "Epoch 903/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0055 - accuracy: 0.9991 - val_loss: 0.1334 - val_accuracy: 0.9903\n",
            "Epoch 904/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0043 - accuracy: 0.9991 - val_loss: 0.4235 - val_accuracy: 0.9903\n",
            "Epoch 905/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0037 - accuracy: 0.9992 - val_loss: 0.3923 - val_accuracy: 0.9903\n",
            "Epoch 906/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0248 - accuracy: 0.9977 - val_loss: 0.2548 - val_accuracy: 0.9897\n",
            "Epoch 907/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0164 - accuracy: 0.9976 - val_loss: 0.3225 - val_accuracy: 0.9891\n",
            "Epoch 908/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0315 - accuracy: 0.9973 - val_loss: 0.1546 - val_accuracy: 0.9891\n",
            "Epoch 909/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0152 - accuracy: 0.9986 - val_loss: 0.1027 - val_accuracy: 0.9909\n",
            "Epoch 910/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0083 - accuracy: 0.9986 - val_loss: 0.0958 - val_accuracy: 0.9909\n",
            "Epoch 911/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0040 - accuracy: 0.9992 - val_loss: 0.1737 - val_accuracy: 0.9909\n",
            "Epoch 912/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.1554 - val_accuracy: 0.9909\n",
            "Epoch 913/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0041 - accuracy: 0.9995 - val_loss: 0.2317 - val_accuracy: 0.9909\n",
            "Epoch 914/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0039 - accuracy: 0.9994 - val_loss: 0.1532 - val_accuracy: 0.9927\n",
            "Epoch 915/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 0.1680 - val_accuracy: 0.9915\n",
            "Epoch 916/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0056 - accuracy: 0.9989 - val_loss: 0.1566 - val_accuracy: 0.9915\n",
            "Epoch 917/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.2036 - val_accuracy: 0.9927\n",
            "Epoch 918/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.3297 - val_accuracy: 0.9915\n",
            "Epoch 919/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 5.6525e-04 - accuracy: 0.9998 - val_loss: 0.1475 - val_accuracy: 0.9903\n",
            "Epoch 920/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0074 - accuracy: 0.9994 - val_loss: 0.0594 - val_accuracy: 0.9921\n",
            "Epoch 921/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0029 - accuracy: 0.9995 - val_loss: 0.0893 - val_accuracy: 0.9915\n",
            "Epoch 922/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.1167 - val_accuracy: 0.9921\n",
            "Epoch 923/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0032 - accuracy: 0.9992 - val_loss: 1.0929 - val_accuracy: 0.9854\n",
            "Epoch 924/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0106 - accuracy: 0.9989 - val_loss: 0.1067 - val_accuracy: 0.9927\n",
            "Epoch 925/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 0.1709 - val_accuracy: 0.9921\n",
            "Epoch 926/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0021 - accuracy: 0.9997 - val_loss: 0.1062 - val_accuracy: 0.9939\n",
            "Epoch 927/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0108 - accuracy: 0.9986 - val_loss: 0.1020 - val_accuracy: 0.9903\n",
            "Epoch 928/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.1426 - val_accuracy: 0.9915\n",
            "Epoch 929/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0094 - accuracy: 0.9994 - val_loss: 0.1937 - val_accuracy: 0.9921\n",
            "Epoch 930/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0174 - accuracy: 0.9977 - val_loss: 0.1220 - val_accuracy: 0.9927\n",
            "Epoch 931/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0127 - accuracy: 0.9979 - val_loss: 0.0651 - val_accuracy: 0.9885\n",
            "Epoch 932/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0097 - accuracy: 0.9985 - val_loss: 0.2459 - val_accuracy: 0.9867\n",
            "Epoch 933/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0061 - accuracy: 0.9989 - val_loss: 0.1196 - val_accuracy: 0.9915\n",
            "Epoch 934/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0087 - accuracy: 0.9983 - val_loss: 0.1481 - val_accuracy: 0.9915\n",
            "Epoch 935/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0082 - accuracy: 0.9991 - val_loss: 0.1164 - val_accuracy: 0.9927\n",
            "Epoch 936/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0063 - accuracy: 0.9989 - val_loss: 0.0934 - val_accuracy: 0.9927\n",
            "Epoch 937/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0047 - accuracy: 0.9992 - val_loss: 0.0927 - val_accuracy: 0.9927\n",
            "Epoch 938/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0036 - accuracy: 0.9994 - val_loss: 0.1600 - val_accuracy: 0.9927\n",
            "Epoch 939/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0033 - accuracy: 0.9992 - val_loss: 0.3072 - val_accuracy: 0.9909\n",
            "Epoch 940/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0067 - accuracy: 0.9988 - val_loss: 0.2708 - val_accuracy: 0.9909\n",
            "Epoch 941/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0074 - accuracy: 0.9985 - val_loss: 0.1126 - val_accuracy: 0.9921\n",
            "Epoch 942/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0082 - accuracy: 0.9985 - val_loss: 0.2097 - val_accuracy: 0.9951\n",
            "Epoch 943/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 0.1246 - val_accuracy: 0.9933\n",
            "Epoch 944/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0038 - accuracy: 0.9994 - val_loss: 0.1072 - val_accuracy: 0.9933\n",
            "Epoch 945/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0067 - accuracy: 0.9988 - val_loss: 0.3345 - val_accuracy: 0.9891\n",
            "Epoch 946/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0067 - accuracy: 0.9991 - val_loss: 0.8564 - val_accuracy: 0.9836\n",
            "Epoch 947/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0114 - accuracy: 0.9995 - val_loss: 0.3338 - val_accuracy: 0.9860\n",
            "Epoch 948/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0034 - accuracy: 0.9991 - val_loss: 0.2531 - val_accuracy: 0.9903\n",
            "Epoch 949/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0057 - accuracy: 0.9989 - val_loss: 0.0872 - val_accuracy: 0.9927\n",
            "Epoch 950/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.1724 - val_accuracy: 0.9933\n",
            "Epoch 951/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0038 - accuracy: 0.9995 - val_loss: 2.1228 - val_accuracy: 0.9557\n",
            "Epoch 952/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0068 - accuracy: 0.9986 - val_loss: 0.4642 - val_accuracy: 0.9788\n",
            "Epoch 953/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0041 - accuracy: 0.9992 - val_loss: 0.0823 - val_accuracy: 0.9897\n",
            "Epoch 954/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0082 - accuracy: 0.9989 - val_loss: 0.4751 - val_accuracy: 0.9721\n",
            "Epoch 955/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0046 - accuracy: 0.9991 - val_loss: 0.0919 - val_accuracy: 0.9921\n",
            "Epoch 956/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0054 - accuracy: 0.9991 - val_loss: 0.0666 - val_accuracy: 0.9921\n",
            "Epoch 957/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0035 - accuracy: 0.9991 - val_loss: 0.1201 - val_accuracy: 0.9927\n",
            "Epoch 958/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0094 - accuracy: 0.9994 - val_loss: 0.0272 - val_accuracy: 0.9951\n",
            "Epoch 959/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.1537 - val_accuracy: 0.9927\n",
            "Epoch 960/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0028 - accuracy: 0.9995 - val_loss: 0.0401 - val_accuracy: 0.9970\n",
            "Epoch 961/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0044 - accuracy: 0.9997 - val_loss: 0.0360 - val_accuracy: 0.9945\n",
            "Epoch 962/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0021 - accuracy: 0.9997 - val_loss: 0.0363 - val_accuracy: 0.9945\n",
            "Epoch 963/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 5.3638e-04 - accuracy: 0.9998 - val_loss: 0.0698 - val_accuracy: 0.9939\n",
            "Epoch 964/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0045 - accuracy: 0.9994 - val_loss: 0.1423 - val_accuracy: 0.9945\n",
            "Epoch 965/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0048 - accuracy: 0.9991 - val_loss: 0.1640 - val_accuracy: 0.9939\n",
            "Epoch 966/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0050 - accuracy: 0.9991 - val_loss: 0.0516 - val_accuracy: 0.9933\n",
            "Epoch 967/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0298 - accuracy: 0.9985 - val_loss: 0.0938 - val_accuracy: 0.9921\n",
            "Epoch 968/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0040 - accuracy: 0.9992 - val_loss: 0.1000 - val_accuracy: 0.9933\n",
            "Epoch 969/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0055 - accuracy: 0.9989 - val_loss: 0.3050 - val_accuracy: 0.9879\n",
            "Epoch 970/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0044 - accuracy: 0.9991 - val_loss: 0.1065 - val_accuracy: 0.9915\n",
            "Epoch 971/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0036 - accuracy: 0.9997 - val_loss: 0.0899 - val_accuracy: 0.9921\n",
            "Epoch 972/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0114 - accuracy: 0.9983 - val_loss: 0.0669 - val_accuracy: 0.9939\n",
            "Epoch 973/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0058 - accuracy: 0.9991 - val_loss: 0.0644 - val_accuracy: 0.9909\n",
            "Epoch 974/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0038 - accuracy: 0.9992 - val_loss: 0.1905 - val_accuracy: 0.9897\n",
            "Epoch 975/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0044 - accuracy: 0.9992 - val_loss: 0.2125 - val_accuracy: 0.9897\n",
            "Epoch 976/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0051 - accuracy: 0.9995 - val_loss: 0.1870 - val_accuracy: 0.9903\n",
            "Epoch 977/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 0.1232 - val_accuracy: 0.9927\n",
            "Epoch 978/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.1356 - val_accuracy: 0.9933\n",
            "Epoch 979/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0055 - accuracy: 0.9991 - val_loss: 0.1360 - val_accuracy: 0.9933\n",
            "Epoch 980/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0060 - accuracy: 0.9995 - val_loss: 0.1223 - val_accuracy: 0.9933\n",
            "Epoch 981/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0019 - accuracy: 0.9997 - val_loss: 0.0588 - val_accuracy: 0.9939\n",
            "Epoch 982/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0022 - accuracy: 0.9997 - val_loss: 0.0626 - val_accuracy: 0.9939\n",
            "Epoch 983/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0038 - accuracy: 0.9994 - val_loss: 0.0476 - val_accuracy: 0.9933\n",
            "Epoch 984/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0055 - accuracy: 0.9991 - val_loss: 0.0404 - val_accuracy: 0.9927\n",
            "Epoch 985/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0091 - accuracy: 0.9992 - val_loss: 0.1115 - val_accuracy: 0.9909\n",
            "Epoch 986/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0026 - accuracy: 0.9995 - val_loss: 0.0520 - val_accuracy: 0.9915\n",
            "Epoch 987/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0070 - accuracy: 0.9989 - val_loss: 0.0833 - val_accuracy: 0.9933\n",
            "Epoch 988/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0055 - accuracy: 0.9991 - val_loss: 0.0794 - val_accuracy: 0.9939\n",
            "Epoch 989/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0067 - accuracy: 0.9988 - val_loss: 0.0576 - val_accuracy: 0.9945\n",
            "Epoch 990/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.0686 - val_accuracy: 0.9945\n",
            "Epoch 991/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0278 - accuracy: 0.9976 - val_loss: 0.1774 - val_accuracy: 0.9897\n",
            "Epoch 992/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0124 - accuracy: 0.9983 - val_loss: 0.6149 - val_accuracy: 0.9836\n",
            "Epoch 993/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0080 - accuracy: 0.9991 - val_loss: 0.3613 - val_accuracy: 0.9903\n",
            "Epoch 994/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0045 - accuracy: 0.9992 - val_loss: 0.1128 - val_accuracy: 0.9921\n",
            "Epoch 995/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0064 - accuracy: 0.9989 - val_loss: 0.1172 - val_accuracy: 0.9897\n",
            "Epoch 996/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0101 - accuracy: 0.9994 - val_loss: 0.1324 - val_accuracy: 0.9927\n",
            "Epoch 997/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0038 - accuracy: 0.9994 - val_loss: 0.1449 - val_accuracy: 0.9921\n",
            "Epoch 998/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0022 - accuracy: 0.9997 - val_loss: 0.0997 - val_accuracy: 0.9933\n",
            "Epoch 999/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.1034 - val_accuracy: 0.9933\n",
            "Epoch 1000/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 0.0470 - val_accuracy: 0.9945\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1200x400 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "206/206 [==============================] - 12s 46ms/step - loss: 3.3302 - accuracy: 0.8677 - val_loss: 0.2747 - val_accuracy: 0.9017\n",
            "Epoch 2/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.2874 - accuracy: 0.8914 - val_loss: 0.2083 - val_accuracy: 0.9120\n",
            "Epoch 3/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.2522 - accuracy: 0.8910 - val_loss: 0.1610 - val_accuracy: 0.9193\n",
            "Epoch 4/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1957 - accuracy: 0.8933 - val_loss: 0.1595 - val_accuracy: 0.9175\n",
            "Epoch 5/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.2027 - accuracy: 0.8976 - val_loss: 0.1516 - val_accuracy: 0.9157\n",
            "Epoch 6/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1665 - accuracy: 0.8971 - val_loss: 0.1232 - val_accuracy: 0.9211\n",
            "Epoch 7/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.1725 - accuracy: 0.8985 - val_loss: 0.1124 - val_accuracy: 0.9229\n",
            "Epoch 8/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1981 - accuracy: 0.8941 - val_loss: 1.0483 - val_accuracy: 0.9120\n",
            "Epoch 9/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.2587 - accuracy: 0.8894 - val_loss: 2.3982 - val_accuracy: 0.8981\n",
            "Epoch 10/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.1723 - accuracy: 0.9083 - val_loss: 0.1065 - val_accuracy: 0.9484\n",
            "Epoch 11/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.2075 - accuracy: 0.9199 - val_loss: 0.3410 - val_accuracy: 0.9205\n",
            "Epoch 12/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.1827 - accuracy: 0.9132 - val_loss: 0.1006 - val_accuracy: 0.9575\n",
            "Epoch 13/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.1359 - accuracy: 0.9381 - val_loss: 0.4291 - val_accuracy: 0.9490\n",
            "Epoch 14/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.1471 - accuracy: 0.9249 - val_loss: 0.1178 - val_accuracy: 0.9508\n",
            "Epoch 15/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.1512 - accuracy: 0.9344 - val_loss: 2.0989 - val_accuracy: 0.9302\n",
            "Epoch 16/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1417 - accuracy: 0.9305 - val_loss: 0.1108 - val_accuracy: 0.9678\n",
            "Epoch 17/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.1439 - accuracy: 0.9413 - val_loss: 0.2152 - val_accuracy: 0.9442\n",
            "Epoch 18/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.4595 - accuracy: 0.8621 - val_loss: 0.6089 - val_accuracy: 0.9430\n",
            "Epoch 19/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.1904 - accuracy: 0.8792 - val_loss: 0.1278 - val_accuracy: 0.9484\n",
            "Epoch 20/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.1555 - accuracy: 0.9175 - val_loss: 0.1256 - val_accuracy: 0.9533\n",
            "Epoch 21/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.1348 - accuracy: 0.9307 - val_loss: 39.0676 - val_accuracy: 0.9066\n",
            "Epoch 22/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.1290 - accuracy: 0.9366 - val_loss: 0.0919 - val_accuracy: 0.9666\n",
            "Epoch 23/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.1379 - accuracy: 0.9275 - val_loss: 0.1177 - val_accuracy: 0.9539\n",
            "Epoch 24/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1187 - accuracy: 0.9410 - val_loss: 0.0919 - val_accuracy: 0.9654\n",
            "Epoch 25/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.1145 - accuracy: 0.9470 - val_loss: 0.0951 - val_accuracy: 0.9666\n",
            "Epoch 26/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.1115 - accuracy: 0.9493 - val_loss: 0.0843 - val_accuracy: 0.9642\n",
            "Epoch 27/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.1143 - accuracy: 0.9420 - val_loss: 0.1107 - val_accuracy: 0.9612\n",
            "Epoch 28/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.1045 - accuracy: 0.9531 - val_loss: 0.0901 - val_accuracy: 0.9709\n",
            "Epoch 29/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1055 - accuracy: 0.9527 - val_loss: 0.1333 - val_accuracy: 0.9642\n",
            "Epoch 30/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0993 - accuracy: 0.9566 - val_loss: 0.0824 - val_accuracy: 0.9721\n",
            "Epoch 31/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0956 - accuracy: 0.9571 - val_loss: 0.0840 - val_accuracy: 0.9697\n",
            "Epoch 32/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0992 - accuracy: 0.9546 - val_loss: 0.0872 - val_accuracy: 0.9618\n",
            "Epoch 33/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0982 - accuracy: 0.9552 - val_loss: 0.2291 - val_accuracy: 0.9684\n",
            "Epoch 34/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0871 - accuracy: 0.9619 - val_loss: 0.0703 - val_accuracy: 0.9794\n",
            "Epoch 35/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0807 - accuracy: 0.9666 - val_loss: 0.0937 - val_accuracy: 0.9745\n",
            "Epoch 36/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.1451 - accuracy: 0.9426 - val_loss: 0.1089 - val_accuracy: 0.9600\n",
            "Epoch 37/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0825 - accuracy: 0.9659 - val_loss: 0.0748 - val_accuracy: 0.9733\n",
            "Epoch 38/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0857 - accuracy: 0.9657 - val_loss: 0.0890 - val_accuracy: 0.9775\n",
            "Epoch 39/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0814 - accuracy: 0.9659 - val_loss: 0.1177 - val_accuracy: 0.9684\n",
            "Epoch 40/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0766 - accuracy: 0.9681 - val_loss: 0.0816 - val_accuracy: 0.9751\n",
            "Epoch 41/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0773 - accuracy: 0.9669 - val_loss: 0.0676 - val_accuracy: 0.9751\n",
            "Epoch 42/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0873 - accuracy: 0.9713 - val_loss: 0.0870 - val_accuracy: 0.9630\n",
            "Epoch 43/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.1608 - accuracy: 0.9574 - val_loss: 5.8611 - val_accuracy: 0.8871\n",
            "Epoch 44/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0775 - accuracy: 0.9693 - val_loss: 5.6240 - val_accuracy: 0.9163\n",
            "Epoch 45/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0764 - accuracy: 0.9713 - val_loss: 0.0763 - val_accuracy: 0.9788\n",
            "Epoch 46/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0597 - accuracy: 0.9810 - val_loss: 0.0713 - val_accuracy: 0.9782\n",
            "Epoch 47/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0540 - accuracy: 0.9804 - val_loss: 0.2885 - val_accuracy: 0.9593\n",
            "Epoch 48/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0649 - accuracy: 0.9768 - val_loss: 0.0991 - val_accuracy: 0.9757\n",
            "Epoch 49/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0504 - accuracy: 0.9821 - val_loss: 0.0695 - val_accuracy: 0.9775\n",
            "Epoch 50/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0622 - accuracy: 0.9810 - val_loss: 0.1177 - val_accuracy: 0.9775\n",
            "Epoch 51/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0509 - accuracy: 0.9842 - val_loss: 0.0790 - val_accuracy: 0.9739\n",
            "Epoch 52/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0519 - accuracy: 0.9813 - val_loss: 0.0867 - val_accuracy: 0.9757\n",
            "Epoch 53/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0458 - accuracy: 0.9836 - val_loss: 0.2241 - val_accuracy: 0.9624\n",
            "Epoch 54/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0451 - accuracy: 0.9873 - val_loss: 0.1354 - val_accuracy: 0.9745\n",
            "Epoch 55/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0387 - accuracy: 0.9871 - val_loss: 0.0939 - val_accuracy: 0.9769\n",
            "Epoch 56/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0735 - accuracy: 0.9774 - val_loss: 0.1042 - val_accuracy: 0.9751\n",
            "Epoch 57/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0519 - accuracy: 0.9860 - val_loss: 0.1146 - val_accuracy: 0.9794\n",
            "Epoch 58/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0412 - accuracy: 0.9842 - val_loss: 0.0652 - val_accuracy: 0.9812\n",
            "Epoch 59/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0428 - accuracy: 0.9857 - val_loss: 0.0845 - val_accuracy: 0.9806\n",
            "Epoch 60/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0386 - accuracy: 0.9869 - val_loss: 0.0548 - val_accuracy: 0.9812\n",
            "Epoch 61/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0302 - accuracy: 0.9915 - val_loss: 0.0774 - val_accuracy: 0.9794\n",
            "Epoch 62/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0419 - accuracy: 0.9880 - val_loss: 0.1287 - val_accuracy: 0.9818\n",
            "Epoch 63/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.1151 - accuracy: 0.9797 - val_loss: 0.2364 - val_accuracy: 0.9606\n",
            "Epoch 64/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0665 - accuracy: 0.9765 - val_loss: 0.0652 - val_accuracy: 0.9812\n",
            "Epoch 65/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0411 - accuracy: 0.9876 - val_loss: 0.3822 - val_accuracy: 0.9636\n",
            "Epoch 66/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0669 - accuracy: 0.9797 - val_loss: 0.1097 - val_accuracy: 0.9824\n",
            "Epoch 67/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.1675 - accuracy: 0.9608 - val_loss: 0.0967 - val_accuracy: 0.9654\n",
            "Epoch 68/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0621 - accuracy: 0.9769 - val_loss: 0.1249 - val_accuracy: 0.9788\n",
            "Epoch 69/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0395 - accuracy: 0.9873 - val_loss: 0.1966 - val_accuracy: 0.9769\n",
            "Epoch 70/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0566 - accuracy: 0.9807 - val_loss: 0.2071 - val_accuracy: 0.9691\n",
            "Epoch 71/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0581 - accuracy: 0.9804 - val_loss: 0.1188 - val_accuracy: 0.9824\n",
            "Epoch 72/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0437 - accuracy: 0.9857 - val_loss: 0.0796 - val_accuracy: 0.9848\n",
            "Epoch 73/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0370 - accuracy: 0.9880 - val_loss: 0.1347 - val_accuracy: 0.9818\n",
            "Epoch 74/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0293 - accuracy: 0.9901 - val_loss: 0.1161 - val_accuracy: 0.9830\n",
            "Epoch 75/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0287 - accuracy: 0.9909 - val_loss: 0.0804 - val_accuracy: 0.9848\n",
            "Epoch 76/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0366 - accuracy: 0.9883 - val_loss: 0.0757 - val_accuracy: 0.9830\n",
            "Epoch 77/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0423 - accuracy: 0.9865 - val_loss: 0.0747 - val_accuracy: 0.9842\n",
            "Epoch 78/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0458 - accuracy: 0.9848 - val_loss: 0.0775 - val_accuracy: 0.9830\n",
            "Epoch 79/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0317 - accuracy: 0.9895 - val_loss: 0.1256 - val_accuracy: 0.9806\n",
            "Epoch 80/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0234 - accuracy: 0.9935 - val_loss: 0.1284 - val_accuracy: 0.9830\n",
            "Epoch 81/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0262 - accuracy: 0.9920 - val_loss: 0.2646 - val_accuracy: 0.9715\n",
            "Epoch 82/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0280 - accuracy: 0.9918 - val_loss: 0.0586 - val_accuracy: 0.9854\n",
            "Epoch 83/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0348 - accuracy: 0.9894 - val_loss: 0.1675 - val_accuracy: 0.9812\n",
            "Epoch 84/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0333 - accuracy: 0.9889 - val_loss: 0.1036 - val_accuracy: 0.9788\n",
            "Epoch 85/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0318 - accuracy: 0.9927 - val_loss: 0.2115 - val_accuracy: 0.9721\n",
            "Epoch 86/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0733 - accuracy: 0.9859 - val_loss: 3.2777 - val_accuracy: 0.9017\n",
            "Epoch 87/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0698 - accuracy: 0.9775 - val_loss: 0.4590 - val_accuracy: 0.9399\n",
            "Epoch 88/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0865 - accuracy: 0.9821 - val_loss: 0.0598 - val_accuracy: 0.9800\n",
            "Epoch 89/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0293 - accuracy: 0.9909 - val_loss: 0.1309 - val_accuracy: 0.9794\n",
            "Epoch 90/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0351 - accuracy: 0.9921 - val_loss: 0.0844 - val_accuracy: 0.9782\n",
            "Epoch 91/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0412 - accuracy: 0.9868 - val_loss: 0.2112 - val_accuracy: 0.9769\n",
            "Epoch 92/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0326 - accuracy: 0.9892 - val_loss: 0.0672 - val_accuracy: 0.9830\n",
            "Epoch 93/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0295 - accuracy: 0.9917 - val_loss: 0.1296 - val_accuracy: 0.9812\n",
            "Epoch 94/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0777 - accuracy: 0.9917 - val_loss: 0.2796 - val_accuracy: 0.9709\n",
            "Epoch 95/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0595 - accuracy: 0.9827 - val_loss: 0.0687 - val_accuracy: 0.9842\n",
            "Epoch 96/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0395 - accuracy: 0.9904 - val_loss: 0.1004 - val_accuracy: 0.9842\n",
            "Epoch 97/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0280 - accuracy: 0.9917 - val_loss: 0.1992 - val_accuracy: 0.9715\n",
            "Epoch 98/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0282 - accuracy: 0.9920 - val_loss: 0.0814 - val_accuracy: 0.9848\n",
            "Epoch 99/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0379 - accuracy: 0.9898 - val_loss: 0.0633 - val_accuracy: 0.9830\n",
            "Epoch 100/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0300 - accuracy: 0.9915 - val_loss: 0.1565 - val_accuracy: 0.9824\n",
            "Epoch 101/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0277 - accuracy: 0.9912 - val_loss: 0.1300 - val_accuracy: 0.9812\n",
            "Epoch 102/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0258 - accuracy: 0.9924 - val_loss: 0.0586 - val_accuracy: 0.9879\n",
            "Epoch 103/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0218 - accuracy: 0.9936 - val_loss: 0.1226 - val_accuracy: 0.9848\n",
            "Epoch 104/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0241 - accuracy: 0.9933 - val_loss: 0.0901 - val_accuracy: 0.9842\n",
            "Epoch 105/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0260 - accuracy: 0.9938 - val_loss: 0.2352 - val_accuracy: 0.9733\n",
            "Epoch 106/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0254 - accuracy: 0.9927 - val_loss: 0.1313 - val_accuracy: 0.9836\n",
            "Epoch 107/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0360 - accuracy: 0.9895 - val_loss: 0.0754 - val_accuracy: 0.9830\n",
            "Epoch 108/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0237 - accuracy: 0.9930 - val_loss: 0.1032 - val_accuracy: 0.9836\n",
            "Epoch 109/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0515 - accuracy: 0.9929 - val_loss: 0.1224 - val_accuracy: 0.9824\n",
            "Epoch 110/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0213 - accuracy: 0.9942 - val_loss: 0.0957 - val_accuracy: 0.9824\n",
            "Epoch 111/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0218 - accuracy: 0.9951 - val_loss: 0.1325 - val_accuracy: 0.9806\n",
            "Epoch 112/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0352 - accuracy: 0.9912 - val_loss: 0.0817 - val_accuracy: 0.9757\n",
            "Epoch 113/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0251 - accuracy: 0.9933 - val_loss: 0.1523 - val_accuracy: 0.9830\n",
            "Epoch 114/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0289 - accuracy: 0.9923 - val_loss: 0.1591 - val_accuracy: 0.9836\n",
            "Epoch 115/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0167 - accuracy: 0.9964 - val_loss: 0.1165 - val_accuracy: 0.9836\n",
            "Epoch 116/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0180 - accuracy: 0.9951 - val_loss: 0.0739 - val_accuracy: 0.9879\n",
            "Epoch 117/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0191 - accuracy: 0.9951 - val_loss: 0.1167 - val_accuracy: 0.9824\n",
            "Epoch 118/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0225 - accuracy: 0.9944 - val_loss: 0.0656 - val_accuracy: 0.9842\n",
            "Epoch 119/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0425 - accuracy: 0.9903 - val_loss: 0.0803 - val_accuracy: 0.9769\n",
            "Epoch 120/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0263 - accuracy: 0.9930 - val_loss: 0.3107 - val_accuracy: 0.9721\n",
            "Epoch 121/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0175 - accuracy: 0.9948 - val_loss: 0.0688 - val_accuracy: 0.9873\n",
            "Epoch 122/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0181 - accuracy: 0.9951 - val_loss: 0.0740 - val_accuracy: 0.9854\n",
            "Epoch 123/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0150 - accuracy: 0.9961 - val_loss: 0.1471 - val_accuracy: 0.9836\n",
            "Epoch 124/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0264 - accuracy: 0.9948 - val_loss: 0.0742 - val_accuracy: 0.9873\n",
            "Epoch 125/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0189 - accuracy: 0.9953 - val_loss: 0.0994 - val_accuracy: 0.9806\n",
            "Epoch 126/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0110 - accuracy: 0.9971 - val_loss: 0.0845 - val_accuracy: 0.9848\n",
            "Epoch 127/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0173 - accuracy: 0.9954 - val_loss: 0.2767 - val_accuracy: 0.9782\n",
            "Epoch 128/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0190 - accuracy: 0.9953 - val_loss: 0.1134 - val_accuracy: 0.9830\n",
            "Epoch 129/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0243 - accuracy: 0.9932 - val_loss: 0.1820 - val_accuracy: 0.9830\n",
            "Epoch 130/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0151 - accuracy: 0.9962 - val_loss: 0.1191 - val_accuracy: 0.9812\n",
            "Epoch 131/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0275 - accuracy: 0.9938 - val_loss: 0.2360 - val_accuracy: 0.9703\n",
            "Epoch 132/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0174 - accuracy: 0.9950 - val_loss: 0.6522 - val_accuracy: 0.9697\n",
            "Epoch 133/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0164 - accuracy: 0.9962 - val_loss: 0.0660 - val_accuracy: 0.9848\n",
            "Epoch 134/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0470 - accuracy: 0.9929 - val_loss: 2.9902 - val_accuracy: 0.9193\n",
            "Epoch 135/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0665 - accuracy: 0.9844 - val_loss: 0.2503 - val_accuracy: 0.9745\n",
            "Epoch 136/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0245 - accuracy: 0.9927 - val_loss: 0.2741 - val_accuracy: 0.9806\n",
            "Epoch 137/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0177 - accuracy: 0.9956 - val_loss: 0.2267 - val_accuracy: 0.9824\n",
            "Epoch 138/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0186 - accuracy: 0.9945 - val_loss: 0.1829 - val_accuracy: 0.9842\n",
            "Epoch 139/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0185 - accuracy: 0.9956 - val_loss: 0.0975 - val_accuracy: 0.9824\n",
            "Epoch 140/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0151 - accuracy: 0.9961 - val_loss: 0.1722 - val_accuracy: 0.9824\n",
            "Epoch 141/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0147 - accuracy: 0.9962 - val_loss: 0.0804 - val_accuracy: 0.9860\n",
            "Epoch 142/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0159 - accuracy: 0.9967 - val_loss: 0.1598 - val_accuracy: 0.9842\n",
            "Epoch 143/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0295 - accuracy: 0.9951 - val_loss: 0.1127 - val_accuracy: 0.9848\n",
            "Epoch 144/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0155 - accuracy: 0.9964 - val_loss: 0.3680 - val_accuracy: 0.9806\n",
            "Epoch 145/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0149 - accuracy: 0.9968 - val_loss: 0.1619 - val_accuracy: 0.9824\n",
            "Epoch 146/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0150 - accuracy: 0.9961 - val_loss: 0.0919 - val_accuracy: 0.9867\n",
            "Epoch 147/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0175 - accuracy: 0.9961 - val_loss: 0.3020 - val_accuracy: 0.9806\n",
            "Epoch 148/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0108 - accuracy: 0.9974 - val_loss: 0.2817 - val_accuracy: 0.9794\n",
            "Epoch 149/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0134 - accuracy: 0.9970 - val_loss: 0.0887 - val_accuracy: 0.9806\n",
            "Epoch 150/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0164 - accuracy: 0.9962 - val_loss: 0.0879 - val_accuracy: 0.9800\n",
            "Epoch 151/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0161 - accuracy: 0.9965 - val_loss: 0.1126 - val_accuracy: 0.9842\n",
            "Epoch 152/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0211 - accuracy: 0.9942 - val_loss: 0.1239 - val_accuracy: 0.9763\n",
            "Epoch 153/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0225 - accuracy: 0.9950 - val_loss: 0.0950 - val_accuracy: 0.9697\n",
            "Epoch 154/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0163 - accuracy: 0.9958 - val_loss: 0.1101 - val_accuracy: 0.9818\n",
            "Epoch 155/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0131 - accuracy: 0.9967 - val_loss: 0.0991 - val_accuracy: 0.9830\n",
            "Epoch 156/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0159 - accuracy: 0.9964 - val_loss: 0.1140 - val_accuracy: 0.9848\n",
            "Epoch 157/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0114 - accuracy: 0.9983 - val_loss: 0.0734 - val_accuracy: 0.9836\n",
            "Epoch 158/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0113 - accuracy: 0.9971 - val_loss: 0.2819 - val_accuracy: 0.9800\n",
            "Epoch 159/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0138 - accuracy: 0.9965 - val_loss: 0.1089 - val_accuracy: 0.9854\n",
            "Epoch 160/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0161 - accuracy: 0.9965 - val_loss: 0.0911 - val_accuracy: 0.9842\n",
            "Epoch 161/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0121 - accuracy: 0.9970 - val_loss: 0.3369 - val_accuracy: 0.9751\n",
            "Epoch 162/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0137 - accuracy: 0.9973 - val_loss: 0.1526 - val_accuracy: 0.9842\n",
            "Epoch 163/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0161 - accuracy: 0.9959 - val_loss: 0.0753 - val_accuracy: 0.9873\n",
            "Epoch 164/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0234 - accuracy: 0.9947 - val_loss: 0.0644 - val_accuracy: 0.9848\n",
            "Epoch 165/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0226 - accuracy: 0.9944 - val_loss: 0.0765 - val_accuracy: 0.9806\n",
            "Epoch 166/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0255 - accuracy: 0.9932 - val_loss: 0.1104 - val_accuracy: 0.9715\n",
            "Epoch 167/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0224 - accuracy: 0.9941 - val_loss: 0.4081 - val_accuracy: 0.9757\n",
            "Epoch 168/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0205 - accuracy: 0.9950 - val_loss: 0.1991 - val_accuracy: 0.9800\n",
            "Epoch 169/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0183 - accuracy: 0.9953 - val_loss: 0.0932 - val_accuracy: 0.9842\n",
            "Epoch 170/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0126 - accuracy: 0.9973 - val_loss: 0.0837 - val_accuracy: 0.9860\n",
            "Epoch 171/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0133 - accuracy: 0.9971 - val_loss: 0.1050 - val_accuracy: 0.9830\n",
            "Epoch 172/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0154 - accuracy: 0.9962 - val_loss: 0.1112 - val_accuracy: 0.9860\n",
            "Epoch 173/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0170 - accuracy: 0.9959 - val_loss: 0.1626 - val_accuracy: 0.9873\n",
            "Epoch 174/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0105 - accuracy: 0.9977 - val_loss: 0.1465 - val_accuracy: 0.9879\n",
            "Epoch 175/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0105 - accuracy: 0.9973 - val_loss: 0.0865 - val_accuracy: 0.9842\n",
            "Epoch 176/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0080 - accuracy: 0.9982 - val_loss: 0.1213 - val_accuracy: 0.9879\n",
            "Epoch 177/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0115 - accuracy: 0.9973 - val_loss: 0.1818 - val_accuracy: 0.9842\n",
            "Epoch 178/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0152 - accuracy: 0.9967 - val_loss: 0.1257 - val_accuracy: 0.9885\n",
            "Epoch 179/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0192 - accuracy: 0.9967 - val_loss: 0.0913 - val_accuracy: 0.9842\n",
            "Epoch 180/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0096 - accuracy: 0.9976 - val_loss: 0.0805 - val_accuracy: 0.9903\n",
            "Epoch 181/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0110 - accuracy: 0.9974 - val_loss: 0.0798 - val_accuracy: 0.9873\n",
            "Epoch 182/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0106 - accuracy: 0.9974 - val_loss: 0.1030 - val_accuracy: 0.9873\n",
            "Epoch 183/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0085 - accuracy: 0.9982 - val_loss: 0.1460 - val_accuracy: 0.9818\n",
            "Epoch 184/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0120 - accuracy: 0.9983 - val_loss: 0.1036 - val_accuracy: 0.9842\n",
            "Epoch 185/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0161 - accuracy: 0.9962 - val_loss: 0.1477 - val_accuracy: 0.9830\n",
            "Epoch 186/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0079 - accuracy: 0.9983 - val_loss: 0.1406 - val_accuracy: 0.9842\n",
            "Epoch 187/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0175 - accuracy: 0.9967 - val_loss: 0.1366 - val_accuracy: 0.9860\n",
            "Epoch 188/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0196 - accuracy: 0.9961 - val_loss: 0.0792 - val_accuracy: 0.9782\n",
            "Epoch 189/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0264 - accuracy: 0.9938 - val_loss: 0.4736 - val_accuracy: 0.9375\n",
            "Epoch 190/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0168 - accuracy: 0.9959 - val_loss: 0.1053 - val_accuracy: 0.9854\n",
            "Epoch 191/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0240 - accuracy: 0.9962 - val_loss: 0.1795 - val_accuracy: 0.9830\n",
            "Epoch 192/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0128 - accuracy: 0.9971 - val_loss: 0.0950 - val_accuracy: 0.9812\n",
            "Epoch 193/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0223 - accuracy: 0.9956 - val_loss: 0.1004 - val_accuracy: 0.9879\n",
            "Epoch 194/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0167 - accuracy: 0.9965 - val_loss: 0.0755 - val_accuracy: 0.9885\n",
            "Epoch 195/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0133 - accuracy: 0.9967 - val_loss: 0.0904 - val_accuracy: 0.9860\n",
            "Epoch 196/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0119 - accuracy: 0.9970 - val_loss: 0.1709 - val_accuracy: 0.9860\n",
            "Epoch 197/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0135 - accuracy: 0.9976 - val_loss: 0.0712 - val_accuracy: 0.9860\n",
            "Epoch 198/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0114 - accuracy: 0.9971 - val_loss: 0.2304 - val_accuracy: 0.9818\n",
            "Epoch 199/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0152 - accuracy: 0.9968 - val_loss: 0.1286 - val_accuracy: 0.9842\n",
            "Epoch 200/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0180 - accuracy: 0.9958 - val_loss: 0.1035 - val_accuracy: 0.9848\n",
            "Epoch 201/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0127 - accuracy: 0.9968 - val_loss: 0.3232 - val_accuracy: 0.9800\n",
            "Epoch 202/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0095 - accuracy: 0.9986 - val_loss: 0.1617 - val_accuracy: 0.9824\n",
            "Epoch 203/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0067 - accuracy: 0.9986 - val_loss: 0.2066 - val_accuracy: 0.9818\n",
            "Epoch 204/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0151 - accuracy: 0.9974 - val_loss: 0.3179 - val_accuracy: 0.9666\n",
            "Epoch 205/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0198 - accuracy: 0.9962 - val_loss: 0.2106 - val_accuracy: 0.9818\n",
            "Epoch 206/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0106 - accuracy: 0.9973 - val_loss: 0.3064 - val_accuracy: 0.9824\n",
            "Epoch 207/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0329 - accuracy: 0.9938 - val_loss: 0.3348 - val_accuracy: 0.9557\n",
            "Epoch 208/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0292 - accuracy: 0.9918 - val_loss: 0.0996 - val_accuracy: 0.9824\n",
            "Epoch 209/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0221 - accuracy: 0.9967 - val_loss: 0.1039 - val_accuracy: 0.9836\n",
            "Epoch 210/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0123 - accuracy: 0.9976 - val_loss: 0.3077 - val_accuracy: 0.9806\n",
            "Epoch 211/1000\n",
            "206/206 [==============================] - 9s 43ms/step - loss: 0.0178 - accuracy: 0.9968 - val_loss: 0.1135 - val_accuracy: 0.9854\n",
            "Epoch 212/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0091 - accuracy: 0.9982 - val_loss: 0.1166 - val_accuracy: 0.9873\n",
            "Epoch 213/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0277 - accuracy: 0.9965 - val_loss: 0.0750 - val_accuracy: 0.9818\n",
            "Epoch 214/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0182 - accuracy: 0.9948 - val_loss: 0.1114 - val_accuracy: 0.9854\n",
            "Epoch 215/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0081 - accuracy: 0.9985 - val_loss: 0.1538 - val_accuracy: 0.9848\n",
            "Epoch 216/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0095 - accuracy: 0.9983 - val_loss: 0.1058 - val_accuracy: 0.9848\n",
            "Epoch 217/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0091 - accuracy: 0.9982 - val_loss: 0.2055 - val_accuracy: 0.9812\n",
            "Epoch 218/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0098 - accuracy: 0.9979 - val_loss: 0.1174 - val_accuracy: 0.9860\n",
            "Epoch 219/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0126 - accuracy: 0.9974 - val_loss: 0.1060 - val_accuracy: 0.9873\n",
            "Epoch 220/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0228 - accuracy: 0.9968 - val_loss: 0.0650 - val_accuracy: 0.9854\n",
            "Epoch 221/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0083 - accuracy: 0.9980 - val_loss: 0.1903 - val_accuracy: 0.9818\n",
            "Epoch 222/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0062 - accuracy: 0.9989 - val_loss: 0.0819 - val_accuracy: 0.9854\n",
            "Epoch 223/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0110 - accuracy: 0.9976 - val_loss: 0.1157 - val_accuracy: 0.9867\n",
            "Epoch 224/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0083 - accuracy: 0.9983 - val_loss: 0.0839 - val_accuracy: 0.9867\n",
            "Epoch 225/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0049 - accuracy: 0.9992 - val_loss: 0.1309 - val_accuracy: 0.9854\n",
            "Epoch 226/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0064 - accuracy: 0.9989 - val_loss: 0.1030 - val_accuracy: 0.9860\n",
            "Epoch 227/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0123 - accuracy: 0.9977 - val_loss: 0.1332 - val_accuracy: 0.9873\n",
            "Epoch 228/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0169 - accuracy: 0.9968 - val_loss: 0.1131 - val_accuracy: 0.9824\n",
            "Epoch 229/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0189 - accuracy: 0.9961 - val_loss: 0.0651 - val_accuracy: 0.9848\n",
            "Epoch 230/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0151 - accuracy: 0.9964 - val_loss: 0.0888 - val_accuracy: 0.9867\n",
            "Epoch 231/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0143 - accuracy: 0.9973 - val_loss: 0.1308 - val_accuracy: 0.9842\n",
            "Epoch 232/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0167 - accuracy: 0.9962 - val_loss: 0.3161 - val_accuracy: 0.9775\n",
            "Epoch 233/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0176 - accuracy: 0.9964 - val_loss: 0.6452 - val_accuracy: 0.9727\n",
            "Epoch 234/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0235 - accuracy: 0.9958 - val_loss: 0.1414 - val_accuracy: 0.9848\n",
            "Epoch 235/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0122 - accuracy: 0.9971 - val_loss: 0.2423 - val_accuracy: 0.9812\n",
            "Epoch 236/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0081 - accuracy: 0.9982 - val_loss: 0.1105 - val_accuracy: 0.9879\n",
            "Epoch 237/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0122 - accuracy: 0.9974 - val_loss: 0.1252 - val_accuracy: 0.9860\n",
            "Epoch 238/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0171 - accuracy: 0.9971 - val_loss: 0.0800 - val_accuracy: 0.9842\n",
            "Epoch 239/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0131 - accuracy: 0.9971 - val_loss: 0.1225 - val_accuracy: 0.9848\n",
            "Epoch 240/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0109 - accuracy: 0.9974 - val_loss: 0.1578 - val_accuracy: 0.9836\n",
            "Epoch 241/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0114 - accuracy: 0.9971 - val_loss: 0.2037 - val_accuracy: 0.9824\n",
            "Epoch 242/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0195 - accuracy: 0.9959 - val_loss: 0.1797 - val_accuracy: 0.9860\n",
            "Epoch 243/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0107 - accuracy: 0.9976 - val_loss: 0.0780 - val_accuracy: 0.9848\n",
            "Epoch 244/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0127 - accuracy: 0.9971 - val_loss: 0.1481 - val_accuracy: 0.9848\n",
            "Epoch 245/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0069 - accuracy: 0.9986 - val_loss: 0.1917 - val_accuracy: 0.9867\n",
            "Epoch 246/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0087 - accuracy: 0.9980 - val_loss: 0.2135 - val_accuracy: 0.9860\n",
            "Epoch 247/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0132 - accuracy: 0.9983 - val_loss: 0.1018 - val_accuracy: 0.9836\n",
            "Epoch 248/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0106 - accuracy: 0.9979 - val_loss: 0.1278 - val_accuracy: 0.9867\n",
            "Epoch 249/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0311 - accuracy: 0.9962 - val_loss: 0.3062 - val_accuracy: 0.9788\n",
            "Epoch 250/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0226 - accuracy: 0.9953 - val_loss: 0.5767 - val_accuracy: 0.9769\n",
            "Epoch 251/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0111 - accuracy: 0.9977 - val_loss: 0.1567 - val_accuracy: 0.9830\n",
            "Epoch 252/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0077 - accuracy: 0.9982 - val_loss: 0.3673 - val_accuracy: 0.9794\n",
            "Epoch 253/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0071 - accuracy: 0.9988 - val_loss: 0.1087 - val_accuracy: 0.9879\n",
            "Epoch 254/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0105 - accuracy: 0.9979 - val_loss: 0.1317 - val_accuracy: 0.9860\n",
            "Epoch 255/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0060 - accuracy: 0.9985 - val_loss: 0.0953 - val_accuracy: 0.9867\n",
            "Epoch 256/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0078 - accuracy: 0.9979 - val_loss: 0.1134 - val_accuracy: 0.9854\n",
            "Epoch 257/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0084 - accuracy: 0.9986 - val_loss: 0.1159 - val_accuracy: 0.9867\n",
            "Epoch 258/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0090 - accuracy: 0.9983 - val_loss: 0.1236 - val_accuracy: 0.9854\n",
            "Epoch 259/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0062 - accuracy: 0.9991 - val_loss: 0.0922 - val_accuracy: 0.9860\n",
            "Epoch 260/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0078 - accuracy: 0.9982 - val_loss: 0.1584 - val_accuracy: 0.9860\n",
            "Epoch 261/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0103 - accuracy: 0.9976 - val_loss: 0.6527 - val_accuracy: 0.9678\n",
            "Epoch 262/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0147 - accuracy: 0.9968 - val_loss: 0.2494 - val_accuracy: 0.9830\n",
            "Epoch 263/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0114 - accuracy: 0.9977 - val_loss: 0.1460 - val_accuracy: 0.9836\n",
            "Epoch 264/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0073 - accuracy: 0.9986 - val_loss: 0.1538 - val_accuracy: 0.9836\n",
            "Epoch 265/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0069 - accuracy: 0.9989 - val_loss: 0.9156 - val_accuracy: 0.9697\n",
            "Epoch 266/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0108 - accuracy: 0.9985 - val_loss: 42.0878 - val_accuracy: 0.9102\n",
            "Epoch 267/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0156 - accuracy: 0.9973 - val_loss: 0.6534 - val_accuracy: 0.9581\n",
            "Epoch 268/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0163 - accuracy: 0.9977 - val_loss: 0.6731 - val_accuracy: 0.9636\n",
            "Epoch 269/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0300 - accuracy: 0.9948 - val_loss: 0.1191 - val_accuracy: 0.9873\n",
            "Epoch 270/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0087 - accuracy: 0.9983 - val_loss: 0.1304 - val_accuracy: 0.9836\n",
            "Epoch 271/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0086 - accuracy: 0.9982 - val_loss: 0.1444 - val_accuracy: 0.9860\n",
            "Epoch 272/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0057 - accuracy: 0.9988 - val_loss: 0.1762 - val_accuracy: 0.9842\n",
            "Epoch 273/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0047 - accuracy: 0.9992 - val_loss: 0.2058 - val_accuracy: 0.9818\n",
            "Epoch 274/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0041 - accuracy: 0.9994 - val_loss: 0.1932 - val_accuracy: 0.9842\n",
            "Epoch 275/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0145 - accuracy: 0.9979 - val_loss: 0.1767 - val_accuracy: 0.9806\n",
            "Epoch 276/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0058 - accuracy: 0.9988 - val_loss: 0.1202 - val_accuracy: 0.9824\n",
            "Epoch 277/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0232 - accuracy: 0.9970 - val_loss: 0.0794 - val_accuracy: 0.9775\n",
            "Epoch 278/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0132 - accuracy: 0.9982 - val_loss: 0.0876 - val_accuracy: 0.9848\n",
            "Epoch 279/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0098 - accuracy: 0.9979 - val_loss: 0.0961 - val_accuracy: 0.9860\n",
            "Epoch 280/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0084 - accuracy: 0.9982 - val_loss: 0.2862 - val_accuracy: 0.9806\n",
            "Epoch 281/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0090 - accuracy: 0.9982 - val_loss: 0.2276 - val_accuracy: 0.9800\n",
            "Epoch 282/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0056 - accuracy: 0.9991 - val_loss: 0.1920 - val_accuracy: 0.9842\n",
            "Epoch 283/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0077 - accuracy: 0.9986 - val_loss: 0.4313 - val_accuracy: 0.9794\n",
            "Epoch 284/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0156 - accuracy: 0.9980 - val_loss: 0.2513 - val_accuracy: 0.9806\n",
            "Epoch 285/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0160 - accuracy: 0.9961 - val_loss: 0.1439 - val_accuracy: 0.9751\n",
            "Epoch 286/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0239 - accuracy: 0.9954 - val_loss: 0.2779 - val_accuracy: 0.9745\n",
            "Epoch 287/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0212 - accuracy: 0.9948 - val_loss: 0.0975 - val_accuracy: 0.9848\n",
            "Epoch 288/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0098 - accuracy: 0.9979 - val_loss: 0.0941 - val_accuracy: 0.9867\n",
            "Epoch 289/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0113 - accuracy: 0.9980 - val_loss: 0.0992 - val_accuracy: 0.9842\n",
            "Epoch 290/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0107 - accuracy: 0.9974 - val_loss: 0.0939 - val_accuracy: 0.9848\n",
            "Epoch 291/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0151 - accuracy: 0.9974 - val_loss: 0.1671 - val_accuracy: 0.9788\n",
            "Epoch 292/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0078 - accuracy: 0.9985 - val_loss: 0.1456 - val_accuracy: 0.9830\n",
            "Epoch 293/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0064 - accuracy: 0.9986 - val_loss: 0.1559 - val_accuracy: 0.9830\n",
            "Epoch 294/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0055 - accuracy: 0.9991 - val_loss: 0.1583 - val_accuracy: 0.9836\n",
            "Epoch 295/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0049 - accuracy: 0.9992 - val_loss: 0.1386 - val_accuracy: 0.9867\n",
            "Epoch 296/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0070 - accuracy: 0.9988 - val_loss: 0.0830 - val_accuracy: 0.9836\n",
            "Epoch 297/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0106 - accuracy: 0.9976 - val_loss: 0.0817 - val_accuracy: 0.9867\n",
            "Epoch 298/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0045 - accuracy: 0.9992 - val_loss: 0.0572 - val_accuracy: 0.9891\n",
            "Epoch 299/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0048 - accuracy: 0.9992 - val_loss: 0.0717 - val_accuracy: 0.9885\n",
            "Epoch 300/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0052 - accuracy: 0.9989 - val_loss: 0.2026 - val_accuracy: 0.9842\n",
            "Epoch 301/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0073 - accuracy: 0.9980 - val_loss: 0.1062 - val_accuracy: 0.9867\n",
            "Epoch 302/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0041 - accuracy: 0.9994 - val_loss: 0.1397 - val_accuracy: 0.9860\n",
            "Epoch 303/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0040 - accuracy: 0.9994 - val_loss: 0.1603 - val_accuracy: 0.9873\n",
            "Epoch 304/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0061 - accuracy: 0.9988 - val_loss: 0.1419 - val_accuracy: 0.9879\n",
            "Epoch 305/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0213 - accuracy: 0.9967 - val_loss: 0.1620 - val_accuracy: 0.9721\n",
            "Epoch 306/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0098 - accuracy: 0.9977 - val_loss: 0.1927 - val_accuracy: 0.9830\n",
            "Epoch 307/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0056 - accuracy: 0.9989 - val_loss: 0.1091 - val_accuracy: 0.9836\n",
            "Epoch 308/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0101 - accuracy: 0.9979 - val_loss: 0.0963 - val_accuracy: 0.9854\n",
            "Epoch 309/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0089 - accuracy: 0.9991 - val_loss: 0.5350 - val_accuracy: 0.9684\n",
            "Epoch 310/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0218 - accuracy: 0.9974 - val_loss: 0.1351 - val_accuracy: 0.9842\n",
            "Epoch 311/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0166 - accuracy: 0.9962 - val_loss: 0.1027 - val_accuracy: 0.9836\n",
            "Epoch 312/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0097 - accuracy: 0.9982 - val_loss: 0.1721 - val_accuracy: 0.9824\n",
            "Epoch 313/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0049 - accuracy: 0.9989 - val_loss: 0.2474 - val_accuracy: 0.9830\n",
            "Epoch 314/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0139 - accuracy: 0.9976 - val_loss: 0.1817 - val_accuracy: 0.9830\n",
            "Epoch 315/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0053 - accuracy: 0.9989 - val_loss: 0.1283 - val_accuracy: 0.9836\n",
            "Epoch 316/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0124 - accuracy: 0.9979 - val_loss: 0.4170 - val_accuracy: 0.9782\n",
            "Epoch 317/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0054 - accuracy: 0.9991 - val_loss: 0.2254 - val_accuracy: 0.9830\n",
            "Epoch 318/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0052 - accuracy: 0.9989 - val_loss: 0.0764 - val_accuracy: 0.9836\n",
            "Epoch 319/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0088 - accuracy: 0.9985 - val_loss: 0.1271 - val_accuracy: 0.9824\n",
            "Epoch 320/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0059 - accuracy: 0.9983 - val_loss: 0.4534 - val_accuracy: 0.9709\n",
            "Epoch 321/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0108 - accuracy: 0.9982 - val_loss: 0.1584 - val_accuracy: 0.9818\n",
            "Epoch 322/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0095 - accuracy: 0.9979 - val_loss: 0.1273 - val_accuracy: 0.9854\n",
            "Epoch 323/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0042 - accuracy: 0.9991 - val_loss: 0.1547 - val_accuracy: 0.9854\n",
            "Epoch 324/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0356 - accuracy: 0.9965 - val_loss: 0.1546 - val_accuracy: 0.9812\n",
            "Epoch 325/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0169 - accuracy: 0.9968 - val_loss: 0.1352 - val_accuracy: 0.9867\n",
            "Epoch 326/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0034 - accuracy: 0.9994 - val_loss: 0.0895 - val_accuracy: 0.9854\n",
            "Epoch 327/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0043 - accuracy: 0.9992 - val_loss: 0.1247 - val_accuracy: 0.9873\n",
            "Epoch 328/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0042 - accuracy: 0.9991 - val_loss: 0.1536 - val_accuracy: 0.9873\n",
            "Epoch 329/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0114 - accuracy: 0.9988 - val_loss: 0.3381 - val_accuracy: 0.9775\n",
            "Epoch 330/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0086 - accuracy: 0.9980 - val_loss: 0.1164 - val_accuracy: 0.9854\n",
            "Epoch 331/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0179 - accuracy: 0.9980 - val_loss: 0.1084 - val_accuracy: 0.9860\n",
            "Epoch 332/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0059 - accuracy: 0.9986 - val_loss: 0.1269 - val_accuracy: 0.9867\n",
            "Epoch 333/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0107 - accuracy: 0.9976 - val_loss: 0.3021 - val_accuracy: 0.9842\n",
            "Epoch 334/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0095 - accuracy: 0.9980 - val_loss: 0.1002 - val_accuracy: 0.9873\n",
            "Epoch 335/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0046 - accuracy: 0.9991 - val_loss: 0.1303 - val_accuracy: 0.9860\n",
            "Epoch 336/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0071 - accuracy: 0.9983 - val_loss: 0.3658 - val_accuracy: 0.9806\n",
            "Epoch 337/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0040 - accuracy: 0.9992 - val_loss: 0.2089 - val_accuracy: 0.9842\n",
            "Epoch 338/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0085 - accuracy: 0.9989 - val_loss: 0.1895 - val_accuracy: 0.9836\n",
            "Epoch 339/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0068 - accuracy: 0.9986 - val_loss: 0.1734 - val_accuracy: 0.9848\n",
            "Epoch 340/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0115 - accuracy: 0.9983 - val_loss: 0.1148 - val_accuracy: 0.9860\n",
            "Epoch 341/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0047 - accuracy: 0.9992 - val_loss: 0.1181 - val_accuracy: 0.9860\n",
            "Epoch 342/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0063 - accuracy: 0.9988 - val_loss: 0.1430 - val_accuracy: 0.9867\n",
            "Epoch 343/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0167 - accuracy: 0.9974 - val_loss: 0.1990 - val_accuracy: 0.9563\n",
            "Epoch 344/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0089 - accuracy: 0.9979 - val_loss: 0.1596 - val_accuracy: 0.9860\n",
            "Epoch 345/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0047 - accuracy: 0.9991 - val_loss: 0.1764 - val_accuracy: 0.9873\n",
            "Epoch 346/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0034 - accuracy: 0.9994 - val_loss: 0.1440 - val_accuracy: 0.9860\n",
            "Epoch 347/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0064 - accuracy: 0.9985 - val_loss: 0.3093 - val_accuracy: 0.9806\n",
            "Epoch 348/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0036 - accuracy: 0.9991 - val_loss: 0.1148 - val_accuracy: 0.9842\n",
            "Epoch 349/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0080 - accuracy: 0.9985 - val_loss: 0.0925 - val_accuracy: 0.9867\n",
            "Epoch 350/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0094 - accuracy: 0.9982 - val_loss: 0.1673 - val_accuracy: 0.9860\n",
            "Epoch 351/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0113 - accuracy: 0.9985 - val_loss: 0.1849 - val_accuracy: 0.9873\n",
            "Epoch 352/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0038 - accuracy: 0.9994 - val_loss: 0.1810 - val_accuracy: 0.9860\n",
            "Epoch 353/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0059 - accuracy: 0.9988 - val_loss: 0.0955 - val_accuracy: 0.9867\n",
            "Epoch 354/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0271 - accuracy: 0.9976 - val_loss: 0.4341 - val_accuracy: 0.9769\n",
            "Epoch 355/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0054 - accuracy: 0.9988 - val_loss: 0.1979 - val_accuracy: 0.9860\n",
            "Epoch 356/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0128 - accuracy: 0.9983 - val_loss: 0.3169 - val_accuracy: 0.9769\n",
            "Epoch 357/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0047 - accuracy: 0.9991 - val_loss: 0.2556 - val_accuracy: 0.9824\n",
            "Epoch 358/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0073 - accuracy: 0.9988 - val_loss: 0.1155 - val_accuracy: 0.9800\n",
            "Epoch 359/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0072 - accuracy: 0.9986 - val_loss: 0.1758 - val_accuracy: 0.9806\n",
            "Epoch 360/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0110 - accuracy: 0.9988 - val_loss: 0.3669 - val_accuracy: 0.9800\n",
            "Epoch 361/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0298 - accuracy: 0.9956 - val_loss: 0.1172 - val_accuracy: 0.9769\n",
            "Epoch 362/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0135 - accuracy: 0.9979 - val_loss: 0.2167 - val_accuracy: 0.9854\n",
            "Epoch 363/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0056 - accuracy: 0.9991 - val_loss: 0.1283 - val_accuracy: 0.9836\n",
            "Epoch 364/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0059 - accuracy: 0.9986 - val_loss: 0.2094 - val_accuracy: 0.9830\n",
            "Epoch 365/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0059 - accuracy: 0.9989 - val_loss: 0.1778 - val_accuracy: 0.9751\n",
            "Epoch 366/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0281 - accuracy: 0.9953 - val_loss: 0.2471 - val_accuracy: 0.9824\n",
            "Epoch 367/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0026 - accuracy: 0.9995 - val_loss: 0.1338 - val_accuracy: 0.9830\n",
            "Epoch 368/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0059 - accuracy: 0.9988 - val_loss: 0.1027 - val_accuracy: 0.9873\n",
            "Epoch 369/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0069 - accuracy: 0.9983 - val_loss: 0.1637 - val_accuracy: 0.9842\n",
            "Epoch 370/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0036 - accuracy: 0.9992 - val_loss: 0.2141 - val_accuracy: 0.9873\n",
            "Epoch 371/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0022 - accuracy: 0.9997 - val_loss: 0.2864 - val_accuracy: 0.9867\n",
            "Epoch 372/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0065 - accuracy: 0.9989 - val_loss: 0.2648 - val_accuracy: 0.9854\n",
            "Epoch 373/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0054 - accuracy: 0.9991 - val_loss: 0.1762 - val_accuracy: 0.9867\n",
            "Epoch 374/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0031 - accuracy: 0.9995 - val_loss: 0.1737 - val_accuracy: 0.9867\n",
            "Epoch 375/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0035 - accuracy: 0.9994 - val_loss: 0.1206 - val_accuracy: 0.9873\n",
            "Epoch 376/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0125 - accuracy: 0.9986 - val_loss: 0.1174 - val_accuracy: 0.9867\n",
            "Epoch 377/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0320 - accuracy: 0.9965 - val_loss: 0.1821 - val_accuracy: 0.9775\n",
            "Epoch 378/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0292 - accuracy: 0.9954 - val_loss: 0.3312 - val_accuracy: 0.9812\n",
            "Epoch 379/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0106 - accuracy: 0.9979 - val_loss: 0.2604 - val_accuracy: 0.9824\n",
            "Epoch 380/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0098 - accuracy: 0.9983 - val_loss: 0.1082 - val_accuracy: 0.9873\n",
            "Epoch 381/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0071 - accuracy: 0.9985 - val_loss: 0.1624 - val_accuracy: 0.9848\n",
            "Epoch 382/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0063 - accuracy: 0.9988 - val_loss: 0.2352 - val_accuracy: 0.9860\n",
            "Epoch 383/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0092 - accuracy: 0.9983 - val_loss: 0.1473 - val_accuracy: 0.9867\n",
            "Epoch 384/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0051 - accuracy: 0.9994 - val_loss: 0.1283 - val_accuracy: 0.9860\n",
            "Epoch 385/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0038 - accuracy: 0.9994 - val_loss: 0.1846 - val_accuracy: 0.9860\n",
            "Epoch 386/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0027 - accuracy: 0.9995 - val_loss: 0.1667 - val_accuracy: 0.9848\n",
            "Epoch 387/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0038 - accuracy: 0.9992 - val_loss: 0.0910 - val_accuracy: 0.9891\n",
            "Epoch 388/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0054 - accuracy: 0.9989 - val_loss: 0.1038 - val_accuracy: 0.9897\n",
            "Epoch 389/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0065 - accuracy: 0.9985 - val_loss: 0.4422 - val_accuracy: 0.9788\n",
            "Epoch 390/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0064 - accuracy: 0.9988 - val_loss: 0.1551 - val_accuracy: 0.9860\n",
            "Epoch 391/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0064 - accuracy: 0.9988 - val_loss: 0.1784 - val_accuracy: 0.9854\n",
            "Epoch 392/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0048 - accuracy: 0.9991 - val_loss: 0.1326 - val_accuracy: 0.9867\n",
            "Epoch 393/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0060 - accuracy: 0.9989 - val_loss: 0.1327 - val_accuracy: 0.9854\n",
            "Epoch 394/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0126 - accuracy: 0.9983 - val_loss: 0.3704 - val_accuracy: 0.9800\n",
            "Epoch 395/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0023 - accuracy: 0.9997 - val_loss: 0.2824 - val_accuracy: 0.9842\n",
            "Epoch 396/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0039 - accuracy: 0.9992 - val_loss: 0.2484 - val_accuracy: 0.9860\n",
            "Epoch 397/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0041 - accuracy: 0.9991 - val_loss: 0.2337 - val_accuracy: 0.9842\n",
            "Epoch 398/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0215 - accuracy: 0.9979 - val_loss: 0.2049 - val_accuracy: 0.9733\n",
            "Epoch 399/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0139 - accuracy: 0.9973 - val_loss: 0.1621 - val_accuracy: 0.9824\n",
            "Epoch 400/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0110 - accuracy: 0.9976 - val_loss: 0.0828 - val_accuracy: 0.9854\n",
            "Epoch 401/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0106 - accuracy: 0.9979 - val_loss: 0.1098 - val_accuracy: 0.9860\n",
            "Epoch 402/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0050 - accuracy: 0.9989 - val_loss: 0.1030 - val_accuracy: 0.9891\n",
            "Epoch 403/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0041 - accuracy: 0.9991 - val_loss: 0.1485 - val_accuracy: 0.9891\n",
            "Epoch 404/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0041 - accuracy: 0.9992 - val_loss: 0.1373 - val_accuracy: 0.9873\n",
            "Epoch 405/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0028 - accuracy: 0.9995 - val_loss: 0.1466 - val_accuracy: 0.9879\n",
            "Epoch 406/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0045 - accuracy: 0.9994 - val_loss: 0.1679 - val_accuracy: 0.9903\n",
            "Epoch 407/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0045 - accuracy: 0.9994 - val_loss: 0.0874 - val_accuracy: 0.9873\n",
            "Epoch 408/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0064 - accuracy: 0.9992 - val_loss: 0.1255 - val_accuracy: 0.9867\n",
            "Epoch 409/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0023 - accuracy: 0.9997 - val_loss: 0.1263 - val_accuracy: 0.9879\n",
            "Epoch 410/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0031 - accuracy: 0.9995 - val_loss: 0.2000 - val_accuracy: 0.9830\n",
            "Epoch 411/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0038 - accuracy: 0.9994 - val_loss: 0.1932 - val_accuracy: 0.9842\n",
            "Epoch 412/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0047 - accuracy: 0.9994 - val_loss: 0.1697 - val_accuracy: 0.9879\n",
            "Epoch 413/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0066 - accuracy: 0.9986 - val_loss: 1.5998 - val_accuracy: 0.9691\n",
            "Epoch 414/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0324 - accuracy: 0.9953 - val_loss: 0.4452 - val_accuracy: 0.9763\n",
            "Epoch 415/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0037 - accuracy: 0.9992 - val_loss: 0.1017 - val_accuracy: 0.9873\n",
            "Epoch 416/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0045 - accuracy: 0.9991 - val_loss: 0.1322 - val_accuracy: 0.9848\n",
            "Epoch 417/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0073 - accuracy: 0.9989 - val_loss: 0.0860 - val_accuracy: 0.9867\n",
            "Epoch 418/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0057 - accuracy: 0.9989 - val_loss: 0.0602 - val_accuracy: 0.9885\n",
            "Epoch 419/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0607 - accuracy: 0.9964 - val_loss: 0.1695 - val_accuracy: 0.9818\n",
            "Epoch 420/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0143 - accuracy: 0.9976 - val_loss: 0.1592 - val_accuracy: 0.9830\n",
            "Epoch 421/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0103 - accuracy: 0.9979 - val_loss: 0.1073 - val_accuracy: 0.9836\n",
            "Epoch 422/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0076 - accuracy: 0.9982 - val_loss: 0.0850 - val_accuracy: 0.9854\n",
            "Epoch 423/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0122 - accuracy: 0.9982 - val_loss: 0.2048 - val_accuracy: 0.9836\n",
            "Epoch 424/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0046 - accuracy: 0.9989 - val_loss: 0.2579 - val_accuracy: 0.9812\n",
            "Epoch 425/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0046 - accuracy: 0.9991 - val_loss: 0.3179 - val_accuracy: 0.9788\n",
            "Epoch 426/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0084 - accuracy: 0.9983 - val_loss: 0.1105 - val_accuracy: 0.9860\n",
            "Epoch 427/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0039 - accuracy: 0.9992 - val_loss: 0.1057 - val_accuracy: 0.9873\n",
            "Epoch 428/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0046 - accuracy: 0.9992 - val_loss: 0.1724 - val_accuracy: 0.9848\n",
            "Epoch 429/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0025 - accuracy: 0.9995 - val_loss: 0.1338 - val_accuracy: 0.9860\n",
            "Epoch 430/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0039 - accuracy: 0.9994 - val_loss: 0.1257 - val_accuracy: 0.9873\n",
            "Epoch 431/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0042 - accuracy: 0.9991 - val_loss: 0.1866 - val_accuracy: 0.9848\n",
            "Epoch 432/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0024 - accuracy: 0.9997 - val_loss: 0.1741 - val_accuracy: 0.9867\n",
            "Epoch 433/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0054 - accuracy: 0.9991 - val_loss: 0.1598 - val_accuracy: 0.9860\n",
            "Epoch 434/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0016 - accuracy: 0.9998 - val_loss: 0.1439 - val_accuracy: 0.9860\n",
            "Epoch 435/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 0.1541 - val_accuracy: 0.9860\n",
            "Epoch 436/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0055 - accuracy: 0.9989 - val_loss: 0.1346 - val_accuracy: 0.9879\n",
            "Epoch 437/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0076 - accuracy: 0.9989 - val_loss: 0.1520 - val_accuracy: 0.9842\n",
            "Epoch 438/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0042 - accuracy: 0.9989 - val_loss: 0.1296 - val_accuracy: 0.9854\n",
            "Epoch 439/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0046 - accuracy: 0.9991 - val_loss: 0.4512 - val_accuracy: 0.9782\n",
            "Epoch 440/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0024 - accuracy: 0.9997 - val_loss: 0.1910 - val_accuracy: 0.9854\n",
            "Epoch 441/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0056 - accuracy: 0.9988 - val_loss: 0.2056 - val_accuracy: 0.9848\n",
            "Epoch 442/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0138 - accuracy: 0.9971 - val_loss: 0.2672 - val_accuracy: 0.9812\n",
            "Epoch 443/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0196 - accuracy: 0.9982 - val_loss: 0.2080 - val_accuracy: 0.9806\n",
            "Epoch 444/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0077 - accuracy: 0.9983 - val_loss: 0.2983 - val_accuracy: 0.9830\n",
            "Epoch 445/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0056 - accuracy: 0.9989 - val_loss: 0.1341 - val_accuracy: 0.9897\n",
            "Epoch 446/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0041 - accuracy: 0.9992 - val_loss: 0.2550 - val_accuracy: 0.9842\n",
            "Epoch 447/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0409 - accuracy: 0.9965 - val_loss: 1.1684 - val_accuracy: 0.9721\n",
            "Epoch 448/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0513 - accuracy: 0.9980 - val_loss: 0.1996 - val_accuracy: 0.9873\n",
            "Epoch 449/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0040 - accuracy: 0.9992 - val_loss: 0.3571 - val_accuracy: 0.9854\n",
            "Epoch 450/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0062 - accuracy: 0.9988 - val_loss: 0.2889 - val_accuracy: 0.9873\n",
            "Epoch 451/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0056 - accuracy: 0.9989 - val_loss: 0.2891 - val_accuracy: 0.9873\n",
            "Epoch 452/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0103 - accuracy: 0.9989 - val_loss: 0.3839 - val_accuracy: 0.9848\n",
            "Epoch 453/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0042 - accuracy: 0.9992 - val_loss: 0.2327 - val_accuracy: 0.9903\n",
            "Epoch 454/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0046 - accuracy: 0.9992 - val_loss: 0.2523 - val_accuracy: 0.9891\n",
            "Epoch 455/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0086 - accuracy: 0.9985 - val_loss: 0.2726 - val_accuracy: 0.9891\n",
            "Epoch 456/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0076 - accuracy: 0.9988 - val_loss: 0.2311 - val_accuracy: 0.9848\n",
            "Epoch 457/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0036 - accuracy: 0.9992 - val_loss: 0.1570 - val_accuracy: 0.9854\n",
            "Epoch 458/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0053 - accuracy: 0.9989 - val_loss: 0.2315 - val_accuracy: 0.9848\n",
            "Epoch 459/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0058 - accuracy: 0.9988 - val_loss: 0.2780 - val_accuracy: 0.9842\n",
            "Epoch 460/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 0.3025 - val_accuracy: 0.9836\n",
            "Epoch 461/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0040 - accuracy: 0.9991 - val_loss: 0.1392 - val_accuracy: 0.9885\n",
            "Epoch 462/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0131 - accuracy: 0.9983 - val_loss: 0.1185 - val_accuracy: 0.9867\n",
            "Epoch 463/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0196 - accuracy: 0.9974 - val_loss: 0.1606 - val_accuracy: 0.9842\n",
            "Epoch 464/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0130 - accuracy: 0.9979 - val_loss: 0.2370 - val_accuracy: 0.9836\n",
            "Epoch 465/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0059 - accuracy: 0.9988 - val_loss: 0.2984 - val_accuracy: 0.9830\n",
            "Epoch 466/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0038 - accuracy: 0.9994 - val_loss: 0.2340 - val_accuracy: 0.9836\n",
            "Epoch 467/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0060 - accuracy: 0.9989 - val_loss: 0.2214 - val_accuracy: 0.9873\n",
            "Epoch 468/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 0.2164 - val_accuracy: 0.9860\n",
            "Epoch 469/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0073 - accuracy: 0.9992 - val_loss: 0.1433 - val_accuracy: 0.9818\n",
            "Epoch 470/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0064 - accuracy: 0.9988 - val_loss: 0.2344 - val_accuracy: 0.9860\n",
            "Epoch 471/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0078 - accuracy: 0.9985 - val_loss: 0.1303 - val_accuracy: 0.9860\n",
            "Epoch 472/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0044 - accuracy: 0.9991 - val_loss: 0.4342 - val_accuracy: 0.9794\n",
            "Epoch 473/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0050 - accuracy: 0.9995 - val_loss: 0.1822 - val_accuracy: 0.9879\n",
            "Epoch 474/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 0.1990 - val_accuracy: 0.9879\n",
            "Epoch 475/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0070 - accuracy: 0.9982 - val_loss: 0.1444 - val_accuracy: 0.9867\n",
            "Epoch 476/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0049 - accuracy: 0.9991 - val_loss: 0.2355 - val_accuracy: 0.9842\n",
            "Epoch 477/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.3560 - val_accuracy: 0.9830\n",
            "Epoch 478/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0031 - accuracy: 0.9995 - val_loss: 0.2832 - val_accuracy: 0.9860\n",
            "Epoch 479/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0059 - accuracy: 0.9991 - val_loss: 0.1038 - val_accuracy: 0.9867\n",
            "Epoch 480/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0088 - accuracy: 0.9982 - val_loss: 0.3852 - val_accuracy: 0.9848\n",
            "Epoch 481/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0057 - accuracy: 0.9991 - val_loss: 0.2083 - val_accuracy: 0.9836\n",
            "Epoch 482/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 0.2428 - val_accuracy: 0.9842\n",
            "Epoch 483/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0047 - accuracy: 0.9991 - val_loss: 0.3389 - val_accuracy: 0.9842\n",
            "Epoch 484/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0083 - accuracy: 0.9989 - val_loss: 0.3263 - val_accuracy: 0.9854\n",
            "Epoch 485/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0037 - accuracy: 0.9992 - val_loss: 0.1995 - val_accuracy: 0.9848\n",
            "Epoch 486/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0080 - accuracy: 0.9986 - val_loss: 0.4164 - val_accuracy: 0.9824\n",
            "Epoch 487/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0048 - accuracy: 0.9992 - val_loss: 0.2304 - val_accuracy: 0.9854\n",
            "Epoch 488/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0062 - accuracy: 0.9989 - val_loss: 0.0957 - val_accuracy: 0.9842\n",
            "Epoch 489/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0073 - accuracy: 0.9986 - val_loss: 0.1147 - val_accuracy: 0.9830\n",
            "Epoch 490/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.2640 - val_accuracy: 0.9824\n",
            "Epoch 491/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0127 - accuracy: 0.9979 - val_loss: 0.0814 - val_accuracy: 0.9867\n",
            "Epoch 492/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0097 - accuracy: 0.9982 - val_loss: 0.0963 - val_accuracy: 0.9854\n",
            "Epoch 493/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0075 - accuracy: 0.9983 - val_loss: 1.2264 - val_accuracy: 0.9521\n",
            "Epoch 494/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0132 - accuracy: 0.9977 - val_loss: 0.1292 - val_accuracy: 0.9848\n",
            "Epoch 495/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0121 - accuracy: 0.9979 - val_loss: 0.1056 - val_accuracy: 0.9873\n",
            "Epoch 496/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0074 - accuracy: 0.9985 - val_loss: 0.1472 - val_accuracy: 0.9873\n",
            "Epoch 497/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.1679 - val_accuracy: 0.9854\n",
            "Epoch 498/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0044 - accuracy: 0.9991 - val_loss: 0.1389 - val_accuracy: 0.9879\n",
            "Epoch 499/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0038 - accuracy: 0.9994 - val_loss: 0.1202 - val_accuracy: 0.9879\n",
            "Epoch 500/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0062 - accuracy: 0.9989 - val_loss: 0.1219 - val_accuracy: 0.9879\n",
            "Epoch 501/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0036 - accuracy: 0.9991 - val_loss: 0.0996 - val_accuracy: 0.9879\n",
            "Epoch 502/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0089 - accuracy: 0.9989 - val_loss: 0.2701 - val_accuracy: 0.9842\n",
            "Epoch 503/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0048 - accuracy: 0.9991 - val_loss: 0.1019 - val_accuracy: 0.9891\n",
            "Epoch 504/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0056 - accuracy: 0.9988 - val_loss: 0.1249 - val_accuracy: 0.9891\n",
            "Epoch 505/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0039 - accuracy: 0.9994 - val_loss: 0.2499 - val_accuracy: 0.9873\n",
            "Epoch 506/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0041 - accuracy: 0.9992 - val_loss: 0.3873 - val_accuracy: 0.9830\n",
            "Epoch 507/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0081 - accuracy: 0.9986 - val_loss: 0.5139 - val_accuracy: 0.9763\n",
            "Epoch 508/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0090 - accuracy: 0.9986 - val_loss: 0.1857 - val_accuracy: 0.9800\n",
            "Epoch 509/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0092 - accuracy: 0.9985 - val_loss: 0.3036 - val_accuracy: 0.9806\n",
            "Epoch 510/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0197 - accuracy: 0.9982 - val_loss: 0.1494 - val_accuracy: 0.9854\n",
            "Epoch 511/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0021 - accuracy: 0.9997 - val_loss: 0.2007 - val_accuracy: 0.9848\n",
            "Epoch 512/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0117 - accuracy: 0.9982 - val_loss: 0.1935 - val_accuracy: 0.9830\n",
            "Epoch 513/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0183 - accuracy: 0.9979 - val_loss: 0.2235 - val_accuracy: 0.9848\n",
            "Epoch 514/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0114 - accuracy: 0.9986 - val_loss: 0.1722 - val_accuracy: 0.9873\n",
            "Epoch 515/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0090 - accuracy: 0.9986 - val_loss: 0.2417 - val_accuracy: 0.9848\n",
            "Epoch 516/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0066 - accuracy: 0.9986 - val_loss: 0.5240 - val_accuracy: 0.9812\n",
            "Epoch 517/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0046 - accuracy: 0.9992 - val_loss: 0.2942 - val_accuracy: 0.9848\n",
            "Epoch 518/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0038 - accuracy: 0.9994 - val_loss: 0.2793 - val_accuracy: 0.9848\n",
            "Epoch 519/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 0.2641 - val_accuracy: 0.9842\n",
            "Epoch 520/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.2935 - val_accuracy: 0.9854\n",
            "Epoch 521/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0054 - accuracy: 0.9989 - val_loss: 0.4293 - val_accuracy: 0.9824\n",
            "Epoch 522/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0055 - accuracy: 0.9991 - val_loss: 0.1779 - val_accuracy: 0.9842\n",
            "Epoch 523/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0134 - accuracy: 0.9979 - val_loss: 0.9310 - val_accuracy: 0.9612\n",
            "Epoch 524/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0212 - accuracy: 0.9970 - val_loss: 0.1256 - val_accuracy: 0.9842\n",
            "Epoch 525/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0097 - accuracy: 0.9974 - val_loss: 0.0962 - val_accuracy: 0.9879\n",
            "Epoch 526/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0049 - accuracy: 0.9992 - val_loss: 0.0948 - val_accuracy: 0.9867\n",
            "Epoch 527/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0042 - accuracy: 0.9992 - val_loss: 0.1293 - val_accuracy: 0.9867\n",
            "Epoch 528/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0045 - accuracy: 0.9992 - val_loss: 0.0887 - val_accuracy: 0.9885\n",
            "Epoch 529/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0040 - accuracy: 0.9992 - val_loss: 0.1443 - val_accuracy: 0.9867\n",
            "Epoch 530/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0025 - accuracy: 0.9995 - val_loss: 0.2991 - val_accuracy: 0.9842\n",
            "Epoch 531/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0233 - accuracy: 0.9992 - val_loss: 0.6725 - val_accuracy: 0.9697\n",
            "Epoch 532/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0127 - accuracy: 0.9980 - val_loss: 0.2468 - val_accuracy: 0.9824\n",
            "Epoch 533/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0103 - accuracy: 0.9982 - val_loss: 0.1248 - val_accuracy: 0.9879\n",
            "Epoch 534/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0062 - accuracy: 0.9991 - val_loss: 0.1895 - val_accuracy: 0.9860\n",
            "Epoch 535/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0050 - accuracy: 0.9991 - val_loss: 0.2026 - val_accuracy: 0.9848\n",
            "Epoch 536/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0022 - accuracy: 0.9997 - val_loss: 0.1699 - val_accuracy: 0.9860\n",
            "Epoch 537/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0029 - accuracy: 0.9995 - val_loss: 0.3086 - val_accuracy: 0.9775\n",
            "Epoch 538/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0056 - accuracy: 0.9989 - val_loss: 0.2340 - val_accuracy: 0.9854\n",
            "Epoch 539/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0060 - accuracy: 0.9986 - val_loss: 0.1916 - val_accuracy: 0.9885\n",
            "Epoch 540/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0054 - accuracy: 0.9992 - val_loss: 0.1697 - val_accuracy: 0.9854\n",
            "Epoch 541/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 0.1852 - val_accuracy: 0.9854\n",
            "Epoch 542/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0093 - accuracy: 0.9985 - val_loss: 0.1603 - val_accuracy: 0.9818\n",
            "Epoch 543/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0035 - accuracy: 0.9992 - val_loss: 0.1074 - val_accuracy: 0.9873\n",
            "Epoch 544/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.1816 - val_accuracy: 0.9867\n",
            "Epoch 545/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0071 - accuracy: 0.9995 - val_loss: 0.2541 - val_accuracy: 0.9812\n",
            "Epoch 546/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0220 - accuracy: 0.9979 - val_loss: 0.1234 - val_accuracy: 0.9848\n",
            "Epoch 547/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0080 - accuracy: 0.9986 - val_loss: 0.1233 - val_accuracy: 0.9848\n",
            "Epoch 548/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0055 - accuracy: 0.9991 - val_loss: 0.1307 - val_accuracy: 0.9848\n",
            "Epoch 549/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0035 - accuracy: 0.9992 - val_loss: 0.1401 - val_accuracy: 0.9854\n",
            "Epoch 550/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0038 - accuracy: 0.9994 - val_loss: 0.1343 - val_accuracy: 0.9854\n",
            "Epoch 551/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0038 - accuracy: 0.9994 - val_loss: 0.1537 - val_accuracy: 0.9854\n",
            "Epoch 552/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 0.2683 - val_accuracy: 0.9848\n",
            "Epoch 553/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0046 - accuracy: 0.9992 - val_loss: 0.1834 - val_accuracy: 0.9867\n",
            "Epoch 554/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0047 - accuracy: 0.9992 - val_loss: 0.2296 - val_accuracy: 0.9860\n",
            "Epoch 555/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0039 - accuracy: 0.9994 - val_loss: 0.1230 - val_accuracy: 0.9867\n",
            "Epoch 556/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0151 - accuracy: 0.9988 - val_loss: 14.2320 - val_accuracy: 0.9296\n",
            "Epoch 557/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0060 - accuracy: 0.9988 - val_loss: 0.2277 - val_accuracy: 0.9873\n",
            "Epoch 558/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0059 - accuracy: 0.9994 - val_loss: 0.2109 - val_accuracy: 0.9873\n",
            "Epoch 559/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.2865 - val_accuracy: 0.9854\n",
            "Epoch 560/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0051 - accuracy: 0.9994 - val_loss: 0.3234 - val_accuracy: 0.9860\n",
            "Epoch 561/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0040 - accuracy: 0.9994 - val_loss: 0.1735 - val_accuracy: 0.9891\n",
            "Epoch 562/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0093 - accuracy: 0.9982 - val_loss: 0.2132 - val_accuracy: 0.9842\n",
            "Epoch 563/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0043 - accuracy: 0.9992 - val_loss: 0.1566 - val_accuracy: 0.9873\n",
            "Epoch 564/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0081 - accuracy: 0.9991 - val_loss: 0.1553 - val_accuracy: 0.9848\n",
            "Epoch 565/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 0.1668 - val_accuracy: 0.9836\n",
            "Epoch 566/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0067 - accuracy: 0.9988 - val_loss: 0.1031 - val_accuracy: 0.9860\n",
            "Epoch 567/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0121 - accuracy: 0.9976 - val_loss: 0.4104 - val_accuracy: 0.9800\n",
            "Epoch 568/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0140 - accuracy: 0.9980 - val_loss: 0.1359 - val_accuracy: 0.9848\n",
            "Epoch 569/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0041 - accuracy: 0.9991 - val_loss: 0.4004 - val_accuracy: 0.9818\n",
            "Epoch 570/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0022 - accuracy: 0.9997 - val_loss: 0.2723 - val_accuracy: 0.9842\n",
            "Epoch 571/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0037 - accuracy: 0.9994 - val_loss: 0.2794 - val_accuracy: 0.9854\n",
            "Epoch 572/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0104 - accuracy: 0.9995 - val_loss: 0.2116 - val_accuracy: 0.9830\n",
            "Epoch 573/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0072 - accuracy: 0.9983 - val_loss: 0.2236 - val_accuracy: 0.9854\n",
            "Epoch 574/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0077 - accuracy: 0.9988 - val_loss: 0.1268 - val_accuracy: 0.9854\n",
            "Epoch 575/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0039 - accuracy: 0.9994 - val_loss: 0.0799 - val_accuracy: 0.9879\n",
            "Epoch 576/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0046 - accuracy: 0.9992 - val_loss: 0.2508 - val_accuracy: 0.9782\n",
            "Epoch 577/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0238 - accuracy: 0.9974 - val_loss: 0.5009 - val_accuracy: 0.9733\n",
            "Epoch 578/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0105 - accuracy: 0.9989 - val_loss: 0.0822 - val_accuracy: 0.9867\n",
            "Epoch 579/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0067 - accuracy: 0.9985 - val_loss: 0.4714 - val_accuracy: 0.9769\n",
            "Epoch 580/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0022 - accuracy: 0.9997 - val_loss: 0.2883 - val_accuracy: 0.9824\n",
            "Epoch 581/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0038 - accuracy: 0.9992 - val_loss: 0.3648 - val_accuracy: 0.9848\n",
            "Epoch 582/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0029 - accuracy: 0.9995 - val_loss: 0.3780 - val_accuracy: 0.9842\n",
            "Epoch 583/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0102 - accuracy: 0.9988 - val_loss: 0.3323 - val_accuracy: 0.9824\n",
            "Epoch 584/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0111 - accuracy: 0.9985 - val_loss: 1.0483 - val_accuracy: 0.9527\n",
            "Epoch 585/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0409 - accuracy: 0.9959 - val_loss: 0.2498 - val_accuracy: 0.9818\n",
            "Epoch 586/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0104 - accuracy: 0.9980 - val_loss: 0.2824 - val_accuracy: 0.9818\n",
            "Epoch 587/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0214 - accuracy: 0.9974 - val_loss: 0.1852 - val_accuracy: 0.9818\n",
            "Epoch 588/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0055 - accuracy: 0.9989 - val_loss: 0.2008 - val_accuracy: 0.9860\n",
            "Epoch 589/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0057 - accuracy: 0.9988 - val_loss: 0.2285 - val_accuracy: 0.9848\n",
            "Epoch 590/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.1507 - val_accuracy: 0.9879\n",
            "Epoch 591/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.1799 - val_accuracy: 0.9885\n",
            "Epoch 592/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 0.2471 - val_accuracy: 0.9879\n",
            "Epoch 593/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 0.2400 - val_accuracy: 0.9879\n",
            "Epoch 594/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0046 - accuracy: 0.9992 - val_loss: 0.3134 - val_accuracy: 0.9860\n",
            "Epoch 595/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0101 - accuracy: 0.9991 - val_loss: 0.3513 - val_accuracy: 0.9836\n",
            "Epoch 596/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0076 - accuracy: 0.9985 - val_loss: 0.2346 - val_accuracy: 0.9867\n",
            "Epoch 597/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0038 - accuracy: 0.9994 - val_loss: 0.2127 - val_accuracy: 0.9873\n",
            "Epoch 598/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0046 - accuracy: 0.9992 - val_loss: 0.2756 - val_accuracy: 0.9848\n",
            "Epoch 599/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0022 - accuracy: 0.9997 - val_loss: 0.2920 - val_accuracy: 0.9854\n",
            "Epoch 600/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0060 - accuracy: 0.9992 - val_loss: 0.2699 - val_accuracy: 0.9848\n",
            "Epoch 601/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0046 - accuracy: 0.9992 - val_loss: 0.2753 - val_accuracy: 0.9842\n",
            "Epoch 602/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0022 - accuracy: 0.9997 - val_loss: 0.2713 - val_accuracy: 0.9854\n",
            "Epoch 603/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0146 - accuracy: 0.9988 - val_loss: 0.2999 - val_accuracy: 0.9697\n",
            "Epoch 604/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0186 - accuracy: 0.9974 - val_loss: 0.2482 - val_accuracy: 0.9800\n",
            "Epoch 605/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0070 - accuracy: 0.9989 - val_loss: 0.2253 - val_accuracy: 0.9860\n",
            "Epoch 606/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0310 - accuracy: 0.9980 - val_loss: 0.1642 - val_accuracy: 0.9830\n",
            "Epoch 607/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0119 - accuracy: 0.9980 - val_loss: 0.1105 - val_accuracy: 0.9830\n",
            "Epoch 608/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0058 - accuracy: 0.9989 - val_loss: 0.1499 - val_accuracy: 0.9867\n",
            "Epoch 609/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0180 - accuracy: 0.9980 - val_loss: 0.2992 - val_accuracy: 0.9788\n",
            "Epoch 610/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0082 - accuracy: 0.9988 - val_loss: 0.2377 - val_accuracy: 0.9830\n",
            "Epoch 611/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0044 - accuracy: 0.9992 - val_loss: 0.1326 - val_accuracy: 0.9854\n",
            "Epoch 612/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0028 - accuracy: 0.9995 - val_loss: 0.2487 - val_accuracy: 0.9824\n",
            "Epoch 613/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0017 - accuracy: 0.9997 - val_loss: 0.3387 - val_accuracy: 0.9812\n",
            "Epoch 614/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0022 - accuracy: 0.9992 - val_loss: 0.3325 - val_accuracy: 0.9818\n",
            "Epoch 615/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 0.1606 - val_accuracy: 0.9848\n",
            "Epoch 616/1000\n",
            "206/206 [==============================] - 9s 43ms/step - loss: 0.0038 - accuracy: 0.9994 - val_loss: 0.2828 - val_accuracy: 0.9812\n",
            "Epoch 617/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0031 - accuracy: 0.9995 - val_loss: 0.1749 - val_accuracy: 0.9848\n",
            "Epoch 618/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0022 - accuracy: 0.9997 - val_loss: 0.2015 - val_accuracy: 0.9842\n",
            "Epoch 619/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0108 - accuracy: 0.9991 - val_loss: 0.0855 - val_accuracy: 0.9854\n",
            "Epoch 620/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0169 - accuracy: 0.9982 - val_loss: 0.1957 - val_accuracy: 0.9836\n",
            "Epoch 621/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0146 - accuracy: 0.9980 - val_loss: 0.2244 - val_accuracy: 0.9842\n",
            "Epoch 622/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0126 - accuracy: 0.9991 - val_loss: 0.8978 - val_accuracy: 0.9709\n",
            "Epoch 623/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 0.3693 - val_accuracy: 0.9824\n",
            "Epoch 624/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0055 - accuracy: 0.9994 - val_loss: 0.5791 - val_accuracy: 0.9775\n",
            "Epoch 625/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 4.2179e-04 - accuracy: 1.0000 - val_loss: 0.2920 - val_accuracy: 0.9830\n",
            "Epoch 626/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0165 - accuracy: 0.9989 - val_loss: 0.7481 - val_accuracy: 0.9660\n",
            "Epoch 627/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0057 - accuracy: 0.9995 - val_loss: 0.2258 - val_accuracy: 0.9848\n",
            "Epoch 628/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0052 - accuracy: 0.9991 - val_loss: 0.3201 - val_accuracy: 0.9818\n",
            "Epoch 629/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 4.8785e-04 - accuracy: 1.0000 - val_loss: 0.3988 - val_accuracy: 0.9806\n",
            "Epoch 630/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0025 - accuracy: 0.9995 - val_loss: 0.3041 - val_accuracy: 0.9824\n",
            "Epoch 631/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0146 - accuracy: 0.9985 - val_loss: 0.6476 - val_accuracy: 0.9691\n",
            "Epoch 632/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0056 - accuracy: 0.9988 - val_loss: 0.1813 - val_accuracy: 0.9830\n",
            "Epoch 633/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.1519 - val_accuracy: 0.9860\n",
            "Epoch 634/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0096 - accuracy: 0.9982 - val_loss: 0.1519 - val_accuracy: 0.9848\n",
            "Epoch 635/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0018 - accuracy: 0.9997 - val_loss: 0.2699 - val_accuracy: 0.9830\n",
            "Epoch 636/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0042 - accuracy: 0.9991 - val_loss: 0.2421 - val_accuracy: 0.9848\n",
            "Epoch 637/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0036 - accuracy: 0.9994 - val_loss: 0.4023 - val_accuracy: 0.9854\n",
            "Epoch 638/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0295 - accuracy: 0.9980 - val_loss: 0.2099 - val_accuracy: 0.9854\n",
            "Epoch 639/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0081 - accuracy: 0.9988 - val_loss: 0.4691 - val_accuracy: 0.9757\n",
            "Epoch 640/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0076 - accuracy: 0.9983 - val_loss: 0.1620 - val_accuracy: 0.9860\n",
            "Epoch 641/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0039 - accuracy: 0.9992 - val_loss: 0.2052 - val_accuracy: 0.9830\n",
            "Epoch 642/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.1774 - val_accuracy: 0.9824\n",
            "Epoch 643/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0050 - accuracy: 0.9994 - val_loss: 0.1900 - val_accuracy: 0.9842\n",
            "Epoch 644/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0046 - accuracy: 0.9992 - val_loss: 0.1481 - val_accuracy: 0.9836\n",
            "Epoch 645/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0039 - accuracy: 0.9991 - val_loss: 0.1964 - val_accuracy: 0.9842\n",
            "Epoch 646/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0032 - accuracy: 0.9995 - val_loss: 0.1870 - val_accuracy: 0.9867\n",
            "Epoch 647/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0041 - accuracy: 0.9991 - val_loss: 0.6176 - val_accuracy: 0.9782\n",
            "Epoch 648/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0246 - accuracy: 0.9986 - val_loss: 0.2666 - val_accuracy: 0.9854\n",
            "Epoch 649/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0054 - accuracy: 0.9991 - val_loss: 0.3058 - val_accuracy: 0.9818\n",
            "Epoch 650/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0067 - accuracy: 0.9991 - val_loss: 0.6370 - val_accuracy: 0.9788\n",
            "Epoch 651/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0040 - accuracy: 0.9994 - val_loss: 0.3378 - val_accuracy: 0.9848\n",
            "Epoch 652/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0287 - accuracy: 0.9988 - val_loss: 0.1292 - val_accuracy: 0.9879\n",
            "Epoch 653/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0036 - accuracy: 0.9992 - val_loss: 0.2691 - val_accuracy: 0.9818\n",
            "Epoch 654/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.3377 - val_accuracy: 0.9800\n",
            "Epoch 655/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0046 - accuracy: 0.9992 - val_loss: 1.6914 - val_accuracy: 0.9624\n",
            "Epoch 656/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0035 - accuracy: 0.9992 - val_loss: 0.2789 - val_accuracy: 0.9842\n",
            "Epoch 657/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0035 - accuracy: 0.9994 - val_loss: 0.5401 - val_accuracy: 0.9794\n",
            "Epoch 658/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0122 - accuracy: 0.9985 - val_loss: 0.1199 - val_accuracy: 0.9854\n",
            "Epoch 659/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0035 - accuracy: 0.9991 - val_loss: 0.1656 - val_accuracy: 0.9842\n",
            "Epoch 660/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0041 - accuracy: 0.9992 - val_loss: 0.3021 - val_accuracy: 0.9842\n",
            "Epoch 661/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.2560 - val_accuracy: 0.9824\n",
            "Epoch 662/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0029 - accuracy: 0.9995 - val_loss: 0.2274 - val_accuracy: 0.9842\n",
            "Epoch 663/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0046 - accuracy: 0.9992 - val_loss: 0.2297 - val_accuracy: 0.9842\n",
            "Epoch 664/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0051 - accuracy: 0.9992 - val_loss: 0.1662 - val_accuracy: 0.9873\n",
            "Epoch 665/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0056 - accuracy: 0.9989 - val_loss: 0.1633 - val_accuracy: 0.9873\n",
            "Epoch 666/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0059 - accuracy: 0.9991 - val_loss: 0.4107 - val_accuracy: 0.9806\n",
            "Epoch 667/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0043 - accuracy: 0.9991 - val_loss: 1.0297 - val_accuracy: 0.9630\n",
            "Epoch 668/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0022 - accuracy: 0.9997 - val_loss: 0.2650 - val_accuracy: 0.9854\n",
            "Epoch 669/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0038 - accuracy: 0.9994 - val_loss: 0.2684 - val_accuracy: 0.9854\n",
            "Epoch 670/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0072 - accuracy: 0.9988 - val_loss: 0.1130 - val_accuracy: 0.9867\n",
            "Epoch 671/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0077 - accuracy: 0.9988 - val_loss: 0.1259 - val_accuracy: 0.9885\n",
            "Epoch 672/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0068 - accuracy: 0.9989 - val_loss: 0.0886 - val_accuracy: 0.9842\n",
            "Epoch 673/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0067 - accuracy: 0.9985 - val_loss: 0.2772 - val_accuracy: 0.9842\n",
            "Epoch 674/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0046 - accuracy: 0.9991 - val_loss: 1.4929 - val_accuracy: 0.9515\n",
            "Epoch 675/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 0.2041 - val_accuracy: 0.9842\n",
            "Epoch 676/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0055 - accuracy: 0.9992 - val_loss: 0.1163 - val_accuracy: 0.9879\n",
            "Epoch 677/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 0.1746 - val_accuracy: 0.9867\n",
            "Epoch 678/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0119 - accuracy: 0.9986 - val_loss: 0.3056 - val_accuracy: 0.9836\n",
            "Epoch 679/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0074 - accuracy: 0.9989 - val_loss: 0.5200 - val_accuracy: 0.9830\n",
            "Epoch 680/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0166 - accuracy: 0.9988 - val_loss: 0.1248 - val_accuracy: 0.9873\n",
            "Epoch 681/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.1572 - val_accuracy: 0.9867\n",
            "Epoch 682/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0037 - accuracy: 0.9997 - val_loss: 0.9352 - val_accuracy: 0.9788\n",
            "Epoch 683/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0094 - accuracy: 0.9986 - val_loss: 0.3351 - val_accuracy: 0.9842\n",
            "Epoch 684/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0097 - accuracy: 0.9992 - val_loss: 0.1390 - val_accuracy: 0.9842\n",
            "Epoch 685/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0071 - accuracy: 0.9988 - val_loss: 0.1715 - val_accuracy: 0.9842\n",
            "Epoch 686/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0025 - accuracy: 0.9995 - val_loss: 0.1344 - val_accuracy: 0.9842\n",
            "Epoch 687/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0048 - accuracy: 0.9989 - val_loss: 0.4515 - val_accuracy: 0.9806\n",
            "Epoch 688/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0041 - accuracy: 0.9992 - val_loss: 0.2125 - val_accuracy: 0.9873\n",
            "Epoch 689/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0059 - accuracy: 0.9995 - val_loss: 0.2612 - val_accuracy: 0.9860\n",
            "Epoch 690/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0046 - accuracy: 0.9992 - val_loss: 0.4641 - val_accuracy: 0.9836\n",
            "Epoch 691/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0073 - accuracy: 0.9988 - val_loss: 0.2111 - val_accuracy: 0.9854\n",
            "Epoch 692/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0039 - accuracy: 0.9994 - val_loss: 0.1801 - val_accuracy: 0.9842\n",
            "Epoch 693/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0087 - accuracy: 0.9989 - val_loss: 0.4496 - val_accuracy: 0.9854\n",
            "Epoch 694/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0056 - accuracy: 0.9989 - val_loss: 0.3343 - val_accuracy: 0.9885\n",
            "Epoch 695/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0033 - accuracy: 0.9995 - val_loss: 0.1779 - val_accuracy: 0.9879\n",
            "Epoch 696/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0029 - accuracy: 0.9995 - val_loss: 0.2176 - val_accuracy: 0.9879\n",
            "Epoch 697/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0314 - accuracy: 0.9971 - val_loss: 0.2805 - val_accuracy: 0.9769\n",
            "Epoch 698/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0127 - accuracy: 0.9982 - val_loss: 0.2258 - val_accuracy: 0.9836\n",
            "Epoch 699/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0056 - accuracy: 0.9992 - val_loss: 0.2338 - val_accuracy: 0.9836\n",
            "Epoch 700/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0052 - accuracy: 0.9992 - val_loss: 0.2957 - val_accuracy: 0.9842\n",
            "Epoch 701/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0082 - accuracy: 0.9986 - val_loss: 0.2234 - val_accuracy: 0.9854\n",
            "Epoch 702/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0045 - accuracy: 0.9991 - val_loss: 0.2883 - val_accuracy: 0.9854\n",
            "Epoch 703/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.2707 - val_accuracy: 0.9867\n",
            "Epoch 704/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.2302 - val_accuracy: 0.9885\n",
            "Epoch 705/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0042 - accuracy: 0.9995 - val_loss: 2.2924 - val_accuracy: 0.9521\n",
            "Epoch 706/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0181 - accuracy: 0.9980 - val_loss: 0.2245 - val_accuracy: 0.9860\n",
            "Epoch 707/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0041 - accuracy: 0.9992 - val_loss: 0.3030 - val_accuracy: 0.9867\n",
            "Epoch 708/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 0.2958 - val_accuracy: 0.9867\n",
            "Epoch 709/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 0.2931 - val_accuracy: 0.9867\n",
            "Epoch 710/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.2953 - val_accuracy: 0.9873\n",
            "Epoch 711/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.2441 - val_accuracy: 0.9873\n",
            "Epoch 712/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0022 - accuracy: 0.9997 - val_loss: 0.1957 - val_accuracy: 0.9867\n",
            "Epoch 713/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0073 - accuracy: 0.9988 - val_loss: 0.2349 - val_accuracy: 0.9891\n",
            "Epoch 714/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0033 - accuracy: 0.9995 - val_loss: 1.7533 - val_accuracy: 0.9727\n",
            "Epoch 715/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0282 - accuracy: 0.9974 - val_loss: 2.7026 - val_accuracy: 0.9363\n",
            "Epoch 716/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0241 - accuracy: 0.9983 - val_loss: 0.1494 - val_accuracy: 0.9860\n",
            "Epoch 717/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0058 - accuracy: 0.9992 - val_loss: 0.2289 - val_accuracy: 0.9842\n",
            "Epoch 718/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0042 - accuracy: 0.9995 - val_loss: 0.1891 - val_accuracy: 0.9842\n",
            "Epoch 719/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.1905 - val_accuracy: 0.9842\n",
            "Epoch 720/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 0.2431 - val_accuracy: 0.9842\n",
            "Epoch 721/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0051 - accuracy: 0.9994 - val_loss: 0.2243 - val_accuracy: 0.9842\n",
            "Epoch 722/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0059 - accuracy: 0.9989 - val_loss: 0.2785 - val_accuracy: 0.9848\n",
            "Epoch 723/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0057 - accuracy: 0.9992 - val_loss: 0.2836 - val_accuracy: 0.9842\n",
            "Epoch 724/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0037 - accuracy: 0.9994 - val_loss: 0.4167 - val_accuracy: 0.9830\n",
            "Epoch 725/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.4047 - val_accuracy: 0.9842\n",
            "Epoch 726/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0027 - accuracy: 0.9995 - val_loss: 0.5250 - val_accuracy: 0.9824\n",
            "Epoch 727/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0025 - accuracy: 0.9995 - val_loss: 0.2911 - val_accuracy: 0.9836\n",
            "Epoch 728/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0037 - accuracy: 0.9994 - val_loss: 0.3258 - val_accuracy: 0.9848\n",
            "Epoch 729/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0064 - accuracy: 0.9994 - val_loss: 0.2440 - val_accuracy: 0.9818\n",
            "Epoch 730/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0035 - accuracy: 0.9994 - val_loss: 0.2900 - val_accuracy: 0.9818\n",
            "Epoch 731/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.9219 - val_accuracy: 0.9782\n",
            "Epoch 732/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0044 - accuracy: 0.9991 - val_loss: 0.3578 - val_accuracy: 0.9794\n",
            "Epoch 733/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0310 - accuracy: 0.9962 - val_loss: 0.1299 - val_accuracy: 0.9836\n",
            "Epoch 734/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0037 - accuracy: 0.9992 - val_loss: 0.2022 - val_accuracy: 0.9873\n",
            "Epoch 735/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0050 - accuracy: 0.9991 - val_loss: 0.5762 - val_accuracy: 0.9836\n",
            "Epoch 736/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0043 - accuracy: 0.9992 - val_loss: 0.3081 - val_accuracy: 0.9854\n",
            "Epoch 737/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.2927 - val_accuracy: 0.9867\n",
            "Epoch 738/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.2870 - val_accuracy: 0.9867\n",
            "Epoch 739/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0055 - accuracy: 0.9991 - val_loss: 0.5210 - val_accuracy: 0.9812\n",
            "Epoch 740/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0070 - accuracy: 0.9988 - val_loss: 0.4509 - val_accuracy: 0.9842\n",
            "Epoch 741/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0039 - accuracy: 0.9992 - val_loss: 0.5112 - val_accuracy: 0.9848\n",
            "Epoch 742/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0042 - accuracy: 0.9994 - val_loss: 0.2485 - val_accuracy: 0.9854\n",
            "Epoch 743/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 0.2818 - val_accuracy: 0.9867\n",
            "Epoch 744/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 0.2577 - val_accuracy: 0.9854\n",
            "Epoch 745/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0063 - accuracy: 0.9989 - val_loss: 0.8079 - val_accuracy: 0.9806\n",
            "Epoch 746/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0113 - accuracy: 0.9982 - val_loss: 0.2478 - val_accuracy: 0.9867\n",
            "Epoch 747/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0043 - accuracy: 0.9992 - val_loss: 0.4314 - val_accuracy: 0.9830\n",
            "Epoch 748/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0046 - accuracy: 0.9992 - val_loss: 0.4236 - val_accuracy: 0.9830\n",
            "Epoch 749/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0051 - accuracy: 0.9994 - val_loss: 0.2546 - val_accuracy: 0.9860\n",
            "Epoch 750/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0101 - accuracy: 0.9991 - val_loss: 0.1562 - val_accuracy: 0.9842\n",
            "Epoch 751/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0034 - accuracy: 0.9995 - val_loss: 0.2650 - val_accuracy: 0.9818\n",
            "Epoch 752/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0056 - accuracy: 0.9995 - val_loss: 0.5811 - val_accuracy: 0.9775\n",
            "Epoch 753/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0070 - accuracy: 0.9988 - val_loss: 0.3654 - val_accuracy: 0.9867\n",
            "Epoch 754/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0140 - accuracy: 0.9985 - val_loss: 0.1257 - val_accuracy: 0.9867\n",
            "Epoch 755/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0042 - accuracy: 0.9991 - val_loss: 0.5772 - val_accuracy: 0.9824\n",
            "Epoch 756/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0120 - accuracy: 0.9980 - val_loss: 0.3037 - val_accuracy: 0.9824\n",
            "Epoch 757/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 0.2064 - val_accuracy: 0.9842\n",
            "Epoch 758/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0076 - accuracy: 0.9985 - val_loss: 0.1959 - val_accuracy: 0.9854\n",
            "Epoch 759/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0043 - accuracy: 0.9992 - val_loss: 0.1011 - val_accuracy: 0.9873\n",
            "Epoch 760/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0081 - accuracy: 0.9989 - val_loss: 0.3234 - val_accuracy: 0.9818\n",
            "Epoch 761/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0036 - accuracy: 0.9995 - val_loss: 0.2477 - val_accuracy: 0.9842\n",
            "Epoch 762/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.1206 - val_accuracy: 0.9873\n",
            "Epoch 763/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0078 - accuracy: 0.9995 - val_loss: 0.1572 - val_accuracy: 0.9873\n",
            "Epoch 764/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0070 - accuracy: 0.9991 - val_loss: 0.2270 - val_accuracy: 0.9860\n",
            "Epoch 765/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0020 - accuracy: 0.9998 - val_loss: 0.1693 - val_accuracy: 0.9879\n",
            "Epoch 766/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 4.2531e-04 - accuracy: 1.0000 - val_loss: 0.1775 - val_accuracy: 0.9873\n",
            "Epoch 767/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.2333 - val_accuracy: 0.9891\n",
            "Epoch 768/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0020 - accuracy: 0.9997 - val_loss: 0.2436 - val_accuracy: 0.9891\n",
            "Epoch 769/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.2459 - val_accuracy: 0.9891\n",
            "Epoch 770/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.2497 - val_accuracy: 0.9891\n",
            "Epoch 771/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0040 - accuracy: 0.9994 - val_loss: 0.2356 - val_accuracy: 0.9903\n",
            "Epoch 772/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.2363 - val_accuracy: 0.9891\n",
            "Epoch 773/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0086 - accuracy: 0.9991 - val_loss: 0.5939 - val_accuracy: 0.9830\n",
            "Epoch 774/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0042 - accuracy: 0.9995 - val_loss: 0.3649 - val_accuracy: 0.9860\n",
            "Epoch 775/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0038 - accuracy: 0.9994 - val_loss: 0.3710 - val_accuracy: 0.9860\n",
            "Epoch 776/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0077 - accuracy: 0.9986 - val_loss: 1.3922 - val_accuracy: 0.9654\n",
            "Epoch 777/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0037 - accuracy: 0.9994 - val_loss: 0.2721 - val_accuracy: 0.9830\n",
            "Epoch 778/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0077 - accuracy: 0.9988 - val_loss: 0.2875 - val_accuracy: 0.9854\n",
            "Epoch 779/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0050 - accuracy: 0.9991 - val_loss: 0.3372 - val_accuracy: 0.9860\n",
            "Epoch 780/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0084 - accuracy: 0.9995 - val_loss: 0.2725 - val_accuracy: 0.9867\n",
            "Epoch 781/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0068 - accuracy: 0.9992 - val_loss: 0.2813 - val_accuracy: 0.9848\n",
            "Epoch 782/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0085 - accuracy: 0.9988 - val_loss: 0.2203 - val_accuracy: 0.9867\n",
            "Epoch 783/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0034 - accuracy: 0.9992 - val_loss: 0.2493 - val_accuracy: 0.9867\n",
            "Epoch 784/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.2544 - val_accuracy: 0.9873\n",
            "Epoch 785/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 4.6300e-04 - accuracy: 1.0000 - val_loss: 0.3261 - val_accuracy: 0.9891\n",
            "Epoch 786/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0022 - accuracy: 0.9997 - val_loss: 0.3487 - val_accuracy: 0.9891\n",
            "Epoch 787/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0035 - accuracy: 0.9994 - val_loss: 0.5168 - val_accuracy: 0.9848\n",
            "Epoch 788/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0062 - accuracy: 0.9992 - val_loss: 0.2495 - val_accuracy: 0.9879\n",
            "Epoch 789/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0064 - accuracy: 0.9992 - val_loss: 0.2969 - val_accuracy: 0.9879\n",
            "Epoch 790/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0040 - accuracy: 0.9992 - val_loss: 0.2500 - val_accuracy: 0.9879\n",
            "Epoch 791/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.2620 - val_accuracy: 0.9879\n",
            "Epoch 792/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0034 - accuracy: 0.9994 - val_loss: 0.4115 - val_accuracy: 0.9867\n",
            "Epoch 793/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0025 - accuracy: 0.9995 - val_loss: 0.4524 - val_accuracy: 0.9848\n",
            "Epoch 794/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0173 - accuracy: 0.9991 - val_loss: 0.6586 - val_accuracy: 0.9800\n",
            "Epoch 795/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0132 - accuracy: 0.9979 - val_loss: 0.1383 - val_accuracy: 0.9879\n",
            "Epoch 796/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0030 - accuracy: 0.9992 - val_loss: 0.2142 - val_accuracy: 0.9860\n",
            "Epoch 797/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 0.2132 - val_accuracy: 0.9879\n",
            "Epoch 798/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.2943 - val_accuracy: 0.9860\n",
            "Epoch 799/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0038 - accuracy: 0.9994 - val_loss: 0.3639 - val_accuracy: 0.9836\n",
            "Epoch 800/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0191 - accuracy: 0.9976 - val_loss: 0.2818 - val_accuracy: 0.9806\n",
            "Epoch 801/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0025 - accuracy: 0.9995 - val_loss: 0.3933 - val_accuracy: 0.9848\n",
            "Epoch 802/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0092 - accuracy: 0.9983 - val_loss: 0.2055 - val_accuracy: 0.9885\n",
            "Epoch 803/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0045 - accuracy: 0.9991 - val_loss: 0.2208 - val_accuracy: 0.9879\n",
            "Epoch 804/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0089 - accuracy: 0.9988 - val_loss: 0.3293 - val_accuracy: 0.9836\n",
            "Epoch 805/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 7.9404e-04 - accuracy: 0.9998 - val_loss: 0.2733 - val_accuracy: 0.9873\n",
            "Epoch 806/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0038 - accuracy: 0.9994 - val_loss: 0.2882 - val_accuracy: 0.9867\n",
            "Epoch 807/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.2981 - val_accuracy: 0.9867\n",
            "Epoch 808/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0021 - accuracy: 0.9997 - val_loss: 0.2991 - val_accuracy: 0.9873\n",
            "Epoch 809/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0045 - accuracy: 0.9995 - val_loss: 0.1904 - val_accuracy: 0.9836\n",
            "Epoch 810/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 0.1896 - val_accuracy: 0.9860\n",
            "Epoch 811/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0097 - accuracy: 0.9988 - val_loss: 0.1948 - val_accuracy: 0.9860\n",
            "Epoch 812/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 0.3194 - val_accuracy: 0.9824\n",
            "Epoch 813/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0107 - accuracy: 0.9992 - val_loss: 0.2936 - val_accuracy: 0.9879\n",
            "Epoch 814/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0041 - accuracy: 0.9992 - val_loss: 0.3153 - val_accuracy: 0.9836\n",
            "Epoch 815/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.3230 - val_accuracy: 0.9842\n",
            "Epoch 816/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0088 - accuracy: 0.9992 - val_loss: 0.4153 - val_accuracy: 0.9794\n",
            "Epoch 817/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0119 - accuracy: 0.9985 - val_loss: 0.2755 - val_accuracy: 0.9836\n",
            "Epoch 818/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0104 - accuracy: 0.9986 - val_loss: 0.3412 - val_accuracy: 0.9860\n",
            "Epoch 819/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 0.3238 - val_accuracy: 0.9860\n",
            "Epoch 820/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 0.3403 - val_accuracy: 0.9848\n",
            "Epoch 821/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 7.1808e-04 - accuracy: 0.9998 - val_loss: 0.3399 - val_accuracy: 0.9854\n",
            "Epoch 822/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0217 - accuracy: 0.9989 - val_loss: 0.3675 - val_accuracy: 0.9800\n",
            "Epoch 823/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0140 - accuracy: 0.9988 - val_loss: 0.6251 - val_accuracy: 0.9867\n",
            "Epoch 824/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0040 - accuracy: 0.9994 - val_loss: 0.2390 - val_accuracy: 0.9879\n",
            "Epoch 825/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0050 - accuracy: 0.9995 - val_loss: 0.2112 - val_accuracy: 0.9885\n",
            "Epoch 826/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 0.2143 - val_accuracy: 0.9885\n",
            "Epoch 827/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0399 - accuracy: 0.9991 - val_loss: 0.3010 - val_accuracy: 0.9836\n",
            "Epoch 828/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0028 - accuracy: 0.9995 - val_loss: 0.3335 - val_accuracy: 0.9891\n",
            "Epoch 829/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0458 - accuracy: 0.9982 - val_loss: 2.2138 - val_accuracy: 0.9648\n",
            "Epoch 830/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0105 - accuracy: 0.9983 - val_loss: 0.3217 - val_accuracy: 0.9854\n",
            "Epoch 831/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0070 - accuracy: 0.9986 - val_loss: 0.4309 - val_accuracy: 0.9848\n",
            "Epoch 832/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 0.3216 - val_accuracy: 0.9842\n",
            "Epoch 833/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0020 - accuracy: 0.9997 - val_loss: 0.3215 - val_accuracy: 0.9848\n",
            "Epoch 834/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0097 - accuracy: 0.9988 - val_loss: 0.3775 - val_accuracy: 0.9860\n",
            "Epoch 835/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.2554 - val_accuracy: 0.9867\n",
            "Epoch 836/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0057 - accuracy: 0.9992 - val_loss: 0.4990 - val_accuracy: 0.9854\n",
            "Epoch 837/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0039 - accuracy: 0.9994 - val_loss: 0.4789 - val_accuracy: 0.9848\n",
            "Epoch 838/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.4272 - val_accuracy: 0.9860\n",
            "Epoch 839/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0084 - accuracy: 0.9991 - val_loss: 0.4665 - val_accuracy: 0.9842\n",
            "Epoch 840/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0374 - accuracy: 0.9971 - val_loss: 4.3458 - val_accuracy: 0.9339\n",
            "Epoch 841/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0062 - accuracy: 0.9989 - val_loss: 0.1995 - val_accuracy: 0.9867\n",
            "Epoch 842/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0188 - accuracy: 0.9989 - val_loss: 0.4615 - val_accuracy: 0.9842\n",
            "Epoch 843/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.4585 - val_accuracy: 0.9860\n",
            "Epoch 844/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.5023 - val_accuracy: 0.9830\n",
            "Epoch 845/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0070 - accuracy: 0.9989 - val_loss: 0.4825 - val_accuracy: 0.9836\n",
            "Epoch 846/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0033 - accuracy: 0.9995 - val_loss: 0.3716 - val_accuracy: 0.9867\n",
            "Epoch 847/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0049 - accuracy: 0.9989 - val_loss: 0.1510 - val_accuracy: 0.9873\n",
            "Epoch 848/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0059 - accuracy: 0.9989 - val_loss: 0.4364 - val_accuracy: 0.9848\n",
            "Epoch 849/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0218 - accuracy: 0.9983 - val_loss: 0.4585 - val_accuracy: 0.9848\n",
            "Epoch 850/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0055 - accuracy: 0.9989 - val_loss: 0.4548 - val_accuracy: 0.9848\n",
            "Epoch 851/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 0.4490 - val_accuracy: 0.9854\n",
            "Epoch 852/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0061 - accuracy: 0.9995 - val_loss: 0.7493 - val_accuracy: 0.9830\n",
            "Epoch 853/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0032 - accuracy: 0.9997 - val_loss: 0.3527 - val_accuracy: 0.9854\n",
            "Epoch 854/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0197 - accuracy: 0.9982 - val_loss: 0.3018 - val_accuracy: 0.9842\n",
            "Epoch 855/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0041 - accuracy: 0.9991 - val_loss: 0.2833 - val_accuracy: 0.9867\n",
            "Epoch 856/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0154 - accuracy: 0.9997 - val_loss: 0.4070 - val_accuracy: 0.9860\n",
            "Epoch 857/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0049 - accuracy: 0.9992 - val_loss: 0.5704 - val_accuracy: 0.9824\n",
            "Epoch 858/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0037 - accuracy: 0.9994 - val_loss: 0.3872 - val_accuracy: 0.9854\n",
            "Epoch 859/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0035 - accuracy: 0.9992 - val_loss: 0.1731 - val_accuracy: 0.9873\n",
            "Epoch 860/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0109 - accuracy: 0.9988 - val_loss: 0.3444 - val_accuracy: 0.9836\n",
            "Epoch 861/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0065 - accuracy: 0.9988 - val_loss: 0.6713 - val_accuracy: 0.9848\n",
            "Epoch 862/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.4128 - val_accuracy: 0.9860\n",
            "Epoch 863/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0039 - accuracy: 0.9992 - val_loss: 0.3064 - val_accuracy: 0.9873\n",
            "Epoch 864/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0370 - accuracy: 0.9980 - val_loss: 0.1648 - val_accuracy: 0.9848\n",
            "Epoch 865/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0057 - accuracy: 0.9989 - val_loss: 0.1278 - val_accuracy: 0.9873\n",
            "Epoch 866/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.3222 - val_accuracy: 0.9854\n",
            "Epoch 867/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 0.2770 - val_accuracy: 0.9860\n",
            "Epoch 868/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0021 - accuracy: 0.9997 - val_loss: 0.2621 - val_accuracy: 0.9867\n",
            "Epoch 869/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0090 - accuracy: 0.9986 - val_loss: 0.2924 - val_accuracy: 0.9836\n",
            "Epoch 870/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0120 - accuracy: 0.9985 - val_loss: 0.3095 - val_accuracy: 0.9867\n",
            "Epoch 871/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0056 - accuracy: 0.9991 - val_loss: 0.3212 - val_accuracy: 0.9860\n",
            "Epoch 872/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0019 - accuracy: 0.9997 - val_loss: 0.4246 - val_accuracy: 0.9854\n",
            "Epoch 873/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0026 - accuracy: 0.9995 - val_loss: 0.2463 - val_accuracy: 0.9891\n",
            "Epoch 874/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0316 - accuracy: 0.9977 - val_loss: 0.4104 - val_accuracy: 0.9842\n",
            "Epoch 875/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0062 - accuracy: 0.9986 - val_loss: 0.2779 - val_accuracy: 0.9836\n",
            "Epoch 876/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0042 - accuracy: 0.9992 - val_loss: 0.1831 - val_accuracy: 0.9842\n",
            "Epoch 877/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0016 - accuracy: 0.9997 - val_loss: 0.3113 - val_accuracy: 0.9854\n",
            "Epoch 878/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.2323 - val_accuracy: 0.9860\n",
            "Epoch 879/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0065 - accuracy: 0.9992 - val_loss: 0.2181 - val_accuracy: 0.9873\n",
            "Epoch 880/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0062 - accuracy: 0.9995 - val_loss: 0.1402 - val_accuracy: 0.9885\n",
            "Epoch 881/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0016 - accuracy: 0.9997 - val_loss: 0.1605 - val_accuracy: 0.9873\n",
            "Epoch 882/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0023 - accuracy: 0.9995 - val_loss: 0.1157 - val_accuracy: 0.9885\n",
            "Epoch 883/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0039 - accuracy: 0.9995 - val_loss: 0.1836 - val_accuracy: 0.9903\n",
            "Epoch 884/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0036 - accuracy: 0.9994 - val_loss: 0.1999 - val_accuracy: 0.9867\n",
            "Epoch 885/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 8.6197e-04 - accuracy: 0.9997 - val_loss: 0.2300 - val_accuracy: 0.9860\n",
            "Epoch 886/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0028 - accuracy: 0.9997 - val_loss: 0.1958 - val_accuracy: 0.9891\n",
            "Epoch 887/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0331 - accuracy: 0.9982 - val_loss: 0.2456 - val_accuracy: 0.9860\n",
            "Epoch 888/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.4021 - val_accuracy: 0.9818\n",
            "Epoch 889/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0114 - accuracy: 0.9986 - val_loss: 0.2665 - val_accuracy: 0.9854\n",
            "Epoch 890/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0056 - accuracy: 0.9989 - val_loss: 0.5471 - val_accuracy: 0.9854\n",
            "Epoch 891/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0113 - accuracy: 0.9988 - val_loss: 0.4983 - val_accuracy: 0.9860\n",
            "Epoch 892/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0165 - accuracy: 0.9988 - val_loss: 0.2549 - val_accuracy: 0.9830\n",
            "Epoch 893/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0031 - accuracy: 0.9995 - val_loss: 0.3165 - val_accuracy: 0.9854\n",
            "Epoch 894/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0048 - accuracy: 0.9992 - val_loss: 0.3233 - val_accuracy: 0.9854\n",
            "Epoch 895/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.3292 - val_accuracy: 0.9854\n",
            "Epoch 896/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0031 - accuracy: 0.9995 - val_loss: 0.3443 - val_accuracy: 0.9848\n",
            "Epoch 897/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0048 - accuracy: 0.9992 - val_loss: 0.2595 - val_accuracy: 0.9873\n",
            "Epoch 898/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0058 - accuracy: 0.9989 - val_loss: 0.5112 - val_accuracy: 0.9830\n",
            "Epoch 899/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0080 - accuracy: 0.9989 - val_loss: 0.3323 - val_accuracy: 0.9830\n",
            "Epoch 900/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0063 - accuracy: 0.9995 - val_loss: 1.0684 - val_accuracy: 0.9763\n",
            "Epoch 901/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0042 - accuracy: 0.9994 - val_loss: 0.3310 - val_accuracy: 0.9867\n",
            "Epoch 902/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0077 - accuracy: 0.9991 - val_loss: 0.2081 - val_accuracy: 0.9873\n",
            "Epoch 903/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0021 - accuracy: 0.9997 - val_loss: 0.2264 - val_accuracy: 0.9867\n",
            "Epoch 904/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0078 - accuracy: 0.9988 - val_loss: 0.2087 - val_accuracy: 0.9854\n",
            "Epoch 905/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.2283 - val_accuracy: 0.9873\n",
            "Epoch 906/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0072 - accuracy: 0.9992 - val_loss: 0.3419 - val_accuracy: 0.9885\n",
            "Epoch 907/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0052 - accuracy: 0.9989 - val_loss: 0.4718 - val_accuracy: 0.9848\n",
            "Epoch 908/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0046 - accuracy: 0.9994 - val_loss: 0.3598 - val_accuracy: 0.9891\n",
            "Epoch 909/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.3796 - val_accuracy: 0.9891\n",
            "Epoch 910/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0037 - accuracy: 0.9995 - val_loss: 0.3741 - val_accuracy: 0.9885\n",
            "Epoch 911/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0203 - accuracy: 0.9983 - val_loss: 0.3749 - val_accuracy: 0.9848\n",
            "Epoch 912/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.4718 - val_accuracy: 0.9873\n",
            "Epoch 913/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 3.7839e-04 - accuracy: 1.0000 - val_loss: 0.5244 - val_accuracy: 0.9860\n",
            "Epoch 914/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0018 - accuracy: 0.9997 - val_loss: 0.5866 - val_accuracy: 0.9860\n",
            "Epoch 915/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0046 - accuracy: 0.9994 - val_loss: 0.4021 - val_accuracy: 0.9879\n",
            "Epoch 916/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 3.5145e-04 - accuracy: 1.0000 - val_loss: 0.4184 - val_accuracy: 0.9885\n",
            "Epoch 917/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0039 - accuracy: 0.9994 - val_loss: 0.4397 - val_accuracy: 0.9879\n",
            "Epoch 918/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0144 - accuracy: 0.9991 - val_loss: 0.2619 - val_accuracy: 0.9842\n",
            "Epoch 919/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0127 - accuracy: 0.9982 - val_loss: 0.3772 - val_accuracy: 0.9824\n",
            "Epoch 920/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0044 - accuracy: 0.9991 - val_loss: 0.3418 - val_accuracy: 0.9860\n",
            "Epoch 921/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0036 - accuracy: 0.9994 - val_loss: 0.3244 - val_accuracy: 0.9860\n",
            "Epoch 922/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0060 - accuracy: 0.9989 - val_loss: 0.2819 - val_accuracy: 0.9873\n",
            "Epoch 923/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 0.4255 - val_accuracy: 0.9848\n",
            "Epoch 924/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0021 - accuracy: 0.9997 - val_loss: 0.3901 - val_accuracy: 0.9836\n",
            "Epoch 925/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0111 - accuracy: 0.9985 - val_loss: 0.2381 - val_accuracy: 0.9873\n",
            "Epoch 926/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0163 - accuracy: 0.9986 - val_loss: 0.2789 - val_accuracy: 0.9879\n",
            "Epoch 927/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0027 - accuracy: 0.9995 - val_loss: 0.3286 - val_accuracy: 0.9854\n",
            "Epoch 928/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.3780 - val_accuracy: 0.9867\n",
            "Epoch 929/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.4248 - val_accuracy: 0.9867\n",
            "Epoch 930/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 3.2824e-04 - accuracy: 0.9998 - val_loss: 0.3208 - val_accuracy: 0.9885\n",
            "Epoch 931/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0031 - accuracy: 0.9995 - val_loss: 0.4215 - val_accuracy: 0.9879\n",
            "Epoch 932/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.2212 - val_accuracy: 0.9885\n",
            "Epoch 933/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.2173 - val_accuracy: 0.9867\n",
            "Epoch 934/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0223 - accuracy: 0.9980 - val_loss: 0.2989 - val_accuracy: 0.9824\n",
            "Epoch 935/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.2058 - val_accuracy: 0.9873\n",
            "Epoch 936/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 3.3454e-04 - accuracy: 1.0000 - val_loss: 0.2505 - val_accuracy: 0.9854\n",
            "Epoch 937/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0086 - accuracy: 0.9986 - val_loss: 0.8203 - val_accuracy: 0.9733\n",
            "Epoch 938/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0075 - accuracy: 0.9986 - val_loss: 0.4039 - val_accuracy: 0.9824\n",
            "Epoch 939/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 3.4415e-04 - accuracy: 1.0000 - val_loss: 0.2797 - val_accuracy: 0.9842\n",
            "Epoch 940/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0039 - accuracy: 0.9992 - val_loss: 0.5078 - val_accuracy: 0.9830\n",
            "Epoch 941/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.4002 - val_accuracy: 0.9824\n",
            "Epoch 942/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0438 - accuracy: 0.9983 - val_loss: 0.2777 - val_accuracy: 0.9873\n",
            "Epoch 943/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0055 - accuracy: 0.9989 - val_loss: 0.5477 - val_accuracy: 0.9788\n",
            "Epoch 944/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0206 - accuracy: 0.9977 - val_loss: 0.3560 - val_accuracy: 0.9800\n",
            "Epoch 945/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0084 - accuracy: 0.9992 - val_loss: 0.1487 - val_accuracy: 0.9854\n",
            "Epoch 946/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0046 - accuracy: 0.9991 - val_loss: 0.2313 - val_accuracy: 0.9860\n",
            "Epoch 947/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0022 - accuracy: 0.9997 - val_loss: 0.2430 - val_accuracy: 0.9867\n",
            "Epoch 948/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0077 - accuracy: 0.9989 - val_loss: 0.2493 - val_accuracy: 0.9867\n",
            "Epoch 949/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0041 - accuracy: 0.9992 - val_loss: 0.7209 - val_accuracy: 0.9824\n",
            "Epoch 950/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0094 - accuracy: 0.9994 - val_loss: 0.2359 - val_accuracy: 0.9885\n",
            "Epoch 951/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0048 - accuracy: 0.9992 - val_loss: 0.2153 - val_accuracy: 0.9885\n",
            "Epoch 952/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0093 - accuracy: 0.9994 - val_loss: 0.3230 - val_accuracy: 0.9854\n",
            "Epoch 953/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.2936 - val_accuracy: 0.9854\n",
            "Epoch 954/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0021 - accuracy: 0.9997 - val_loss: 0.2905 - val_accuracy: 0.9854\n",
            "Epoch 955/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 3.4424e-04 - accuracy: 1.0000 - val_loss: 0.2935 - val_accuracy: 0.9854\n",
            "Epoch 956/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.2635 - val_accuracy: 0.9860\n",
            "Epoch 957/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.3363 - val_accuracy: 0.9830\n",
            "Epoch 958/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0031 - accuracy: 0.9995 - val_loss: 0.2557 - val_accuracy: 0.9854\n",
            "Epoch 959/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.2447 - val_accuracy: 0.9860\n",
            "Epoch 960/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 7.8440e-04 - accuracy: 0.9998 - val_loss: 0.2892 - val_accuracy: 0.9842\n",
            "Epoch 961/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0044 - accuracy: 0.9992 - val_loss: 0.1576 - val_accuracy: 0.9897\n",
            "Epoch 962/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 3.1612e-04 - accuracy: 1.0000 - val_loss: 0.1676 - val_accuracy: 0.9897\n",
            "Epoch 963/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0106 - accuracy: 0.9994 - val_loss: 0.1319 - val_accuracy: 0.9867\n",
            "Epoch 964/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0141 - accuracy: 0.9985 - val_loss: 0.4073 - val_accuracy: 0.9860\n",
            "Epoch 965/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0074 - accuracy: 0.9989 - val_loss: 0.2582 - val_accuracy: 0.9867\n",
            "Epoch 966/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0134 - accuracy: 0.9988 - val_loss: 0.2948 - val_accuracy: 0.9854\n",
            "Epoch 967/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.3435 - val_accuracy: 0.9854\n",
            "Epoch 968/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0037 - accuracy: 0.9995 - val_loss: 0.2657 - val_accuracy: 0.9848\n",
            "Epoch 969/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0039 - accuracy: 0.9992 - val_loss: 0.2878 - val_accuracy: 0.9848\n",
            "Epoch 970/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0054 - accuracy: 0.9988 - val_loss: 6.4353 - val_accuracy: 0.9442\n",
            "Epoch 971/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0160 - accuracy: 0.9983 - val_loss: 0.4680 - val_accuracy: 0.9848\n",
            "Epoch 972/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0050 - accuracy: 0.9992 - val_loss: 0.5641 - val_accuracy: 0.9836\n",
            "Epoch 973/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0018 - accuracy: 0.9997 - val_loss: 0.3573 - val_accuracy: 0.9848\n",
            "Epoch 974/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.3673 - val_accuracy: 0.9842\n",
            "Epoch 975/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.3756 - val_accuracy: 0.9873\n",
            "Epoch 976/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0021 - accuracy: 0.9997 - val_loss: 0.3525 - val_accuracy: 0.9873\n",
            "Epoch 977/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0074 - accuracy: 0.9992 - val_loss: 0.7662 - val_accuracy: 0.9794\n",
            "Epoch 978/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0028 - accuracy: 0.9995 - val_loss: 0.3638 - val_accuracy: 0.9867\n",
            "Epoch 979/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0029 - accuracy: 0.9995 - val_loss: 0.3643 - val_accuracy: 0.9873\n",
            "Epoch 980/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.3655 - val_accuracy: 0.9867\n",
            "Epoch 981/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0035 - accuracy: 0.9997 - val_loss: 0.2982 - val_accuracy: 0.9873\n",
            "Epoch 982/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0068 - accuracy: 0.9989 - val_loss: 0.2316 - val_accuracy: 0.9848\n",
            "Epoch 983/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0131 - accuracy: 0.9979 - val_loss: 0.9715 - val_accuracy: 0.9745\n",
            "Epoch 984/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0133 - accuracy: 0.9983 - val_loss: 0.1379 - val_accuracy: 0.9836\n",
            "Epoch 985/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0059 - accuracy: 0.9988 - val_loss: 0.1849 - val_accuracy: 0.9842\n",
            "Epoch 986/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0088 - accuracy: 0.9991 - val_loss: 0.2379 - val_accuracy: 0.9836\n",
            "Epoch 987/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0029 - accuracy: 0.9995 - val_loss: 0.2300 - val_accuracy: 0.9848\n",
            "Epoch 988/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0018 - accuracy: 0.9997 - val_loss: 0.3653 - val_accuracy: 0.9824\n",
            "Epoch 989/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 2.6301e-04 - accuracy: 1.0000 - val_loss: 0.3601 - val_accuracy: 0.9836\n",
            "Epoch 990/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0092 - accuracy: 0.9989 - val_loss: 0.2250 - val_accuracy: 0.9830\n",
            "Epoch 991/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0034 - accuracy: 0.9991 - val_loss: 0.2538 - val_accuracy: 0.9873\n",
            "Epoch 992/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0073 - accuracy: 0.9989 - val_loss: 0.2832 - val_accuracy: 0.9873\n",
            "Epoch 993/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0068 - accuracy: 0.9992 - val_loss: 0.5990 - val_accuracy: 0.9794\n",
            "Epoch 994/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0074 - accuracy: 0.9992 - val_loss: 0.3971 - val_accuracy: 0.9842\n",
            "Epoch 995/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0046 - accuracy: 0.9995 - val_loss: 0.3864 - val_accuracy: 0.9848\n",
            "Epoch 996/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0129 - accuracy: 0.9992 - val_loss: 0.4451 - val_accuracy: 0.9806\n",
            "Epoch 997/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0137 - accuracy: 0.9992 - val_loss: 0.5739 - val_accuracy: 0.9830\n",
            "Epoch 998/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0120 - accuracy: 0.9992 - val_loss: 0.2483 - val_accuracy: 0.9879\n",
            "Epoch 999/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0028 - accuracy: 0.9995 - val_loss: 0.4540 - val_accuracy: 0.9854\n",
            "Epoch 1000/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 0.4229 - val_accuracy: 0.9848\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1200x400 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "206/206 [==============================] - 12s 46ms/step - loss: 1.9649 - accuracy: 0.8710 - val_loss: 0.2618 - val_accuracy: 0.8823\n",
            "Epoch 2/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.3287 - accuracy: 0.8819 - val_loss: 0.2056 - val_accuracy: 0.8908\n",
            "Epoch 3/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.2489 - accuracy: 0.8833 - val_loss: 0.4027 - val_accuracy: 0.8580\n",
            "Epoch 4/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.2389 - accuracy: 0.8810 - val_loss: 0.2240 - val_accuracy: 0.8738\n",
            "Epoch 5/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.2070 - accuracy: 0.8804 - val_loss: 0.1829 - val_accuracy: 0.8750\n",
            "Epoch 6/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.1845 - accuracy: 0.8869 - val_loss: 0.1505 - val_accuracy: 0.8871\n",
            "Epoch 7/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.1798 - accuracy: 0.8866 - val_loss: 0.1641 - val_accuracy: 0.8799\n",
            "Epoch 8/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.2016 - accuracy: 0.8836 - val_loss: 0.1430 - val_accuracy: 0.8835\n",
            "Epoch 9/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.1827 - accuracy: 0.8836 - val_loss: 0.1711 - val_accuracy: 0.8738\n",
            "Epoch 10/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.2406 - accuracy: 0.8815 - val_loss: 0.1695 - val_accuracy: 0.8871\n",
            "Epoch 11/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.1786 - accuracy: 0.8895 - val_loss: 0.1410 - val_accuracy: 0.8841\n",
            "Epoch 12/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.1552 - accuracy: 0.8897 - val_loss: 0.1648 - val_accuracy: 0.9193\n",
            "Epoch 13/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.1660 - accuracy: 0.9231 - val_loss: 0.2168 - val_accuracy: 0.9217\n",
            "Epoch 14/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.1547 - accuracy: 0.9263 - val_loss: 0.1237 - val_accuracy: 0.9581\n",
            "Epoch 15/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.1873 - accuracy: 0.9086 - val_loss: 2.2705 - val_accuracy: 0.8962\n",
            "Epoch 16/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.1629 - accuracy: 0.9215 - val_loss: 0.1237 - val_accuracy: 0.9672\n",
            "Epoch 17/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.4658 - accuracy: 0.8012 - val_loss: 8.4531 - val_accuracy: 0.8786\n",
            "Epoch 18/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 1.1054 - accuracy: 0.8786 - val_loss: 0.2468 - val_accuracy: 0.8683\n",
            "Epoch 19/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.2139 - accuracy: 0.8851 - val_loss: 0.1555 - val_accuracy: 0.9235\n",
            "Epoch 20/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.2103 - accuracy: 0.8903 - val_loss: 0.1568 - val_accuracy: 0.8865\n",
            "Epoch 21/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.1929 - accuracy: 0.8904 - val_loss: 0.1562 - val_accuracy: 0.9272\n",
            "Epoch 22/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1664 - accuracy: 0.8848 - val_loss: 0.1504 - val_accuracy: 0.9333\n",
            "Epoch 23/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1438 - accuracy: 0.9131 - val_loss: 0.1283 - val_accuracy: 0.9545\n",
            "Epoch 24/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1396 - accuracy: 0.9373 - val_loss: 0.1272 - val_accuracy: 0.9436\n",
            "Epoch 25/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.1233 - accuracy: 0.9373 - val_loss: 0.1545 - val_accuracy: 0.9612\n",
            "Epoch 26/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.1494 - accuracy: 0.9270 - val_loss: 0.1061 - val_accuracy: 0.9515\n",
            "Epoch 27/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1198 - accuracy: 0.9335 - val_loss: 0.1458 - val_accuracy: 0.9618\n",
            "Epoch 28/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1153 - accuracy: 0.9378 - val_loss: 0.1377 - val_accuracy: 0.9684\n",
            "Epoch 29/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.1748 - accuracy: 0.9313 - val_loss: 0.1506 - val_accuracy: 0.9472\n",
            "Epoch 30/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1420 - accuracy: 0.9253 - val_loss: 0.1006 - val_accuracy: 0.9612\n",
            "Epoch 31/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1184 - accuracy: 0.9351 - val_loss: 0.0730 - val_accuracy: 0.9775\n",
            "Epoch 32/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1336 - accuracy: 0.9363 - val_loss: 0.1278 - val_accuracy: 0.9569\n",
            "Epoch 33/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.1086 - accuracy: 0.9516 - val_loss: 0.0781 - val_accuracy: 0.9763\n",
            "Epoch 34/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1738 - accuracy: 0.9219 - val_loss: 0.1313 - val_accuracy: 0.9727\n",
            "Epoch 35/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.1586 - accuracy: 0.9023 - val_loss: 0.0796 - val_accuracy: 0.9763\n",
            "Epoch 36/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1251 - accuracy: 0.9231 - val_loss: 0.0898 - val_accuracy: 0.9715\n",
            "Epoch 37/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1346 - accuracy: 0.9223 - val_loss: 0.1092 - val_accuracy: 0.9672\n",
            "Epoch 38/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.1156 - accuracy: 0.9354 - val_loss: 0.0849 - val_accuracy: 0.9788\n",
            "Epoch 39/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1011 - accuracy: 0.9478 - val_loss: 0.1038 - val_accuracy: 0.9672\n",
            "Epoch 40/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.1234 - accuracy: 0.9387 - val_loss: 0.0760 - val_accuracy: 0.9721\n",
            "Epoch 41/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.1482 - accuracy: 0.9109 - val_loss: 0.1281 - val_accuracy: 0.9387\n",
            "Epoch 42/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.1171 - accuracy: 0.9294 - val_loss: 0.0762 - val_accuracy: 0.9812\n",
            "Epoch 43/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1104 - accuracy: 0.9408 - val_loss: 0.0794 - val_accuracy: 0.9642\n",
            "Epoch 44/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.2383 - accuracy: 0.9481 - val_loss: 0.4961 - val_accuracy: 0.9515\n",
            "Epoch 45/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.1197 - accuracy: 0.9252 - val_loss: 0.1915 - val_accuracy: 0.9666\n",
            "Epoch 46/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1152 - accuracy: 0.9354 - val_loss: 0.2197 - val_accuracy: 0.9466\n",
            "Epoch 47/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.1637 - accuracy: 0.9046 - val_loss: 0.1355 - val_accuracy: 0.9387\n",
            "Epoch 48/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1394 - accuracy: 0.9178 - val_loss: 0.0739 - val_accuracy: 0.9630\n",
            "Epoch 49/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1152 - accuracy: 0.9346 - val_loss: 0.1112 - val_accuracy: 0.9618\n",
            "Epoch 50/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1203 - accuracy: 0.9404 - val_loss: 0.0706 - val_accuracy: 0.9812\n",
            "Epoch 51/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1317 - accuracy: 0.9294 - val_loss: 0.0560 - val_accuracy: 0.9769\n",
            "Epoch 52/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.1241 - accuracy: 0.9188 - val_loss: 0.0602 - val_accuracy: 0.9812\n",
            "Epoch 53/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1117 - accuracy: 0.9293 - val_loss: 0.0528 - val_accuracy: 0.9782\n",
            "Epoch 54/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0951 - accuracy: 0.9558 - val_loss: 0.0571 - val_accuracy: 0.9824\n",
            "Epoch 55/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0927 - accuracy: 0.9520 - val_loss: 0.0581 - val_accuracy: 0.9769\n",
            "Epoch 56/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1011 - accuracy: 0.9505 - val_loss: 0.0572 - val_accuracy: 0.9830\n",
            "Epoch 57/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0932 - accuracy: 0.9534 - val_loss: 0.0884 - val_accuracy: 0.9733\n",
            "Epoch 58/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0944 - accuracy: 0.9593 - val_loss: 0.1687 - val_accuracy: 0.9678\n",
            "Epoch 59/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0836 - accuracy: 0.9663 - val_loss: 0.0887 - val_accuracy: 0.9575\n",
            "Epoch 60/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0956 - accuracy: 0.9520 - val_loss: 0.0662 - val_accuracy: 0.9830\n",
            "Epoch 61/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0816 - accuracy: 0.9587 - val_loss: 0.0565 - val_accuracy: 0.9848\n",
            "Epoch 62/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0671 - accuracy: 0.9715 - val_loss: 0.0343 - val_accuracy: 0.9915\n",
            "Epoch 63/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0634 - accuracy: 0.9730 - val_loss: 0.0381 - val_accuracy: 0.9879\n",
            "Epoch 64/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0705 - accuracy: 0.9703 - val_loss: 0.0461 - val_accuracy: 0.9879\n",
            "Epoch 65/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0937 - accuracy: 0.9709 - val_loss: 1.0759 - val_accuracy: 0.9545\n",
            "Epoch 66/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.4571 - accuracy: 0.8537 - val_loss: 0.2392 - val_accuracy: 0.8665\n",
            "Epoch 67/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1425 - accuracy: 0.9056 - val_loss: 0.1567 - val_accuracy: 0.8968\n",
            "Epoch 68/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.1075 - accuracy: 0.9344 - val_loss: 0.0509 - val_accuracy: 0.9860\n",
            "Epoch 69/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1610 - accuracy: 0.9568 - val_loss: 889.1066 - val_accuracy: 0.8744\n",
            "Epoch 70/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1720 - accuracy: 0.9240 - val_loss: 0.0890 - val_accuracy: 0.9563\n",
            "Epoch 71/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1139 - accuracy: 0.9446 - val_loss: 0.0728 - val_accuracy: 0.9782\n",
            "Epoch 72/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0784 - accuracy: 0.9607 - val_loss: 0.0599 - val_accuracy: 0.9842\n",
            "Epoch 73/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0759 - accuracy: 0.9640 - val_loss: 0.0893 - val_accuracy: 0.9873\n",
            "Epoch 74/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0850 - accuracy: 0.9634 - val_loss: 0.0649 - val_accuracy: 0.9836\n",
            "Epoch 75/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0803 - accuracy: 0.9645 - val_loss: 0.0692 - val_accuracy: 0.9824\n",
            "Epoch 76/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0666 - accuracy: 0.9710 - val_loss: 0.0594 - val_accuracy: 0.9867\n",
            "Epoch 77/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0640 - accuracy: 0.9687 - val_loss: 0.1712 - val_accuracy: 0.9897\n",
            "Epoch 78/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0649 - accuracy: 0.9754 - val_loss: 0.2701 - val_accuracy: 0.9854\n",
            "Epoch 79/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0710 - accuracy: 0.9675 - val_loss: 0.0814 - val_accuracy: 0.9818\n",
            "Epoch 80/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1124 - accuracy: 0.9486 - val_loss: 0.1437 - val_accuracy: 0.9684\n",
            "Epoch 81/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0786 - accuracy: 0.9657 - val_loss: 0.0773 - val_accuracy: 0.9867\n",
            "Epoch 82/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0607 - accuracy: 0.9736 - val_loss: 0.0546 - val_accuracy: 0.9885\n",
            "Epoch 83/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0639 - accuracy: 0.9768 - val_loss: 0.0920 - val_accuracy: 0.9836\n",
            "Epoch 84/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0647 - accuracy: 0.9698 - val_loss: 0.0431 - val_accuracy: 0.9860\n",
            "Epoch 85/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0578 - accuracy: 0.9771 - val_loss: 0.1173 - val_accuracy: 0.9867\n",
            "Epoch 86/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0600 - accuracy: 0.9759 - val_loss: 0.0557 - val_accuracy: 0.9873\n",
            "Epoch 87/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1807 - accuracy: 0.9577 - val_loss: 0.0942 - val_accuracy: 0.9345\n",
            "Epoch 88/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0955 - accuracy: 0.9525 - val_loss: 0.1608 - val_accuracy: 0.9830\n",
            "Epoch 89/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0798 - accuracy: 0.9669 - val_loss: 0.0743 - val_accuracy: 0.9733\n",
            "Epoch 90/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0791 - accuracy: 0.9660 - val_loss: 0.1354 - val_accuracy: 0.9867\n",
            "Epoch 91/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0523 - accuracy: 0.9783 - val_loss: 0.0670 - val_accuracy: 0.9909\n",
            "Epoch 92/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.1404 - accuracy: 0.9772 - val_loss: 197.1525 - val_accuracy: 0.6899\n",
            "Epoch 93/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0857 - accuracy: 0.9634 - val_loss: 1.2133 - val_accuracy: 0.9642\n",
            "Epoch 94/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0696 - accuracy: 0.9706 - val_loss: 0.1052 - val_accuracy: 0.9848\n",
            "Epoch 95/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0862 - accuracy: 0.9733 - val_loss: 0.0670 - val_accuracy: 0.9800\n",
            "Epoch 96/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0785 - accuracy: 0.9684 - val_loss: 0.0564 - val_accuracy: 0.9836\n",
            "Epoch 97/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0760 - accuracy: 0.9736 - val_loss: 0.0814 - val_accuracy: 0.9842\n",
            "Epoch 98/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0555 - accuracy: 0.9812 - val_loss: 0.1752 - val_accuracy: 0.9794\n",
            "Epoch 99/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0534 - accuracy: 0.9821 - val_loss: 0.0685 - val_accuracy: 0.9897\n",
            "Epoch 100/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0496 - accuracy: 0.9821 - val_loss: 0.0472 - val_accuracy: 0.9891\n",
            "Epoch 101/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0408 - accuracy: 0.9859 - val_loss: 0.0918 - val_accuracy: 0.9824\n",
            "Epoch 102/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0969 - accuracy: 0.9771 - val_loss: 0.1238 - val_accuracy: 0.9867\n",
            "Epoch 103/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0669 - accuracy: 0.9728 - val_loss: 0.1294 - val_accuracy: 0.9879\n",
            "Epoch 104/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0467 - accuracy: 0.9853 - val_loss: 0.0815 - val_accuracy: 0.9885\n",
            "Epoch 105/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0528 - accuracy: 0.9807 - val_loss: 0.0515 - val_accuracy: 0.9873\n",
            "Epoch 106/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0546 - accuracy: 0.9822 - val_loss: 0.1929 - val_accuracy: 0.9818\n",
            "Epoch 107/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0759 - accuracy: 0.9824 - val_loss: 0.1019 - val_accuracy: 0.9794\n",
            "Epoch 108/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0537 - accuracy: 0.9815 - val_loss: 0.0556 - val_accuracy: 0.9903\n",
            "Epoch 109/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0625 - accuracy: 0.9813 - val_loss: 0.0476 - val_accuracy: 0.9903\n",
            "Epoch 110/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0351 - accuracy: 0.9885 - val_loss: 0.0603 - val_accuracy: 0.9903\n",
            "Epoch 111/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0603 - accuracy: 0.9863 - val_loss: 0.1101 - val_accuracy: 0.9885\n",
            "Epoch 112/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0524 - accuracy: 0.9822 - val_loss: 0.0301 - val_accuracy: 0.9915\n",
            "Epoch 113/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0395 - accuracy: 0.9856 - val_loss: 0.0363 - val_accuracy: 0.9903\n",
            "Epoch 114/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0521 - accuracy: 0.9830 - val_loss: 0.0572 - val_accuracy: 0.9909\n",
            "Epoch 115/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0384 - accuracy: 0.9869 - val_loss: 0.0420 - val_accuracy: 0.9873\n",
            "Epoch 116/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0444 - accuracy: 0.9848 - val_loss: 0.0551 - val_accuracy: 0.9885\n",
            "Epoch 117/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0396 - accuracy: 0.9876 - val_loss: 0.0453 - val_accuracy: 0.9915\n",
            "Epoch 118/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0381 - accuracy: 0.9873 - val_loss: 0.0470 - val_accuracy: 0.9921\n",
            "Epoch 119/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0393 - accuracy: 0.9885 - val_loss: 0.1158 - val_accuracy: 0.9830\n",
            "Epoch 120/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0456 - accuracy: 0.9824 - val_loss: 0.0816 - val_accuracy: 0.9897\n",
            "Epoch 121/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0434 - accuracy: 0.9850 - val_loss: 2.8047 - val_accuracy: 0.9575\n",
            "Epoch 122/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0405 - accuracy: 0.9879 - val_loss: 1071.2203 - val_accuracy: 0.9072\n",
            "Epoch 123/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0791 - accuracy: 0.9728 - val_loss: 938.9426 - val_accuracy: 0.8671\n",
            "Epoch 124/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0527 - accuracy: 0.9813 - val_loss: 0.0564 - val_accuracy: 0.9788\n",
            "Epoch 125/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0313 - accuracy: 0.9895 - val_loss: 0.2046 - val_accuracy: 0.9854\n",
            "Epoch 126/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0345 - accuracy: 0.9907 - val_loss: 0.0425 - val_accuracy: 0.9903\n",
            "Epoch 127/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0313 - accuracy: 0.9892 - val_loss: 0.0827 - val_accuracy: 0.9891\n",
            "Epoch 128/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0481 - accuracy: 0.9885 - val_loss: 0.0836 - val_accuracy: 0.9891\n",
            "Epoch 129/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0374 - accuracy: 0.9871 - val_loss: 0.1268 - val_accuracy: 0.9867\n",
            "Epoch 130/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0343 - accuracy: 0.9920 - val_loss: 0.1342 - val_accuracy: 0.9867\n",
            "Epoch 131/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0580 - accuracy: 0.9869 - val_loss: 0.0559 - val_accuracy: 0.9848\n",
            "Epoch 132/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0335 - accuracy: 0.9892 - val_loss: 0.1191 - val_accuracy: 0.9854\n",
            "Epoch 133/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0739 - accuracy: 0.9871 - val_loss: 133.0009 - val_accuracy: 0.8944\n",
            "Epoch 134/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0436 - accuracy: 0.9869 - val_loss: 0.2439 - val_accuracy: 0.9733\n",
            "Epoch 135/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0314 - accuracy: 0.9912 - val_loss: 0.0955 - val_accuracy: 0.9885\n",
            "Epoch 136/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0364 - accuracy: 0.9889 - val_loss: 0.0887 - val_accuracy: 0.9842\n",
            "Epoch 137/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0274 - accuracy: 0.9912 - val_loss: 0.0735 - val_accuracy: 0.9885\n",
            "Epoch 138/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0368 - accuracy: 0.9904 - val_loss: 0.0559 - val_accuracy: 0.9854\n",
            "Epoch 139/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0370 - accuracy: 0.9877 - val_loss: 0.1342 - val_accuracy: 0.9873\n",
            "Epoch 140/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0295 - accuracy: 0.9897 - val_loss: 0.2012 - val_accuracy: 0.9885\n",
            "Epoch 141/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0496 - accuracy: 0.9882 - val_loss: 0.2825 - val_accuracy: 0.9751\n",
            "Epoch 142/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0318 - accuracy: 0.9906 - val_loss: 0.0922 - val_accuracy: 0.9927\n",
            "Epoch 143/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0617 - accuracy: 0.9895 - val_loss: 0.1622 - val_accuracy: 0.9757\n",
            "Epoch 144/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0382 - accuracy: 0.9882 - val_loss: 0.0771 - val_accuracy: 0.9867\n",
            "Epoch 145/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0478 - accuracy: 0.9924 - val_loss: 0.0833 - val_accuracy: 0.9921\n",
            "Epoch 146/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0292 - accuracy: 0.9912 - val_loss: 0.1042 - val_accuracy: 0.9909\n",
            "Epoch 147/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0209 - accuracy: 0.9938 - val_loss: 0.1489 - val_accuracy: 0.9891\n",
            "Epoch 148/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0323 - accuracy: 0.9924 - val_loss: 0.0971 - val_accuracy: 0.9903\n",
            "Epoch 149/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0224 - accuracy: 0.9927 - val_loss: 0.1280 - val_accuracy: 0.9873\n",
            "Epoch 150/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0292 - accuracy: 0.9903 - val_loss: 0.0905 - val_accuracy: 0.9903\n",
            "Epoch 151/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0398 - accuracy: 0.9909 - val_loss: 0.1227 - val_accuracy: 0.9909\n",
            "Epoch 152/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0235 - accuracy: 0.9923 - val_loss: 0.1075 - val_accuracy: 0.9903\n",
            "Epoch 153/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0211 - accuracy: 0.9938 - val_loss: 0.1890 - val_accuracy: 0.9879\n",
            "Epoch 154/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0211 - accuracy: 0.9939 - val_loss: 0.1022 - val_accuracy: 0.9903\n",
            "Epoch 155/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0269 - accuracy: 0.9918 - val_loss: 0.0727 - val_accuracy: 0.9915\n",
            "Epoch 156/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0231 - accuracy: 0.9938 - val_loss: 0.1818 - val_accuracy: 0.9903\n",
            "Epoch 157/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0486 - accuracy: 0.9854 - val_loss: 0.1091 - val_accuracy: 0.9873\n",
            "Epoch 158/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0367 - accuracy: 0.9873 - val_loss: 0.1541 - val_accuracy: 0.9867\n",
            "Epoch 159/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0342 - accuracy: 0.9907 - val_loss: 0.1034 - val_accuracy: 0.9927\n",
            "Epoch 160/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0452 - accuracy: 0.9915 - val_loss: 0.0898 - val_accuracy: 0.9836\n",
            "Epoch 161/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0284 - accuracy: 0.9907 - val_loss: 0.0946 - val_accuracy: 0.9903\n",
            "Epoch 162/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0272 - accuracy: 0.9924 - val_loss: 0.0814 - val_accuracy: 0.9854\n",
            "Epoch 163/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0204 - accuracy: 0.9938 - val_loss: 0.1034 - val_accuracy: 0.9879\n",
            "Epoch 164/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0320 - accuracy: 0.9917 - val_loss: 0.2342 - val_accuracy: 0.9775\n",
            "Epoch 165/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0262 - accuracy: 0.9915 - val_loss: 0.1064 - val_accuracy: 0.9903\n",
            "Epoch 166/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0625 - accuracy: 0.9851 - val_loss: 0.1074 - val_accuracy: 0.9697\n",
            "Epoch 167/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0327 - accuracy: 0.9906 - val_loss: 0.1783 - val_accuracy: 0.9842\n",
            "Epoch 168/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0425 - accuracy: 0.9909 - val_loss: 0.1480 - val_accuracy: 0.9873\n",
            "Epoch 169/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0321 - accuracy: 0.9907 - val_loss: 0.1088 - val_accuracy: 0.9879\n",
            "Epoch 170/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0585 - accuracy: 0.9898 - val_loss: 0.0907 - val_accuracy: 0.9757\n",
            "Epoch 171/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0341 - accuracy: 0.9894 - val_loss: 0.1083 - val_accuracy: 0.9921\n",
            "Epoch 172/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0240 - accuracy: 0.9932 - val_loss: 0.2108 - val_accuracy: 0.9879\n",
            "Epoch 173/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0249 - accuracy: 0.9929 - val_loss: 0.1134 - val_accuracy: 0.9885\n",
            "Epoch 174/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0212 - accuracy: 0.9945 - val_loss: 0.1101 - val_accuracy: 0.9915\n",
            "Epoch 175/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0302 - accuracy: 0.9933 - val_loss: 0.1299 - val_accuracy: 0.9903\n",
            "Epoch 176/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0211 - accuracy: 0.9936 - val_loss: 0.0857 - val_accuracy: 0.9927\n",
            "Epoch 177/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0129 - accuracy: 0.9970 - val_loss: 0.1233 - val_accuracy: 0.9915\n",
            "Epoch 178/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0220 - accuracy: 0.9935 - val_loss: 0.1300 - val_accuracy: 0.9927\n",
            "Epoch 179/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0307 - accuracy: 0.9907 - val_loss: 0.1949 - val_accuracy: 0.9873\n",
            "Epoch 180/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0177 - accuracy: 0.9951 - val_loss: 0.2630 - val_accuracy: 0.9472\n",
            "Epoch 181/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0503 - accuracy: 0.9873 - val_loss: 0.1300 - val_accuracy: 0.9885\n",
            "Epoch 182/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0300 - accuracy: 0.9906 - val_loss: 0.0900 - val_accuracy: 0.9891\n",
            "Epoch 183/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0229 - accuracy: 0.9932 - val_loss: 0.1463 - val_accuracy: 0.9891\n",
            "Epoch 184/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0249 - accuracy: 0.9932 - val_loss: 0.1277 - val_accuracy: 0.9897\n",
            "Epoch 185/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0297 - accuracy: 0.9906 - val_loss: 0.0949 - val_accuracy: 0.9915\n",
            "Epoch 186/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0245 - accuracy: 0.9924 - val_loss: 0.0779 - val_accuracy: 0.9909\n",
            "Epoch 187/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0282 - accuracy: 0.9932 - val_loss: 0.1253 - val_accuracy: 0.9885\n",
            "Epoch 188/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0374 - accuracy: 0.9914 - val_loss: 0.1090 - val_accuracy: 0.9885\n",
            "Epoch 189/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0273 - accuracy: 0.9926 - val_loss: 0.0873 - val_accuracy: 0.9915\n",
            "Epoch 190/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0210 - accuracy: 0.9938 - val_loss: 0.0934 - val_accuracy: 0.9909\n",
            "Epoch 191/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0135 - accuracy: 0.9968 - val_loss: 0.1277 - val_accuracy: 0.9903\n",
            "Epoch 192/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0162 - accuracy: 0.9956 - val_loss: 0.0667 - val_accuracy: 0.9933\n",
            "Epoch 193/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0221 - accuracy: 0.9961 - val_loss: 0.3687 - val_accuracy: 0.9684\n",
            "Epoch 194/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0238 - accuracy: 0.9927 - val_loss: 0.0693 - val_accuracy: 0.9909\n",
            "Epoch 195/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0273 - accuracy: 0.9932 - val_loss: 0.1185 - val_accuracy: 0.9836\n",
            "Epoch 196/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0315 - accuracy: 0.9912 - val_loss: 0.0452 - val_accuracy: 0.9879\n",
            "Epoch 197/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0636 - accuracy: 0.9909 - val_loss: 0.1028 - val_accuracy: 0.9830\n",
            "Epoch 198/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0241 - accuracy: 0.9939 - val_loss: 0.1711 - val_accuracy: 0.9909\n",
            "Epoch 199/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0237 - accuracy: 0.9941 - val_loss: 0.3047 - val_accuracy: 0.9794\n",
            "Epoch 200/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0283 - accuracy: 0.9914 - val_loss: 0.1772 - val_accuracy: 0.9860\n",
            "Epoch 201/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0202 - accuracy: 0.9938 - val_loss: 0.2160 - val_accuracy: 0.9897\n",
            "Epoch 202/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0171 - accuracy: 0.9953 - val_loss: 0.1294 - val_accuracy: 0.9897\n",
            "Epoch 203/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0304 - accuracy: 0.9912 - val_loss: 0.1783 - val_accuracy: 0.9921\n",
            "Epoch 204/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0481 - accuracy: 0.9898 - val_loss: 0.2396 - val_accuracy: 0.9788\n",
            "Epoch 205/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0411 - accuracy: 0.9918 - val_loss: 0.1053 - val_accuracy: 0.9897\n",
            "Epoch 206/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0219 - accuracy: 0.9938 - val_loss: 0.1107 - val_accuracy: 0.9891\n",
            "Epoch 207/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0179 - accuracy: 0.9954 - val_loss: 0.1736 - val_accuracy: 0.9879\n",
            "Epoch 208/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0291 - accuracy: 0.9936 - val_loss: 0.1521 - val_accuracy: 0.9945\n",
            "Epoch 209/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0141 - accuracy: 0.9961 - val_loss: 0.1039 - val_accuracy: 0.9933\n",
            "Epoch 210/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0136 - accuracy: 0.9962 - val_loss: 0.1283 - val_accuracy: 0.9921\n",
            "Epoch 211/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0315 - accuracy: 0.9944 - val_loss: 0.1819 - val_accuracy: 0.9891\n",
            "Epoch 212/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0171 - accuracy: 0.9947 - val_loss: 0.1158 - val_accuracy: 0.9879\n",
            "Epoch 213/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0304 - accuracy: 0.9926 - val_loss: 0.3823 - val_accuracy: 0.9788\n",
            "Epoch 214/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0213 - accuracy: 0.9933 - val_loss: 0.1432 - val_accuracy: 0.9915\n",
            "Epoch 215/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0332 - accuracy: 0.9936 - val_loss: 9.4944 - val_accuracy: 0.9466\n",
            "Epoch 216/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0267 - accuracy: 0.9923 - val_loss: 0.1696 - val_accuracy: 0.9897\n",
            "Epoch 217/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0230 - accuracy: 0.9935 - val_loss: 0.0748 - val_accuracy: 0.9848\n",
            "Epoch 218/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0203 - accuracy: 0.9936 - val_loss: 0.1594 - val_accuracy: 0.9909\n",
            "Epoch 219/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0136 - accuracy: 0.9962 - val_loss: 0.1143 - val_accuracy: 0.9951\n",
            "Epoch 220/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0161 - accuracy: 0.9951 - val_loss: 0.1435 - val_accuracy: 0.9915\n",
            "Epoch 221/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0187 - accuracy: 0.9953 - val_loss: 0.0949 - val_accuracy: 0.9903\n",
            "Epoch 222/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0437 - accuracy: 0.9933 - val_loss: 0.1249 - val_accuracy: 0.9939\n",
            "Epoch 223/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0258 - accuracy: 0.9935 - val_loss: 0.1064 - val_accuracy: 0.9939\n",
            "Epoch 224/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0189 - accuracy: 0.9945 - val_loss: 0.1033 - val_accuracy: 0.9945\n",
            "Epoch 225/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0207 - accuracy: 0.9939 - val_loss: 0.1192 - val_accuracy: 0.9885\n",
            "Epoch 226/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0196 - accuracy: 0.9939 - val_loss: 0.1474 - val_accuracy: 0.9897\n",
            "Epoch 227/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0268 - accuracy: 0.9936 - val_loss: 0.0762 - val_accuracy: 0.9854\n",
            "Epoch 228/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0660 - accuracy: 0.9917 - val_loss: 0.1223 - val_accuracy: 0.9897\n",
            "Epoch 229/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0248 - accuracy: 0.9933 - val_loss: 0.1425 - val_accuracy: 0.9897\n",
            "Epoch 230/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0208 - accuracy: 0.9939 - val_loss: 0.0755 - val_accuracy: 0.9939\n",
            "Epoch 231/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0224 - accuracy: 0.9944 - val_loss: 0.0640 - val_accuracy: 0.9933\n",
            "Epoch 232/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0192 - accuracy: 0.9936 - val_loss: 0.1181 - val_accuracy: 0.9933\n",
            "Epoch 233/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0130 - accuracy: 0.9959 - val_loss: 0.1756 - val_accuracy: 0.9909\n",
            "Epoch 234/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0788 - accuracy: 0.9891 - val_loss: 0.0536 - val_accuracy: 0.9933\n",
            "Epoch 235/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0227 - accuracy: 0.9935 - val_loss: 0.0983 - val_accuracy: 0.9933\n",
            "Epoch 236/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0235 - accuracy: 0.9935 - val_loss: 0.0964 - val_accuracy: 0.9915\n",
            "Epoch 237/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0177 - accuracy: 0.9951 - val_loss: 0.0914 - val_accuracy: 0.9915\n",
            "Epoch 238/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0177 - accuracy: 0.9964 - val_loss: 0.1798 - val_accuracy: 0.9867\n",
            "Epoch 239/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0126 - accuracy: 0.9965 - val_loss: 0.1271 - val_accuracy: 0.9903\n",
            "Epoch 240/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0270 - accuracy: 0.9929 - val_loss: 0.1036 - val_accuracy: 0.9909\n",
            "Epoch 241/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0267 - accuracy: 0.9950 - val_loss: 0.0955 - val_accuracy: 0.9891\n",
            "Epoch 242/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0195 - accuracy: 0.9944 - val_loss: 0.1503 - val_accuracy: 0.9915\n",
            "Epoch 243/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0181 - accuracy: 0.9953 - val_loss: 0.2565 - val_accuracy: 0.9873\n",
            "Epoch 244/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0199 - accuracy: 0.9933 - val_loss: 0.1775 - val_accuracy: 0.9903\n",
            "Epoch 245/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0433 - accuracy: 0.9903 - val_loss: 0.0793 - val_accuracy: 0.9824\n",
            "Epoch 246/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0253 - accuracy: 0.9935 - val_loss: 0.1203 - val_accuracy: 0.9921\n",
            "Epoch 247/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0204 - accuracy: 0.9956 - val_loss: 0.2957 - val_accuracy: 0.9873\n",
            "Epoch 248/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0273 - accuracy: 0.9938 - val_loss: 0.1843 - val_accuracy: 0.9885\n",
            "Epoch 249/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0204 - accuracy: 0.9929 - val_loss: 0.1409 - val_accuracy: 0.9897\n",
            "Epoch 250/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0235 - accuracy: 0.9932 - val_loss: 0.2412 - val_accuracy: 0.9885\n",
            "Epoch 251/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0176 - accuracy: 0.9947 - val_loss: 0.1785 - val_accuracy: 0.9921\n",
            "Epoch 252/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0486 - accuracy: 0.9915 - val_loss: 0.2637 - val_accuracy: 0.9909\n",
            "Epoch 253/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0173 - accuracy: 0.9941 - val_loss: 0.2373 - val_accuracy: 0.9903\n",
            "Epoch 254/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0164 - accuracy: 0.9945 - val_loss: 0.1819 - val_accuracy: 0.9903\n",
            "Epoch 255/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0129 - accuracy: 0.9954 - val_loss: 0.4173 - val_accuracy: 0.9891\n",
            "Epoch 256/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0175 - accuracy: 0.9959 - val_loss: 0.2152 - val_accuracy: 0.9885\n",
            "Epoch 257/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0157 - accuracy: 0.9959 - val_loss: 0.3525 - val_accuracy: 0.9891\n",
            "Epoch 258/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0181 - accuracy: 0.9953 - val_loss: 0.2153 - val_accuracy: 0.9939\n",
            "Epoch 259/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0363 - accuracy: 0.9933 - val_loss: 0.2549 - val_accuracy: 0.9873\n",
            "Epoch 260/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0248 - accuracy: 0.9929 - val_loss: 0.3132 - val_accuracy: 0.9879\n",
            "Epoch 261/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0170 - accuracy: 0.9945 - val_loss: 0.2613 - val_accuracy: 0.9903\n",
            "Epoch 262/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0476 - accuracy: 0.9941 - val_loss: 0.2078 - val_accuracy: 0.9891\n",
            "Epoch 263/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0206 - accuracy: 0.9939 - val_loss: 0.1783 - val_accuracy: 0.9921\n",
            "Epoch 264/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0198 - accuracy: 0.9947 - val_loss: 0.2047 - val_accuracy: 0.9854\n",
            "Epoch 265/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0373 - accuracy: 0.9920 - val_loss: 0.2149 - val_accuracy: 0.9891\n",
            "Epoch 266/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0153 - accuracy: 0.9959 - val_loss: 0.0983 - val_accuracy: 0.9909\n",
            "Epoch 267/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0176 - accuracy: 0.9944 - val_loss: 0.2308 - val_accuracy: 0.9915\n",
            "Epoch 268/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0101 - accuracy: 0.9970 - val_loss: 0.3436 - val_accuracy: 0.9879\n",
            "Epoch 269/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0269 - accuracy: 0.9945 - val_loss: 0.1123 - val_accuracy: 0.9933\n",
            "Epoch 270/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0161 - accuracy: 0.9951 - val_loss: 0.1428 - val_accuracy: 0.9933\n",
            "Epoch 271/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0210 - accuracy: 0.9942 - val_loss: 0.0825 - val_accuracy: 0.9927\n",
            "Epoch 272/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0334 - accuracy: 0.9921 - val_loss: 0.1402 - val_accuracy: 0.9891\n",
            "Epoch 273/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0274 - accuracy: 0.9935 - val_loss: 0.1550 - val_accuracy: 0.9897\n",
            "Epoch 274/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0169 - accuracy: 0.9958 - val_loss: 0.2147 - val_accuracy: 0.9897\n",
            "Epoch 275/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0211 - accuracy: 0.9935 - val_loss: 0.1097 - val_accuracy: 0.9921\n",
            "Epoch 276/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0196 - accuracy: 0.9944 - val_loss: 0.0948 - val_accuracy: 0.9921\n",
            "Epoch 277/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0916 - accuracy: 0.9892 - val_loss: 0.1823 - val_accuracy: 0.9800\n",
            "Epoch 278/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0279 - accuracy: 0.9948 - val_loss: 0.1026 - val_accuracy: 0.9727\n",
            "Epoch 279/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0157 - accuracy: 0.9962 - val_loss: 0.1277 - val_accuracy: 0.9909\n",
            "Epoch 280/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0151 - accuracy: 0.9956 - val_loss: 0.1639 - val_accuracy: 0.9909\n",
            "Epoch 281/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0120 - accuracy: 0.9964 - val_loss: 0.1423 - val_accuracy: 0.9921\n",
            "Epoch 282/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0115 - accuracy: 0.9965 - val_loss: 0.2266 - val_accuracy: 0.9903\n",
            "Epoch 283/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0257 - accuracy: 0.9950 - val_loss: 0.1156 - val_accuracy: 0.9933\n",
            "Epoch 284/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0155 - accuracy: 0.9956 - val_loss: 0.1146 - val_accuracy: 0.9939\n",
            "Epoch 285/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0175 - accuracy: 0.9938 - val_loss: 0.1958 - val_accuracy: 0.9915\n",
            "Epoch 286/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0165 - accuracy: 0.9951 - val_loss: 0.1810 - val_accuracy: 0.9909\n",
            "Epoch 287/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0132 - accuracy: 0.9962 - val_loss: 0.1584 - val_accuracy: 0.9897\n",
            "Epoch 288/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0165 - accuracy: 0.9953 - val_loss: 0.1370 - val_accuracy: 0.9921\n",
            "Epoch 289/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0147 - accuracy: 0.9954 - val_loss: 0.2071 - val_accuracy: 0.9933\n",
            "Epoch 290/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0326 - accuracy: 0.9938 - val_loss: 0.0784 - val_accuracy: 0.9836\n",
            "Epoch 291/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0240 - accuracy: 0.9950 - val_loss: 0.1121 - val_accuracy: 0.9909\n",
            "Epoch 292/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0133 - accuracy: 0.9954 - val_loss: 0.1670 - val_accuracy: 0.9921\n",
            "Epoch 293/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0161 - accuracy: 0.9951 - val_loss: 0.2340 - val_accuracy: 0.9836\n",
            "Epoch 294/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0461 - accuracy: 0.9918 - val_loss: 0.2346 - val_accuracy: 0.9897\n",
            "Epoch 295/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0100 - accuracy: 0.9971 - val_loss: 0.1255 - val_accuracy: 0.9915\n",
            "Epoch 296/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0214 - accuracy: 0.9941 - val_loss: 0.2752 - val_accuracy: 0.9891\n",
            "Epoch 297/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0180 - accuracy: 0.9939 - val_loss: 0.2918 - val_accuracy: 0.9903\n",
            "Epoch 298/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0175 - accuracy: 0.9945 - val_loss: 0.3599 - val_accuracy: 0.9879\n",
            "Epoch 299/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0189 - accuracy: 0.9941 - val_loss: 0.1913 - val_accuracy: 0.9909\n",
            "Epoch 300/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0295 - accuracy: 0.9932 - val_loss: 0.3539 - val_accuracy: 0.9812\n",
            "Epoch 301/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0338 - accuracy: 0.9930 - val_loss: 0.0975 - val_accuracy: 0.9891\n",
            "Epoch 302/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0358 - accuracy: 0.9889 - val_loss: 0.1332 - val_accuracy: 0.9860\n",
            "Epoch 303/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0257 - accuracy: 0.9941 - val_loss: 0.1744 - val_accuracy: 0.9903\n",
            "Epoch 304/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0099 - accuracy: 0.9974 - val_loss: 0.1696 - val_accuracy: 0.9897\n",
            "Epoch 305/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0180 - accuracy: 0.9950 - val_loss: 0.1656 - val_accuracy: 0.9927\n",
            "Epoch 306/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0090 - accuracy: 0.9977 - val_loss: 0.2309 - val_accuracy: 0.9909\n",
            "Epoch 307/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0241 - accuracy: 0.9958 - val_loss: 0.2737 - val_accuracy: 0.9879\n",
            "Epoch 308/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0175 - accuracy: 0.9962 - val_loss: 2.2921 - val_accuracy: 0.9436\n",
            "Epoch 309/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0361 - accuracy: 0.9930 - val_loss: 0.8862 - val_accuracy: 0.9800\n",
            "Epoch 310/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0254 - accuracy: 0.9930 - val_loss: 0.2233 - val_accuracy: 0.9909\n",
            "Epoch 311/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0238 - accuracy: 0.9945 - val_loss: 0.2255 - val_accuracy: 0.9891\n",
            "Epoch 312/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0137 - accuracy: 0.9962 - val_loss: 0.1998 - val_accuracy: 0.9909\n",
            "Epoch 313/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0182 - accuracy: 0.9967 - val_loss: 0.2696 - val_accuracy: 0.9903\n",
            "Epoch 314/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0356 - accuracy: 0.9954 - val_loss: 0.5631 - val_accuracy: 0.9745\n",
            "Epoch 315/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0183 - accuracy: 0.9948 - val_loss: 0.3120 - val_accuracy: 0.9891\n",
            "Epoch 316/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0109 - accuracy: 0.9968 - val_loss: 0.4564 - val_accuracy: 0.9854\n",
            "Epoch 317/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0134 - accuracy: 0.9958 - val_loss: 0.3822 - val_accuracy: 0.9915\n",
            "Epoch 318/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0122 - accuracy: 0.9968 - val_loss: 0.2864 - val_accuracy: 0.9909\n",
            "Epoch 319/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0139 - accuracy: 0.9968 - val_loss: 0.2089 - val_accuracy: 0.9915\n",
            "Epoch 320/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0217 - accuracy: 0.9954 - val_loss: 0.1783 - val_accuracy: 0.9915\n",
            "Epoch 321/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0096 - accuracy: 0.9971 - val_loss: 0.5768 - val_accuracy: 0.9867\n",
            "Epoch 322/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0262 - accuracy: 0.9948 - val_loss: 0.2659 - val_accuracy: 0.9842\n",
            "Epoch 323/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0228 - accuracy: 0.9941 - val_loss: 0.3058 - val_accuracy: 0.9879\n",
            "Epoch 324/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0448 - accuracy: 0.9918 - val_loss: 0.1304 - val_accuracy: 0.9903\n",
            "Epoch 325/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0182 - accuracy: 0.9953 - val_loss: 0.1577 - val_accuracy: 0.9903\n",
            "Epoch 326/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0576 - accuracy: 0.9932 - val_loss: 0.1081 - val_accuracy: 0.9933\n",
            "Epoch 327/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0186 - accuracy: 0.9962 - val_loss: 0.1756 - val_accuracy: 0.9909\n",
            "Epoch 328/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0244 - accuracy: 0.9942 - val_loss: 0.1263 - val_accuracy: 0.9915\n",
            "Epoch 329/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0246 - accuracy: 0.9951 - val_loss: 0.1285 - val_accuracy: 0.9939\n",
            "Epoch 330/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0159 - accuracy: 0.9956 - val_loss: 0.1633 - val_accuracy: 0.9921\n",
            "Epoch 331/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0154 - accuracy: 0.9973 - val_loss: 0.2314 - val_accuracy: 0.9903\n",
            "Epoch 332/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0090 - accuracy: 0.9977 - val_loss: 0.1987 - val_accuracy: 0.9915\n",
            "Epoch 333/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0233 - accuracy: 0.9938 - val_loss: 0.0921 - val_accuracy: 0.9848\n",
            "Epoch 334/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0242 - accuracy: 0.9924 - val_loss: 0.1767 - val_accuracy: 0.9885\n",
            "Epoch 335/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0120 - accuracy: 0.9965 - val_loss: 0.2412 - val_accuracy: 0.9903\n",
            "Epoch 336/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0129 - accuracy: 0.9965 - val_loss: 0.1847 - val_accuracy: 0.9909\n",
            "Epoch 337/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0198 - accuracy: 0.9951 - val_loss: 0.1382 - val_accuracy: 0.9933\n",
            "Epoch 338/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0132 - accuracy: 0.9967 - val_loss: 0.1066 - val_accuracy: 0.9933\n",
            "Epoch 339/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0095 - accuracy: 0.9976 - val_loss: 0.1266 - val_accuracy: 0.9915\n",
            "Epoch 340/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0201 - accuracy: 0.9951 - val_loss: 0.1389 - val_accuracy: 0.9830\n",
            "Epoch 341/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0120 - accuracy: 0.9970 - val_loss: 0.1553 - val_accuracy: 0.9933\n",
            "Epoch 342/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0136 - accuracy: 0.9971 - val_loss: 0.1815 - val_accuracy: 0.9927\n",
            "Epoch 343/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0101 - accuracy: 0.9977 - val_loss: 0.1687 - val_accuracy: 0.9915\n",
            "Epoch 344/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0081 - accuracy: 0.9973 - val_loss: 0.2580 - val_accuracy: 0.9915\n",
            "Epoch 345/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0478 - accuracy: 0.9962 - val_loss: 0.2918 - val_accuracy: 0.9903\n",
            "Epoch 346/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0318 - accuracy: 0.9929 - val_loss: 0.2569 - val_accuracy: 0.9903\n",
            "Epoch 347/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0450 - accuracy: 0.9942 - val_loss: 0.1587 - val_accuracy: 0.9891\n",
            "Epoch 348/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0155 - accuracy: 0.9951 - val_loss: 0.0957 - val_accuracy: 0.9933\n",
            "Epoch 349/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0150 - accuracy: 0.9948 - val_loss: 0.1367 - val_accuracy: 0.9939\n",
            "Epoch 350/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0155 - accuracy: 0.9965 - val_loss: 0.4054 - val_accuracy: 0.9945\n",
            "Epoch 351/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0374 - accuracy: 0.9956 - val_loss: 0.3330 - val_accuracy: 0.9824\n",
            "Epoch 352/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0371 - accuracy: 0.9935 - val_loss: 0.1453 - val_accuracy: 0.9885\n",
            "Epoch 353/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0239 - accuracy: 0.9961 - val_loss: 0.1795 - val_accuracy: 0.9909\n",
            "Epoch 354/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0141 - accuracy: 0.9954 - val_loss: 0.1514 - val_accuracy: 0.9921\n",
            "Epoch 355/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0073 - accuracy: 0.9985 - val_loss: 0.1596 - val_accuracy: 0.9945\n",
            "Epoch 356/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0117 - accuracy: 0.9964 - val_loss: 0.1217 - val_accuracy: 0.9964\n",
            "Epoch 357/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0129 - accuracy: 0.9970 - val_loss: 7.9703 - val_accuracy: 0.9648\n",
            "Epoch 358/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0189 - accuracy: 0.9950 - val_loss: 0.1473 - val_accuracy: 0.9933\n",
            "Epoch 359/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0072 - accuracy: 0.9980 - val_loss: 0.2538 - val_accuracy: 0.9921\n",
            "Epoch 360/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0073 - accuracy: 0.9982 - val_loss: 0.2383 - val_accuracy: 0.9933\n",
            "Epoch 361/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0079 - accuracy: 0.9976 - val_loss: 0.2307 - val_accuracy: 0.9945\n",
            "Epoch 362/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0062 - accuracy: 0.9983 - val_loss: 0.2326 - val_accuracy: 0.9945\n",
            "Epoch 363/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0043 - accuracy: 0.9989 - val_loss: 0.2258 - val_accuracy: 0.9958\n",
            "Epoch 364/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0072 - accuracy: 0.9983 - val_loss: 0.2553 - val_accuracy: 0.9939\n",
            "Epoch 365/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0109 - accuracy: 0.9976 - val_loss: 0.1133 - val_accuracy: 0.9915\n",
            "Epoch 366/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0304 - accuracy: 0.9941 - val_loss: 0.0911 - val_accuracy: 0.9915\n",
            "Epoch 367/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0327 - accuracy: 0.9942 - val_loss: 0.1773 - val_accuracy: 0.9909\n",
            "Epoch 368/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0144 - accuracy: 0.9964 - val_loss: 0.1699 - val_accuracy: 0.9921\n",
            "Epoch 369/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0125 - accuracy: 0.9967 - val_loss: 0.1202 - val_accuracy: 0.9933\n",
            "Epoch 370/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0120 - accuracy: 0.9965 - val_loss: 0.0858 - val_accuracy: 0.9933\n",
            "Epoch 371/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0320 - accuracy: 0.9961 - val_loss: 0.1138 - val_accuracy: 0.9836\n",
            "Epoch 372/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0196 - accuracy: 0.9938 - val_loss: 0.0702 - val_accuracy: 0.9867\n",
            "Epoch 373/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0109 - accuracy: 0.9968 - val_loss: 0.1873 - val_accuracy: 0.9879\n",
            "Epoch 374/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0232 - accuracy: 0.9953 - val_loss: 0.0891 - val_accuracy: 0.9939\n",
            "Epoch 375/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0128 - accuracy: 0.9971 - val_loss: 0.1024 - val_accuracy: 0.9964\n",
            "Epoch 376/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0190 - accuracy: 0.9967 - val_loss: 0.0934 - val_accuracy: 0.9927\n",
            "Epoch 377/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0291 - accuracy: 0.9938 - val_loss: 0.1372 - val_accuracy: 0.9867\n",
            "Epoch 378/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0158 - accuracy: 0.9961 - val_loss: 0.0629 - val_accuracy: 0.9945\n",
            "Epoch 379/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0103 - accuracy: 0.9971 - val_loss: 0.0894 - val_accuracy: 0.9921\n",
            "Epoch 380/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0070 - accuracy: 0.9982 - val_loss: 0.1182 - val_accuracy: 0.9921\n",
            "Epoch 381/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0077 - accuracy: 0.9977 - val_loss: 0.1653 - val_accuracy: 0.9921\n",
            "Epoch 382/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0089 - accuracy: 0.9971 - val_loss: 0.1467 - val_accuracy: 0.9945\n",
            "Epoch 383/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0044 - accuracy: 0.9988 - val_loss: 0.1928 - val_accuracy: 0.9939\n",
            "Epoch 384/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0304 - accuracy: 0.9970 - val_loss: 0.1742 - val_accuracy: 0.9879\n",
            "Epoch 385/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0446 - accuracy: 0.9939 - val_loss: 0.1511 - val_accuracy: 0.9854\n",
            "Epoch 386/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0207 - accuracy: 0.9951 - val_loss: 0.1506 - val_accuracy: 0.9915\n",
            "Epoch 387/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0170 - accuracy: 0.9958 - val_loss: 0.3833 - val_accuracy: 0.9836\n",
            "Epoch 388/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0123 - accuracy: 0.9967 - val_loss: 0.0743 - val_accuracy: 0.9927\n",
            "Epoch 389/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0104 - accuracy: 0.9968 - val_loss: 0.1580 - val_accuracy: 0.9933\n",
            "Epoch 390/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0077 - accuracy: 0.9980 - val_loss: 0.1060 - val_accuracy: 0.9958\n",
            "Epoch 391/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0256 - accuracy: 0.9971 - val_loss: 0.2152 - val_accuracy: 0.9933\n",
            "Epoch 392/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0305 - accuracy: 0.9918 - val_loss: 0.1382 - val_accuracy: 0.9903\n",
            "Epoch 393/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0417 - accuracy: 0.9951 - val_loss: 0.0576 - val_accuracy: 0.9933\n",
            "Epoch 394/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0145 - accuracy: 0.9958 - val_loss: 0.0717 - val_accuracy: 0.9933\n",
            "Epoch 395/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0086 - accuracy: 0.9979 - val_loss: 0.1481 - val_accuracy: 0.9939\n",
            "Epoch 396/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0079 - accuracy: 0.9979 - val_loss: 0.0556 - val_accuracy: 0.9927\n",
            "Epoch 397/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0925 - accuracy: 0.9903 - val_loss: 0.2184 - val_accuracy: 0.9836\n",
            "Epoch 398/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0278 - accuracy: 0.9965 - val_loss: 0.1407 - val_accuracy: 0.9927\n",
            "Epoch 399/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0107 - accuracy: 0.9974 - val_loss: 0.1458 - val_accuracy: 0.9933\n",
            "Epoch 400/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0105 - accuracy: 0.9973 - val_loss: 0.1108 - val_accuracy: 0.9951\n",
            "Epoch 401/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0094 - accuracy: 0.9976 - val_loss: 0.1278 - val_accuracy: 0.9927\n",
            "Epoch 402/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0397 - accuracy: 0.9947 - val_loss: 0.1394 - val_accuracy: 0.9921\n",
            "Epoch 403/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0175 - accuracy: 0.9968 - val_loss: 0.1623 - val_accuracy: 0.9927\n",
            "Epoch 404/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0114 - accuracy: 0.9971 - val_loss: 0.1988 - val_accuracy: 0.9927\n",
            "Epoch 405/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0144 - accuracy: 0.9973 - val_loss: 0.2204 - val_accuracy: 0.9927\n",
            "Epoch 406/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0092 - accuracy: 0.9979 - val_loss: 0.2467 - val_accuracy: 0.9927\n",
            "Epoch 407/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0156 - accuracy: 0.9962 - val_loss: 0.1421 - val_accuracy: 0.9927\n",
            "Epoch 408/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0102 - accuracy: 0.9971 - val_loss: 0.1674 - val_accuracy: 0.9939\n",
            "Epoch 409/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0065 - accuracy: 0.9983 - val_loss: 0.2747 - val_accuracy: 0.9915\n",
            "Epoch 410/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0109 - accuracy: 0.9980 - val_loss: 0.1446 - val_accuracy: 0.9939\n",
            "Epoch 411/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0788 - accuracy: 0.9929 - val_loss: 0.0991 - val_accuracy: 0.9879\n",
            "Epoch 412/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0278 - accuracy: 0.9926 - val_loss: 0.2031 - val_accuracy: 0.9867\n",
            "Epoch 413/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0173 - accuracy: 0.9951 - val_loss: 0.1298 - val_accuracy: 0.9921\n",
            "Epoch 414/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0125 - accuracy: 0.9967 - val_loss: 0.2060 - val_accuracy: 0.9915\n",
            "Epoch 415/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0107 - accuracy: 0.9971 - val_loss: 0.1963 - val_accuracy: 0.9909\n",
            "Epoch 416/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0072 - accuracy: 0.9985 - val_loss: 0.1415 - val_accuracy: 0.9933\n",
            "Epoch 417/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0119 - accuracy: 0.9979 - val_loss: 0.1902 - val_accuracy: 0.9933\n",
            "Epoch 418/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0186 - accuracy: 0.9961 - val_loss: 0.1815 - val_accuracy: 0.9915\n",
            "Epoch 419/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0166 - accuracy: 0.9954 - val_loss: 0.2211 - val_accuracy: 0.9921\n",
            "Epoch 420/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0195 - accuracy: 0.9970 - val_loss: 0.0775 - val_accuracy: 0.9933\n",
            "Epoch 421/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0436 - accuracy: 0.9941 - val_loss: 0.0890 - val_accuracy: 0.9879\n",
            "Epoch 422/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0788 - accuracy: 0.9944 - val_loss: 0.1173 - val_accuracy: 0.9939\n",
            "Epoch 423/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0217 - accuracy: 0.9959 - val_loss: 0.1553 - val_accuracy: 0.9945\n",
            "Epoch 424/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0130 - accuracy: 0.9976 - val_loss: 0.2385 - val_accuracy: 0.9939\n",
            "Epoch 425/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0092 - accuracy: 0.9979 - val_loss: 0.1977 - val_accuracy: 0.9933\n",
            "Epoch 426/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0311 - accuracy: 0.9974 - val_loss: 0.1607 - val_accuracy: 0.9933\n",
            "Epoch 427/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0073 - accuracy: 0.9985 - val_loss: 0.2076 - val_accuracy: 0.9927\n",
            "Epoch 428/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0071 - accuracy: 0.9982 - val_loss: 0.2380 - val_accuracy: 0.9927\n",
            "Epoch 429/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0087 - accuracy: 0.9977 - val_loss: 0.2386 - val_accuracy: 0.9939\n",
            "Epoch 430/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0268 - accuracy: 0.9967 - val_loss: 0.1361 - val_accuracy: 0.9885\n",
            "Epoch 431/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0168 - accuracy: 0.9956 - val_loss: 0.2415 - val_accuracy: 0.9939\n",
            "Epoch 432/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0091 - accuracy: 0.9976 - val_loss: 0.3168 - val_accuracy: 0.9921\n",
            "Epoch 433/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0097 - accuracy: 0.9976 - val_loss: 0.2351 - val_accuracy: 0.9921\n",
            "Epoch 434/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0239 - accuracy: 0.9980 - val_loss: 0.3146 - val_accuracy: 0.9921\n",
            "Epoch 435/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0146 - accuracy: 0.9970 - val_loss: 0.1523 - val_accuracy: 0.9921\n",
            "Epoch 436/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0104 - accuracy: 0.9970 - val_loss: 0.1790 - val_accuracy: 0.9927\n",
            "Epoch 437/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0259 - accuracy: 0.9958 - val_loss: 0.1560 - val_accuracy: 0.9921\n",
            "Epoch 438/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0142 - accuracy: 0.9965 - val_loss: 0.3620 - val_accuracy: 0.9860\n",
            "Epoch 439/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0085 - accuracy: 0.9976 - val_loss: 0.1290 - val_accuracy: 0.9945\n",
            "Epoch 440/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0144 - accuracy: 0.9979 - val_loss: 0.1807 - val_accuracy: 0.9939\n",
            "Epoch 441/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0123 - accuracy: 0.9976 - val_loss: 0.1753 - val_accuracy: 0.9921\n",
            "Epoch 442/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0081 - accuracy: 0.9976 - val_loss: 0.1460 - val_accuracy: 0.9921\n",
            "Epoch 443/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0232 - accuracy: 0.9953 - val_loss: 0.8064 - val_accuracy: 0.9703\n",
            "Epoch 444/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0331 - accuracy: 0.9947 - val_loss: 0.1383 - val_accuracy: 0.9933\n",
            "Epoch 445/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0078 - accuracy: 0.9976 - val_loss: 0.2189 - val_accuracy: 0.9927\n",
            "Epoch 446/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0198 - accuracy: 0.9956 - val_loss: 0.0957 - val_accuracy: 0.9915\n",
            "Epoch 447/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0103 - accuracy: 0.9973 - val_loss: 0.1148 - val_accuracy: 0.9927\n",
            "Epoch 448/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0071 - accuracy: 0.9977 - val_loss: 0.1639 - val_accuracy: 0.9945\n",
            "Epoch 449/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0069 - accuracy: 0.9980 - val_loss: 0.1581 - val_accuracy: 0.9945\n",
            "Epoch 450/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0269 - accuracy: 0.9964 - val_loss: 0.1172 - val_accuracy: 0.9939\n",
            "Epoch 451/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0153 - accuracy: 0.9973 - val_loss: 0.1308 - val_accuracy: 0.9951\n",
            "Epoch 452/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0155 - accuracy: 0.9961 - val_loss: 0.1705 - val_accuracy: 0.9885\n",
            "Epoch 453/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0191 - accuracy: 0.9973 - val_loss: 0.1702 - val_accuracy: 0.9951\n",
            "Epoch 454/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0091 - accuracy: 0.9974 - val_loss: 0.1336 - val_accuracy: 0.9933\n",
            "Epoch 455/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0076 - accuracy: 0.9980 - val_loss: 0.2016 - val_accuracy: 0.9933\n",
            "Epoch 456/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0041 - accuracy: 0.9991 - val_loss: 0.2148 - val_accuracy: 0.9945\n",
            "Epoch 457/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0246 - accuracy: 0.9964 - val_loss: 0.1720 - val_accuracy: 0.9951\n",
            "Epoch 458/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0203 - accuracy: 0.9961 - val_loss: 0.3640 - val_accuracy: 0.9873\n",
            "Epoch 459/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0089 - accuracy: 0.9977 - val_loss: 0.1954 - val_accuracy: 0.9933\n",
            "Epoch 460/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0066 - accuracy: 0.9985 - val_loss: 0.3211 - val_accuracy: 0.9909\n",
            "Epoch 461/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0153 - accuracy: 0.9964 - val_loss: 0.3125 - val_accuracy: 0.9927\n",
            "Epoch 462/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0128 - accuracy: 0.9967 - val_loss: 0.5122 - val_accuracy: 0.9806\n",
            "Epoch 463/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0082 - accuracy: 0.9985 - val_loss: 0.1841 - val_accuracy: 0.9951\n",
            "Epoch 464/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0184 - accuracy: 0.9973 - val_loss: 0.0765 - val_accuracy: 0.9909\n",
            "Epoch 465/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0205 - accuracy: 0.9950 - val_loss: 0.2526 - val_accuracy: 0.9927\n",
            "Epoch 466/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0141 - accuracy: 0.9973 - val_loss: 0.2234 - val_accuracy: 0.9933\n",
            "Epoch 467/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0096 - accuracy: 0.9974 - val_loss: 0.3035 - val_accuracy: 0.9945\n",
            "Epoch 468/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0055 - accuracy: 0.9988 - val_loss: 0.2916 - val_accuracy: 0.9939\n",
            "Epoch 469/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0069 - accuracy: 0.9982 - val_loss: 0.2966 - val_accuracy: 0.9945\n",
            "Epoch 470/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0139 - accuracy: 0.9970 - val_loss: 0.1882 - val_accuracy: 0.9891\n",
            "Epoch 471/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0149 - accuracy: 0.9968 - val_loss: 0.1364 - val_accuracy: 0.9939\n",
            "Epoch 472/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0127 - accuracy: 0.9974 - val_loss: 0.3168 - val_accuracy: 0.9933\n",
            "Epoch 473/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0227 - accuracy: 0.9965 - val_loss: 0.2222 - val_accuracy: 0.9915\n",
            "Epoch 474/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0304 - accuracy: 0.9959 - val_loss: 0.1014 - val_accuracy: 0.9794\n",
            "Epoch 475/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0158 - accuracy: 0.9958 - val_loss: 0.3029 - val_accuracy: 0.9860\n",
            "Epoch 476/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0063 - accuracy: 0.9988 - val_loss: 0.2065 - val_accuracy: 0.9915\n",
            "Epoch 477/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0059 - accuracy: 0.9988 - val_loss: 0.1512 - val_accuracy: 0.9945\n",
            "Epoch 478/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0176 - accuracy: 0.9986 - val_loss: 0.1607 - val_accuracy: 0.9933\n",
            "Epoch 479/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0039 - accuracy: 0.9992 - val_loss: 0.2253 - val_accuracy: 0.9945\n",
            "Epoch 480/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0053 - accuracy: 0.9988 - val_loss: 0.2103 - val_accuracy: 0.9945\n",
            "Epoch 481/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0058 - accuracy: 0.9985 - val_loss: 0.2623 - val_accuracy: 0.9915\n",
            "Epoch 482/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0143 - accuracy: 0.9982 - val_loss: 0.1487 - val_accuracy: 0.9958\n",
            "Epoch 483/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0059 - accuracy: 0.9983 - val_loss: 0.2046 - val_accuracy: 0.9964\n",
            "Epoch 484/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0020 - accuracy: 0.9997 - val_loss: 0.2386 - val_accuracy: 0.9939\n",
            "Epoch 485/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0169 - accuracy: 0.9977 - val_loss: 0.1824 - val_accuracy: 0.9915\n",
            "Epoch 486/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0060 - accuracy: 0.9988 - val_loss: 0.1476 - val_accuracy: 0.9927\n",
            "Epoch 487/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0040 - accuracy: 0.9992 - val_loss: 0.1743 - val_accuracy: 0.9921\n",
            "Epoch 488/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0131 - accuracy: 0.9968 - val_loss: 0.1679 - val_accuracy: 0.9903\n",
            "Epoch 489/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0234 - accuracy: 0.9944 - val_loss: 0.1807 - val_accuracy: 0.9879\n",
            "Epoch 490/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0400 - accuracy: 0.9956 - val_loss: 0.1371 - val_accuracy: 0.9806\n",
            "Epoch 491/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0448 - accuracy: 0.9935 - val_loss: 0.1694 - val_accuracy: 0.9903\n",
            "Epoch 492/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0178 - accuracy: 0.9951 - val_loss: 0.1904 - val_accuracy: 0.9927\n",
            "Epoch 493/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0089 - accuracy: 0.9979 - val_loss: 0.2543 - val_accuracy: 0.9927\n",
            "Epoch 494/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0089 - accuracy: 0.9979 - val_loss: 0.2916 - val_accuracy: 0.9927\n",
            "Epoch 495/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0348 - accuracy: 0.9983 - val_loss: 0.2141 - val_accuracy: 0.9927\n",
            "Epoch 496/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0098 - accuracy: 0.9983 - val_loss: 0.3526 - val_accuracy: 0.9885\n",
            "Epoch 497/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0070 - accuracy: 0.9985 - val_loss: 0.1286 - val_accuracy: 0.9933\n",
            "Epoch 498/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0058 - accuracy: 0.9988 - val_loss: 0.1505 - val_accuracy: 0.9933\n",
            "Epoch 499/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0050 - accuracy: 0.9986 - val_loss: 0.1425 - val_accuracy: 0.9933\n",
            "Epoch 500/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0086 - accuracy: 0.9979 - val_loss: 0.3403 - val_accuracy: 0.9885\n",
            "Epoch 501/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0115 - accuracy: 0.9982 - val_loss: 0.1647 - val_accuracy: 0.9927\n",
            "Epoch 502/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0312 - accuracy: 0.9968 - val_loss: 0.3177 - val_accuracy: 0.9879\n",
            "Epoch 503/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0186 - accuracy: 0.9950 - val_loss: 0.2666 - val_accuracy: 0.9897\n",
            "Epoch 504/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0640 - accuracy: 0.9936 - val_loss: 0.2377 - val_accuracy: 0.9885\n",
            "Epoch 505/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0168 - accuracy: 0.9961 - val_loss: 0.5726 - val_accuracy: 0.9903\n",
            "Epoch 506/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0135 - accuracy: 0.9976 - val_loss: 0.6163 - val_accuracy: 0.9818\n",
            "Epoch 507/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0286 - accuracy: 0.9970 - val_loss: 0.2978 - val_accuracy: 0.9903\n",
            "Epoch 508/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0131 - accuracy: 0.9974 - val_loss: 0.0864 - val_accuracy: 0.9958\n",
            "Epoch 509/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0078 - accuracy: 0.9980 - val_loss: 0.2280 - val_accuracy: 0.9939\n",
            "Epoch 510/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0057 - accuracy: 0.9986 - val_loss: 0.2408 - val_accuracy: 0.9939\n",
            "Epoch 511/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0040 - accuracy: 0.9992 - val_loss: 0.2329 - val_accuracy: 0.9939\n",
            "Epoch 512/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0036 - accuracy: 0.9994 - val_loss: 0.2432 - val_accuracy: 0.9939\n",
            "Epoch 513/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0049 - accuracy: 0.9989 - val_loss: 0.3553 - val_accuracy: 0.9927\n",
            "Epoch 514/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0044 - accuracy: 0.9991 - val_loss: 0.3582 - val_accuracy: 0.9933\n",
            "Epoch 515/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0045 - accuracy: 0.9988 - val_loss: 0.3004 - val_accuracy: 0.9939\n",
            "Epoch 516/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0095 - accuracy: 0.9985 - val_loss: 0.2092 - val_accuracy: 0.9921\n",
            "Epoch 517/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0109 - accuracy: 0.9980 - val_loss: 0.2301 - val_accuracy: 0.9933\n",
            "Epoch 518/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0074 - accuracy: 0.9983 - val_loss: 0.2384 - val_accuracy: 0.9939\n",
            "Epoch 519/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0117 - accuracy: 0.9980 - val_loss: 0.0728 - val_accuracy: 0.9939\n",
            "Epoch 520/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0107 - accuracy: 0.9973 - val_loss: 0.1056 - val_accuracy: 0.9939\n",
            "Epoch 521/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0186 - accuracy: 0.9973 - val_loss: 0.3096 - val_accuracy: 0.9903\n",
            "Epoch 522/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0184 - accuracy: 0.9967 - val_loss: 0.1686 - val_accuracy: 0.9921\n",
            "Epoch 523/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0174 - accuracy: 0.9958 - val_loss: 0.0994 - val_accuracy: 0.9945\n",
            "Epoch 524/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0285 - accuracy: 0.9961 - val_loss: 0.1476 - val_accuracy: 0.9933\n",
            "Epoch 525/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0143 - accuracy: 0.9970 - val_loss: 0.1561 - val_accuracy: 0.9945\n",
            "Epoch 526/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0104 - accuracy: 0.9974 - val_loss: 0.3076 - val_accuracy: 0.9915\n",
            "Epoch 527/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0087 - accuracy: 0.9980 - val_loss: 0.1329 - val_accuracy: 0.9945\n",
            "Epoch 528/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0193 - accuracy: 0.9970 - val_loss: 0.2154 - val_accuracy: 0.9939\n",
            "Epoch 529/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0076 - accuracy: 0.9980 - val_loss: 0.2830 - val_accuracy: 0.9951\n",
            "Epoch 530/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0120 - accuracy: 0.9980 - val_loss: 0.1691 - val_accuracy: 0.9921\n",
            "Epoch 531/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0066 - accuracy: 0.9982 - val_loss: 0.3101 - val_accuracy: 0.9927\n",
            "Epoch 532/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0383 - accuracy: 0.9980 - val_loss: 0.5007 - val_accuracy: 0.8337\n",
            "Epoch 533/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0138 - accuracy: 0.9965 - val_loss: 0.1456 - val_accuracy: 0.9927\n",
            "Epoch 534/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0084 - accuracy: 0.9985 - val_loss: 0.0994 - val_accuracy: 0.9933\n",
            "Epoch 535/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0154 - accuracy: 0.9976 - val_loss: 0.1061 - val_accuracy: 0.9945\n",
            "Epoch 536/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0104 - accuracy: 0.9976 - val_loss: 0.1692 - val_accuracy: 0.9933\n",
            "Epoch 537/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0069 - accuracy: 0.9985 - val_loss: 0.1667 - val_accuracy: 0.9933\n",
            "Epoch 538/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0062 - accuracy: 0.9991 - val_loss: 0.2113 - val_accuracy: 0.9927\n",
            "Epoch 539/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0949 - accuracy: 0.9939 - val_loss: 0.1975 - val_accuracy: 0.9927\n",
            "Epoch 540/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0305 - accuracy: 0.9938 - val_loss: 0.1395 - val_accuracy: 0.9939\n",
            "Epoch 541/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0122 - accuracy: 0.9971 - val_loss: 0.2673 - val_accuracy: 0.9927\n",
            "Epoch 542/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0042 - accuracy: 0.9995 - val_loss: 0.2427 - val_accuracy: 0.9927\n",
            "Epoch 543/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0131 - accuracy: 0.9985 - val_loss: 0.1445 - val_accuracy: 0.9939\n",
            "Epoch 544/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0090 - accuracy: 0.9980 - val_loss: 0.2116 - val_accuracy: 0.9915\n",
            "Epoch 545/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0104 - accuracy: 0.9977 - val_loss: 0.1792 - val_accuracy: 0.9951\n",
            "Epoch 546/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0220 - accuracy: 0.9964 - val_loss: 0.3461 - val_accuracy: 0.9860\n",
            "Epoch 547/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0083 - accuracy: 0.9983 - val_loss: 0.1705 - val_accuracy: 0.9939\n",
            "Epoch 548/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0093 - accuracy: 0.9979 - val_loss: 0.1635 - val_accuracy: 0.9958\n",
            "Epoch 549/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0605 - accuracy: 0.9979 - val_loss: 0.3575 - val_accuracy: 0.9891\n",
            "Epoch 550/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0247 - accuracy: 0.9974 - val_loss: 0.3760 - val_accuracy: 0.9891\n",
            "Epoch 551/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0188 - accuracy: 0.9954 - val_loss: 0.5559 - val_accuracy: 0.9757\n",
            "Epoch 552/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0215 - accuracy: 0.9970 - val_loss: 0.1420 - val_accuracy: 0.9933\n",
            "Epoch 553/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0158 - accuracy: 0.9967 - val_loss: 0.0664 - val_accuracy: 0.9933\n",
            "Epoch 554/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0193 - accuracy: 0.9951 - val_loss: 0.0698 - val_accuracy: 0.9927\n",
            "Epoch 555/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0077 - accuracy: 0.9983 - val_loss: 0.1735 - val_accuracy: 0.9921\n",
            "Epoch 556/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0283 - accuracy: 0.9977 - val_loss: 0.0938 - val_accuracy: 0.9939\n",
            "Epoch 557/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0222 - accuracy: 0.9954 - val_loss: 0.2215 - val_accuracy: 0.9909\n",
            "Epoch 558/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0114 - accuracy: 0.9976 - val_loss: 0.1677 - val_accuracy: 0.9921\n",
            "Epoch 559/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0171 - accuracy: 0.9973 - val_loss: 0.2225 - val_accuracy: 0.9915\n",
            "Epoch 560/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0095 - accuracy: 0.9980 - val_loss: 0.1151 - val_accuracy: 0.9939\n",
            "Epoch 561/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0114 - accuracy: 0.9979 - val_loss: 0.1246 - val_accuracy: 0.9945\n",
            "Epoch 562/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0095 - accuracy: 0.9977 - val_loss: 0.1591 - val_accuracy: 0.9958\n",
            "Epoch 563/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0093 - accuracy: 0.9977 - val_loss: 0.2417 - val_accuracy: 0.9951\n",
            "Epoch 564/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0043 - accuracy: 0.9991 - val_loss: 0.2155 - val_accuracy: 0.9945\n",
            "Epoch 565/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0072 - accuracy: 0.9988 - val_loss: 0.1729 - val_accuracy: 0.9958\n",
            "Epoch 566/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0280 - accuracy: 0.9964 - val_loss: 0.2488 - val_accuracy: 0.9897\n",
            "Epoch 567/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0165 - accuracy: 0.9970 - val_loss: 0.2306 - val_accuracy: 0.9933\n",
            "Epoch 568/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0070 - accuracy: 0.9983 - val_loss: 0.2518 - val_accuracy: 0.9915\n",
            "Epoch 569/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0061 - accuracy: 0.9988 - val_loss: 0.3655 - val_accuracy: 0.9897\n",
            "Epoch 570/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0156 - accuracy: 0.9982 - val_loss: 0.2129 - val_accuracy: 0.9879\n",
            "Epoch 571/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0216 - accuracy: 0.9950 - val_loss: 0.2049 - val_accuracy: 0.9958\n",
            "Epoch 572/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0111 - accuracy: 0.9971 - val_loss: 0.1493 - val_accuracy: 0.9939\n",
            "Epoch 573/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0391 - accuracy: 0.9945 - val_loss: 0.0885 - val_accuracy: 0.9939\n",
            "Epoch 574/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0151 - accuracy: 0.9964 - val_loss: 0.0807 - val_accuracy: 0.9945\n",
            "Epoch 575/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0047 - accuracy: 0.9991 - val_loss: 0.1603 - val_accuracy: 0.9939\n",
            "Epoch 576/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0053 - accuracy: 0.9988 - val_loss: 0.2416 - val_accuracy: 0.9921\n",
            "Epoch 577/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0227 - accuracy: 0.9968 - val_loss: 0.0507 - val_accuracy: 0.9945\n",
            "Epoch 578/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0139 - accuracy: 0.9965 - val_loss: 0.1660 - val_accuracy: 0.9927\n",
            "Epoch 579/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0084 - accuracy: 0.9986 - val_loss: 0.3798 - val_accuracy: 0.9939\n",
            "Epoch 580/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0234 - accuracy: 0.9976 - val_loss: 0.6460 - val_accuracy: 0.9873\n",
            "Epoch 581/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0091 - accuracy: 0.9977 - val_loss: 0.1612 - val_accuracy: 0.9939\n",
            "Epoch 582/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0426 - accuracy: 0.9980 - val_loss: 0.4194 - val_accuracy: 0.9903\n",
            "Epoch 583/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0153 - accuracy: 0.9980 - val_loss: 0.3175 - val_accuracy: 0.9903\n",
            "Epoch 584/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0100 - accuracy: 0.9976 - val_loss: 0.2455 - val_accuracy: 0.9921\n",
            "Epoch 585/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0063 - accuracy: 0.9986 - val_loss: 0.2806 - val_accuracy: 0.9927\n",
            "Epoch 586/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0108 - accuracy: 0.9977 - val_loss: 0.1720 - val_accuracy: 0.9951\n",
            "Epoch 587/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0314 - accuracy: 0.9965 - val_loss: 0.1420 - val_accuracy: 0.9915\n",
            "Epoch 588/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0093 - accuracy: 0.9983 - val_loss: 0.1349 - val_accuracy: 0.9939\n",
            "Epoch 589/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0170 - accuracy: 0.9974 - val_loss: 0.2216 - val_accuracy: 0.9927\n",
            "Epoch 590/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0063 - accuracy: 0.9985 - val_loss: 0.3939 - val_accuracy: 0.9903\n",
            "Epoch 591/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0124 - accuracy: 0.9982 - val_loss: 0.2415 - val_accuracy: 0.9921\n",
            "Epoch 592/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0152 - accuracy: 0.9976 - val_loss: 0.6412 - val_accuracy: 0.9891\n",
            "Epoch 593/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0090 - accuracy: 0.9979 - val_loss: 0.5939 - val_accuracy: 0.9806\n",
            "Epoch 594/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0182 - accuracy: 0.9977 - val_loss: 0.2230 - val_accuracy: 0.9945\n",
            "Epoch 595/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0037 - accuracy: 0.9992 - val_loss: 0.3416 - val_accuracy: 0.9897\n",
            "Epoch 596/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0063 - accuracy: 0.9986 - val_loss: 0.3557 - val_accuracy: 0.9921\n",
            "Epoch 597/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0121 - accuracy: 0.9980 - val_loss: 0.2438 - val_accuracy: 0.9945\n",
            "Epoch 598/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0060 - accuracy: 0.9989 - val_loss: 0.2819 - val_accuracy: 0.9945\n",
            "Epoch 599/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0043 - accuracy: 0.9991 - val_loss: 0.2824 - val_accuracy: 0.9945\n",
            "Epoch 600/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0044 - accuracy: 0.9991 - val_loss: 0.2589 - val_accuracy: 0.9951\n",
            "Epoch 601/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0049 - accuracy: 0.9989 - val_loss: 0.2696 - val_accuracy: 0.9945\n",
            "Epoch 602/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0047 - accuracy: 0.9989 - val_loss: 0.2758 - val_accuracy: 0.9939\n",
            "Epoch 603/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0086 - accuracy: 0.9979 - val_loss: 0.2628 - val_accuracy: 0.9951\n",
            "Epoch 604/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0026 - accuracy: 0.9995 - val_loss: 0.2764 - val_accuracy: 0.9945\n",
            "Epoch 605/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0599 - accuracy: 0.9974 - val_loss: 0.2092 - val_accuracy: 0.9915\n",
            "Epoch 606/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0054 - accuracy: 0.9989 - val_loss: 0.4462 - val_accuracy: 0.9921\n",
            "Epoch 607/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0070 - accuracy: 0.9982 - val_loss: 0.4993 - val_accuracy: 0.9909\n",
            "Epoch 608/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0076 - accuracy: 0.9982 - val_loss: 0.4167 - val_accuracy: 0.9933\n",
            "Epoch 609/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0082 - accuracy: 0.9980 - val_loss: 0.3656 - val_accuracy: 0.9927\n",
            "Epoch 610/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0113 - accuracy: 0.9983 - val_loss: 0.3897 - val_accuracy: 0.9921\n",
            "Epoch 611/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0047 - accuracy: 0.9991 - val_loss: 0.3503 - val_accuracy: 0.9927\n",
            "Epoch 612/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0252 - accuracy: 0.9959 - val_loss: 0.2778 - val_accuracy: 0.9927\n",
            "Epoch 613/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0100 - accuracy: 0.9977 - val_loss: 0.4512 - val_accuracy: 0.9933\n",
            "Epoch 614/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0066 - accuracy: 0.9983 - val_loss: 0.4995 - val_accuracy: 0.9933\n",
            "Epoch 615/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0044 - accuracy: 0.9989 - val_loss: 0.2726 - val_accuracy: 0.9939\n",
            "Epoch 616/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0065 - accuracy: 0.9985 - val_loss: 0.2881 - val_accuracy: 0.9945\n",
            "Epoch 617/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0047 - accuracy: 0.9989 - val_loss: 0.3601 - val_accuracy: 0.9933\n",
            "Epoch 618/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0048 - accuracy: 0.9988 - val_loss: 0.3166 - val_accuracy: 0.9945\n",
            "Epoch 619/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0366 - accuracy: 0.9956 - val_loss: 0.2156 - val_accuracy: 0.9945\n",
            "Epoch 620/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0174 - accuracy: 0.9974 - val_loss: 0.3205 - val_accuracy: 0.9909\n",
            "Epoch 621/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0216 - accuracy: 0.9954 - val_loss: 0.3197 - val_accuracy: 0.9921\n",
            "Epoch 622/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0102 - accuracy: 0.9979 - val_loss: 0.3413 - val_accuracy: 0.9903\n",
            "Epoch 623/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0103 - accuracy: 0.9979 - val_loss: 0.2409 - val_accuracy: 0.9945\n",
            "Epoch 624/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0059 - accuracy: 0.9986 - val_loss: 0.2748 - val_accuracy: 0.9945\n",
            "Epoch 625/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0112 - accuracy: 0.9979 - val_loss: 0.2766 - val_accuracy: 0.9939\n",
            "Epoch 626/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0130 - accuracy: 0.9980 - val_loss: 0.2984 - val_accuracy: 0.9939\n",
            "Epoch 627/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.4218 - val_accuracy: 0.9915\n",
            "Epoch 628/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0079 - accuracy: 0.9983 - val_loss: 0.1998 - val_accuracy: 0.9951\n",
            "Epoch 629/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0365 - accuracy: 0.9964 - val_loss: 0.3587 - val_accuracy: 0.9873\n",
            "Epoch 630/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0172 - accuracy: 0.9980 - val_loss: 0.0944 - val_accuracy: 0.9976\n",
            "Epoch 631/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0076 - accuracy: 0.9989 - val_loss: 0.1520 - val_accuracy: 0.9958\n",
            "Epoch 632/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0058 - accuracy: 0.9986 - val_loss: 0.2229 - val_accuracy: 0.9939\n",
            "Epoch 633/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0082 - accuracy: 0.9977 - val_loss: 0.1546 - val_accuracy: 0.9970\n",
            "Epoch 634/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.1796 - val_accuracy: 0.9964\n",
            "Epoch 635/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0125 - accuracy: 0.9982 - val_loss: 0.1553 - val_accuracy: 0.9958\n",
            "Epoch 636/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0062 - accuracy: 0.9983 - val_loss: 0.2153 - val_accuracy: 0.9951\n",
            "Epoch 637/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0078 - accuracy: 0.9983 - val_loss: 0.1882 - val_accuracy: 0.9964\n",
            "Epoch 638/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 0.1901 - val_accuracy: 0.9970\n",
            "Epoch 639/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0229 - accuracy: 0.9979 - val_loss: 0.1347 - val_accuracy: 0.9964\n",
            "Epoch 640/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0135 - accuracy: 0.9986 - val_loss: 0.3508 - val_accuracy: 0.9915\n",
            "Epoch 641/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0439 - accuracy: 0.9977 - val_loss: 0.0871 - val_accuracy: 0.9830\n",
            "Epoch 642/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0229 - accuracy: 0.9950 - val_loss: 0.2605 - val_accuracy: 0.9927\n",
            "Epoch 643/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0086 - accuracy: 0.9982 - val_loss: 0.2522 - val_accuracy: 0.9927\n",
            "Epoch 644/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0090 - accuracy: 0.9979 - val_loss: 0.1746 - val_accuracy: 0.9939\n",
            "Epoch 645/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0094 - accuracy: 0.9983 - val_loss: 0.2713 - val_accuracy: 0.9921\n",
            "Epoch 646/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0094 - accuracy: 0.9976 - val_loss: 0.3672 - val_accuracy: 0.9909\n",
            "Epoch 647/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0074 - accuracy: 0.9985 - val_loss: 0.3058 - val_accuracy: 0.9939\n",
            "Epoch 648/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0079 - accuracy: 0.9982 - val_loss: 0.2458 - val_accuracy: 0.9933\n",
            "Epoch 649/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0081 - accuracy: 0.9982 - val_loss: 0.1741 - val_accuracy: 0.9945\n",
            "Epoch 650/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0036 - accuracy: 0.9989 - val_loss: 0.2632 - val_accuracy: 0.9921\n",
            "Epoch 651/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0048 - accuracy: 0.9989 - val_loss: 0.2732 - val_accuracy: 0.9933\n",
            "Epoch 652/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0035 - accuracy: 0.9992 - val_loss: 0.2680 - val_accuracy: 0.9933\n",
            "Epoch 653/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0167 - accuracy: 0.9977 - val_loss: 0.1283 - val_accuracy: 0.9951\n",
            "Epoch 654/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0104 - accuracy: 0.9976 - val_loss: 0.1758 - val_accuracy: 0.9927\n",
            "Epoch 655/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0081 - accuracy: 0.9985 - val_loss: 0.4930 - val_accuracy: 0.9848\n",
            "Epoch 656/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0107 - accuracy: 0.9982 - val_loss: 0.2236 - val_accuracy: 0.9958\n",
            "Epoch 657/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0504 - accuracy: 0.9970 - val_loss: 0.1433 - val_accuracy: 0.9939\n",
            "Epoch 658/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0172 - accuracy: 0.9968 - val_loss: 0.1473 - val_accuracy: 0.9927\n",
            "Epoch 659/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0134 - accuracy: 0.9970 - val_loss: 0.1767 - val_accuracy: 0.9939\n",
            "Epoch 660/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0119 - accuracy: 0.9982 - val_loss: 0.0717 - val_accuracy: 0.9915\n",
            "Epoch 661/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0116 - accuracy: 0.9977 - val_loss: 0.1086 - val_accuracy: 0.9945\n",
            "Epoch 662/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0043 - accuracy: 0.9988 - val_loss: 0.1482 - val_accuracy: 0.9951\n",
            "Epoch 663/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0152 - accuracy: 0.9970 - val_loss: 0.3985 - val_accuracy: 0.9897\n",
            "Epoch 664/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0065 - accuracy: 0.9989 - val_loss: 0.1578 - val_accuracy: 0.9958\n",
            "Epoch 665/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0671 - accuracy: 0.9965 - val_loss: 0.1767 - val_accuracy: 0.9897\n",
            "Epoch 666/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0154 - accuracy: 0.9971 - val_loss: 0.2492 - val_accuracy: 0.9915\n",
            "Epoch 667/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0245 - accuracy: 0.9967 - val_loss: 0.2772 - val_accuracy: 0.9909\n",
            "Epoch 668/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0223 - accuracy: 0.9971 - val_loss: 0.1710 - val_accuracy: 0.9933\n",
            "Epoch 669/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0361 - accuracy: 0.9974 - val_loss: 0.3961 - val_accuracy: 0.9915\n",
            "Epoch 670/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0149 - accuracy: 0.9974 - val_loss: 0.2023 - val_accuracy: 0.9939\n",
            "Epoch 671/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0110 - accuracy: 0.9977 - val_loss: 0.2335 - val_accuracy: 0.9921\n",
            "Epoch 672/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0106 - accuracy: 0.9980 - val_loss: 0.1705 - val_accuracy: 0.9945\n",
            "Epoch 673/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0162 - accuracy: 0.9968 - val_loss: 0.1112 - val_accuracy: 0.9945\n",
            "Epoch 674/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0117 - accuracy: 0.9979 - val_loss: 0.2256 - val_accuracy: 0.9927\n",
            "Epoch 675/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0068 - accuracy: 0.9983 - val_loss: 0.3197 - val_accuracy: 0.9903\n",
            "Epoch 676/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0098 - accuracy: 0.9979 - val_loss: 0.3977 - val_accuracy: 0.9903\n",
            "Epoch 677/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0083 - accuracy: 0.9986 - val_loss: 0.2127 - val_accuracy: 0.9945\n",
            "Epoch 678/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0080 - accuracy: 0.9986 - val_loss: 0.2528 - val_accuracy: 0.9927\n",
            "Epoch 679/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0051 - accuracy: 0.9989 - val_loss: 0.3018 - val_accuracy: 0.9915\n",
            "Epoch 680/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0049 - accuracy: 0.9991 - val_loss: 0.2242 - val_accuracy: 0.9921\n",
            "Epoch 681/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0038 - accuracy: 0.9994 - val_loss: 0.2971 - val_accuracy: 0.9933\n",
            "Epoch 682/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0109 - accuracy: 0.9986 - val_loss: 0.3580 - val_accuracy: 0.9915\n",
            "Epoch 683/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0043 - accuracy: 0.9989 - val_loss: 0.2397 - val_accuracy: 0.9939\n",
            "Epoch 684/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0034 - accuracy: 0.9992 - val_loss: 0.2529 - val_accuracy: 0.9951\n",
            "Epoch 685/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0048 - accuracy: 0.9989 - val_loss: 0.2415 - val_accuracy: 0.9951\n",
            "Epoch 686/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.2374 - val_accuracy: 0.9951\n",
            "Epoch 687/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0074 - accuracy: 0.9985 - val_loss: 0.1124 - val_accuracy: 0.9958\n",
            "Epoch 688/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0039 - accuracy: 0.9989 - val_loss: 0.2829 - val_accuracy: 0.9951\n",
            "Epoch 689/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0331 - accuracy: 0.9973 - val_loss: 0.2307 - val_accuracy: 0.9915\n",
            "Epoch 690/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0142 - accuracy: 0.9986 - val_loss: 0.2176 - val_accuracy: 0.9933\n",
            "Epoch 691/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0213 - accuracy: 0.9964 - val_loss: 0.2157 - val_accuracy: 0.9921\n",
            "Epoch 692/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0109 - accuracy: 0.9970 - val_loss: 0.2243 - val_accuracy: 0.9939\n",
            "Epoch 693/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0233 - accuracy: 0.9983 - val_loss: 0.3197 - val_accuracy: 0.9867\n",
            "Epoch 694/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0126 - accuracy: 0.9979 - val_loss: 0.1425 - val_accuracy: 0.9927\n",
            "Epoch 695/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0076 - accuracy: 0.9982 - val_loss: 0.1991 - val_accuracy: 0.9903\n",
            "Epoch 696/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0081 - accuracy: 0.9979 - val_loss: 0.2624 - val_accuracy: 0.9927\n",
            "Epoch 697/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0065 - accuracy: 0.9986 - val_loss: 0.3480 - val_accuracy: 0.9891\n",
            "Epoch 698/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0079 - accuracy: 0.9982 - val_loss: 0.4355 - val_accuracy: 0.9945\n",
            "Epoch 699/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0021 - accuracy: 0.9997 - val_loss: 0.5151 - val_accuracy: 0.9945\n",
            "Epoch 700/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0116 - accuracy: 0.9979 - val_loss: 0.2885 - val_accuracy: 0.9903\n",
            "Epoch 701/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0040 - accuracy: 0.9992 - val_loss: 0.2137 - val_accuracy: 0.9933\n",
            "Epoch 702/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0106 - accuracy: 0.9988 - val_loss: 0.2414 - val_accuracy: 0.9921\n",
            "Epoch 703/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0075 - accuracy: 0.9985 - val_loss: 0.1692 - val_accuracy: 0.9939\n",
            "Epoch 704/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0078 - accuracy: 0.9989 - val_loss: 0.2279 - val_accuracy: 0.9939\n",
            "Epoch 705/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0067 - accuracy: 0.9985 - val_loss: 0.1676 - val_accuracy: 0.9933\n",
            "Epoch 706/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2184 - val_accuracy: 0.9933\n",
            "Epoch 707/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0039 - accuracy: 0.9992 - val_loss: 0.2135 - val_accuracy: 0.9939\n",
            "Epoch 708/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0057 - accuracy: 0.9992 - val_loss: 0.1711 - val_accuracy: 0.9939\n",
            "Epoch 709/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.1711 - val_accuracy: 0.9939\n",
            "Epoch 710/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0047 - accuracy: 0.9989 - val_loss: 0.2073 - val_accuracy: 0.9933\n",
            "Epoch 711/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.2641 - val_accuracy: 0.9891\n",
            "Epoch 712/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0041 - accuracy: 0.9991 - val_loss: 0.2075 - val_accuracy: 0.9909\n",
            "Epoch 713/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0298 - accuracy: 0.9977 - val_loss: 0.3207 - val_accuracy: 0.9873\n",
            "Epoch 714/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0133 - accuracy: 0.9974 - val_loss: 0.5733 - val_accuracy: 0.9830\n",
            "Epoch 715/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0130 - accuracy: 0.9979 - val_loss: 0.2761 - val_accuracy: 0.9921\n",
            "Epoch 716/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0204 - accuracy: 0.9986 - val_loss: 0.3307 - val_accuracy: 0.9909\n",
            "Epoch 717/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0068 - accuracy: 0.9983 - val_loss: 0.3233 - val_accuracy: 0.9915\n",
            "Epoch 718/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0200 - accuracy: 0.9973 - val_loss: 0.2196 - val_accuracy: 0.9903\n",
            "Epoch 719/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0085 - accuracy: 0.9991 - val_loss: 0.4913 - val_accuracy: 0.9897\n",
            "Epoch 720/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0074 - accuracy: 0.9986 - val_loss: 0.3294 - val_accuracy: 0.9939\n",
            "Epoch 721/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0033 - accuracy: 0.9995 - val_loss: 0.4804 - val_accuracy: 0.9885\n",
            "Epoch 722/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0056 - accuracy: 0.9988 - val_loss: 0.4228 - val_accuracy: 0.9933\n",
            "Epoch 723/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0042 - accuracy: 0.9991 - val_loss: 0.1760 - val_accuracy: 0.9939\n",
            "Epoch 724/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0039 - accuracy: 0.9992 - val_loss: 0.2475 - val_accuracy: 0.9939\n",
            "Epoch 725/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1611 - accuracy: 0.9935 - val_loss: 0.2587 - val_accuracy: 0.9939\n",
            "Epoch 726/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0150 - accuracy: 0.9968 - val_loss: 0.1717 - val_accuracy: 0.9933\n",
            "Epoch 727/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0203 - accuracy: 0.9959 - val_loss: 0.4878 - val_accuracy: 0.9782\n",
            "Epoch 728/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0120 - accuracy: 0.9976 - val_loss: 0.3586 - val_accuracy: 0.9903\n",
            "Epoch 729/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0647 - accuracy: 0.9950 - val_loss: 0.1466 - val_accuracy: 0.9939\n",
            "Epoch 730/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0143 - accuracy: 0.9973 - val_loss: 0.2381 - val_accuracy: 0.9891\n",
            "Epoch 731/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0088 - accuracy: 0.9983 - val_loss: 0.2420 - val_accuracy: 0.9909\n",
            "Epoch 732/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0042 - accuracy: 0.9994 - val_loss: 0.2702 - val_accuracy: 0.9915\n",
            "Epoch 733/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0106 - accuracy: 0.9986 - val_loss: 0.2570 - val_accuracy: 0.9915\n",
            "Epoch 734/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0132 - accuracy: 0.9976 - val_loss: 0.2491 - val_accuracy: 0.9927\n",
            "Epoch 735/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0100 - accuracy: 0.9988 - val_loss: 0.3224 - val_accuracy: 0.9915\n",
            "Epoch 736/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0117 - accuracy: 0.9979 - val_loss: 0.3517 - val_accuracy: 0.9915\n",
            "Epoch 737/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0098 - accuracy: 0.9976 - val_loss: 0.1681 - val_accuracy: 0.9915\n",
            "Epoch 738/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0045 - accuracy: 0.9991 - val_loss: 0.2253 - val_accuracy: 0.9915\n",
            "Epoch 739/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0087 - accuracy: 0.9986 - val_loss: 0.1757 - val_accuracy: 0.9933\n",
            "Epoch 740/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0043 - accuracy: 0.9992 - val_loss: 0.2162 - val_accuracy: 0.9927\n",
            "Epoch 741/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0090 - accuracy: 0.9985 - val_loss: 0.2119 - val_accuracy: 0.9927\n",
            "Epoch 742/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.2231 - val_accuracy: 0.9939\n",
            "Epoch 743/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0053 - accuracy: 0.9989 - val_loss: 0.2173 - val_accuracy: 0.9945\n",
            "Epoch 744/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.4188 - val_accuracy: 0.9891\n",
            "Epoch 745/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0519 - accuracy: 0.9964 - val_loss: 0.1558 - val_accuracy: 0.9933\n",
            "Epoch 746/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0087 - accuracy: 0.9980 - val_loss: 0.2027 - val_accuracy: 0.9915\n",
            "Epoch 747/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0051 - accuracy: 0.9988 - val_loss: 0.2691 - val_accuracy: 0.9939\n",
            "Epoch 748/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0127 - accuracy: 0.9971 - val_loss: 0.3179 - val_accuracy: 0.9873\n",
            "Epoch 749/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0072 - accuracy: 0.9986 - val_loss: 0.3354 - val_accuracy: 0.9897\n",
            "Epoch 750/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0104 - accuracy: 0.9979 - val_loss: 0.2404 - val_accuracy: 0.9927\n",
            "Epoch 751/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0230 - accuracy: 0.9980 - val_loss: 0.3089 - val_accuracy: 0.9945\n",
            "Epoch 752/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0029 - accuracy: 0.9995 - val_loss: 0.3544 - val_accuracy: 0.9939\n",
            "Epoch 753/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0054 - accuracy: 0.9989 - val_loss: 0.2894 - val_accuracy: 0.9939\n",
            "Epoch 754/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0080 - accuracy: 0.9986 - val_loss: 0.2731 - val_accuracy: 0.9939\n",
            "Epoch 755/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0058 - accuracy: 0.9986 - val_loss: 0.4105 - val_accuracy: 0.9909\n",
            "Epoch 756/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.3140 - val_accuracy: 0.9921\n",
            "Epoch 757/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0536 - accuracy: 0.9977 - val_loss: 0.4704 - val_accuracy: 0.9879\n",
            "Epoch 758/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0085 - accuracy: 0.9986 - val_loss: 0.5313 - val_accuracy: 0.9885\n",
            "Epoch 759/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0318 - accuracy: 0.9988 - val_loss: 0.3813 - val_accuracy: 0.9921\n",
            "Epoch 760/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0161 - accuracy: 0.9988 - val_loss: 0.2264 - val_accuracy: 0.9909\n",
            "Epoch 761/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0094 - accuracy: 0.9983 - val_loss: 0.2124 - val_accuracy: 0.9915\n",
            "Epoch 762/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0063 - accuracy: 0.9985 - val_loss: 0.2445 - val_accuracy: 0.9933\n",
            "Epoch 763/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0076 - accuracy: 0.9989 - val_loss: 0.2320 - val_accuracy: 0.9909\n",
            "Epoch 764/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0036 - accuracy: 0.9994 - val_loss: 0.2657 - val_accuracy: 0.9933\n",
            "Epoch 765/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0149 - accuracy: 0.9983 - val_loss: 0.1558 - val_accuracy: 0.9909\n",
            "Epoch 766/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0141 - accuracy: 0.9977 - val_loss: 0.4052 - val_accuracy: 0.9873\n",
            "Epoch 767/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0138 - accuracy: 0.9985 - val_loss: 0.2091 - val_accuracy: 0.9909\n",
            "Epoch 768/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0067 - accuracy: 0.9983 - val_loss: 0.5603 - val_accuracy: 0.9867\n",
            "Epoch 769/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0163 - accuracy: 0.9980 - val_loss: 0.2694 - val_accuracy: 0.9915\n",
            "Epoch 770/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0295 - accuracy: 0.9979 - val_loss: 0.2203 - val_accuracy: 0.9885\n",
            "Epoch 771/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0448 - accuracy: 0.9967 - val_loss: 0.1280 - val_accuracy: 0.9939\n",
            "Epoch 772/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0070 - accuracy: 0.9985 - val_loss: 0.2084 - val_accuracy: 0.9909\n",
            "Epoch 773/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0051 - accuracy: 0.9989 - val_loss: 0.2382 - val_accuracy: 0.9915\n",
            "Epoch 774/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0055 - accuracy: 0.9989 - val_loss: 0.3243 - val_accuracy: 0.9915\n",
            "Epoch 775/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0059 - accuracy: 0.9988 - val_loss: 0.5884 - val_accuracy: 0.9854\n",
            "Epoch 776/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0069 - accuracy: 0.9983 - val_loss: 0.2926 - val_accuracy: 0.9945\n",
            "Epoch 777/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0029 - accuracy: 0.9995 - val_loss: 0.3562 - val_accuracy: 0.9951\n",
            "Epoch 778/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0016 - accuracy: 0.9998 - val_loss: 0.3610 - val_accuracy: 0.9945\n",
            "Epoch 779/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0040 - accuracy: 0.9994 - val_loss: 0.1867 - val_accuracy: 0.9951\n",
            "Epoch 780/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0154 - accuracy: 0.9983 - val_loss: 0.2043 - val_accuracy: 0.9958\n",
            "Epoch 781/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0040 - accuracy: 0.9992 - val_loss: 0.1947 - val_accuracy: 0.9964\n",
            "Epoch 782/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0153 - accuracy: 0.9994 - val_loss: 0.2831 - val_accuracy: 0.9933\n",
            "Epoch 783/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0096 - accuracy: 0.9986 - val_loss: 0.2305 - val_accuracy: 0.9958\n",
            "Epoch 784/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0071 - accuracy: 0.9983 - val_loss: 0.1867 - val_accuracy: 0.9964\n",
            "Epoch 785/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0087 - accuracy: 0.9988 - val_loss: 0.1973 - val_accuracy: 0.9939\n",
            "Epoch 786/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0368 - accuracy: 0.9968 - val_loss: 0.2070 - val_accuracy: 0.9885\n",
            "Epoch 787/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0088 - accuracy: 0.9983 - val_loss: 0.1653 - val_accuracy: 0.9939\n",
            "Epoch 788/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0147 - accuracy: 0.9988 - val_loss: 0.3775 - val_accuracy: 0.9927\n",
            "Epoch 789/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0112 - accuracy: 0.9995 - val_loss: 0.5054 - val_accuracy: 0.9927\n",
            "Epoch 790/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0046 - accuracy: 0.9992 - val_loss: 0.6717 - val_accuracy: 0.9909\n",
            "Epoch 791/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0072 - accuracy: 0.9997 - val_loss: 0.3972 - val_accuracy: 0.9945\n",
            "Epoch 792/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0076 - accuracy: 0.9985 - val_loss: 0.3975 - val_accuracy: 0.9927\n",
            "Epoch 793/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0081 - accuracy: 0.9983 - val_loss: 0.2179 - val_accuracy: 0.9945\n",
            "Epoch 794/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0057 - accuracy: 0.9988 - val_loss: 0.2268 - val_accuracy: 0.9933\n",
            "Epoch 795/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0040 - accuracy: 0.9991 - val_loss: 0.2319 - val_accuracy: 0.9933\n",
            "Epoch 796/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0149 - accuracy: 0.9992 - val_loss: 0.1508 - val_accuracy: 0.9951\n",
            "Epoch 797/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0047 - accuracy: 0.9989 - val_loss: 0.3175 - val_accuracy: 0.9921\n",
            "Epoch 798/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0062 - accuracy: 0.9985 - val_loss: 0.2769 - val_accuracy: 0.9951\n",
            "Epoch 799/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0033 - accuracy: 0.9992 - val_loss: 0.3720 - val_accuracy: 0.9945\n",
            "Epoch 800/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 0.3433 - val_accuracy: 0.9939\n",
            "Epoch 801/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0017 - accuracy: 0.9997 - val_loss: 0.3411 - val_accuracy: 0.9945\n",
            "Epoch 802/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0054 - accuracy: 0.9991 - val_loss: 0.3006 - val_accuracy: 0.9945\n",
            "Epoch 803/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.2900 - val_accuracy: 0.9939\n",
            "Epoch 804/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0694 - accuracy: 0.9965 - val_loss: 0.1931 - val_accuracy: 0.9903\n",
            "Epoch 805/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0211 - accuracy: 0.9974 - val_loss: 0.1635 - val_accuracy: 0.9927\n",
            "Epoch 806/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0091 - accuracy: 0.9979 - val_loss: 0.3205 - val_accuracy: 0.9867\n",
            "Epoch 807/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0065 - accuracy: 0.9986 - val_loss: 0.2278 - val_accuracy: 0.9945\n",
            "Epoch 808/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0108 - accuracy: 0.9992 - val_loss: 0.1727 - val_accuracy: 0.9921\n",
            "Epoch 809/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0045 - accuracy: 0.9989 - val_loss: 0.1810 - val_accuracy: 0.9933\n",
            "Epoch 810/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.3435 - val_accuracy: 0.9915\n",
            "Epoch 811/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0067 - accuracy: 0.9992 - val_loss: 0.3479 - val_accuracy: 0.9921\n",
            "Epoch 812/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0047 - accuracy: 0.9995 - val_loss: 0.2162 - val_accuracy: 0.9933\n",
            "Epoch 813/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0040 - accuracy: 0.9994 - val_loss: 0.2937 - val_accuracy: 0.9891\n",
            "Epoch 814/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0230 - accuracy: 0.9985 - val_loss: 0.1845 - val_accuracy: 0.9927\n",
            "Epoch 815/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0351 - accuracy: 0.9979 - val_loss: 0.1473 - val_accuracy: 0.9933\n",
            "Epoch 816/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0030 - accuracy: 0.9992 - val_loss: 0.2920 - val_accuracy: 0.9939\n",
            "Epoch 817/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0075 - accuracy: 0.9982 - val_loss: 0.1549 - val_accuracy: 0.9945\n",
            "Epoch 818/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0031 - accuracy: 0.9991 - val_loss: 0.2201 - val_accuracy: 0.9933\n",
            "Epoch 819/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0043 - accuracy: 0.9992 - val_loss: 0.2015 - val_accuracy: 0.9951\n",
            "Epoch 820/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0071 - accuracy: 0.9988 - val_loss: 0.4624 - val_accuracy: 0.9903\n",
            "Epoch 821/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0081 - accuracy: 0.9992 - val_loss: 0.2736 - val_accuracy: 0.9927\n",
            "Epoch 822/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0047 - accuracy: 0.9997 - val_loss: 0.3065 - val_accuracy: 0.9921\n",
            "Epoch 823/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0101 - accuracy: 0.9983 - val_loss: 0.1558 - val_accuracy: 0.9927\n",
            "Epoch 824/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0049 - accuracy: 0.9991 - val_loss: 0.2192 - val_accuracy: 0.9933\n",
            "Epoch 825/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0036 - accuracy: 0.9992 - val_loss: 0.2121 - val_accuracy: 0.9927\n",
            "Epoch 826/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0043 - accuracy: 0.9991 - val_loss: 0.3279 - val_accuracy: 0.9909\n",
            "Epoch 827/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0031 - accuracy: 0.9992 - val_loss: 0.2350 - val_accuracy: 0.9939\n",
            "Epoch 828/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0046 - accuracy: 0.9992 - val_loss: 0.2627 - val_accuracy: 0.9927\n",
            "Epoch 829/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0017 - accuracy: 0.9997 - val_loss: 0.2610 - val_accuracy: 0.9933\n",
            "Epoch 830/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0059 - accuracy: 0.9992 - val_loss: 0.2383 - val_accuracy: 0.9939\n",
            "Epoch 831/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0131 - accuracy: 0.9992 - val_loss: 0.2376 - val_accuracy: 0.9909\n",
            "Epoch 832/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0120 - accuracy: 0.9982 - val_loss: 0.1708 - val_accuracy: 0.9939\n",
            "Epoch 833/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0058 - accuracy: 0.9989 - val_loss: 0.1694 - val_accuracy: 0.9939\n",
            "Epoch 834/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0420 - accuracy: 0.9977 - val_loss: 0.3328 - val_accuracy: 0.9854\n",
            "Epoch 835/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0059 - accuracy: 0.9986 - val_loss: 0.2311 - val_accuracy: 0.9927\n",
            "Epoch 836/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0026 - accuracy: 0.9995 - val_loss: 0.2069 - val_accuracy: 0.9921\n",
            "Epoch 837/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0132 - accuracy: 0.9991 - val_loss: 0.5953 - val_accuracy: 0.9897\n",
            "Epoch 838/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0331 - accuracy: 0.9985 - val_loss: 0.1292 - val_accuracy: 0.9951\n",
            "Epoch 839/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0043 - accuracy: 0.9991 - val_loss: 0.6411 - val_accuracy: 0.9818\n",
            "Epoch 840/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0050 - accuracy: 0.9992 - val_loss: 0.2225 - val_accuracy: 0.9933\n",
            "Epoch 841/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0096 - accuracy: 0.9989 - val_loss: 0.1811 - val_accuracy: 0.9939\n",
            "Epoch 842/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0093 - accuracy: 0.9986 - val_loss: 0.1502 - val_accuracy: 0.9958\n",
            "Epoch 843/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0314 - accuracy: 0.9983 - val_loss: 0.1127 - val_accuracy: 0.9958\n",
            "Epoch 844/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0045 - accuracy: 0.9989 - val_loss: 0.1591 - val_accuracy: 0.9958\n",
            "Epoch 845/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0043 - accuracy: 0.9989 - val_loss: 0.1620 - val_accuracy: 0.9945\n",
            "Epoch 846/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0015 - accuracy: 0.9998 - val_loss: 0.1725 - val_accuracy: 0.9939\n",
            "Epoch 847/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 9.8492e-04 - accuracy: 0.9998 - val_loss: 0.2606 - val_accuracy: 0.9939\n",
            "Epoch 848/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0047 - accuracy: 0.9991 - val_loss: 0.2758 - val_accuracy: 0.9939\n",
            "Epoch 849/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0018 - accuracy: 0.9997 - val_loss: 0.2862 - val_accuracy: 0.9939\n",
            "Epoch 850/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0072 - accuracy: 0.9991 - val_loss: 0.3275 - val_accuracy: 0.9939\n",
            "Epoch 851/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0026 - accuracy: 0.9992 - val_loss: 0.2230 - val_accuracy: 0.9939\n",
            "Epoch 852/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.2466 - val_accuracy: 0.9945\n",
            "Epoch 853/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0020 - accuracy: 0.9997 - val_loss: 0.1375 - val_accuracy: 0.9939\n",
            "Epoch 854/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0038 - accuracy: 0.9992 - val_loss: 0.1605 - val_accuracy: 0.9945\n",
            "Epoch 855/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0082 - accuracy: 0.9988 - val_loss: 0.1448 - val_accuracy: 0.9939\n",
            "Epoch 856/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0271 - accuracy: 0.9974 - val_loss: 0.6000 - val_accuracy: 0.9854\n",
            "Epoch 857/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0075 - accuracy: 0.9992 - val_loss: 0.3854 - val_accuracy: 0.9939\n",
            "Epoch 858/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0134 - accuracy: 0.9986 - val_loss: 0.4198 - val_accuracy: 0.9933\n",
            "Epoch 859/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0272 - accuracy: 0.9964 - val_loss: 0.2411 - val_accuracy: 0.9897\n",
            "Epoch 860/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0035 - accuracy: 0.9991 - val_loss: 0.3006 - val_accuracy: 0.9909\n",
            "Epoch 861/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0043 - accuracy: 0.9992 - val_loss: 0.1653 - val_accuracy: 0.9939\n",
            "Epoch 862/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.2048 - val_accuracy: 0.9921\n",
            "Epoch 863/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0034 - accuracy: 0.9991 - val_loss: 0.2211 - val_accuracy: 0.9933\n",
            "Epoch 864/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0041 - accuracy: 0.9995 - val_loss: 0.2406 - val_accuracy: 0.9933\n",
            "Epoch 865/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0048 - accuracy: 0.9991 - val_loss: 0.2050 - val_accuracy: 0.9939\n",
            "Epoch 866/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.5572 - val_accuracy: 0.9933\n",
            "Epoch 867/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.4203 - val_accuracy: 0.9933\n",
            "Epoch 868/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0057 - accuracy: 0.9989 - val_loss: 0.2004 - val_accuracy: 0.9958\n",
            "Epoch 869/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0255 - accuracy: 0.9983 - val_loss: 0.2843 - val_accuracy: 0.9939\n",
            "Epoch 870/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0249 - accuracy: 0.9968 - val_loss: 0.3182 - val_accuracy: 0.9939\n",
            "Epoch 871/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0091 - accuracy: 0.9985 - val_loss: 0.3536 - val_accuracy: 0.9933\n",
            "Epoch 872/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0055 - accuracy: 0.9991 - val_loss: 0.3523 - val_accuracy: 0.9933\n",
            "Epoch 873/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0069 - accuracy: 0.9986 - val_loss: 0.2316 - val_accuracy: 0.9933\n",
            "Epoch 874/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0046 - accuracy: 0.9991 - val_loss: 0.2913 - val_accuracy: 0.9921\n",
            "Epoch 875/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0089 - accuracy: 0.9977 - val_loss: 0.2855 - val_accuracy: 0.9927\n",
            "Epoch 876/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0078 - accuracy: 0.9986 - val_loss: 0.3375 - val_accuracy: 0.9921\n",
            "Epoch 877/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0041 - accuracy: 0.9991 - val_loss: 0.3409 - val_accuracy: 0.9927\n",
            "Epoch 878/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0059 - accuracy: 0.9986 - val_loss: 0.3592 - val_accuracy: 0.9927\n",
            "Epoch 879/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0095 - accuracy: 0.9983 - val_loss: 0.2967 - val_accuracy: 0.9909\n",
            "Epoch 880/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0040 - accuracy: 0.9989 - val_loss: 0.2205 - val_accuracy: 0.9933\n",
            "Epoch 881/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0061 - accuracy: 0.9991 - val_loss: 0.1971 - val_accuracy: 0.9933\n",
            "Epoch 882/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.2843 - val_accuracy: 0.9921\n",
            "Epoch 883/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0093 - accuracy: 0.9991 - val_loss: 0.3068 - val_accuracy: 0.9921\n",
            "Epoch 884/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0114 - accuracy: 0.9988 - val_loss: 0.1636 - val_accuracy: 0.9927\n",
            "Epoch 885/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0010 - accuracy: 0.9998 - val_loss: 0.2226 - val_accuracy: 0.9921\n",
            "Epoch 886/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0027 - accuracy: 0.9995 - val_loss: 0.3537 - val_accuracy: 0.9915\n",
            "Epoch 887/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0389 - accuracy: 0.9964 - val_loss: 0.2018 - val_accuracy: 0.9933\n",
            "Epoch 888/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0068 - accuracy: 0.9986 - val_loss: 0.1994 - val_accuracy: 0.9958\n",
            "Epoch 889/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0025 - accuracy: 0.9995 - val_loss: 0.2011 - val_accuracy: 0.9958\n",
            "Epoch 890/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0424 - accuracy: 0.9979 - val_loss: 0.1128 - val_accuracy: 0.9945\n",
            "Epoch 891/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0049 - accuracy: 0.9988 - val_loss: 0.2003 - val_accuracy: 0.9927\n",
            "Epoch 892/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0018 - accuracy: 0.9997 - val_loss: 0.4189 - val_accuracy: 0.9867\n",
            "Epoch 893/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0091 - accuracy: 0.9991 - val_loss: 0.2058 - val_accuracy: 0.9939\n",
            "Epoch 894/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0080 - accuracy: 0.9995 - val_loss: 0.2102 - val_accuracy: 0.9939\n",
            "Epoch 895/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0075 - accuracy: 0.9992 - val_loss: 0.1680 - val_accuracy: 0.9945\n",
            "Epoch 896/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.2645 - val_accuracy: 0.9964\n",
            "Epoch 897/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0141 - accuracy: 0.9982 - val_loss: 0.2215 - val_accuracy: 0.9945\n",
            "Epoch 898/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0093 - accuracy: 0.9992 - val_loss: 0.2678 - val_accuracy: 0.9927\n",
            "Epoch 899/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 7.5983e-04 - accuracy: 0.9998 - val_loss: 0.2525 - val_accuracy: 0.9964\n",
            "Epoch 900/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0248 - accuracy: 0.9988 - val_loss: 0.3730 - val_accuracy: 0.9915\n",
            "Epoch 901/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 0.3771 - val_accuracy: 0.9921\n",
            "Epoch 902/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0028 - accuracy: 0.9995 - val_loss: 0.2404 - val_accuracy: 0.9958\n",
            "Epoch 903/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0053 - accuracy: 0.9988 - val_loss: 0.6213 - val_accuracy: 0.9915\n",
            "Epoch 904/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0075 - accuracy: 0.9991 - val_loss: 0.2465 - val_accuracy: 0.9927\n",
            "Epoch 905/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0039 - accuracy: 0.9995 - val_loss: 0.2206 - val_accuracy: 0.9970\n",
            "Epoch 906/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0047 - accuracy: 0.9992 - val_loss: 0.2412 - val_accuracy: 0.9945\n",
            "Epoch 907/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0199 - accuracy: 0.9992 - val_loss: 0.9537 - val_accuracy: 0.9867\n",
            "Epoch 908/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0161 - accuracy: 0.9985 - val_loss: 0.3144 - val_accuracy: 0.9939\n",
            "Epoch 909/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0040 - accuracy: 0.9992 - val_loss: 0.3303 - val_accuracy: 0.9933\n",
            "Epoch 910/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 0.3114 - val_accuracy: 0.9939\n",
            "Epoch 911/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0048 - accuracy: 0.9989 - val_loss: 0.3187 - val_accuracy: 0.9945\n",
            "Epoch 912/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0026 - accuracy: 0.9995 - val_loss: 0.3241 - val_accuracy: 0.9939\n",
            "Epoch 913/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0026 - accuracy: 0.9995 - val_loss: 0.3248 - val_accuracy: 0.9939\n",
            "Epoch 914/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.3382 - val_accuracy: 0.9939\n",
            "Epoch 915/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0140 - accuracy: 0.9989 - val_loss: 0.2164 - val_accuracy: 0.9951\n",
            "Epoch 916/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0034 - accuracy: 0.9992 - val_loss: 0.2357 - val_accuracy: 0.9951\n",
            "Epoch 917/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0450 - accuracy: 0.9962 - val_loss: 0.2745 - val_accuracy: 0.9860\n",
            "Epoch 918/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0338 - accuracy: 0.9971 - val_loss: 0.1476 - val_accuracy: 0.9939\n",
            "Epoch 919/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0063 - accuracy: 0.9985 - val_loss: 0.1656 - val_accuracy: 0.9958\n",
            "Epoch 920/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0037 - accuracy: 0.9992 - val_loss: 0.1934 - val_accuracy: 0.9958\n",
            "Epoch 921/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.2142 - val_accuracy: 0.9958\n",
            "Epoch 922/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0047 - accuracy: 0.9992 - val_loss: 0.1765 - val_accuracy: 0.9951\n",
            "Epoch 923/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0038 - accuracy: 0.9992 - val_loss: 0.2119 - val_accuracy: 0.9951\n",
            "Epoch 924/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.2472 - val_accuracy: 0.9945\n",
            "Epoch 925/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0060 - accuracy: 0.9995 - val_loss: 0.2099 - val_accuracy: 0.9927\n",
            "Epoch 926/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0045 - accuracy: 0.9991 - val_loss: 0.2481 - val_accuracy: 0.9927\n",
            "Epoch 927/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 0.2510 - val_accuracy: 0.9903\n",
            "Epoch 928/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0173 - accuracy: 0.9983 - val_loss: 0.2505 - val_accuracy: 0.9951\n",
            "Epoch 929/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0051 - accuracy: 0.9994 - val_loss: 0.2438 - val_accuracy: 0.9939\n",
            "Epoch 930/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0293 - accuracy: 0.9983 - val_loss: 0.2066 - val_accuracy: 0.9909\n",
            "Epoch 931/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0123 - accuracy: 0.9977 - val_loss: 0.2149 - val_accuracy: 0.9933\n",
            "Epoch 932/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 0.2497 - val_accuracy: 0.9933\n",
            "Epoch 933/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0112 - accuracy: 0.9977 - val_loss: 0.1913 - val_accuracy: 0.9939\n",
            "Epoch 934/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0067 - accuracy: 0.9986 - val_loss: 0.1930 - val_accuracy: 0.9939\n",
            "Epoch 935/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0078 - accuracy: 0.9985 - val_loss: 0.2629 - val_accuracy: 0.9933\n",
            "Epoch 936/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0020 - accuracy: 0.9997 - val_loss: 0.2395 - val_accuracy: 0.9945\n",
            "Epoch 937/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0033 - accuracy: 0.9992 - val_loss: 0.2054 - val_accuracy: 0.9933\n",
            "Epoch 938/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0019 - accuracy: 0.9997 - val_loss: 0.2250 - val_accuracy: 0.9933\n",
            "Epoch 939/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0149 - accuracy: 0.9992 - val_loss: 1.3552 - val_accuracy: 0.9739\n",
            "Epoch 940/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0063 - accuracy: 0.9986 - val_loss: 0.1387 - val_accuracy: 0.9951\n",
            "Epoch 941/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0162 - accuracy: 0.9979 - val_loss: 0.1536 - val_accuracy: 0.9945\n",
            "Epoch 942/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0085 - accuracy: 0.9988 - val_loss: 0.1556 - val_accuracy: 0.9939\n",
            "Epoch 943/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0059 - accuracy: 0.9988 - val_loss: 0.3175 - val_accuracy: 0.9909\n",
            "Epoch 944/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0036 - accuracy: 0.9992 - val_loss: 0.3217 - val_accuracy: 0.9927\n",
            "Epoch 945/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0023 - accuracy: 0.9995 - val_loss: 0.1815 - val_accuracy: 0.9958\n",
            "Epoch 946/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0026 - accuracy: 0.9995 - val_loss: 0.2120 - val_accuracy: 0.9958\n",
            "Epoch 947/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0052 - accuracy: 0.9989 - val_loss: 0.2211 - val_accuracy: 0.9951\n",
            "Epoch 948/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0039 - accuracy: 0.9992 - val_loss: 0.3226 - val_accuracy: 0.9945\n",
            "Epoch 949/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.3198 - val_accuracy: 0.9945\n",
            "Epoch 950/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.3088 - val_accuracy: 0.9945\n",
            "Epoch 951/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0033 - accuracy: 0.9991 - val_loss: 0.1554 - val_accuracy: 0.9958\n",
            "Epoch 952/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0037 - accuracy: 0.9992 - val_loss: 0.1767 - val_accuracy: 0.9958\n",
            "Epoch 953/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0063 - accuracy: 0.9995 - val_loss: 0.2675 - val_accuracy: 0.9921\n",
            "Epoch 954/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0648 - accuracy: 0.9962 - val_loss: 0.2729 - val_accuracy: 0.9897\n",
            "Epoch 955/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0240 - accuracy: 0.9959 - val_loss: 0.4567 - val_accuracy: 0.9891\n",
            "Epoch 956/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0321 - accuracy: 0.9979 - val_loss: 0.2214 - val_accuracy: 0.9958\n",
            "Epoch 957/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0067 - accuracy: 0.9986 - val_loss: 0.2622 - val_accuracy: 0.9958\n",
            "Epoch 958/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0066 - accuracy: 0.9989 - val_loss: 0.1846 - val_accuracy: 0.9945\n",
            "Epoch 959/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0048 - accuracy: 0.9989 - val_loss: 0.3204 - val_accuracy: 0.9958\n",
            "Epoch 960/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0045 - accuracy: 0.9991 - val_loss: 0.2980 - val_accuracy: 0.9958\n",
            "Epoch 961/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0037 - accuracy: 0.9995 - val_loss: 0.2560 - val_accuracy: 0.9964\n",
            "Epoch 962/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0056 - accuracy: 0.9994 - val_loss: 0.4337 - val_accuracy: 0.9958\n",
            "Epoch 963/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0060 - accuracy: 0.9991 - val_loss: 0.3147 - val_accuracy: 0.9958\n",
            "Epoch 964/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0016 - accuracy: 0.9998 - val_loss: 0.2625 - val_accuracy: 0.9958\n",
            "Epoch 965/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0062 - accuracy: 0.9988 - val_loss: 0.2743 - val_accuracy: 0.9958\n",
            "Epoch 966/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0262 - accuracy: 0.9983 - val_loss: 0.5824 - val_accuracy: 0.9860\n",
            "Epoch 967/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0346 - accuracy: 0.9976 - val_loss: 0.2541 - val_accuracy: 0.9933\n",
            "Epoch 968/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0071 - accuracy: 0.9991 - val_loss: 0.3514 - val_accuracy: 0.9921\n",
            "Epoch 969/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0018 - accuracy: 0.9997 - val_loss: 0.3526 - val_accuracy: 0.9927\n",
            "Epoch 970/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.4343 - val_accuracy: 0.9927\n",
            "Epoch 971/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0031 - accuracy: 0.9992 - val_loss: 0.6335 - val_accuracy: 0.9909\n",
            "Epoch 972/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0017 - accuracy: 0.9998 - val_loss: 0.3414 - val_accuracy: 0.9927\n",
            "Epoch 973/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0041 - accuracy: 0.9992 - val_loss: 0.3011 - val_accuracy: 0.9933\n",
            "Epoch 974/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0018 - accuracy: 0.9997 - val_loss: 0.3036 - val_accuracy: 0.9939\n",
            "Epoch 975/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0040 - accuracy: 0.9991 - val_loss: 0.2913 - val_accuracy: 0.9939\n",
            "Epoch 976/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0025 - accuracy: 0.9995 - val_loss: 0.3009 - val_accuracy: 0.9939\n",
            "Epoch 977/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 6.6244e-04 - accuracy: 0.9998 - val_loss: 0.3114 - val_accuracy: 0.9939\n",
            "Epoch 978/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.3135 - val_accuracy: 0.9939\n",
            "Epoch 979/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0017 - accuracy: 0.9997 - val_loss: 0.3136 - val_accuracy: 0.9939\n",
            "Epoch 980/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0077 - accuracy: 0.9985 - val_loss: 0.2673 - val_accuracy: 0.9885\n",
            "Epoch 981/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0133 - accuracy: 0.9986 - val_loss: 0.5692 - val_accuracy: 0.9909\n",
            "Epoch 982/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0044 - accuracy: 0.9992 - val_loss: 0.5203 - val_accuracy: 0.9915\n",
            "Epoch 983/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0060 - accuracy: 0.9988 - val_loss: 0.4971 - val_accuracy: 0.9897\n",
            "Epoch 984/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0084 - accuracy: 0.9995 - val_loss: 0.3033 - val_accuracy: 0.9951\n",
            "Epoch 985/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0071 - accuracy: 0.9989 - val_loss: 0.2023 - val_accuracy: 0.9964\n",
            "Epoch 986/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0025 - accuracy: 0.9995 - val_loss: 0.1960 - val_accuracy: 0.9958\n",
            "Epoch 987/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0056 - accuracy: 0.9989 - val_loss: 0.4024 - val_accuracy: 0.9927\n",
            "Epoch 988/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0018 - accuracy: 0.9997 - val_loss: 0.4122 - val_accuracy: 0.9933\n",
            "Epoch 989/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0019 - accuracy: 0.9997 - val_loss: 0.4657 - val_accuracy: 0.9921\n",
            "Epoch 990/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0045 - accuracy: 0.9991 - val_loss: 0.4240 - val_accuracy: 0.9933\n",
            "Epoch 991/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0018 - accuracy: 0.9997 - val_loss: 0.2362 - val_accuracy: 0.9958\n",
            "Epoch 992/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0037 - accuracy: 0.9992 - val_loss: 0.2462 - val_accuracy: 0.9958\n",
            "Epoch 993/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0019 - accuracy: 0.9997 - val_loss: 0.4425 - val_accuracy: 0.9958\n",
            "Epoch 994/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0305 - accuracy: 0.9989 - val_loss: 1.4754 - val_accuracy: 0.9836\n",
            "Epoch 995/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0083 - accuracy: 0.9986 - val_loss: 0.8970 - val_accuracy: 0.9927\n",
            "Epoch 996/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0552 - accuracy: 0.9962 - val_loss: 0.1718 - val_accuracy: 0.9915\n",
            "Epoch 997/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0244 - accuracy: 0.9965 - val_loss: 0.0924 - val_accuracy: 0.9927\n",
            "Epoch 998/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0066 - accuracy: 0.9988 - val_loss: 0.1733 - val_accuracy: 0.9927\n",
            "Epoch 999/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0067 - accuracy: 0.9986 - val_loss: 0.3294 - val_accuracy: 0.9921\n",
            "Epoch 1000/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0022 - accuracy: 0.9997 - val_loss: 0.2877 - val_accuracy: 0.9921\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1200x400 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "206/206 [==============================] - 12s 46ms/step - loss: 3.3932 - accuracy: 0.8680 - val_loss: 0.3526 - val_accuracy: 0.8768\n",
            "Epoch 2/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.2820 - accuracy: 0.8945 - val_loss: 0.2045 - val_accuracy: 0.8823\n",
            "Epoch 3/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.2100 - accuracy: 0.8926 - val_loss: 0.1235 - val_accuracy: 0.9539\n",
            "Epoch 4/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.2058 - accuracy: 0.9120 - val_loss: 0.5992 - val_accuracy: 0.8726\n",
            "Epoch 5/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.2293 - accuracy: 0.8777 - val_loss: 0.1532 - val_accuracy: 0.8811\n",
            "Epoch 6/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1794 - accuracy: 0.9042 - val_loss: 1.5007 - val_accuracy: 0.7184\n",
            "Epoch 7/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.3504 - accuracy: 0.8819 - val_loss: 0.1628 - val_accuracy: 0.8823\n",
            "Epoch 8/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.2151 - accuracy: 0.9082 - val_loss: 0.1024 - val_accuracy: 0.9496\n",
            "Epoch 9/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1614 - accuracy: 0.9202 - val_loss: 0.1006 - val_accuracy: 0.9545\n",
            "Epoch 10/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1331 - accuracy: 0.9182 - val_loss: 0.0721 - val_accuracy: 0.9642\n",
            "Epoch 11/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1294 - accuracy: 0.9226 - val_loss: 0.0941 - val_accuracy: 0.9569\n",
            "Epoch 12/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1275 - accuracy: 0.9217 - val_loss: 0.1032 - val_accuracy: 0.9515\n",
            "Epoch 13/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1123 - accuracy: 0.9222 - val_loss: 0.0642 - val_accuracy: 0.9618\n",
            "Epoch 14/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1146 - accuracy: 0.9272 - val_loss: 0.0664 - val_accuracy: 0.9715\n",
            "Epoch 15/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1868 - accuracy: 0.9164 - val_loss: 4.5646 - val_accuracy: 0.8829\n",
            "Epoch 16/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.2018 - accuracy: 0.9143 - val_loss: 0.0940 - val_accuracy: 0.9569\n",
            "Epoch 17/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1465 - accuracy: 0.9205 - val_loss: 0.1142 - val_accuracy: 0.9575\n",
            "Epoch 18/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1307 - accuracy: 0.9229 - val_loss: 0.0752 - val_accuracy: 0.9600\n",
            "Epoch 19/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1658 - accuracy: 0.9272 - val_loss: 5.8369 - val_accuracy: 0.9551\n",
            "Epoch 20/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1383 - accuracy: 0.9193 - val_loss: 0.0810 - val_accuracy: 0.9630\n",
            "Epoch 21/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1272 - accuracy: 0.9237 - val_loss: 0.0684 - val_accuracy: 0.9630\n",
            "Epoch 22/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1074 - accuracy: 0.9228 - val_loss: 0.0491 - val_accuracy: 0.9642\n",
            "Epoch 23/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0966 - accuracy: 0.9275 - val_loss: 0.0569 - val_accuracy: 0.9636\n",
            "Epoch 24/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1049 - accuracy: 0.9338 - val_loss: 0.0618 - val_accuracy: 0.9782\n",
            "Epoch 25/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1126 - accuracy: 0.9360 - val_loss: 0.0630 - val_accuracy: 0.9860\n",
            "Epoch 26/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0952 - accuracy: 0.9511 - val_loss: 0.2438 - val_accuracy: 0.9593\n",
            "Epoch 27/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1093 - accuracy: 0.9475 - val_loss: 0.0802 - val_accuracy: 0.9763\n",
            "Epoch 28/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0958 - accuracy: 0.9484 - val_loss: 0.0551 - val_accuracy: 0.9921\n",
            "Epoch 29/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0869 - accuracy: 0.9551 - val_loss: 2.6178 - val_accuracy: 0.9278\n",
            "Epoch 30/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1906 - accuracy: 0.9261 - val_loss: 0.1318 - val_accuracy: 0.9697\n",
            "Epoch 31/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1490 - accuracy: 0.9476 - val_loss: 0.1035 - val_accuracy: 0.9630\n",
            "Epoch 32/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0866 - accuracy: 0.9589 - val_loss: 0.0500 - val_accuracy: 0.9879\n",
            "Epoch 33/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.4506 - accuracy: 0.8646 - val_loss: 49.9869 - val_accuracy: 0.8829\n",
            "Epoch 34/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.2163 - accuracy: 0.8693 - val_loss: 0.1583 - val_accuracy: 0.9587\n",
            "Epoch 35/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1731 - accuracy: 0.9015 - val_loss: 0.1197 - val_accuracy: 0.9842\n",
            "Epoch 36/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1498 - accuracy: 0.9146 - val_loss: 0.1159 - val_accuracy: 0.9727\n",
            "Epoch 37/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1472 - accuracy: 0.9156 - val_loss: 0.1706 - val_accuracy: 0.9587\n",
            "Epoch 38/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1454 - accuracy: 0.9185 - val_loss: 0.1196 - val_accuracy: 0.9836\n",
            "Epoch 39/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1305 - accuracy: 0.9302 - val_loss: 0.1169 - val_accuracy: 0.9660\n",
            "Epoch 40/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1362 - accuracy: 0.9426 - val_loss: 32.7129 - val_accuracy: 0.7791\n",
            "Epoch 41/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1217 - accuracy: 0.9445 - val_loss: 0.3593 - val_accuracy: 0.9788\n",
            "Epoch 42/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0917 - accuracy: 0.9520 - val_loss: 0.0715 - val_accuracy: 0.9818\n",
            "Epoch 43/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1253 - accuracy: 0.9540 - val_loss: 593.1132 - val_accuracy: 0.8786\n",
            "Epoch 44/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1807 - accuracy: 0.9209 - val_loss: 0.1369 - val_accuracy: 0.9751\n",
            "Epoch 45/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.2068 - accuracy: 0.9376 - val_loss: 0.0807 - val_accuracy: 0.9794\n",
            "Epoch 46/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1030 - accuracy: 0.9552 - val_loss: 0.0489 - val_accuracy: 0.9860\n",
            "Epoch 47/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0984 - accuracy: 0.9569 - val_loss: 0.1153 - val_accuracy: 0.9812\n",
            "Epoch 48/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0769 - accuracy: 0.9613 - val_loss: 0.0719 - val_accuracy: 0.9860\n",
            "Epoch 49/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0788 - accuracy: 0.9616 - val_loss: 0.1005 - val_accuracy: 0.9842\n",
            "Epoch 50/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0883 - accuracy: 0.9619 - val_loss: 122.1122 - val_accuracy: 0.9320\n",
            "Epoch 51/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0784 - accuracy: 0.9639 - val_loss: 0.0704 - val_accuracy: 0.9879\n",
            "Epoch 52/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0751 - accuracy: 0.9654 - val_loss: 0.0815 - val_accuracy: 0.9885\n",
            "Epoch 53/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0719 - accuracy: 0.9690 - val_loss: 0.0880 - val_accuracy: 0.9879\n",
            "Epoch 54/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1673 - accuracy: 0.9432 - val_loss: 0.0985 - val_accuracy: 0.9739\n",
            "Epoch 55/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1346 - accuracy: 0.9310 - val_loss: 0.1663 - val_accuracy: 0.9678\n",
            "Epoch 56/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1050 - accuracy: 0.9367 - val_loss: 0.0624 - val_accuracy: 0.9873\n",
            "Epoch 57/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0981 - accuracy: 0.9540 - val_loss: 0.0507 - val_accuracy: 0.9867\n",
            "Epoch 58/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0725 - accuracy: 0.9649 - val_loss: 0.0646 - val_accuracy: 0.9873\n",
            "Epoch 59/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0816 - accuracy: 0.9656 - val_loss: 0.0600 - val_accuracy: 0.9775\n",
            "Epoch 60/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0901 - accuracy: 0.9653 - val_loss: 0.0511 - val_accuracy: 0.9921\n",
            "Epoch 61/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0720 - accuracy: 0.9678 - val_loss: 0.0458 - val_accuracy: 0.9903\n",
            "Epoch 62/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0591 - accuracy: 0.9742 - val_loss: 0.1471 - val_accuracy: 0.9848\n",
            "Epoch 63/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0667 - accuracy: 0.9693 - val_loss: 0.0812 - val_accuracy: 0.9885\n",
            "Epoch 64/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1137 - accuracy: 0.9687 - val_loss: 2.0893 - val_accuracy: 0.9084\n",
            "Epoch 65/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0703 - accuracy: 0.9692 - val_loss: 0.0589 - val_accuracy: 0.9909\n",
            "Epoch 66/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0893 - accuracy: 0.9621 - val_loss: 0.0663 - val_accuracy: 0.9879\n",
            "Epoch 67/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0811 - accuracy: 0.9666 - val_loss: 0.0500 - val_accuracy: 0.9921\n",
            "Epoch 68/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0647 - accuracy: 0.9716 - val_loss: 0.0522 - val_accuracy: 0.9891\n",
            "Epoch 69/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0639 - accuracy: 0.9698 - val_loss: 0.0516 - val_accuracy: 0.9915\n",
            "Epoch 70/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0538 - accuracy: 0.9786 - val_loss: 0.0505 - val_accuracy: 0.9921\n",
            "Epoch 71/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0646 - accuracy: 0.9734 - val_loss: 0.0400 - val_accuracy: 0.9927\n",
            "Epoch 72/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0601 - accuracy: 0.9759 - val_loss: 0.0802 - val_accuracy: 0.9909\n",
            "Epoch 73/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0623 - accuracy: 0.9756 - val_loss: 0.1040 - val_accuracy: 0.9806\n",
            "Epoch 74/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0738 - accuracy: 0.9721 - val_loss: 0.1317 - val_accuracy: 0.9527\n",
            "Epoch 75/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0910 - accuracy: 0.9574 - val_loss: 0.0762 - val_accuracy: 0.9867\n",
            "Epoch 76/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0872 - accuracy: 0.9678 - val_loss: 0.0606 - val_accuracy: 0.9860\n",
            "Epoch 77/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0646 - accuracy: 0.9731 - val_loss: 0.0404 - val_accuracy: 0.9891\n",
            "Epoch 78/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0714 - accuracy: 0.9701 - val_loss: 0.0469 - val_accuracy: 0.9885\n",
            "Epoch 79/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0709 - accuracy: 0.9780 - val_loss: 0.4076 - val_accuracy: 0.9684\n",
            "Epoch 80/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0749 - accuracy: 0.9747 - val_loss: 0.1210 - val_accuracy: 0.9775\n",
            "Epoch 81/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0964 - accuracy: 0.9719 - val_loss: 0.0528 - val_accuracy: 0.9897\n",
            "Epoch 82/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0587 - accuracy: 0.9747 - val_loss: 0.0936 - val_accuracy: 0.9939\n",
            "Epoch 83/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0546 - accuracy: 0.9765 - val_loss: 0.0766 - val_accuracy: 0.9909\n",
            "Epoch 84/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0451 - accuracy: 0.9827 - val_loss: 0.0502 - val_accuracy: 0.9921\n",
            "Epoch 85/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0465 - accuracy: 0.9824 - val_loss: 0.0590 - val_accuracy: 0.9921\n",
            "Epoch 86/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0384 - accuracy: 0.9866 - val_loss: 0.0481 - val_accuracy: 0.9927\n",
            "Epoch 87/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0407 - accuracy: 0.9868 - val_loss: 0.0701 - val_accuracy: 0.9921\n",
            "Epoch 88/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0499 - accuracy: 0.9871 - val_loss: 0.2945 - val_accuracy: 0.9709\n",
            "Epoch 89/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0776 - accuracy: 0.9854 - val_loss: 24.5683 - val_accuracy: 0.9751\n",
            "Epoch 90/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0365 - accuracy: 0.9880 - val_loss: 0.1022 - val_accuracy: 0.9879\n",
            "Epoch 91/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0339 - accuracy: 0.9910 - val_loss: 0.0419 - val_accuracy: 0.9873\n",
            "Epoch 92/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0419 - accuracy: 0.9859 - val_loss: 0.0687 - val_accuracy: 0.9909\n",
            "Epoch 93/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0382 - accuracy: 0.9874 - val_loss: 0.0488 - val_accuracy: 0.9945\n",
            "Epoch 94/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0479 - accuracy: 0.9835 - val_loss: 0.1361 - val_accuracy: 0.9812\n",
            "Epoch 95/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0612 - accuracy: 0.9809 - val_loss: 0.0483 - val_accuracy: 0.9921\n",
            "Epoch 96/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0540 - accuracy: 0.9825 - val_loss: 0.0591 - val_accuracy: 0.9885\n",
            "Epoch 97/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0380 - accuracy: 0.9871 - val_loss: 0.0534 - val_accuracy: 0.9933\n",
            "Epoch 98/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0300 - accuracy: 0.9903 - val_loss: 0.0473 - val_accuracy: 0.9927\n",
            "Epoch 99/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0347 - accuracy: 0.9903 - val_loss: 0.0594 - val_accuracy: 0.9848\n",
            "Epoch 100/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0385 - accuracy: 0.9865 - val_loss: 0.0527 - val_accuracy: 0.9921\n",
            "Epoch 101/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0385 - accuracy: 0.9876 - val_loss: 0.0501 - val_accuracy: 0.9933\n",
            "Epoch 102/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0474 - accuracy: 0.9874 - val_loss: 0.0920 - val_accuracy: 0.9842\n",
            "Epoch 103/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0361 - accuracy: 0.9888 - val_loss: 0.0998 - val_accuracy: 0.9903\n",
            "Epoch 104/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0536 - accuracy: 0.9832 - val_loss: 0.1255 - val_accuracy: 0.9854\n",
            "Epoch 105/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0541 - accuracy: 0.9844 - val_loss: 0.0618 - val_accuracy: 0.9903\n",
            "Epoch 106/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0369 - accuracy: 0.9882 - val_loss: 0.0412 - val_accuracy: 0.9933\n",
            "Epoch 107/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0307 - accuracy: 0.9901 - val_loss: 0.0772 - val_accuracy: 0.9909\n",
            "Epoch 108/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0340 - accuracy: 0.9891 - val_loss: 0.0433 - val_accuracy: 0.9933\n",
            "Epoch 109/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0304 - accuracy: 0.9906 - val_loss: 0.0423 - val_accuracy: 0.9927\n",
            "Epoch 110/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0253 - accuracy: 0.9929 - val_loss: 0.0435 - val_accuracy: 0.9945\n",
            "Epoch 111/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0239 - accuracy: 0.9930 - val_loss: 0.0475 - val_accuracy: 0.9933\n",
            "Epoch 112/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0444 - accuracy: 0.9918 - val_loss: 0.0399 - val_accuracy: 0.9927\n",
            "Epoch 113/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0489 - accuracy: 0.9889 - val_loss: 53.4948 - val_accuracy: 0.9430\n",
            "Epoch 114/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0379 - accuracy: 0.9903 - val_loss: 0.0835 - val_accuracy: 0.9945\n",
            "Epoch 115/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0236 - accuracy: 0.9935 - val_loss: 0.0741 - val_accuracy: 0.9927\n",
            "Epoch 116/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0236 - accuracy: 0.9929 - val_loss: 0.1046 - val_accuracy: 0.9891\n",
            "Epoch 117/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0371 - accuracy: 0.9897 - val_loss: 0.0825 - val_accuracy: 0.9860\n",
            "Epoch 118/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0314 - accuracy: 0.9914 - val_loss: 0.2112 - val_accuracy: 0.9842\n",
            "Epoch 119/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0355 - accuracy: 0.9889 - val_loss: 0.0399 - val_accuracy: 0.9921\n",
            "Epoch 120/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0278 - accuracy: 0.9918 - val_loss: 0.0542 - val_accuracy: 0.9915\n",
            "Epoch 121/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0286 - accuracy: 0.9917 - val_loss: 0.1605 - val_accuracy: 0.9897\n",
            "Epoch 122/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0255 - accuracy: 0.9947 - val_loss: 0.0696 - val_accuracy: 0.9915\n",
            "Epoch 123/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0242 - accuracy: 0.9933 - val_loss: 0.0676 - val_accuracy: 0.9933\n",
            "Epoch 124/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0401 - accuracy: 0.9933 - val_loss: 0.0565 - val_accuracy: 0.9873\n",
            "Epoch 125/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0298 - accuracy: 0.9932 - val_loss: 0.0954 - val_accuracy: 0.9788\n",
            "Epoch 126/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0268 - accuracy: 0.9914 - val_loss: 0.1694 - val_accuracy: 0.9873\n",
            "Epoch 127/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0262 - accuracy: 0.9918 - val_loss: 0.0750 - val_accuracy: 0.9939\n",
            "Epoch 128/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0247 - accuracy: 0.9927 - val_loss: 0.0535 - val_accuracy: 0.9933\n",
            "Epoch 129/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0163 - accuracy: 0.9959 - val_loss: 0.0422 - val_accuracy: 0.9958\n",
            "Epoch 130/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0146 - accuracy: 0.9968 - val_loss: 0.0468 - val_accuracy: 0.9939\n",
            "Epoch 131/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0150 - accuracy: 0.9965 - val_loss: 0.0526 - val_accuracy: 0.9945\n",
            "Epoch 132/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0165 - accuracy: 0.9958 - val_loss: 0.0655 - val_accuracy: 0.9951\n",
            "Epoch 133/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0218 - accuracy: 0.9932 - val_loss: 0.5754 - val_accuracy: 0.9794\n",
            "Epoch 134/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0471 - accuracy: 0.9863 - val_loss: 0.0892 - val_accuracy: 0.9921\n",
            "Epoch 135/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0279 - accuracy: 0.9923 - val_loss: 0.0519 - val_accuracy: 0.9945\n",
            "Epoch 136/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0212 - accuracy: 0.9936 - val_loss: 0.0654 - val_accuracy: 0.9958\n",
            "Epoch 137/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0180 - accuracy: 0.9950 - val_loss: 0.1554 - val_accuracy: 0.9927\n",
            "Epoch 138/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0206 - accuracy: 0.9942 - val_loss: 0.0837 - val_accuracy: 0.9933\n",
            "Epoch 139/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0242 - accuracy: 0.9950 - val_loss: 0.0395 - val_accuracy: 0.9939\n",
            "Epoch 140/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0193 - accuracy: 0.9954 - val_loss: 0.0603 - val_accuracy: 0.9927\n",
            "Epoch 141/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0133 - accuracy: 0.9968 - val_loss: 0.0459 - val_accuracy: 0.9958\n",
            "Epoch 142/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0103 - accuracy: 0.9976 - val_loss: 0.0568 - val_accuracy: 0.9939\n",
            "Epoch 143/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0267 - accuracy: 0.9944 - val_loss: 0.0337 - val_accuracy: 0.9982\n",
            "Epoch 144/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0191 - accuracy: 0.9947 - val_loss: 0.0729 - val_accuracy: 0.9885\n",
            "Epoch 145/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0165 - accuracy: 0.9959 - val_loss: 0.1903 - val_accuracy: 0.9873\n",
            "Epoch 146/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0299 - accuracy: 0.9936 - val_loss: 2.3707 - val_accuracy: 0.9114\n",
            "Epoch 147/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0245 - accuracy: 0.9936 - val_loss: 0.0775 - val_accuracy: 0.9927\n",
            "Epoch 148/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0104 - accuracy: 0.9979 - val_loss: 0.0532 - val_accuracy: 0.9970\n",
            "Epoch 149/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0187 - accuracy: 0.9958 - val_loss: 0.0658 - val_accuracy: 0.9915\n",
            "Epoch 150/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0149 - accuracy: 0.9965 - val_loss: 0.0481 - val_accuracy: 0.9964\n",
            "Epoch 151/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0273 - accuracy: 0.9950 - val_loss: 0.0464 - val_accuracy: 0.9915\n",
            "Epoch 152/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0148 - accuracy: 0.9958 - val_loss: 0.0931 - val_accuracy: 0.9945\n",
            "Epoch 153/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0174 - accuracy: 0.9962 - val_loss: 0.0473 - val_accuracy: 0.9921\n",
            "Epoch 154/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0158 - accuracy: 0.9958 - val_loss: 0.0972 - val_accuracy: 0.9933\n",
            "Epoch 155/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0113 - accuracy: 0.9979 - val_loss: 0.0834 - val_accuracy: 0.9915\n",
            "Epoch 156/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0171 - accuracy: 0.9959 - val_loss: 0.0665 - val_accuracy: 0.9951\n",
            "Epoch 157/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0131 - accuracy: 0.9973 - val_loss: 0.0760 - val_accuracy: 0.9958\n",
            "Epoch 158/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0110 - accuracy: 0.9976 - val_loss: 0.0476 - val_accuracy: 0.9909\n",
            "Epoch 159/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0242 - accuracy: 0.9948 - val_loss: 0.0591 - val_accuracy: 0.9915\n",
            "Epoch 160/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0122 - accuracy: 0.9968 - val_loss: 0.1089 - val_accuracy: 0.9939\n",
            "Epoch 161/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0113 - accuracy: 0.9971 - val_loss: 0.1812 - val_accuracy: 0.9860\n",
            "Epoch 162/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0127 - accuracy: 0.9968 - val_loss: 0.0965 - val_accuracy: 0.9939\n",
            "Epoch 163/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0185 - accuracy: 0.9958 - val_loss: 0.0608 - val_accuracy: 0.9885\n",
            "Epoch 164/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0302 - accuracy: 0.9927 - val_loss: 0.0877 - val_accuracy: 0.9939\n",
            "Epoch 165/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0263 - accuracy: 0.9961 - val_loss: 0.0961 - val_accuracy: 0.9939\n",
            "Epoch 166/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0108 - accuracy: 0.9973 - val_loss: 0.0596 - val_accuracy: 0.9945\n",
            "Epoch 167/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0136 - accuracy: 0.9967 - val_loss: 1.1684 - val_accuracy: 0.9733\n",
            "Epoch 168/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0082 - accuracy: 0.9985 - val_loss: 0.0393 - val_accuracy: 0.9970\n",
            "Epoch 169/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0185 - accuracy: 0.9970 - val_loss: 0.0520 - val_accuracy: 0.9945\n",
            "Epoch 170/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0157 - accuracy: 0.9958 - val_loss: 0.1231 - val_accuracy: 0.9921\n",
            "Epoch 171/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0190 - accuracy: 0.9973 - val_loss: 0.0754 - val_accuracy: 0.9927\n",
            "Epoch 172/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0164 - accuracy: 0.9948 - val_loss: 0.0469 - val_accuracy: 0.9958\n",
            "Epoch 173/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0116 - accuracy: 0.9968 - val_loss: 0.0696 - val_accuracy: 0.9951\n",
            "Epoch 174/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0129 - accuracy: 0.9964 - val_loss: 0.0520 - val_accuracy: 0.9964\n",
            "Epoch 175/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0176 - accuracy: 0.9971 - val_loss: 0.0757 - val_accuracy: 0.9945\n",
            "Epoch 176/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0110 - accuracy: 0.9971 - val_loss: 0.0869 - val_accuracy: 0.9951\n",
            "Epoch 177/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0113 - accuracy: 0.9980 - val_loss: 0.0915 - val_accuracy: 0.9945\n",
            "Epoch 178/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0098 - accuracy: 0.9982 - val_loss: 0.0814 - val_accuracy: 0.9939\n",
            "Epoch 179/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0195 - accuracy: 0.9971 - val_loss: 0.0709 - val_accuracy: 0.9970\n",
            "Epoch 180/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0231 - accuracy: 0.9951 - val_loss: 0.0922 - val_accuracy: 0.9945\n",
            "Epoch 181/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0124 - accuracy: 0.9970 - val_loss: 0.0871 - val_accuracy: 0.9921\n",
            "Epoch 182/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0113 - accuracy: 0.9970 - val_loss: 0.0771 - val_accuracy: 0.9970\n",
            "Epoch 183/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0146 - accuracy: 0.9964 - val_loss: 0.1021 - val_accuracy: 0.9945\n",
            "Epoch 184/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0199 - accuracy: 0.9965 - val_loss: 0.1320 - val_accuracy: 0.9885\n",
            "Epoch 185/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0182 - accuracy: 0.9970 - val_loss: 0.1069 - val_accuracy: 0.9951\n",
            "Epoch 186/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0188 - accuracy: 0.9973 - val_loss: 0.0825 - val_accuracy: 0.9927\n",
            "Epoch 187/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0092 - accuracy: 0.9980 - val_loss: 0.0577 - val_accuracy: 0.9897\n",
            "Epoch 188/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0212 - accuracy: 0.9956 - val_loss: 0.0472 - val_accuracy: 0.9964\n",
            "Epoch 189/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0131 - accuracy: 0.9973 - val_loss: 0.0970 - val_accuracy: 0.9933\n",
            "Epoch 190/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0129 - accuracy: 0.9971 - val_loss: 0.1095 - val_accuracy: 0.9945\n",
            "Epoch 191/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0097 - accuracy: 0.9976 - val_loss: 0.0924 - val_accuracy: 0.9964\n",
            "Epoch 192/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0169 - accuracy: 0.9974 - val_loss: 0.0152 - val_accuracy: 0.9976\n",
            "Epoch 193/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0144 - accuracy: 0.9971 - val_loss: 0.0870 - val_accuracy: 0.9933\n",
            "Epoch 194/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0134 - accuracy: 0.9976 - val_loss: 0.0608 - val_accuracy: 0.9964\n",
            "Epoch 195/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0115 - accuracy: 0.9979 - val_loss: 0.0604 - val_accuracy: 0.9958\n",
            "Epoch 196/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0066 - accuracy: 0.9988 - val_loss: 0.0603 - val_accuracy: 0.9945\n",
            "Epoch 197/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0086 - accuracy: 0.9980 - val_loss: 0.0606 - val_accuracy: 0.9951\n",
            "Epoch 198/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0058 - accuracy: 0.9988 - val_loss: 0.0589 - val_accuracy: 0.9970\n",
            "Epoch 199/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0087 - accuracy: 0.9982 - val_loss: 0.0767 - val_accuracy: 0.9958\n",
            "Epoch 200/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0048 - accuracy: 0.9992 - val_loss: 0.0730 - val_accuracy: 0.9970\n",
            "Epoch 201/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0074 - accuracy: 0.9985 - val_loss: 0.0802 - val_accuracy: 0.9970\n",
            "Epoch 202/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0075 - accuracy: 0.9982 - val_loss: 0.0784 - val_accuracy: 0.9970\n",
            "Epoch 203/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0057 - accuracy: 0.9986 - val_loss: 0.0820 - val_accuracy: 0.9970\n",
            "Epoch 204/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0204 - accuracy: 0.9964 - val_loss: 0.0638 - val_accuracy: 0.9903\n",
            "Epoch 205/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0146 - accuracy: 0.9965 - val_loss: 0.0726 - val_accuracy: 0.9982\n",
            "Epoch 206/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0074 - accuracy: 0.9985 - val_loss: 0.0452 - val_accuracy: 0.9951\n",
            "Epoch 207/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0079 - accuracy: 0.9980 - val_loss: 0.0371 - val_accuracy: 0.9951\n",
            "Epoch 208/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0083 - accuracy: 0.9979 - val_loss: 0.0487 - val_accuracy: 0.9964\n",
            "Epoch 209/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0088 - accuracy: 0.9983 - val_loss: 0.0707 - val_accuracy: 0.9976\n",
            "Epoch 210/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0065 - accuracy: 0.9988 - val_loss: 0.3345 - val_accuracy: 0.9824\n",
            "Epoch 211/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0124 - accuracy: 0.9976 - val_loss: 0.0754 - val_accuracy: 0.9933\n",
            "Epoch 212/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0332 - accuracy: 0.9958 - val_loss: 0.0443 - val_accuracy: 0.9921\n",
            "Epoch 213/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0076 - accuracy: 0.9983 - val_loss: 0.0368 - val_accuracy: 0.9970\n",
            "Epoch 214/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0065 - accuracy: 0.9988 - val_loss: 0.0683 - val_accuracy: 0.9933\n",
            "Epoch 215/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0122 - accuracy: 0.9986 - val_loss: 0.0760 - val_accuracy: 0.9958\n",
            "Epoch 216/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0092 - accuracy: 0.9985 - val_loss: 0.0689 - val_accuracy: 0.9982\n",
            "Epoch 217/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0033 - accuracy: 0.9992 - val_loss: 0.0938 - val_accuracy: 0.9970\n",
            "Epoch 218/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0163 - accuracy: 0.9976 - val_loss: 0.0666 - val_accuracy: 0.9958\n",
            "Epoch 219/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0059 - accuracy: 0.9986 - val_loss: 0.0697 - val_accuracy: 0.9976\n",
            "Epoch 220/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.1034 - val_accuracy: 0.9970\n",
            "Epoch 221/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0054 - accuracy: 0.9989 - val_loss: 0.0692 - val_accuracy: 0.9964\n",
            "Epoch 222/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0071 - accuracy: 0.9988 - val_loss: 0.1237 - val_accuracy: 0.9958\n",
            "Epoch 223/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0160 - accuracy: 0.9970 - val_loss: 0.2100 - val_accuracy: 0.9915\n",
            "Epoch 224/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0131 - accuracy: 0.9979 - val_loss: 0.0607 - val_accuracy: 0.9958\n",
            "Epoch 225/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0046 - accuracy: 0.9991 - val_loss: 0.0849 - val_accuracy: 0.9945\n",
            "Epoch 226/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0075 - accuracy: 0.9980 - val_loss: 0.0564 - val_accuracy: 0.9964\n",
            "Epoch 227/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0074 - accuracy: 0.9988 - val_loss: 0.0896 - val_accuracy: 0.9976\n",
            "Epoch 228/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0093 - accuracy: 0.9986 - val_loss: 0.0868 - val_accuracy: 0.9964\n",
            "Epoch 229/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0055 - accuracy: 0.9992 - val_loss: 0.0585 - val_accuracy: 0.9939\n",
            "Epoch 230/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0054 - accuracy: 0.9989 - val_loss: 0.0644 - val_accuracy: 0.9964\n",
            "Epoch 231/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0168 - accuracy: 0.9980 - val_loss: 0.6015 - val_accuracy: 0.9860\n",
            "Epoch 232/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0216 - accuracy: 0.9965 - val_loss: 0.7971 - val_accuracy: 0.9788\n",
            "Epoch 233/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0218 - accuracy: 0.9959 - val_loss: 0.1126 - val_accuracy: 0.9964\n",
            "Epoch 234/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0086 - accuracy: 0.9983 - val_loss: 0.2188 - val_accuracy: 0.9964\n",
            "Epoch 235/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0044 - accuracy: 0.9992 - val_loss: 0.1295 - val_accuracy: 0.9958\n",
            "Epoch 236/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0071 - accuracy: 0.9983 - val_loss: 0.1353 - val_accuracy: 0.9951\n",
            "Epoch 237/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0099 - accuracy: 0.9988 - val_loss: 0.1240 - val_accuracy: 0.9951\n",
            "Epoch 238/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0070 - accuracy: 0.9985 - val_loss: 0.1252 - val_accuracy: 0.9976\n",
            "Epoch 239/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0085 - accuracy: 0.9985 - val_loss: 0.4816 - val_accuracy: 0.9739\n",
            "Epoch 240/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0639 - accuracy: 0.9977 - val_loss: 0.1101 - val_accuracy: 0.9860\n",
            "Epoch 241/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0115 - accuracy: 0.9970 - val_loss: 0.1491 - val_accuracy: 0.9927\n",
            "Epoch 242/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0108 - accuracy: 0.9980 - val_loss: 0.1235 - val_accuracy: 0.9976\n",
            "Epoch 243/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0041 - accuracy: 0.9991 - val_loss: 0.1096 - val_accuracy: 0.9964\n",
            "Epoch 244/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.1197 - val_accuracy: 0.9982\n",
            "Epoch 245/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0063 - accuracy: 0.9991 - val_loss: 0.1626 - val_accuracy: 0.9964\n",
            "Epoch 246/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0251 - accuracy: 0.9989 - val_loss: 0.2046 - val_accuracy: 0.9927\n",
            "Epoch 247/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.1395 - val_accuracy: 0.9945\n",
            "Epoch 248/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0057 - accuracy: 0.9986 - val_loss: 0.1130 - val_accuracy: 0.9958\n",
            "Epoch 249/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0035 - accuracy: 0.9992 - val_loss: 0.1409 - val_accuracy: 0.9939\n",
            "Epoch 250/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0054 - accuracy: 0.9986 - val_loss: 0.0930 - val_accuracy: 0.9958\n",
            "Epoch 251/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.2259 - val_accuracy: 0.9951\n",
            "Epoch 252/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0019 - accuracy: 0.9997 - val_loss: 0.2119 - val_accuracy: 0.9933\n",
            "Epoch 253/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0076 - accuracy: 0.9986 - val_loss: 0.0775 - val_accuracy: 0.9958\n",
            "Epoch 254/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0087 - accuracy: 0.9979 - val_loss: 0.1383 - val_accuracy: 0.9951\n",
            "Epoch 255/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0086 - accuracy: 0.9982 - val_loss: 0.1111 - val_accuracy: 0.9939\n",
            "Epoch 256/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0197 - accuracy: 0.9964 - val_loss: 0.0960 - val_accuracy: 0.9951\n",
            "Epoch 257/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0099 - accuracy: 0.9979 - val_loss: 0.0744 - val_accuracy: 0.9945\n",
            "Epoch 258/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0127 - accuracy: 0.9979 - val_loss: 0.1202 - val_accuracy: 0.9909\n",
            "Epoch 259/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0088 - accuracy: 0.9986 - val_loss: 0.0805 - val_accuracy: 0.9951\n",
            "Epoch 260/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0095 - accuracy: 0.9982 - val_loss: 0.0510 - val_accuracy: 0.9939\n",
            "Epoch 261/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0064 - accuracy: 0.9982 - val_loss: 0.1170 - val_accuracy: 0.9958\n",
            "Epoch 262/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0171 - accuracy: 0.9977 - val_loss: 0.0909 - val_accuracy: 0.9945\n",
            "Epoch 263/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0051 - accuracy: 0.9989 - val_loss: 0.0914 - val_accuracy: 0.9945\n",
            "Epoch 264/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0439 - accuracy: 0.9971 - val_loss: 0.0825 - val_accuracy: 0.9897\n",
            "Epoch 265/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0068 - accuracy: 0.9983 - val_loss: 0.0908 - val_accuracy: 0.9958\n",
            "Epoch 266/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0061 - accuracy: 0.9986 - val_loss: 0.1175 - val_accuracy: 0.9945\n",
            "Epoch 267/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0072 - accuracy: 0.9991 - val_loss: 0.0672 - val_accuracy: 0.9951\n",
            "Epoch 268/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0082 - accuracy: 0.9988 - val_loss: 0.0721 - val_accuracy: 0.9958\n",
            "Epoch 269/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0252 - accuracy: 0.9973 - val_loss: 0.0740 - val_accuracy: 0.9945\n",
            "Epoch 270/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0058 - accuracy: 0.9986 - val_loss: 0.1275 - val_accuracy: 0.9951\n",
            "Epoch 271/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0067 - accuracy: 0.9982 - val_loss: 0.0859 - val_accuracy: 0.9939\n",
            "Epoch 272/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0083 - accuracy: 0.9979 - val_loss: 0.1037 - val_accuracy: 0.9933\n",
            "Epoch 273/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0038 - accuracy: 0.9992 - val_loss: 0.1411 - val_accuracy: 0.9951\n",
            "Epoch 274/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0070 - accuracy: 0.9989 - val_loss: 0.1389 - val_accuracy: 0.9945\n",
            "Epoch 275/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0068 - accuracy: 0.9983 - val_loss: 0.0690 - val_accuracy: 0.9951\n",
            "Epoch 276/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0070 - accuracy: 0.9986 - val_loss: 0.9061 - val_accuracy: 0.9587\n",
            "Epoch 277/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0188 - accuracy: 0.9970 - val_loss: 0.1015 - val_accuracy: 0.9958\n",
            "Epoch 278/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0079 - accuracy: 0.9982 - val_loss: 0.2501 - val_accuracy: 0.9921\n",
            "Epoch 279/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0071 - accuracy: 0.9986 - val_loss: 0.1191 - val_accuracy: 0.9945\n",
            "Epoch 280/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0072 - accuracy: 0.9983 - val_loss: 0.0985 - val_accuracy: 0.9970\n",
            "Epoch 281/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0127 - accuracy: 0.9976 - val_loss: 0.2054 - val_accuracy: 0.9848\n",
            "Epoch 282/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0137 - accuracy: 0.9973 - val_loss: 0.0904 - val_accuracy: 0.9970\n",
            "Epoch 283/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0034 - accuracy: 0.9991 - val_loss: 0.0933 - val_accuracy: 0.9970\n",
            "Epoch 284/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0050 - accuracy: 0.9989 - val_loss: 0.1019 - val_accuracy: 0.9976\n",
            "Epoch 285/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0050 - accuracy: 0.9989 - val_loss: 0.1194 - val_accuracy: 0.9976\n",
            "Epoch 286/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0037 - accuracy: 0.9994 - val_loss: 0.1399 - val_accuracy: 0.9976\n",
            "Epoch 287/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0114 - accuracy: 0.9977 - val_loss: 0.0820 - val_accuracy: 0.9933\n",
            "Epoch 288/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0050 - accuracy: 0.9992 - val_loss: 0.1705 - val_accuracy: 0.9927\n",
            "Epoch 289/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0143 - accuracy: 0.9991 - val_loss: 100.2038 - val_accuracy: 0.8865\n",
            "Epoch 290/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0061 - accuracy: 0.9985 - val_loss: 0.0677 - val_accuracy: 0.9927\n",
            "Epoch 291/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0152 - accuracy: 0.9986 - val_loss: 0.1066 - val_accuracy: 0.9921\n",
            "Epoch 292/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0082 - accuracy: 0.9989 - val_loss: 0.1821 - val_accuracy: 0.9933\n",
            "Epoch 293/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0062 - accuracy: 0.9989 - val_loss: 0.1434 - val_accuracy: 0.9939\n",
            "Epoch 294/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0041 - accuracy: 0.9991 - val_loss: 0.2765 - val_accuracy: 0.9951\n",
            "Epoch 295/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 0.2089 - val_accuracy: 0.9951\n",
            "Epoch 296/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0136 - accuracy: 0.9985 - val_loss: 0.2024 - val_accuracy: 0.9945\n",
            "Epoch 297/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0161 - accuracy: 0.9989 - val_loss: 0.1592 - val_accuracy: 0.9933\n",
            "Epoch 298/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0134 - accuracy: 0.9980 - val_loss: 0.1387 - val_accuracy: 0.9945\n",
            "Epoch 299/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0076 - accuracy: 0.9989 - val_loss: 0.1005 - val_accuracy: 0.9970\n",
            "Epoch 300/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0078 - accuracy: 0.9982 - val_loss: 0.2599 - val_accuracy: 0.9933\n",
            "Epoch 301/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0045 - accuracy: 0.9995 - val_loss: 0.0924 - val_accuracy: 0.9958\n",
            "Epoch 302/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0067 - accuracy: 0.9986 - val_loss: 0.1042 - val_accuracy: 0.9958\n",
            "Epoch 303/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0198 - accuracy: 0.9979 - val_loss: 0.1426 - val_accuracy: 0.9939\n",
            "Epoch 304/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0103 - accuracy: 0.9985 - val_loss: 0.1024 - val_accuracy: 0.9921\n",
            "Epoch 305/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0104 - accuracy: 0.9974 - val_loss: 0.0989 - val_accuracy: 0.9964\n",
            "Epoch 306/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0045 - accuracy: 0.9991 - val_loss: 0.1259 - val_accuracy: 0.9958\n",
            "Epoch 307/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0016 - accuracy: 0.9997 - val_loss: 0.1656 - val_accuracy: 0.9933\n",
            "Epoch 308/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0257 - accuracy: 0.9983 - val_loss: 0.0996 - val_accuracy: 0.9958\n",
            "Epoch 309/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0053 - accuracy: 0.9989 - val_loss: 0.1029 - val_accuracy: 0.9970\n",
            "Epoch 310/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0068 - accuracy: 0.9985 - val_loss: 0.0696 - val_accuracy: 0.9970\n",
            "Epoch 311/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0108 - accuracy: 0.9982 - val_loss: 0.0851 - val_accuracy: 0.9976\n",
            "Epoch 312/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0059 - accuracy: 0.9988 - val_loss: 0.0881 - val_accuracy: 0.9964\n",
            "Epoch 313/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0103 - accuracy: 0.9988 - val_loss: 0.0730 - val_accuracy: 0.9970\n",
            "Epoch 314/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0058 - accuracy: 0.9989 - val_loss: 0.0841 - val_accuracy: 0.9970\n",
            "Epoch 315/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0043 - accuracy: 0.9989 - val_loss: 0.0777 - val_accuracy: 0.9976\n",
            "Epoch 316/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0081 - accuracy: 0.9989 - val_loss: 0.2023 - val_accuracy: 0.9933\n",
            "Epoch 317/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0108 - accuracy: 0.9985 - val_loss: 0.1170 - val_accuracy: 0.9970\n",
            "Epoch 318/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0406 - accuracy: 0.9983 - val_loss: 0.0887 - val_accuracy: 0.9939\n",
            "Epoch 319/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0078 - accuracy: 0.9980 - val_loss: 0.0883 - val_accuracy: 0.9958\n",
            "Epoch 320/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0039 - accuracy: 0.9991 - val_loss: 0.1199 - val_accuracy: 0.9958\n",
            "Epoch 321/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0078 - accuracy: 0.9994 - val_loss: 0.1495 - val_accuracy: 0.9721\n",
            "Epoch 322/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0129 - accuracy: 0.9982 - val_loss: 0.0892 - val_accuracy: 0.9939\n",
            "Epoch 323/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0060 - accuracy: 0.9986 - val_loss: 0.1206 - val_accuracy: 0.9958\n",
            "Epoch 324/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0069 - accuracy: 0.9986 - val_loss: 0.0787 - val_accuracy: 0.9958\n",
            "Epoch 325/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0044 - accuracy: 0.9989 - val_loss: 0.1180 - val_accuracy: 0.9951\n",
            "Epoch 326/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0061 - accuracy: 0.9988 - val_loss: 0.1394 - val_accuracy: 0.9958\n",
            "Epoch 327/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0052 - accuracy: 0.9986 - val_loss: 0.1502 - val_accuracy: 0.9958\n",
            "Epoch 328/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0015 - accuracy: 0.9998 - val_loss: 0.1155 - val_accuracy: 0.9964\n",
            "Epoch 329/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0038 - accuracy: 0.9991 - val_loss: 0.1249 - val_accuracy: 0.9970\n",
            "Epoch 330/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0046 - accuracy: 0.9991 - val_loss: 0.1292 - val_accuracy: 0.9970\n",
            "Epoch 331/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0038 - accuracy: 0.9994 - val_loss: 0.1578 - val_accuracy: 0.9970\n",
            "Epoch 332/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0041 - accuracy: 0.9991 - val_loss: 0.0985 - val_accuracy: 0.9970\n",
            "Epoch 333/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0133 - accuracy: 0.9976 - val_loss: 0.0821 - val_accuracy: 0.9964\n",
            "Epoch 334/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0034 - accuracy: 0.9994 - val_loss: 5.6820 - val_accuracy: 0.9369\n",
            "Epoch 335/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0159 - accuracy: 0.9986 - val_loss: 0.0696 - val_accuracy: 0.9964\n",
            "Epoch 336/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0118 - accuracy: 0.9986 - val_loss: 0.0890 - val_accuracy: 0.9970\n",
            "Epoch 337/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0055 - accuracy: 0.9988 - val_loss: 0.0760 - val_accuracy: 0.9970\n",
            "Epoch 338/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0061 - accuracy: 0.9989 - val_loss: 0.0670 - val_accuracy: 0.9958\n",
            "Epoch 339/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0018 - accuracy: 0.9997 - val_loss: 0.0754 - val_accuracy: 0.9964\n",
            "Epoch 340/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0084 - accuracy: 0.9986 - val_loss: 0.1035 - val_accuracy: 0.9964\n",
            "Epoch 341/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0393 - accuracy: 0.9980 - val_loss: 0.1838 - val_accuracy: 0.9933\n",
            "Epoch 342/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0118 - accuracy: 0.9980 - val_loss: 0.0906 - val_accuracy: 0.9945\n",
            "Epoch 343/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0116 - accuracy: 0.9982 - val_loss: 0.1114 - val_accuracy: 0.9970\n",
            "Epoch 344/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0044 - accuracy: 0.9989 - val_loss: 0.1052 - val_accuracy: 0.9976\n",
            "Epoch 345/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0039 - accuracy: 0.9992 - val_loss: 0.1143 - val_accuracy: 0.9976\n",
            "Epoch 346/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0049 - accuracy: 0.9995 - val_loss: 0.1251 - val_accuracy: 0.9976\n",
            "Epoch 347/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0123 - accuracy: 0.9986 - val_loss: 0.1257 - val_accuracy: 0.9964\n",
            "Epoch 348/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0036 - accuracy: 0.9994 - val_loss: 0.1170 - val_accuracy: 0.9976\n",
            "Epoch 349/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0044 - accuracy: 0.9992 - val_loss: 0.1376 - val_accuracy: 0.9964\n",
            "Epoch 350/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0249 - accuracy: 0.9989 - val_loss: 0.2003 - val_accuracy: 0.9958\n",
            "Epoch 351/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0092 - accuracy: 0.9979 - val_loss: 0.1593 - val_accuracy: 0.9958\n",
            "Epoch 352/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0107 - accuracy: 0.9982 - val_loss: 0.1604 - val_accuracy: 0.9945\n",
            "Epoch 353/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0060 - accuracy: 0.9988 - val_loss: 0.1134 - val_accuracy: 0.9970\n",
            "Epoch 354/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0054 - accuracy: 0.9994 - val_loss: 0.1145 - val_accuracy: 0.9976\n",
            "Epoch 355/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0078 - accuracy: 0.9985 - val_loss: 0.2446 - val_accuracy: 0.9897\n",
            "Epoch 356/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0277 - accuracy: 0.9974 - val_loss: 0.1016 - val_accuracy: 0.9958\n",
            "Epoch 357/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0063 - accuracy: 0.9988 - val_loss: 0.0807 - val_accuracy: 0.9970\n",
            "Epoch 358/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0059 - accuracy: 0.9992 - val_loss: 0.0896 - val_accuracy: 0.9958\n",
            "Epoch 359/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0121 - accuracy: 0.9976 - val_loss: 0.0718 - val_accuracy: 0.9921\n",
            "Epoch 360/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0062 - accuracy: 0.9986 - val_loss: 0.1611 - val_accuracy: 0.9909\n",
            "Epoch 361/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0044 - accuracy: 0.9991 - val_loss: 0.0862 - val_accuracy: 0.9964\n",
            "Epoch 362/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0067 - accuracy: 0.9989 - val_loss: 0.0961 - val_accuracy: 0.9951\n",
            "Epoch 363/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0042 - accuracy: 0.9992 - val_loss: 0.1134 - val_accuracy: 0.9958\n",
            "Epoch 364/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0041 - accuracy: 0.9992 - val_loss: 0.1263 - val_accuracy: 0.9958\n",
            "Epoch 365/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0068 - accuracy: 0.9992 - val_loss: 0.1062 - val_accuracy: 0.9970\n",
            "Epoch 366/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0031 - accuracy: 0.9997 - val_loss: 0.0814 - val_accuracy: 0.9970\n",
            "Epoch 367/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0095 - accuracy: 0.9991 - val_loss: 0.1253 - val_accuracy: 0.9933\n",
            "Epoch 368/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 0.1269 - val_accuracy: 0.9958\n",
            "Epoch 369/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0053 - accuracy: 0.9989 - val_loss: 0.0861 - val_accuracy: 0.9951\n",
            "Epoch 370/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0055 - accuracy: 0.9991 - val_loss: 0.1305 - val_accuracy: 0.9970\n",
            "Epoch 371/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0047 - accuracy: 0.9991 - val_loss: 0.1860 - val_accuracy: 0.9939\n",
            "Epoch 372/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0075 - accuracy: 0.9985 - val_loss: 0.0926 - val_accuracy: 0.9964\n",
            "Epoch 373/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0406 - accuracy: 0.9970 - val_loss: 0.0567 - val_accuracy: 0.9897\n",
            "Epoch 374/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0063 - accuracy: 0.9983 - val_loss: 0.0696 - val_accuracy: 0.9945\n",
            "Epoch 375/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0071 - accuracy: 0.9986 - val_loss: 0.0901 - val_accuracy: 0.9958\n",
            "Epoch 376/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0152 - accuracy: 0.9974 - val_loss: 0.1066 - val_accuracy: 0.9933\n",
            "Epoch 377/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0060 - accuracy: 0.9988 - val_loss: 0.0911 - val_accuracy: 0.9964\n",
            "Epoch 378/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0050 - accuracy: 0.9994 - val_loss: 0.0722 - val_accuracy: 0.9970\n",
            "Epoch 379/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0056 - accuracy: 0.9989 - val_loss: 0.1055 - val_accuracy: 0.9958\n",
            "Epoch 380/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0041 - accuracy: 0.9992 - val_loss: 0.0747 - val_accuracy: 0.9976\n",
            "Epoch 381/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0038 - accuracy: 0.9994 - val_loss: 0.0613 - val_accuracy: 0.9970\n",
            "Epoch 382/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0023 - accuracy: 0.9997 - val_loss: 0.0633 - val_accuracy: 0.9982\n",
            "Epoch 383/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0047 - accuracy: 0.9989 - val_loss: 0.2015 - val_accuracy: 0.9897\n",
            "Epoch 384/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0142 - accuracy: 0.9977 - val_loss: 0.0655 - val_accuracy: 0.9964\n",
            "Epoch 385/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0098 - accuracy: 0.9979 - val_loss: 0.0395 - val_accuracy: 0.9939\n",
            "Epoch 386/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0057 - accuracy: 0.9986 - val_loss: 0.0480 - val_accuracy: 0.9970\n",
            "Epoch 387/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0052 - accuracy: 0.9992 - val_loss: 0.0722 - val_accuracy: 0.9976\n",
            "Epoch 388/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0064 - accuracy: 0.9989 - val_loss: 0.0548 - val_accuracy: 0.9982\n",
            "Epoch 389/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0063 - accuracy: 0.9992 - val_loss: 0.0806 - val_accuracy: 0.9976\n",
            "Epoch 390/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0158 - accuracy: 0.9982 - val_loss: 0.0969 - val_accuracy: 0.9982\n",
            "Epoch 391/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0046 - accuracy: 0.9989 - val_loss: 0.2416 - val_accuracy: 0.9939\n",
            "Epoch 392/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0777 - accuracy: 0.9964 - val_loss: 0.0905 - val_accuracy: 0.9982\n",
            "Epoch 393/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0048 - accuracy: 0.9992 - val_loss: 0.0789 - val_accuracy: 0.9982\n",
            "Epoch 394/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0046 - accuracy: 0.9991 - val_loss: 0.1123 - val_accuracy: 0.9982\n",
            "Epoch 395/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0027 - accuracy: 0.9995 - val_loss: 0.1011 - val_accuracy: 0.9976\n",
            "Epoch 396/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0081 - accuracy: 0.9992 - val_loss: 0.0838 - val_accuracy: 0.9970\n",
            "Epoch 397/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.0879 - val_accuracy: 0.9976\n",
            "Epoch 398/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0020 - accuracy: 0.9997 - val_loss: 0.0937 - val_accuracy: 0.9970\n",
            "Epoch 399/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0026 - accuracy: 0.9995 - val_loss: 0.1061 - val_accuracy: 0.9970\n",
            "Epoch 400/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0031 - accuracy: 0.9992 - val_loss: 0.1569 - val_accuracy: 0.9970\n",
            "Epoch 401/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 0.1548 - val_accuracy: 0.9970\n",
            "Epoch 402/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0010 - accuracy: 0.9997 - val_loss: 0.1823 - val_accuracy: 0.9958\n",
            "Epoch 403/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0021 - accuracy: 0.9997 - val_loss: 0.1298 - val_accuracy: 0.9958\n",
            "Epoch 404/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0059 - accuracy: 0.9994 - val_loss: 0.1417 - val_accuracy: 0.9945\n",
            "Epoch 405/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0158 - accuracy: 0.9985 - val_loss: 0.1181 - val_accuracy: 0.9921\n",
            "Epoch 406/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 7.3553e-04 - accuracy: 0.9998 - val_loss: 0.1318 - val_accuracy: 0.9939\n",
            "Epoch 407/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.1495 - val_accuracy: 0.9945\n",
            "Epoch 408/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0032 - accuracy: 0.9992 - val_loss: 0.1320 - val_accuracy: 0.9951\n",
            "Epoch 409/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0041 - accuracy: 0.9988 - val_loss: 0.0997 - val_accuracy: 0.9945\n",
            "Epoch 410/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0029 - accuracy: 0.9995 - val_loss: 0.1169 - val_accuracy: 0.9939\n",
            "Epoch 411/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0036 - accuracy: 0.9989 - val_loss: 0.1200 - val_accuracy: 0.9951\n",
            "Epoch 412/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0016 - accuracy: 0.9997 - val_loss: 0.0837 - val_accuracy: 0.9964\n",
            "Epoch 413/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0029 - accuracy: 0.9995 - val_loss: 0.1068 - val_accuracy: 0.9958\n",
            "Epoch 414/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0018 - accuracy: 0.9997 - val_loss: 0.0730 - val_accuracy: 0.9964\n",
            "Epoch 415/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 8.7813e-04 - accuracy: 0.9998 - val_loss: 0.1042 - val_accuracy: 0.9970\n",
            "Epoch 416/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0072 - accuracy: 0.9992 - val_loss: 0.6200 - val_accuracy: 0.9842\n",
            "Epoch 417/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0081 - accuracy: 0.9995 - val_loss: 0.0974 - val_accuracy: 0.9958\n",
            "Epoch 418/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0142 - accuracy: 0.9976 - val_loss: 0.1204 - val_accuracy: 0.9927\n",
            "Epoch 419/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0036 - accuracy: 0.9991 - val_loss: 0.2267 - val_accuracy: 0.9945\n",
            "Epoch 420/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0097 - accuracy: 0.9992 - val_loss: 0.1350 - val_accuracy: 0.9945\n",
            "Epoch 421/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0026 - accuracy: 0.9992 - val_loss: 0.1365 - val_accuracy: 0.9958\n",
            "Epoch 422/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0058 - accuracy: 0.9989 - val_loss: 0.1017 - val_accuracy: 0.9970\n",
            "Epoch 423/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0039 - accuracy: 0.9989 - val_loss: 0.0742 - val_accuracy: 0.9964\n",
            "Epoch 424/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.1005 - val_accuracy: 0.9951\n",
            "Epoch 425/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0038 - accuracy: 0.9991 - val_loss: 0.1217 - val_accuracy: 0.9945\n",
            "Epoch 426/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0068 - accuracy: 0.9986 - val_loss: 0.1079 - val_accuracy: 0.9958\n",
            "Epoch 427/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0028 - accuracy: 0.9992 - val_loss: 0.0910 - val_accuracy: 0.9958\n",
            "Epoch 428/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0059 - accuracy: 0.9989 - val_loss: 0.1260 - val_accuracy: 0.9945\n",
            "Epoch 429/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0035 - accuracy: 0.9992 - val_loss: 0.1447 - val_accuracy: 0.9951\n",
            "Epoch 430/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.0742 - val_accuracy: 0.9970\n",
            "Epoch 431/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0017 - accuracy: 0.9997 - val_loss: 0.0793 - val_accuracy: 0.9970\n",
            "Epoch 432/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0088 - accuracy: 0.9989 - val_loss: 0.0863 - val_accuracy: 0.9964\n",
            "Epoch 433/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0015 - accuracy: 0.9998 - val_loss: 0.0943 - val_accuracy: 0.9970\n",
            "Epoch 434/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0146 - accuracy: 0.9989 - val_loss: 0.2144 - val_accuracy: 0.9854\n",
            "Epoch 435/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0184 - accuracy: 0.9980 - val_loss: 0.0500 - val_accuracy: 0.9951\n",
            "Epoch 436/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0071 - accuracy: 0.9986 - val_loss: 0.0702 - val_accuracy: 0.9945\n",
            "Epoch 437/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.0941 - val_accuracy: 0.9970\n",
            "Epoch 438/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0062 - accuracy: 0.9986 - val_loss: 0.0936 - val_accuracy: 0.9958\n",
            "Epoch 439/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0066 - accuracy: 0.9991 - val_loss: 0.0647 - val_accuracy: 0.9964\n",
            "Epoch 440/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0039 - accuracy: 0.9992 - val_loss: 0.1403 - val_accuracy: 0.9915\n",
            "Epoch 441/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0113 - accuracy: 0.9983 - val_loss: 0.0980 - val_accuracy: 0.9933\n",
            "Epoch 442/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0051 - accuracy: 0.9992 - val_loss: 0.0987 - val_accuracy: 0.9939\n",
            "Epoch 443/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0029 - accuracy: 0.9995 - val_loss: 0.1472 - val_accuracy: 0.9939\n",
            "Epoch 444/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0054 - accuracy: 0.9991 - val_loss: 0.0952 - val_accuracy: 0.9958\n",
            "Epoch 445/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0028 - accuracy: 0.9995 - val_loss: 0.1085 - val_accuracy: 0.9964\n",
            "Epoch 446/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0027 - accuracy: 0.9995 - val_loss: 0.1110 - val_accuracy: 0.9951\n",
            "Epoch 447/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.0998 - val_accuracy: 0.9958\n",
            "Epoch 448/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0046 - accuracy: 0.9992 - val_loss: 0.0971 - val_accuracy: 0.9945\n",
            "Epoch 449/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.1148 - val_accuracy: 0.9970\n",
            "Epoch 450/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 3.2624e-04 - accuracy: 1.0000 - val_loss: 0.1146 - val_accuracy: 0.9964\n",
            "Epoch 451/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0016 - accuracy: 0.9997 - val_loss: 0.1666 - val_accuracy: 0.9958\n",
            "Epoch 452/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0175 - accuracy: 0.9982 - val_loss: 0.1081 - val_accuracy: 0.9964\n",
            "Epoch 453/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0049 - accuracy: 0.9991 - val_loss: 0.2807 - val_accuracy: 0.9945\n",
            "Epoch 454/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0494 - accuracy: 0.9979 - val_loss: 0.1076 - val_accuracy: 0.9885\n",
            "Epoch 455/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0127 - accuracy: 0.9980 - val_loss: 0.1253 - val_accuracy: 0.9921\n",
            "Epoch 456/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0070 - accuracy: 0.9986 - val_loss: 0.0860 - val_accuracy: 0.9976\n",
            "Epoch 457/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 6.6255e-04 - accuracy: 0.9998 - val_loss: 0.0848 - val_accuracy: 0.9970\n",
            "Epoch 458/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 4.9200e-04 - accuracy: 1.0000 - val_loss: 0.0840 - val_accuracy: 0.9970\n",
            "Epoch 459/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0028 - accuracy: 0.9995 - val_loss: 0.0929 - val_accuracy: 0.9964\n",
            "Epoch 460/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0019 - accuracy: 0.9998 - val_loss: 0.0713 - val_accuracy: 0.9958\n",
            "Epoch 461/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0038 - accuracy: 0.9994 - val_loss: 0.0845 - val_accuracy: 0.9970\n",
            "Epoch 462/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0028 - accuracy: 0.9995 - val_loss: 0.1272 - val_accuracy: 0.9970\n",
            "Epoch 463/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0035 - accuracy: 0.9994 - val_loss: 0.1295 - val_accuracy: 0.9976\n",
            "Epoch 464/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0042 - accuracy: 0.9991 - val_loss: 0.0763 - val_accuracy: 0.9982\n",
            "Epoch 465/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0019 - accuracy: 0.9997 - val_loss: 0.0963 - val_accuracy: 0.9964\n",
            "Epoch 466/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0094 - accuracy: 0.9985 - val_loss: 0.0423 - val_accuracy: 0.9964\n",
            "Epoch 467/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.0705 - val_accuracy: 0.9976\n",
            "Epoch 468/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0024 - accuracy: 0.9997 - val_loss: 0.0454 - val_accuracy: 0.9964\n",
            "Epoch 469/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0035 - accuracy: 0.9992 - val_loss: 0.0806 - val_accuracy: 0.9970\n",
            "Epoch 470/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0050 - accuracy: 0.9997 - val_loss: 0.0857 - val_accuracy: 0.9964\n",
            "Epoch 471/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0036 - accuracy: 0.9994 - val_loss: 0.0657 - val_accuracy: 0.9976\n",
            "Epoch 472/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 0.1059 - val_accuracy: 0.9970\n",
            "Epoch 473/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0020 - accuracy: 0.9997 - val_loss: 0.0901 - val_accuracy: 0.9982\n",
            "Epoch 474/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 3.2134e-04 - accuracy: 1.0000 - val_loss: 0.0913 - val_accuracy: 0.9982\n",
            "Epoch 475/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0043 - accuracy: 0.9992 - val_loss: 0.1297 - val_accuracy: 0.9964\n",
            "Epoch 476/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0054 - accuracy: 0.9994 - val_loss: 0.0874 - val_accuracy: 0.9945\n",
            "Epoch 477/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0016 - accuracy: 0.9997 - val_loss: 0.0722 - val_accuracy: 0.9988\n",
            "Epoch 478/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0020 - accuracy: 0.9997 - val_loss: 0.0671 - val_accuracy: 0.9976\n",
            "Epoch 479/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0112 - accuracy: 0.9983 - val_loss: 0.0589 - val_accuracy: 0.9915\n",
            "Epoch 480/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0083 - accuracy: 0.9980 - val_loss: 0.0688 - val_accuracy: 0.9964\n",
            "Epoch 481/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0075 - accuracy: 0.9986 - val_loss: 0.0850 - val_accuracy: 0.9964\n",
            "Epoch 482/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0027 - accuracy: 0.9995 - val_loss: 0.0681 - val_accuracy: 0.9970\n",
            "Epoch 483/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.0721 - val_accuracy: 0.9958\n",
            "Epoch 484/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0019 - accuracy: 0.9997 - val_loss: 0.0507 - val_accuracy: 0.9970\n",
            "Epoch 485/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.1215 - val_accuracy: 0.9964\n",
            "Epoch 486/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 7.1272e-04 - accuracy: 0.9998 - val_loss: 0.0479 - val_accuracy: 0.9964\n",
            "Epoch 487/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.0666 - val_accuracy: 0.9982\n",
            "Epoch 488/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0021 - accuracy: 0.9997 - val_loss: 0.0680 - val_accuracy: 0.9982\n",
            "Epoch 489/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0066 - accuracy: 0.9988 - val_loss: 0.0685 - val_accuracy: 0.9964\n",
            "Epoch 490/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0329 - accuracy: 0.9977 - val_loss: 0.1045 - val_accuracy: 0.9958\n",
            "Epoch 491/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0113 - accuracy: 0.9983 - val_loss: 0.0751 - val_accuracy: 0.9964\n",
            "Epoch 492/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0036 - accuracy: 0.9991 - val_loss: 0.1130 - val_accuracy: 0.9964\n",
            "Epoch 493/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 7.0833e-04 - accuracy: 0.9998 - val_loss: 0.1180 - val_accuracy: 0.9951\n",
            "Epoch 494/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0017 - accuracy: 0.9997 - val_loss: 0.1139 - val_accuracy: 0.9951\n",
            "Epoch 495/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.1385 - val_accuracy: 0.9958\n",
            "Epoch 496/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0021 - accuracy: 0.9997 - val_loss: 0.1190 - val_accuracy: 0.9945\n",
            "Epoch 497/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.1310 - val_accuracy: 0.9958\n",
            "Epoch 498/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.1334 - val_accuracy: 0.9958\n",
            "Epoch 499/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.1929 - val_accuracy: 0.9964\n",
            "Epoch 500/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.1632 - val_accuracy: 0.9970\n",
            "Epoch 501/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 7.9529e-04 - accuracy: 0.9998 - val_loss: 0.1647 - val_accuracy: 0.9970\n",
            "Epoch 502/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0089 - accuracy: 0.9988 - val_loss: 0.0661 - val_accuracy: 0.9970\n",
            "Epoch 503/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0019 - accuracy: 0.9997 - val_loss: 0.0711 - val_accuracy: 0.9970\n",
            "Epoch 504/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0052 - accuracy: 0.9991 - val_loss: 0.1261 - val_accuracy: 0.9951\n",
            "Epoch 505/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0040 - accuracy: 0.9997 - val_loss: 0.0734 - val_accuracy: 0.9951\n",
            "Epoch 506/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0206 - accuracy: 0.9986 - val_loss: 0.1526 - val_accuracy: 0.9927\n",
            "Epoch 507/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0205 - accuracy: 0.9970 - val_loss: 0.1543 - val_accuracy: 0.9909\n",
            "Epoch 508/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0080 - accuracy: 0.9985 - val_loss: 0.1627 - val_accuracy: 0.9958\n",
            "Epoch 509/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.2445 - val_accuracy: 0.9951\n",
            "Epoch 510/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0026 - accuracy: 0.9995 - val_loss: 0.0950 - val_accuracy: 0.9964\n",
            "Epoch 511/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0037 - accuracy: 0.9992 - val_loss: 0.1598 - val_accuracy: 0.9958\n",
            "Epoch 512/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 4.3726e-04 - accuracy: 1.0000 - val_loss: 0.2129 - val_accuracy: 0.9958\n",
            "Epoch 513/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 3.5375e-04 - accuracy: 1.0000 - val_loss: 0.1789 - val_accuracy: 0.9958\n",
            "Epoch 514/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 3.6325e-04 - accuracy: 1.0000 - val_loss: 0.1579 - val_accuracy: 0.9951\n",
            "Epoch 515/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.1659 - val_accuracy: 0.9951\n",
            "Epoch 516/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 3.2815e-04 - accuracy: 1.0000 - val_loss: 0.1688 - val_accuracy: 0.9951\n",
            "Epoch 517/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0027 - accuracy: 0.9995 - val_loss: 0.1508 - val_accuracy: 0.9964\n",
            "Epoch 518/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 5.5736e-04 - accuracy: 0.9997 - val_loss: 0.2224 - val_accuracy: 0.9958\n",
            "Epoch 519/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.1640 - val_accuracy: 0.9964\n",
            "Epoch 520/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 7.8973e-04 - accuracy: 0.9998 - val_loss: 0.1292 - val_accuracy: 0.9976\n",
            "Epoch 521/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 2.7705e-04 - accuracy: 1.0000 - val_loss: 0.1427 - val_accuracy: 0.9976\n",
            "Epoch 522/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 2.4600e-04 - accuracy: 1.0000 - val_loss: 0.1438 - val_accuracy: 0.9976\n",
            "Epoch 523/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0051 - accuracy: 0.9994 - val_loss: 0.2849 - val_accuracy: 0.9897\n",
            "Epoch 524/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0040 - accuracy: 0.9994 - val_loss: 0.1188 - val_accuracy: 0.9970\n",
            "Epoch 525/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0094 - accuracy: 0.9983 - val_loss: 0.0906 - val_accuracy: 0.9951\n",
            "Epoch 526/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0037 - accuracy: 0.9994 - val_loss: 0.1045 - val_accuracy: 0.9951\n",
            "Epoch 527/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.2138 - val_accuracy: 0.9927\n",
            "Epoch 528/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0039 - accuracy: 0.9992 - val_loss: 0.0916 - val_accuracy: 0.9964\n",
            "Epoch 529/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0036 - accuracy: 0.9994 - val_loss: 0.1045 - val_accuracy: 0.9970\n",
            "Epoch 530/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.1240 - val_accuracy: 0.9964\n",
            "Epoch 531/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0039 - accuracy: 0.9994 - val_loss: 0.1054 - val_accuracy: 0.9964\n",
            "Epoch 532/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.0527 - val_accuracy: 0.9976\n",
            "Epoch 533/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0034 - accuracy: 0.9994 - val_loss: 0.0619 - val_accuracy: 0.9982\n",
            "Epoch 534/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0036 - accuracy: 0.9995 - val_loss: 0.0952 - val_accuracy: 0.9982\n",
            "Epoch 535/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0039 - accuracy: 0.9994 - val_loss: 0.0946 - val_accuracy: 0.9982\n",
            "Epoch 536/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0063 - accuracy: 0.9988 - val_loss: 0.0463 - val_accuracy: 0.9970\n",
            "Epoch 537/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0060 - accuracy: 0.9991 - val_loss: 0.1992 - val_accuracy: 0.9933\n",
            "Epoch 538/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0085 - accuracy: 0.9982 - val_loss: 0.0996 - val_accuracy: 0.9945\n",
            "Epoch 539/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0139 - accuracy: 0.9985 - val_loss: 0.0825 - val_accuracy: 0.9939\n",
            "Epoch 540/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0010 - accuracy: 0.9997 - val_loss: 0.0634 - val_accuracy: 0.9958\n",
            "Epoch 541/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 6.2992e-04 - accuracy: 0.9998 - val_loss: 0.1032 - val_accuracy: 0.9964\n",
            "Epoch 542/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 9.8538e-04 - accuracy: 0.9998 - val_loss: 0.1251 - val_accuracy: 0.9964\n",
            "Epoch 543/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 3.5014e-04 - accuracy: 1.0000 - val_loss: 0.1241 - val_accuracy: 0.9964\n",
            "Epoch 544/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.1065 - val_accuracy: 0.9964\n",
            "Epoch 545/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.1553 - val_accuracy: 0.9958\n",
            "Epoch 546/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 4.9491e-04 - accuracy: 0.9998 - val_loss: 0.1135 - val_accuracy: 0.9958\n",
            "Epoch 547/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0016 - accuracy: 0.9997 - val_loss: 0.1313 - val_accuracy: 0.9951\n",
            "Epoch 548/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 5.2125e-04 - accuracy: 0.9998 - val_loss: 0.1307 - val_accuracy: 0.9958\n",
            "Epoch 549/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 2.4853e-04 - accuracy: 1.0000 - val_loss: 0.1535 - val_accuracy: 0.9958\n",
            "Epoch 550/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.1099 - val_accuracy: 0.9964\n",
            "Epoch 551/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0074 - accuracy: 0.9994 - val_loss: 0.0917 - val_accuracy: 0.9982\n",
            "Epoch 552/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.0978 - val_accuracy: 0.9970\n",
            "Epoch 553/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.1081 - val_accuracy: 0.9964\n",
            "Epoch 554/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 0.1080 - val_accuracy: 0.9964\n",
            "Epoch 555/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0072 - accuracy: 0.9995 - val_loss: 0.1408 - val_accuracy: 0.9970\n",
            "Epoch 556/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.1100 - val_accuracy: 0.9988\n",
            "Epoch 557/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.3284 - val_accuracy: 0.9945\n",
            "Epoch 558/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0117 - accuracy: 0.9992 - val_loss: 0.1562 - val_accuracy: 0.9951\n",
            "Epoch 559/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.1415 - val_accuracy: 0.9945\n",
            "Epoch 560/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 0.2196 - val_accuracy: 0.9933\n",
            "Epoch 561/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0230 - accuracy: 0.9982 - val_loss: 0.0611 - val_accuracy: 0.9891\n",
            "Epoch 562/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0128 - accuracy: 0.9979 - val_loss: 0.0695 - val_accuracy: 0.9958\n",
            "Epoch 563/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0061 - accuracy: 0.9989 - val_loss: 0.1632 - val_accuracy: 0.9939\n",
            "Epoch 564/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0025 - accuracy: 0.9997 - val_loss: 0.1485 - val_accuracy: 0.9964\n",
            "Epoch 565/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 7.2743e-04 - accuracy: 0.9998 - val_loss: 0.1985 - val_accuracy: 0.9933\n",
            "Epoch 566/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.1471 - val_accuracy: 0.9970\n",
            "Epoch 567/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.1304 - val_accuracy: 0.9976\n",
            "Epoch 568/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.1274 - val_accuracy: 0.9976\n",
            "Epoch 569/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0215 - accuracy: 0.9985 - val_loss: 0.1054 - val_accuracy: 0.9879\n",
            "Epoch 570/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0056 - accuracy: 0.9986 - val_loss: 0.0384 - val_accuracy: 0.9958\n",
            "Epoch 571/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0357 - accuracy: 0.9979 - val_loss: 0.0612 - val_accuracy: 0.9964\n",
            "Epoch 572/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0043 - accuracy: 0.9989 - val_loss: 0.0784 - val_accuracy: 0.9976\n",
            "Epoch 573/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0136 - accuracy: 0.9986 - val_loss: 0.1007 - val_accuracy: 0.9982\n",
            "Epoch 574/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0017 - accuracy: 0.9997 - val_loss: 0.1174 - val_accuracy: 0.9970\n",
            "Epoch 575/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0044 - accuracy: 0.9992 - val_loss: 0.0744 - val_accuracy: 0.9976\n",
            "Epoch 576/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.0602 - val_accuracy: 0.9970\n",
            "Epoch 577/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0062 - accuracy: 0.9986 - val_loss: 0.0743 - val_accuracy: 0.9988\n",
            "Epoch 578/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.1010 - val_accuracy: 0.9988\n",
            "Epoch 579/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0045 - accuracy: 0.9991 - val_loss: 0.1158 - val_accuracy: 0.9988\n",
            "Epoch 580/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0021 - accuracy: 0.9997 - val_loss: 0.1186 - val_accuracy: 0.9988\n",
            "Epoch 581/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 3.0337e-04 - accuracy: 1.0000 - val_loss: 0.1183 - val_accuracy: 0.9988\n",
            "Epoch 582/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0023 - accuracy: 0.9995 - val_loss: 0.1473 - val_accuracy: 0.9970\n",
            "Epoch 583/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 7.4241e-04 - accuracy: 0.9997 - val_loss: 0.0715 - val_accuracy: 0.9988\n",
            "Epoch 584/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.0836 - val_accuracy: 0.9982\n",
            "Epoch 585/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.1099 - val_accuracy: 0.9970\n",
            "Epoch 586/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0187 - accuracy: 0.9983 - val_loss: 0.1110 - val_accuracy: 0.9909\n",
            "Epoch 587/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0055 - accuracy: 0.9989 - val_loss: 0.0574 - val_accuracy: 0.9970\n",
            "Epoch 588/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0072 - accuracy: 0.9994 - val_loss: 0.0618 - val_accuracy: 0.9945\n",
            "Epoch 589/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0026 - accuracy: 0.9995 - val_loss: 0.1070 - val_accuracy: 0.9970\n",
            "Epoch 590/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0075 - accuracy: 0.9992 - val_loss: 0.1694 - val_accuracy: 0.9945\n",
            "Epoch 591/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0047 - accuracy: 0.9992 - val_loss: 0.0636 - val_accuracy: 0.9976\n",
            "Epoch 592/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.0899 - val_accuracy: 0.9988\n",
            "Epoch 593/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0040 - accuracy: 0.9994 - val_loss: 0.0816 - val_accuracy: 0.9988\n",
            "Epoch 594/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.1650 - val_accuracy: 0.9951\n",
            "Epoch 595/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0058 - accuracy: 0.9992 - val_loss: 0.0965 - val_accuracy: 0.9970\n",
            "Epoch 596/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 2.7960e-04 - accuracy: 1.0000 - val_loss: 0.1266 - val_accuracy: 0.9964\n",
            "Epoch 597/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.1315 - val_accuracy: 0.9964\n",
            "Epoch 598/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.1356 - val_accuracy: 0.9988\n",
            "Epoch 599/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 2.6956e-04 - accuracy: 1.0000 - val_loss: 0.1308 - val_accuracy: 0.9976\n",
            "Epoch 600/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 2.6769e-04 - accuracy: 1.0000 - val_loss: 0.1262 - val_accuracy: 0.9976\n",
            "Epoch 601/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 5.0332e-04 - accuracy: 0.9998 - val_loss: 0.1151 - val_accuracy: 0.9970\n",
            "Epoch 602/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0031 - accuracy: 0.9995 - val_loss: 0.1124 - val_accuracy: 0.9945\n",
            "Epoch 603/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0040 - accuracy: 0.9998 - val_loss: 0.0744 - val_accuracy: 0.9976\n",
            "Epoch 604/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0021 - accuracy: 0.9997 - val_loss: 0.0804 - val_accuracy: 0.9982\n",
            "Epoch 605/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0038 - accuracy: 0.9994 - val_loss: 0.0890 - val_accuracy: 0.9970\n",
            "Epoch 606/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0037 - accuracy: 0.9991 - val_loss: 0.0737 - val_accuracy: 0.9964\n",
            "Epoch 607/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 8.9714e-04 - accuracy: 0.9997 - val_loss: 0.0580 - val_accuracy: 0.9976\n",
            "Epoch 608/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0019 - accuracy: 0.9997 - val_loss: 0.0580 - val_accuracy: 0.9976\n",
            "Epoch 609/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.0682 - val_accuracy: 0.9964\n",
            "Epoch 610/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0040 - accuracy: 0.9994 - val_loss: 0.0622 - val_accuracy: 0.9964\n",
            "Epoch 611/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0298 - accuracy: 0.9982 - val_loss: 0.4889 - val_accuracy: 0.9763\n",
            "Epoch 612/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0039 - accuracy: 0.9991 - val_loss: 0.1023 - val_accuracy: 0.9958\n",
            "Epoch 613/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0022 - accuracy: 0.9991 - val_loss: 0.1244 - val_accuracy: 0.9970\n",
            "Epoch 614/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.1052 - val_accuracy: 0.9976\n",
            "Epoch 615/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0488 - accuracy: 0.9977 - val_loss: 0.0832 - val_accuracy: 0.9951\n",
            "Epoch 616/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0099 - accuracy: 0.9985 - val_loss: 0.0883 - val_accuracy: 0.9982\n",
            "Epoch 617/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0040 - accuracy: 0.9994 - val_loss: 0.0976 - val_accuracy: 0.9970\n",
            "Epoch 618/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0068 - accuracy: 0.9991 - val_loss: 0.1014 - val_accuracy: 0.9976\n",
            "Epoch 619/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0059 - accuracy: 0.9991 - val_loss: 0.0389 - val_accuracy: 0.9988\n",
            "Epoch 620/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0060 - accuracy: 0.9988 - val_loss: 0.0441 - val_accuracy: 0.9988\n",
            "Epoch 621/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 3.9161e-04 - accuracy: 0.9998 - val_loss: 0.0489 - val_accuracy: 0.9988\n",
            "Epoch 622/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.0637 - val_accuracy: 0.9988\n",
            "Epoch 623/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.0773 - val_accuracy: 0.9982\n",
            "Epoch 624/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.0705 - val_accuracy: 0.9988\n",
            "Epoch 625/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 0.0783 - val_accuracy: 0.9988\n",
            "Epoch 626/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.0703 - val_accuracy: 0.9988\n",
            "Epoch 627/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 2.9835e-04 - accuracy: 1.0000 - val_loss: 0.0730 - val_accuracy: 0.9994\n",
            "Epoch 628/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.0729 - val_accuracy: 0.9994\n",
            "Epoch 629/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0028 - accuracy: 0.9995 - val_loss: 0.1082 - val_accuracy: 0.9976\n",
            "Epoch 630/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0141 - accuracy: 0.9986 - val_loss: 0.0405 - val_accuracy: 0.9976\n",
            "Epoch 631/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0050 - accuracy: 0.9989 - val_loss: 0.0208 - val_accuracy: 0.9988\n",
            "Epoch 632/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0047 - accuracy: 0.9992 - val_loss: 0.0221 - val_accuracy: 0.9976\n",
            "Epoch 633/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.0393 - val_accuracy: 0.9976\n",
            "Epoch 634/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.0390 - val_accuracy: 0.9976\n",
            "Epoch 635/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0025 - accuracy: 0.9998 - val_loss: 0.0279 - val_accuracy: 0.9982\n",
            "Epoch 636/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0038 - accuracy: 0.9995 - val_loss: 0.0634 - val_accuracy: 0.9951\n",
            "Epoch 637/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0032 - accuracy: 0.9995 - val_loss: 0.0406 - val_accuracy: 0.9988\n",
            "Epoch 638/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0108 - accuracy: 0.9989 - val_loss: 0.0372 - val_accuracy: 0.9976\n",
            "Epoch 639/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0059 - accuracy: 0.9992 - val_loss: 0.1134 - val_accuracy: 0.9970\n",
            "Epoch 640/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0047 - accuracy: 0.9992 - val_loss: 0.0679 - val_accuracy: 0.9982\n",
            "Epoch 641/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.0779 - val_accuracy: 0.9976\n",
            "Epoch 642/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0016 - accuracy: 0.9998 - val_loss: 0.0296 - val_accuracy: 0.9988\n",
            "Epoch 643/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.0309 - val_accuracy: 0.9988\n",
            "Epoch 644/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 5.5549e-04 - accuracy: 0.9998 - val_loss: 0.0494 - val_accuracy: 0.9988\n",
            "Epoch 645/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.0616 - val_accuracy: 0.9988\n",
            "Epoch 646/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 2.0477e-04 - accuracy: 1.0000 - val_loss: 0.0643 - val_accuracy: 0.9988\n",
            "Epoch 647/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0010 - accuracy: 0.9998 - val_loss: 0.1034 - val_accuracy: 0.9976\n",
            "Epoch 648/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0052 - accuracy: 0.9992 - val_loss: 0.0678 - val_accuracy: 0.9964\n",
            "Epoch 649/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0031 - accuracy: 0.9995 - val_loss: 0.0702 - val_accuracy: 0.9976\n",
            "Epoch 650/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0071 - accuracy: 0.9986 - val_loss: 0.0398 - val_accuracy: 0.9976\n",
            "Epoch 651/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0022 - accuracy: 0.9997 - val_loss: 0.0342 - val_accuracy: 0.9982\n",
            "Epoch 652/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0040 - accuracy: 0.9994 - val_loss: 0.0340 - val_accuracy: 0.9982\n",
            "Epoch 653/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0040 - accuracy: 0.9994 - val_loss: 0.0341 - val_accuracy: 0.9988\n",
            "Epoch 654/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 2.4260e-04 - accuracy: 1.0000 - val_loss: 0.0331 - val_accuracy: 0.9988\n",
            "Epoch 655/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0050 - accuracy: 0.9995 - val_loss: 0.0292 - val_accuracy: 0.9982\n",
            "Epoch 656/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.0243 - val_accuracy: 0.9988\n",
            "Epoch 657/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0053 - accuracy: 0.9991 - val_loss: 0.0442 - val_accuracy: 0.9976\n",
            "Epoch 658/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0051 - accuracy: 0.9992 - val_loss: 0.0275 - val_accuracy: 0.9976\n",
            "Epoch 659/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0045 - accuracy: 0.9992 - val_loss: 0.0295 - val_accuracy: 0.9964\n",
            "Epoch 660/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 2.3697e-04 - accuracy: 1.0000 - val_loss: 0.0278 - val_accuracy: 0.9970\n",
            "Epoch 661/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0044 - accuracy: 0.9992 - val_loss: 0.0511 - val_accuracy: 0.9976\n",
            "Epoch 662/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0019 - accuracy: 0.9997 - val_loss: 0.0692 - val_accuracy: 0.9982\n",
            "Epoch 663/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0045 - accuracy: 0.9991 - val_loss: 0.1388 - val_accuracy: 0.9951\n",
            "Epoch 664/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0027 - accuracy: 0.9997 - val_loss: 0.0649 - val_accuracy: 0.9964\n",
            "Epoch 665/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0409 - accuracy: 0.9976 - val_loss: 0.0084 - val_accuracy: 0.9970\n",
            "Epoch 666/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0080 - accuracy: 0.9988 - val_loss: 0.0190 - val_accuracy: 0.9970\n",
            "Epoch 667/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0040 - accuracy: 0.9989 - val_loss: 0.0193 - val_accuracy: 0.9988\n",
            "Epoch 668/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.0362 - val_accuracy: 0.9988\n",
            "Epoch 669/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.0619 - val_accuracy: 0.9976\n",
            "Epoch 670/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 2.4554e-04 - accuracy: 1.0000 - val_loss: 0.0562 - val_accuracy: 0.9976\n",
            "Epoch 671/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.0331 - val_accuracy: 0.9982\n",
            "Epoch 672/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 2.5183e-04 - accuracy: 1.0000 - val_loss: 0.0345 - val_accuracy: 0.9982\n",
            "Epoch 673/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0025 - accuracy: 0.9997 - val_loss: 0.0456 - val_accuracy: 0.9982\n",
            "Epoch 674/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0153 - accuracy: 0.9988 - val_loss: 0.0360 - val_accuracy: 0.9982\n",
            "Epoch 675/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0027 - accuracy: 0.9992 - val_loss: 0.0780 - val_accuracy: 0.9982\n",
            "Epoch 676/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0033 - accuracy: 0.9992 - val_loss: 0.0662 - val_accuracy: 0.9976\n",
            "Epoch 677/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 2.7882e-04 - accuracy: 1.0000 - val_loss: 0.0519 - val_accuracy: 0.9982\n",
            "Epoch 678/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0022 - accuracy: 0.9997 - val_loss: 0.0489 - val_accuracy: 0.9982\n",
            "Epoch 679/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 2.3334e-04 - accuracy: 1.0000 - val_loss: 0.0470 - val_accuracy: 0.9982\n",
            "Epoch 680/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0051 - accuracy: 0.9994 - val_loss: 0.0446 - val_accuracy: 0.9982\n",
            "Epoch 681/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0040 - accuracy: 0.9992 - val_loss: 0.0746 - val_accuracy: 0.9970\n",
            "Epoch 682/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0042 - accuracy: 0.9995 - val_loss: 0.0225 - val_accuracy: 0.9976\n",
            "Epoch 683/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0055 - accuracy: 0.9997 - val_loss: 0.0177 - val_accuracy: 0.9988\n",
            "Epoch 684/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0026 - accuracy: 0.9995 - val_loss: 0.0461 - val_accuracy: 0.9970\n",
            "Epoch 685/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 1.9364e-04 - accuracy: 1.0000 - val_loss: 0.0443 - val_accuracy: 0.9970\n",
            "Epoch 686/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 1.9006e-04 - accuracy: 1.0000 - val_loss: 0.0424 - val_accuracy: 0.9970\n",
            "Epoch 687/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 1.8825e-04 - accuracy: 1.0000 - val_loss: 0.0443 - val_accuracy: 0.9970\n",
            "Epoch 688/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.0449 - val_accuracy: 0.9970\n",
            "Epoch 689/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 1.8461e-04 - accuracy: 1.0000 - val_loss: 0.0461 - val_accuracy: 0.9964\n",
            "Epoch 690/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.0612 - val_accuracy: 0.9976\n",
            "Epoch 691/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0016 - accuracy: 0.9997 - val_loss: 0.0641 - val_accuracy: 0.9976\n",
            "Epoch 692/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 1.4493e-04 - accuracy: 1.0000 - val_loss: 0.0669 - val_accuracy: 0.9976\n",
            "Epoch 693/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0021 - accuracy: 0.9997 - val_loss: 0.0699 - val_accuracy: 0.9976\n",
            "Epoch 694/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.0979 - val_accuracy: 0.9982\n",
            "Epoch 695/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 6.9521e-04 - accuracy: 0.9998 - val_loss: 0.0584 - val_accuracy: 0.9982\n",
            "Epoch 696/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0022 - accuracy: 0.9997 - val_loss: 0.0557 - val_accuracy: 0.9982\n",
            "Epoch 697/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0117 - accuracy: 0.9985 - val_loss: 0.0628 - val_accuracy: 0.9964\n",
            "Epoch 698/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0102 - accuracy: 0.9991 - val_loss: 0.0795 - val_accuracy: 0.9964\n",
            "Epoch 699/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0095 - accuracy: 0.9982 - val_loss: 0.0314 - val_accuracy: 0.9964\n",
            "Epoch 700/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0044 - accuracy: 0.9992 - val_loss: 0.0814 - val_accuracy: 0.9976\n",
            "Epoch 701/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0032 - accuracy: 0.9995 - val_loss: 0.0797 - val_accuracy: 0.9982\n",
            "Epoch 702/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 5.7971e-04 - accuracy: 0.9998 - val_loss: 0.0623 - val_accuracy: 0.9988\n",
            "Epoch 703/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0028 - accuracy: 0.9995 - val_loss: 0.0966 - val_accuracy: 0.9976\n",
            "Epoch 704/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 6.8423e-04 - accuracy: 0.9998 - val_loss: 0.0725 - val_accuracy: 0.9988\n",
            "Epoch 705/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0021 - accuracy: 0.9997 - val_loss: 0.0764 - val_accuracy: 0.9988\n",
            "Epoch 706/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0032 - accuracy: 0.9995 - val_loss: 0.0811 - val_accuracy: 0.9982\n",
            "Epoch 707/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.0791 - val_accuracy: 0.9982\n",
            "Epoch 708/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 2.1319e-04 - accuracy: 1.0000 - val_loss: 0.0767 - val_accuracy: 0.9982\n",
            "Epoch 709/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.0794 - val_accuracy: 0.9982\n",
            "Epoch 710/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0406 - accuracy: 0.9985 - val_loss: 0.0323 - val_accuracy: 0.9982\n",
            "Epoch 711/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0057 - accuracy: 0.9992 - val_loss: 0.0681 - val_accuracy: 0.9976\n",
            "Epoch 712/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0038 - accuracy: 0.9994 - val_loss: 0.0803 - val_accuracy: 0.9976\n",
            "Epoch 713/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.0920 - val_accuracy: 0.9964\n",
            "Epoch 714/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0022 - accuracy: 0.9997 - val_loss: 0.0682 - val_accuracy: 0.9976\n",
            "Epoch 715/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0069 - accuracy: 0.9992 - val_loss: 0.0613 - val_accuracy: 0.9976\n",
            "Epoch 716/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0039 - accuracy: 0.9994 - val_loss: 0.0785 - val_accuracy: 0.9976\n",
            "Epoch 717/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0089 - accuracy: 0.9989 - val_loss: 1.4187 - val_accuracy: 0.9593\n",
            "Epoch 718/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0046 - accuracy: 0.9992 - val_loss: 0.0662 - val_accuracy: 0.9964\n",
            "Epoch 719/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0022 - accuracy: 0.9997 - val_loss: 0.0601 - val_accuracy: 0.9964\n",
            "Epoch 720/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0058 - accuracy: 0.9991 - val_loss: 0.0644 - val_accuracy: 0.9982\n",
            "Epoch 721/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0063 - accuracy: 0.9992 - val_loss: 0.1474 - val_accuracy: 0.9915\n",
            "Epoch 722/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0048 - accuracy: 0.9992 - val_loss: 0.1293 - val_accuracy: 0.9964\n",
            "Epoch 723/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.1083 - val_accuracy: 0.9982\n",
            "Epoch 724/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 2.2929e-04 - accuracy: 1.0000 - val_loss: 0.1092 - val_accuracy: 0.9982\n",
            "Epoch 725/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 3.5573e-04 - accuracy: 1.0000 - val_loss: 0.1273 - val_accuracy: 0.9982\n",
            "Epoch 726/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.1139 - val_accuracy: 0.9982\n",
            "Epoch 727/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0026 - accuracy: 0.9997 - val_loss: 0.1053 - val_accuracy: 0.9982\n",
            "Epoch 728/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0091 - accuracy: 0.9989 - val_loss: 0.0782 - val_accuracy: 0.9951\n",
            "Epoch 729/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0101 - accuracy: 0.9989 - val_loss: 0.0908 - val_accuracy: 0.9964\n",
            "Epoch 730/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0142 - accuracy: 0.9989 - val_loss: 0.0735 - val_accuracy: 0.9945\n",
            "Epoch 731/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0022 - accuracy: 0.9997 - val_loss: 0.0711 - val_accuracy: 0.9951\n",
            "Epoch 732/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0100 - accuracy: 0.9985 - val_loss: 0.1048 - val_accuracy: 0.9945\n",
            "Epoch 733/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0042 - accuracy: 0.9994 - val_loss: 0.0929 - val_accuracy: 0.9970\n",
            "Epoch 734/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0022 - accuracy: 0.9997 - val_loss: 0.0984 - val_accuracy: 0.9964\n",
            "Epoch 735/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 6.5880e-04 - accuracy: 0.9997 - val_loss: 0.1458 - val_accuracy: 0.9921\n",
            "Epoch 736/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0091 - accuracy: 0.9986 - val_loss: 0.0489 - val_accuracy: 0.9964\n",
            "Epoch 737/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0019 - accuracy: 0.9997 - val_loss: 0.0715 - val_accuracy: 0.9970\n",
            "Epoch 738/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.0955 - val_accuracy: 0.9958\n",
            "Epoch 739/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0253 - accuracy: 0.9992 - val_loss: 0.2005 - val_accuracy: 0.9945\n",
            "Epoch 740/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0045 - accuracy: 0.9995 - val_loss: 0.1455 - val_accuracy: 0.9964\n",
            "Epoch 741/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0031 - accuracy: 0.9995 - val_loss: 0.1039 - val_accuracy: 0.9970\n",
            "Epoch 742/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 0.1477 - val_accuracy: 0.9970\n",
            "Epoch 743/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.1299 - val_accuracy: 0.9970\n",
            "Epoch 744/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.1611 - val_accuracy: 0.9970\n",
            "Epoch 745/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.0798 - val_accuracy: 0.9970\n",
            "Epoch 746/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 3.8483e-04 - accuracy: 1.0000 - val_loss: 0.0809 - val_accuracy: 0.9982\n",
            "Epoch 747/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.0732 - val_accuracy: 0.9982\n",
            "Epoch 748/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.0752 - val_accuracy: 0.9982\n",
            "Epoch 749/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.0762 - val_accuracy: 0.9982\n",
            "Epoch 750/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0021 - accuracy: 0.9997 - val_loss: 0.0753 - val_accuracy: 0.9982\n",
            "Epoch 751/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 2.1386e-04 - accuracy: 1.0000 - val_loss: 0.0771 - val_accuracy: 0.9976\n",
            "Epoch 752/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0021 - accuracy: 0.9997 - val_loss: 0.0759 - val_accuracy: 0.9982\n",
            "Epoch 753/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 2.1244e-04 - accuracy: 1.0000 - val_loss: 0.0750 - val_accuracy: 0.9976\n",
            "Epoch 754/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.0765 - val_accuracy: 0.9982\n",
            "Epoch 755/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.0770 - val_accuracy: 0.9982\n",
            "Epoch 756/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 2.0597e-04 - accuracy: 1.0000 - val_loss: 0.0777 - val_accuracy: 0.9982\n",
            "Epoch 757/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0021 - accuracy: 0.9997 - val_loss: 0.0766 - val_accuracy: 0.9982\n",
            "Epoch 758/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 2.0322e-04 - accuracy: 1.0000 - val_loss: 0.0759 - val_accuracy: 0.9982\n",
            "Epoch 759/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 1.9959e-04 - accuracy: 1.0000 - val_loss: 0.0777 - val_accuracy: 0.9982\n",
            "Epoch 760/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 1.9497e-04 - accuracy: 1.0000 - val_loss: 0.0774 - val_accuracy: 0.9982\n",
            "Epoch 761/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0022 - accuracy: 0.9997 - val_loss: 0.0771 - val_accuracy: 0.9982\n",
            "Epoch 762/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.0766 - val_accuracy: 0.9982\n",
            "Epoch 763/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.0761 - val_accuracy: 0.9982\n",
            "Epoch 764/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0022 - accuracy: 0.9997 - val_loss: 0.0903 - val_accuracy: 0.9982\n",
            "Epoch 765/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0144 - accuracy: 0.9992 - val_loss: 0.1213 - val_accuracy: 0.9964\n",
            "Epoch 766/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0147 - accuracy: 0.9980 - val_loss: 0.1745 - val_accuracy: 0.9909\n",
            "Epoch 767/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0034 - accuracy: 0.9995 - val_loss: 0.1226 - val_accuracy: 0.9970\n",
            "Epoch 768/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0087 - accuracy: 0.9988 - val_loss: 0.0592 - val_accuracy: 0.9964\n",
            "Epoch 769/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0016 - accuracy: 0.9997 - val_loss: 0.1021 - val_accuracy: 0.9982\n",
            "Epoch 770/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0023 - accuracy: 0.9995 - val_loss: 0.0864 - val_accuracy: 0.9982\n",
            "Epoch 771/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0021 - accuracy: 0.9997 - val_loss: 0.0765 - val_accuracy: 0.9982\n",
            "Epoch 772/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.0752 - val_accuracy: 0.9982\n",
            "Epoch 773/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.1042 - val_accuracy: 0.9970\n",
            "Epoch 774/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0031 - accuracy: 0.9995 - val_loss: 0.1119 - val_accuracy: 0.9970\n",
            "Epoch 775/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 2.0117e-04 - accuracy: 1.0000 - val_loss: 0.0858 - val_accuracy: 0.9976\n",
            "Epoch 776/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 1.9859e-04 - accuracy: 1.0000 - val_loss: 0.0843 - val_accuracy: 0.9976\n",
            "Epoch 777/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.0847 - val_accuracy: 0.9976\n",
            "Epoch 778/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.0870 - val_accuracy: 0.9976\n",
            "Epoch 779/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.0847 - val_accuracy: 0.9976\n",
            "Epoch 780/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0010 - accuracy: 0.9997 - val_loss: 0.0641 - val_accuracy: 0.9976\n",
            "Epoch 781/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0034 - accuracy: 0.9994 - val_loss: 0.1127 - val_accuracy: 0.9945\n",
            "Epoch 782/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.1681 - val_accuracy: 0.9939\n",
            "Epoch 783/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0079 - accuracy: 0.9985 - val_loss: 0.0835 - val_accuracy: 0.9958\n",
            "Epoch 784/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0029 - accuracy: 0.9995 - val_loss: 0.0765 - val_accuracy: 0.9988\n",
            "Epoch 785/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.0807 - val_accuracy: 0.9964\n",
            "Epoch 786/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0050 - accuracy: 0.9992 - val_loss: 0.0658 - val_accuracy: 0.9970\n",
            "Epoch 787/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0034 - accuracy: 0.9992 - val_loss: 0.0512 - val_accuracy: 0.9951\n",
            "Epoch 788/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0098 - accuracy: 0.9982 - val_loss: 0.1044 - val_accuracy: 0.9976\n",
            "Epoch 789/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.1889 - val_accuracy: 0.9951\n",
            "Epoch 790/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0050 - accuracy: 0.9992 - val_loss: 0.1130 - val_accuracy: 0.9994\n",
            "Epoch 791/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 2.0112e-04 - accuracy: 1.0000 - val_loss: 0.1262 - val_accuracy: 0.9988\n",
            "Epoch 792/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0046 - accuracy: 0.9992 - val_loss: 0.1686 - val_accuracy: 0.9994\n",
            "Epoch 793/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 2.0259e-04 - accuracy: 1.0000 - val_loss: 0.1639 - val_accuracy: 0.9994\n",
            "Epoch 794/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 8.1399e-04 - accuracy: 0.9995 - val_loss: 0.1635 - val_accuracy: 0.9982\n",
            "Epoch 795/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0016 - accuracy: 0.9997 - val_loss: 0.1617 - val_accuracy: 0.9976\n",
            "Epoch 796/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0055 - accuracy: 0.9992 - val_loss: 0.1452 - val_accuracy: 0.9982\n",
            "Epoch 797/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0021 - accuracy: 0.9997 - val_loss: 0.1892 - val_accuracy: 0.9958\n",
            "Epoch 798/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 8.6400e-04 - accuracy: 0.9998 - val_loss: 0.1671 - val_accuracy: 0.9945\n",
            "Epoch 799/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0047 - accuracy: 0.9995 - val_loss: 0.1516 - val_accuracy: 0.9982\n",
            "Epoch 800/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.1482 - val_accuracy: 0.9982\n",
            "Epoch 801/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 0.1656 - val_accuracy: 0.9976\n",
            "Epoch 802/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.1422 - val_accuracy: 0.9988\n",
            "Epoch 803/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.1457 - val_accuracy: 0.9982\n",
            "Epoch 804/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.1564 - val_accuracy: 0.9982\n",
            "Epoch 805/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 2.1232e-04 - accuracy: 1.0000 - val_loss: 0.1586 - val_accuracy: 0.9982\n",
            "Epoch 806/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0035 - accuracy: 0.9994 - val_loss: 0.1384 - val_accuracy: 0.9976\n",
            "Epoch 807/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 1.9644e-04 - accuracy: 1.0000 - val_loss: 0.1269 - val_accuracy: 0.9976\n",
            "Epoch 808/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.0794 - val_accuracy: 0.9970\n",
            "Epoch 809/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0039 - accuracy: 0.9994 - val_loss: 0.1724 - val_accuracy: 0.9970\n",
            "Epoch 810/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 1.9401e-04 - accuracy: 1.0000 - val_loss: 0.1657 - val_accuracy: 0.9970\n",
            "Epoch 811/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0045 - accuracy: 0.9991 - val_loss: 0.0977 - val_accuracy: 0.9951\n",
            "Epoch 812/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0139 - accuracy: 0.9986 - val_loss: 0.2570 - val_accuracy: 0.9830\n",
            "Epoch 813/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0080 - accuracy: 0.9985 - val_loss: 0.1428 - val_accuracy: 0.9976\n",
            "Epoch 814/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0046 - accuracy: 0.9991 - val_loss: 0.1350 - val_accuracy: 0.9964\n",
            "Epoch 815/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0225 - accuracy: 0.9991 - val_loss: 0.1136 - val_accuracy: 0.9976\n",
            "Epoch 816/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0021 - accuracy: 0.9997 - val_loss: 0.1300 - val_accuracy: 0.9976\n",
            "Epoch 817/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0038 - accuracy: 0.9991 - val_loss: 0.1412 - val_accuracy: 0.9976\n",
            "Epoch 818/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 1.8912e-04 - accuracy: 1.0000 - val_loss: 0.1139 - val_accuracy: 0.9976\n",
            "Epoch 819/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.1329 - val_accuracy: 0.9982\n",
            "Epoch 820/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0016 - accuracy: 0.9997 - val_loss: 0.1124 - val_accuracy: 0.9976\n",
            "Epoch 821/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0035 - accuracy: 0.9994 - val_loss: 0.0966 - val_accuracy: 0.9976\n",
            "Epoch 822/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 1.6762e-04 - accuracy: 1.0000 - val_loss: 0.1136 - val_accuracy: 0.9976\n",
            "Epoch 823/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0177 - accuracy: 0.9997 - val_loss: 0.1417 - val_accuracy: 0.9976\n",
            "Epoch 824/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0161 - accuracy: 0.9982 - val_loss: 0.0426 - val_accuracy: 0.9970\n",
            "Epoch 825/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0227 - accuracy: 0.9970 - val_loss: 0.0446 - val_accuracy: 0.9964\n",
            "Epoch 826/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0044 - accuracy: 0.9994 - val_loss: 0.0577 - val_accuracy: 0.9982\n",
            "Epoch 827/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0022 - accuracy: 0.9997 - val_loss: 0.0855 - val_accuracy: 0.9976\n",
            "Epoch 828/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0022 - accuracy: 0.9997 - val_loss: 0.1175 - val_accuracy: 0.9958\n",
            "Epoch 829/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0053 - accuracy: 0.9991 - val_loss: 0.1649 - val_accuracy: 0.9951\n",
            "Epoch 830/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0132 - accuracy: 0.9982 - val_loss: 0.1205 - val_accuracy: 0.9982\n",
            "Epoch 831/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0207 - accuracy: 0.9988 - val_loss: 0.0955 - val_accuracy: 0.9970\n",
            "Epoch 832/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.1191 - val_accuracy: 0.9982\n",
            "Epoch 833/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.1012 - val_accuracy: 0.9964\n",
            "Epoch 834/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0067 - accuracy: 0.9991 - val_loss: 0.1163 - val_accuracy: 0.9964\n",
            "Epoch 835/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 3.1653e-04 - accuracy: 1.0000 - val_loss: 0.0796 - val_accuracy: 0.9964\n",
            "Epoch 836/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.1042 - val_accuracy: 0.9964\n",
            "Epoch 837/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.1067 - val_accuracy: 0.9964\n",
            "Epoch 838/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.1058 - val_accuracy: 0.9964\n",
            "Epoch 839/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0036 - accuracy: 0.9995 - val_loss: 0.1088 - val_accuracy: 0.9970\n",
            "Epoch 840/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.1063 - val_accuracy: 0.9970\n",
            "Epoch 841/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 2.3030e-04 - accuracy: 1.0000 - val_loss: 0.1031 - val_accuracy: 0.9970\n",
            "Epoch 842/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.1078 - val_accuracy: 0.9970\n",
            "Epoch 843/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0098 - accuracy: 0.9994 - val_loss: 0.1207 - val_accuracy: 0.9879\n",
            "Epoch 844/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.0786 - val_accuracy: 0.9964\n",
            "Epoch 845/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 2.4027e-04 - accuracy: 1.0000 - val_loss: 0.0733 - val_accuracy: 0.9994\n",
            "Epoch 846/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0025 - accuracy: 0.9995 - val_loss: 0.0774 - val_accuracy: 0.9982\n",
            "Epoch 847/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.1282 - val_accuracy: 0.9982\n",
            "Epoch 848/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 7.9089e-04 - accuracy: 0.9997 - val_loss: 0.1073 - val_accuracy: 0.9970\n",
            "Epoch 849/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0154 - accuracy: 0.9995 - val_loss: 0.0756 - val_accuracy: 0.9951\n",
            "Epoch 850/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0056 - accuracy: 0.9991 - val_loss: 0.2299 - val_accuracy: 0.9951\n",
            "Epoch 851/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0251 - accuracy: 0.9988 - val_loss: 0.0692 - val_accuracy: 0.9970\n",
            "Epoch 852/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0133 - accuracy: 0.9983 - val_loss: 0.1549 - val_accuracy: 0.9970\n",
            "Epoch 853/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0067 - accuracy: 0.9994 - val_loss: 0.2302 - val_accuracy: 0.9970\n",
            "Epoch 854/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0022 - accuracy: 0.9997 - val_loss: 0.1618 - val_accuracy: 0.9970\n",
            "Epoch 855/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0022 - accuracy: 0.9997 - val_loss: 0.1610 - val_accuracy: 0.9976\n",
            "Epoch 856/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0021 - accuracy: 0.9997 - val_loss: 0.1640 - val_accuracy: 0.9976\n",
            "Epoch 857/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.1495 - val_accuracy: 0.9976\n",
            "Epoch 858/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.1556 - val_accuracy: 0.9976\n",
            "Epoch 859/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0031 - accuracy: 0.9995 - val_loss: 0.1406 - val_accuracy: 0.9976\n",
            "Epoch 860/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.1744 - val_accuracy: 0.9970\n",
            "Epoch 861/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0022 - accuracy: 0.9997 - val_loss: 0.1847 - val_accuracy: 0.9964\n",
            "Epoch 862/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.1735 - val_accuracy: 0.9970\n",
            "Epoch 863/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0021 - accuracy: 0.9997 - val_loss: 0.1737 - val_accuracy: 0.9976\n",
            "Epoch 864/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0021 - accuracy: 0.9997 - val_loss: 0.1705 - val_accuracy: 0.9976\n",
            "Epoch 865/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0048 - accuracy: 0.9995 - val_loss: 0.1632 - val_accuracy: 0.9970\n",
            "Epoch 866/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.1669 - val_accuracy: 0.9964\n",
            "Epoch 867/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0025 - accuracy: 0.9997 - val_loss: 0.1430 - val_accuracy: 0.9970\n",
            "Epoch 868/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0026 - accuracy: 0.9997 - val_loss: 0.2667 - val_accuracy: 0.9909\n",
            "Epoch 869/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0049 - accuracy: 0.9992 - val_loss: 0.1219 - val_accuracy: 0.9970\n",
            "Epoch 870/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0115 - accuracy: 0.9995 - val_loss: 0.1489 - val_accuracy: 0.9945\n",
            "Epoch 871/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0022 - accuracy: 0.9997 - val_loss: 0.1390 - val_accuracy: 0.9964\n",
            "Epoch 872/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0120 - accuracy: 0.9979 - val_loss: 0.0982 - val_accuracy: 0.9958\n",
            "Epoch 873/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0058 - accuracy: 0.9991 - val_loss: 0.1304 - val_accuracy: 0.9988\n",
            "Epoch 874/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.1276 - val_accuracy: 0.9976\n",
            "Epoch 875/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0086 - accuracy: 0.9989 - val_loss: 0.1708 - val_accuracy: 0.9951\n",
            "Epoch 876/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0140 - accuracy: 0.9994 - val_loss: 0.0960 - val_accuracy: 0.9976\n",
            "Epoch 877/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0028 - accuracy: 0.9995 - val_loss: 0.1078 - val_accuracy: 0.9982\n",
            "Epoch 878/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0085 - accuracy: 0.9991 - val_loss: 0.0674 - val_accuracy: 0.9939\n",
            "Epoch 879/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.1063 - val_accuracy: 0.9982\n",
            "Epoch 880/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0045 - accuracy: 0.9994 - val_loss: 0.0950 - val_accuracy: 0.9982\n",
            "Epoch 881/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0029 - accuracy: 0.9995 - val_loss: 0.1321 - val_accuracy: 0.9976\n",
            "Epoch 882/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0044 - accuracy: 0.9991 - val_loss: 0.0757 - val_accuracy: 0.9970\n",
            "Epoch 883/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 2.1699e-04 - accuracy: 1.0000 - val_loss: 0.0800 - val_accuracy: 0.9976\n",
            "Epoch 884/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0045 - accuracy: 0.9992 - val_loss: 0.1082 - val_accuracy: 0.9976\n",
            "Epoch 885/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0182 - accuracy: 0.9991 - val_loss: 0.0761 - val_accuracy: 0.9964\n",
            "Epoch 886/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0052 - accuracy: 0.9992 - val_loss: 0.0583 - val_accuracy: 0.9958\n",
            "Epoch 887/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.0643 - val_accuracy: 0.9982\n",
            "Epoch 888/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.0704 - val_accuracy: 0.9982\n",
            "Epoch 889/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0021 - accuracy: 0.9997 - val_loss: 0.0725 - val_accuracy: 0.9982\n",
            "Epoch 890/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.0715 - val_accuracy: 0.9982\n",
            "Epoch 891/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0060 - accuracy: 0.9994 - val_loss: 0.1020 - val_accuracy: 0.9976\n",
            "Epoch 892/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0028 - accuracy: 0.9995 - val_loss: 0.1147 - val_accuracy: 0.9970\n",
            "Epoch 893/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0044 - accuracy: 0.9991 - val_loss: 0.1130 - val_accuracy: 0.9970\n",
            "Epoch 894/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 2.3277e-04 - accuracy: 1.0000 - val_loss: 0.1113 - val_accuracy: 0.9970\n",
            "Epoch 895/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 3.7122e-04 - accuracy: 0.9998 - val_loss: 0.1501 - val_accuracy: 0.9976\n",
            "Epoch 896/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0041 - accuracy: 0.9995 - val_loss: 0.0874 - val_accuracy: 0.9976\n",
            "Epoch 897/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.1102 - val_accuracy: 0.9970\n",
            "Epoch 898/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.1154 - val_accuracy: 0.9970\n",
            "Epoch 899/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0040 - accuracy: 0.9994 - val_loss: 0.1153 - val_accuracy: 0.9970\n",
            "Epoch 900/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0025 - accuracy: 0.9995 - val_loss: 0.1057 - val_accuracy: 0.9958\n",
            "Epoch 901/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0054 - accuracy: 0.9991 - val_loss: 0.2326 - val_accuracy: 0.9964\n",
            "Epoch 902/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 2.1708e-04 - accuracy: 1.0000 - val_loss: 0.1742 - val_accuracy: 0.9982\n",
            "Epoch 903/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0076 - accuracy: 0.9994 - val_loss: 0.1558 - val_accuracy: 0.9982\n",
            "Epoch 904/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0160 - accuracy: 0.9989 - val_loss: 0.1260 - val_accuracy: 0.9970\n",
            "Epoch 905/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0023 - accuracy: 0.9995 - val_loss: 0.1363 - val_accuracy: 0.9976\n",
            "Epoch 906/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0066 - accuracy: 0.9994 - val_loss: 0.1791 - val_accuracy: 0.9970\n",
            "Epoch 907/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0077 - accuracy: 0.9989 - val_loss: 0.0557 - val_accuracy: 0.9958\n",
            "Epoch 908/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0114 - accuracy: 0.9988 - val_loss: 0.0585 - val_accuracy: 0.9958\n",
            "Epoch 909/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0031 - accuracy: 0.9995 - val_loss: 0.0649 - val_accuracy: 0.9964\n",
            "Epoch 910/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0041 - accuracy: 0.9994 - val_loss: 0.0650 - val_accuracy: 0.9970\n",
            "Epoch 911/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0057 - accuracy: 0.9989 - val_loss: 0.1504 - val_accuracy: 0.9958\n",
            "Epoch 912/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.0956 - val_accuracy: 0.9982\n",
            "Epoch 913/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.1096 - val_accuracy: 0.9982\n",
            "Epoch 914/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.0992 - val_accuracy: 0.9988\n",
            "Epoch 915/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0021 - accuracy: 0.9997 - val_loss: 0.0995 - val_accuracy: 0.9988\n",
            "Epoch 916/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 2.6370e-04 - accuracy: 1.0000 - val_loss: 0.1302 - val_accuracy: 0.9982\n",
            "Epoch 917/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.1283 - val_accuracy: 0.9982\n",
            "Epoch 918/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.1272 - val_accuracy: 0.9982\n",
            "Epoch 919/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0021 - accuracy: 0.9997 - val_loss: 0.1217 - val_accuracy: 0.9982\n",
            "Epoch 920/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0122 - accuracy: 0.9994 - val_loss: 0.5625 - val_accuracy: 0.9879\n",
            "Epoch 921/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0095 - accuracy: 0.9989 - val_loss: 0.0632 - val_accuracy: 0.9958\n",
            "Epoch 922/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0113 - accuracy: 0.9988 - val_loss: 0.1104 - val_accuracy: 0.9970\n",
            "Epoch 923/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0099 - accuracy: 0.9988 - val_loss: 0.1142 - val_accuracy: 0.9970\n",
            "Epoch 924/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0021 - accuracy: 0.9997 - val_loss: 0.1600 - val_accuracy: 0.9958\n",
            "Epoch 925/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0034 - accuracy: 0.9994 - val_loss: 0.1258 - val_accuracy: 0.9976\n",
            "Epoch 926/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0036 - accuracy: 0.9994 - val_loss: 0.1085 - val_accuracy: 0.9982\n",
            "Epoch 927/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 4.0737e-04 - accuracy: 0.9998 - val_loss: 0.1351 - val_accuracy: 0.9982\n",
            "Epoch 928/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 4.0501e-04 - accuracy: 0.9998 - val_loss: 0.1337 - val_accuracy: 0.9976\n",
            "Epoch 929/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.1165 - val_accuracy: 0.9982\n",
            "Epoch 930/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.1355 - val_accuracy: 0.9982\n",
            "Epoch 931/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 5.8638e-04 - accuracy: 0.9998 - val_loss: 0.2117 - val_accuracy: 0.9970\n",
            "Epoch 932/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 0.1156 - val_accuracy: 0.9982\n",
            "Epoch 933/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0021 - accuracy: 0.9997 - val_loss: 0.1256 - val_accuracy: 0.9976\n",
            "Epoch 934/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 1.6770e-04 - accuracy: 1.0000 - val_loss: 0.1238 - val_accuracy: 0.9976\n",
            "Epoch 935/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 1.6538e-04 - accuracy: 1.0000 - val_loss: 0.1245 - val_accuracy: 0.9976\n",
            "Epoch 936/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.1290 - val_accuracy: 0.9970\n",
            "Epoch 937/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0066 - accuracy: 0.9997 - val_loss: 0.0276 - val_accuracy: 0.9970\n",
            "Epoch 938/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0021 - accuracy: 0.9997 - val_loss: 0.0629 - val_accuracy: 0.9982\n",
            "Epoch 939/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0344 - accuracy: 0.9983 - val_loss: 0.1247 - val_accuracy: 0.9909\n",
            "Epoch 940/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0034 - accuracy: 0.9994 - val_loss: 0.0806 - val_accuracy: 0.9976\n",
            "Epoch 941/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0239 - accuracy: 0.9989 - val_loss: 0.0922 - val_accuracy: 0.9964\n",
            "Epoch 942/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0178 - accuracy: 0.9985 - val_loss: 0.0855 - val_accuracy: 0.9970\n",
            "Epoch 943/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.1192 - val_accuracy: 0.9970\n",
            "Epoch 944/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0105 - accuracy: 0.9995 - val_loss: 0.1654 - val_accuracy: 0.9964\n",
            "Epoch 945/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.1310 - val_accuracy: 0.9970\n",
            "Epoch 946/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0021 - accuracy: 0.9997 - val_loss: 0.1116 - val_accuracy: 0.9970\n",
            "Epoch 947/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0048 - accuracy: 0.9992 - val_loss: 0.1387 - val_accuracy: 0.9970\n",
            "Epoch 948/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 2.2885e-04 - accuracy: 1.0000 - val_loss: 0.1233 - val_accuracy: 0.9970\n",
            "Epoch 949/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.1004 - val_accuracy: 0.9982\n",
            "Epoch 950/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.1584 - val_accuracy: 0.9964\n",
            "Epoch 951/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0030 - accuracy: 0.9992 - val_loss: 0.1364 - val_accuracy: 0.9970\n",
            "Epoch 952/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0018 - accuracy: 0.9997 - val_loss: 0.1466 - val_accuracy: 0.9976\n",
            "Epoch 953/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0061 - accuracy: 0.9992 - val_loss: 0.1422 - val_accuracy: 0.9964\n",
            "Epoch 954/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0021 - accuracy: 0.9997 - val_loss: 0.1029 - val_accuracy: 0.9970\n",
            "Epoch 955/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 2.0444e-04 - accuracy: 1.0000 - val_loss: 0.0992 - val_accuracy: 0.9976\n",
            "Epoch 956/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.0992 - val_accuracy: 0.9976\n",
            "Epoch 957/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.0990 - val_accuracy: 0.9970\n",
            "Epoch 958/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0021 - accuracy: 0.9997 - val_loss: 0.0979 - val_accuracy: 0.9982\n",
            "Epoch 959/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0049 - accuracy: 0.9995 - val_loss: 0.2001 - val_accuracy: 0.9958\n",
            "Epoch 960/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0022 - accuracy: 0.9997 - val_loss: 0.1606 - val_accuracy: 0.9964\n",
            "Epoch 961/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0021 - accuracy: 0.9997 - val_loss: 0.1571 - val_accuracy: 0.9970\n",
            "Epoch 962/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0133 - accuracy: 0.9991 - val_loss: 0.0875 - val_accuracy: 0.9970\n",
            "Epoch 963/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0130 - accuracy: 0.9989 - val_loss: 0.1233 - val_accuracy: 0.9976\n",
            "Epoch 964/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 2.6463e-04 - accuracy: 1.0000 - val_loss: 0.0929 - val_accuracy: 0.9970\n",
            "Epoch 965/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0018 - accuracy: 0.9997 - val_loss: 0.0761 - val_accuracy: 0.9982\n",
            "Epoch 966/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.0912 - val_accuracy: 0.9976\n",
            "Epoch 967/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0016 - accuracy: 0.9997 - val_loss: 0.0949 - val_accuracy: 0.9976\n",
            "Epoch 968/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0037 - accuracy: 0.9998 - val_loss: 0.0905 - val_accuracy: 0.9976\n",
            "Epoch 969/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0016 - accuracy: 0.9997 - val_loss: 0.1569 - val_accuracy: 0.9970\n",
            "Epoch 970/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0046 - accuracy: 0.9997 - val_loss: 0.0711 - val_accuracy: 0.9970\n",
            "Epoch 971/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.1062 - val_accuracy: 0.9951\n",
            "Epoch 972/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 5.7596e-04 - accuracy: 0.9998 - val_loss: 0.2022 - val_accuracy: 0.9939\n",
            "Epoch 973/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0040 - accuracy: 0.9994 - val_loss: 0.0374 - val_accuracy: 0.9939\n",
            "Epoch 974/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0115 - accuracy: 0.9988 - val_loss: 0.1775 - val_accuracy: 0.9927\n",
            "Epoch 975/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.2473 - val_accuracy: 0.9958\n",
            "Epoch 976/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0031 - accuracy: 0.9995 - val_loss: 0.3084 - val_accuracy: 0.9939\n",
            "Epoch 977/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0067 - accuracy: 0.9994 - val_loss: 0.2229 - val_accuracy: 0.9945\n",
            "Epoch 978/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0079 - accuracy: 0.9991 - val_loss: 0.1363 - val_accuracy: 0.9970\n",
            "Epoch 979/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0029 - accuracy: 0.9997 - val_loss: 0.1032 - val_accuracy: 0.9970\n",
            "Epoch 980/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.1142 - val_accuracy: 0.9970\n",
            "Epoch 981/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 4.5566e-04 - accuracy: 0.9998 - val_loss: 0.1405 - val_accuracy: 0.9970\n",
            "Epoch 982/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.1394 - val_accuracy: 0.9970\n",
            "Epoch 983/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.1411 - val_accuracy: 0.9970\n",
            "Epoch 984/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.2083 - val_accuracy: 0.9945\n",
            "Epoch 985/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 1.7330e-04 - accuracy: 1.0000 - val_loss: 0.1833 - val_accuracy: 0.9958\n",
            "Epoch 986/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 1.7179e-04 - accuracy: 1.0000 - val_loss: 0.1813 - val_accuracy: 0.9958\n",
            "Epoch 987/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0122 - accuracy: 0.9982 - val_loss: 0.1172 - val_accuracy: 0.9921\n",
            "Epoch 988/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0072 - accuracy: 0.9989 - val_loss: 0.0872 - val_accuracy: 0.9976\n",
            "Epoch 989/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0064 - accuracy: 0.9988 - val_loss: 0.0876 - val_accuracy: 0.9976\n",
            "Epoch 990/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0032 - accuracy: 0.9995 - val_loss: 0.1018 - val_accuracy: 0.9988\n",
            "Epoch 991/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0027 - accuracy: 0.9995 - val_loss: 0.1282 - val_accuracy: 0.9982\n",
            "Epoch 992/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.1666 - val_accuracy: 0.9939\n",
            "Epoch 993/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.1190 - val_accuracy: 0.9988\n",
            "Epoch 994/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0069 - accuracy: 0.9989 - val_loss: 0.1123 - val_accuracy: 0.9988\n",
            "Epoch 995/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 1.9898e-04 - accuracy: 1.0000 - val_loss: 0.1084 - val_accuracy: 0.9994\n",
            "Epoch 996/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 1.9614e-04 - accuracy: 1.0000 - val_loss: 0.1082 - val_accuracy: 0.9994\n",
            "Epoch 997/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.1066 - val_accuracy: 0.9994\n",
            "Epoch 998/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.1076 - val_accuracy: 0.9994\n",
            "Epoch 999/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.1077 - val_accuracy: 0.9994\n",
            "Epoch 1000/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.1073 - val_accuracy: 0.9994\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABKUAAAGGCAYAAACqvTJ0AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAACgn0lEQVR4nOzdeVhUZfsH8O/MwMywg7IvCgiCu7gRampJmqiplaktGpVtUpqVr5RZaUWbiqVpWqa5pGlm/co0pcjMfd9xB0QWUfZlGGbO7w/kMMMMCAgMDN/Pdc31cs55zpnnDJPvw33u534kgiAIICIiIiIiIiIiakRSU3eAiIiIiIiIiIhaHgaliIiIiIiIiIio0TEoRUREREREREREjY5BKSIiIiIiIiIianQMShERERERERERUaNjUIqIiIiIiIiIiBodg1JERERERERERNToGJQiIiIiIiIiIqJGx6AUERERERERERE1OgaliFqY9957DxKJBJmZmY32nvHx8ZBIJNi0aVOjvefd8PX1xdNPP23qbhAREZGZ4Pjrzjj+ImqZGJQiIrpL2dnZUCqVkEgkOHv2rKm7Q0RERGS2JBIJoqKiTN0NIqonDEoREd2ljRs3QiKRwN3dHWvXrjV1d4iIiIiIiJoFBqWIqMUpKCio1+utWbMGERERmDBhAtatW1ev165PxcXF0Gq1pu4GERERtUD1Pf4iIvPAoBQRITExEQEBAejcuTPS09MBlE1JmzZtGnx8fKBQKBAQEIBPPvlEDGoIggBfX1+MGjXK4HrFxcVwcHDACy+8oLdfo9Hgrbfegru7O2xsbPDQQw8hOTnZ4PyNGzeiZ8+esLKygrOzM5588kmkpKTotTlx4gSefvpp+Pv7Q6lUwt3dHc888wxu3ryp1668hsOZM2fw+OOPw8nJCf379xfv4YMPPoC3tzesra1x33334fTp07X67JKSkvDvv/9i/PjxGD9+PK5cuYI9e/YYbbtmzRr06dMH1tbWcHJywoABA/Dnn3/qtfnjjz8wcOBA2NnZwd7eHr1799YLdFVVb2HQoEEYNGiQuF1eR2L9+vWYNWsWvLy8YG1tjdzcXNy6dQtvvPEGunTpAltbW9jb22PYsGE4fvy4wXWLi4vx3nvvoX379lAqlfDw8MDDDz+MS5cu1ek7QERERGU4/qr7+OtOCgoK8Prrr4ufY1BQED7//HMIgqDXbseOHejfvz8cHR1ha2uLoKAgvPXWW3ptvvzyS3Tq1Ekcv/Xq1atJP4Qkam4sTN0BIjKtS5cu4f7770erVq2wY8cOODs7o7CwEAMHDkRKSgpeeOEFtGnTBnv27EF0dDRSU1MRGxsLiUSCJ598Ep9++ilu3bqFVq1aidf8v//7P+Tm5uLJJ5/Ue68PP/wQEokE//vf/5CRkYHY2FiEh4fj2LFjsLKyAgCsXLkSkZGR6N27N2JiYpCeno6FCxfiv//+w9GjR+Ho6AigbBBx+fJlREZGwt3dHadPn8ayZctw+vRp7Nu3DxKJRO+9x44di8DAQHz00UfigGT27Nn44IMPEBERgYiICBw5cgRDhgxBSUlJjT+/H374ATY2NhgxYgSsrKzQrl07rF27Fn379tVr9/777+O9995D3759MWfOHMjlcuzfvx9//fUXhgwZIt77M888g06dOiE6OhqOjo44evQotm3bhscff7zGfdI1d+5cyOVyvPHGG1CpVJDL5Thz5gy2bNmCsWPHws/PD+np6fj6668xcOBAnDlzBp6engDKBrEjRoxAXFwcxo8fj6lTpyIvLw87duzAqVOn0K5du1p/B4iIiIjjr7sdf1VHEAQ89NBD+Pvvv/Hss8+ie/fu2L59O958802kpKRgwYIFAIDTp09jxIgR6Nq1K+bMmQOFQoGLFy/iv//+E6+1fPlyvPrqq3j00UcxdepUFBcX48SJE9i/f3+dx2ZEVIlARC3Ku+++KwAQbty4IZw9e1bw9PQUevfuLdy6dUtsM3fuXMHGxkY4f/683rkzZ84UZDKZkJSUJAiCICQkJAgAhCVLlui1e+ihhwRfX19Bq9UKgiAIf//9twBA8PLyEnJzc8V2P/74owBAWLhwoSAIglBSUiK4uroKnTt3FoqKisR2v/32mwBAmD17trivsLDQ4N5++OEHAYCwa9cug/udMGGCXtuMjAxBLpcLw4cPF/spCILw1ltvCQCESZMmVf9B3talSxfhiSee0Dvf2dlZUKvV4r4LFy4IUqlUGDNmjKDRaPTOL3/v7Oxswc7OTggNDdW7d902giAIbdu2Ndq3gQMHCgMHDhS3yz9zf39/g8+quLjYoB9XrlwRFAqFMGfOHHHfihUrBADC/PnzDd6vvE81/Q4QERG1ZBx/lamP8RcAYcqUKVUe37JliwBA+OCDD/T2P/roo4JEIhEuXrwoCIIgLFiwQPydVGXUqFFCp06d7tgnIqo7Tt8jaqFOnTqFgQMHwtfXFzt37oSTk5N4bOPGjbj33nvh5OSEzMxM8RUeHg6NRoNdu3YBANq3b4/Q0FC94t63bt3CH3/8gSeeeMLgadnEiRNhZ2cnbj/66KPw8PDA1q1bAQCHDh1CRkYGXn75ZSiVSrHd8OHDERwcjN9//13cV/5kDyhLV8/MzMQ999wDADhy5IjB/b744ot62zt37kRJSQleeeUVvX5Omzbtzh/ebSdOnMDJkycxYcIEcd+ECROQmZmJ7du3i/u2bNkCrVaL2bNnQyrV/2e3/L137NiBvLw8zJw5U+/eddvUxaRJk/Q+KwBQKBRiPzQaDW7evCmmrOt+dj/99BOcnZ3xyiuvGFy3vE+1/Q4QERG1ZBx/3f346062bt0KmUyGV199VW//66+/DkEQ8McffwCAmP31yy+/VFlz09HREdeuXcPBgwfrrX9EpI9BKaIWauTIkbCzs8P27dthb2+vd+zChQvYtm0bXFxc9F7h4eEAgIyMDLHtxIkT8d9//yExMRFA2YBKrVbjqaeeMnjPwMBAvW2JRIKAgABcvXoVAMRrBAUFGZwbHBwsHgfKBl9Tp06Fm5sbrKys4OLiAj8/PwBATk6Owfnlx8qVX6tyn1xcXPQGiNVZs2YNbGxs4O/vj4sXL+LixYtQKpXw9fXVGyheunQJUqkUHTt2rPJaly5dAgB07ty5Ru9dU5XvGwC0Wi0WLFiAwMBAKBQKODs7w8XFBSdOnND77C5duoSgoCBYWFQ/07s23wEiIqKWjOOvux9/3UliYiI8PT31AnEA0KFDB70+jBs3Dv369cNzzz0HNzc3jB8/Hj/++KNegOp///sfbG1t0adPHwQGBmLKlCl60/uI6O4xKEXUQj3yyCO4dOmSXvCknFarxQMPPIAdO3YYfT3yyCNi2/Hjx8PS0lK8zpo1a9CrVy+jA5v69Nhjj2H58uV48cUXsXnzZvz555/Ytm2b2P/KKmcL3S1BEPDDDz+goKAAHTt2RGBgoPi6evUqfvnlF+Tn59frewJVZ01pNBqj+43d90cffYTp06djwIABWLNmDbZv344dO3agU6dOdVqdz1TfASIiouaG46+mw8rKCrt27cLOnTvx1FNP4cSJExg3bhweeOABcVzVoUMHJCQkYP369ejfvz9++ukn9O/fH++++66Je09kPljonKiF+uyzz2BhYYGXX34ZdnZ2esUa27Vrh/z8fPHJXHVatWqF4cOHY+3atXjiiSfw33//ITY21mjbCxcu6G0LgoCLFy+ia9euAIC2bdsCABISEnD//ffrtU1ISBCPZ2VlIS4uDu+//z5mz55d5fWrU36tCxcuwN/fX9x/48YNZGVl3fH8f/75B9euXcOcOXPEJ2/lsrKy8Pzzz2PLli148skn0a5dO2i1Wpw5cwbdu3c3er127doBKEvrDwgIqPJ9nZyckJ2dbbA/MTFR7z6qs2nTJtx333349ttv9fZnZ2fD2dlZr0/79++HWq2GpaVllderzXeAiIioJeP46+7GXzV9j507dyIvL08vW+rcuXN6fQAAqVSKwYMHY/DgwZg/fz4++ugjvP322/j777/F34ONjQ3GjRuHcePGoaSkBA8//DA+/PBDREdHG5RcIKLaY6YUUQslkUiwbNkyPProo5g0aRJ+/fVX8dhjjz2GvXv36tVFKpednY3S0lK9fU899RTOnDmDN998EzKZDOPHjzf6nt9//z3y8vLE7U2bNiE1NRXDhg0DAPTq1Quurq5YunQpVCqV2O6PP/7A2bNnMXz4cACATCYDAINlfWsTCAkPD4elpSW+/PJLvevU9BrlU/fefPNNPProo3qvyZMnIzAwUHx6OXr0aEilUsyZM8fgKWL5ew8ZMgR2dnaIiYlBcXGx0TZA2YB13759eivU/Pbbb0aXdq6KTCYz+Ow2btxosOzzI488gszMTCxatMjgGpXPr+l3gIiIqCXj+Ovuxl81ERERAY1GYzB+WbBgASQSiXjft27dMji3/OFh+edw8+ZNveNyuRwdO3aEIAhQq9X11meiloyZUkQtmFQqxZo1azB69Gg89thj2Lp1K+6//368+eab+PXXXzFixAg8/fTT6NmzJwoKCnDy5Els2rQJV69e1cuoGT58OFq3bo2NGzdi2LBhcHV1Nfp+rVq1Qv/+/REZGYn09HTExsYiICAAkydPBgBYWlrik08+QWRkJAYOHIgJEyaISxL7+vritddeAwDY29tjwIAB+PTTT6FWq+Hl5YU///wTV65cqfG9u7i44I033kBMTAxGjBiBiIgIHD16FH/88YfevRmjUqnw008/4YEHHqjyCdlDDz2EhQsXIiMjAwEBAXj77bcxd+5c3HvvvXj44YehUChw8OBBeHp6IiYmBvb29liwYAGee+459O7dG48//jicnJxw/PhxFBYWYtWqVQCA5557Dps2bcKDDz6Ixx57DJcuXcKaNWvETKuaGDFiBObMmYPIyEj07dsXJ0+exNq1aw0yrSZOnIjvv/8e06dPx4EDB3DvvfeioKAAO3fuxMsvv4xRo0aJbWv6HSAiImrpOP6q2/hL16FDh/DBBx8Y7B80aBBGjhyJ++67D2+//TauXr2Kbt264c8//8Qvv/yCadOmiWOmOXPmYNeuXRg+fDjatm2LjIwMfPXVV/D29kb//v0BlD00dHd3R79+/eDm5oazZ89i0aJFGD58uEHNKiKqI5Os+UdEJqO7JHG5wsJCYeDAgYKtra2wb98+QRAEIS8vT4iOjhYCAgIEuVwuODs7C3379hU+//xzoaSkxOC6L7/8sgBAWLduncGx8iWJf/jhByE6OlpwdXUVrKyshOHDhwuJiYkG7Tds2CCEhIQICoVCaNWqlfDEE08I165d02tz7do1YcyYMYKjo6Pg4OAgjB07Vrh+/boAQHj33Xervd9yGo1GeP/99wUPDw/ByspKGDRokHDq1Cmhbdu21S5J/NNPPwkAhG+//bbKNvHx8XrLLQuCIKxYsUK8LycnJ2HgwIHCjh079M779ddfhb59+wpWVlaCvb290KdPH+GHH37QazNv3jzBy8tLUCgUQr9+/YRDhw4JAwcOFAYOHCi2Kf/MN27caNC34uJi4fXXXxfvu1+/fsLevXsNriEIZd+Nt99+W/Dz8xMsLS0Fd3d34dFHHxUuXbpkcN3qvgNEREQtGcdfFeo6/ioHoMrX3Llzxc/xtddeEzw9PQVLS0shMDBQ+OyzzwStViteJy4uThg1apTg6ekpyOVywdPTU5gwYYJw/vx5sc3XX38tDBgwQGjdurWgUCiEdu3aCW+++aaQk5Nzx34SUc1IBKFS/iURUR289tpr+Pbbb5GWlgZra2tTd4dMgN8BIiKixsX/7yWi5o41pYjorhUXF2PNmjV45JFHOCBqofgdICIialz8/14iMgesKUVEdZaRkYGdO3di06ZNuHnzJqZOnWrqLlEj43eAiIiocfH/e4nInDAoRUR1dubMGTzxxBNwdXXFF198Ia5YQi0HvwNERESNi//fS0TmhDWliIiIiIiIiIio0bGmFBERERERERERNToGpYiIiIiIiIiIqNGxppQRWq0W169fh52dHSQSiam7Q0RERE2IIAjIy8uDp6cnpNKW+3yP4yUiIiKqSk3HSwxKGXH9+nX4+PiYuhtERETUhCUnJ8Pb29vU3TAZjpeIiIjoTu40XmJQygg7OzsAZR+evb29iXtDRERETUlubi58fHzE8UJTsGTJEixZsgRXr14FAHTq1AmzZ8/GsGHDjLZfuXIlIiMj9fYpFAoUFxfX+D05XiIiIqKq1HS8xKCUEeUp6Pb29hxkERERkVFNacqat7c3Pv74YwQGBkIQBKxatQqjRo3C0aNH0alTJ6Pn2NvbIyEhQdyu7f1wvERERER3cqfxBYNSRERERM3cyJEj9bY//PBDLFmyBPv27asyKCWRSODu7t4Y3SMiIiIyquVW5yQiIiIyQxqNBuvXr0dBQQHCwsKqbJefn4+2bdvCx8cHo0aNwunTp6u9rkqlQm5urt6LiIiI6G4wKEVERERkBk6ePAlbW1soFAq8+OKL+Pnnn9GxY0ejbYOCgrBixQr88ssvWLNmDbRaLfr27Ytr165Vef2YmBg4ODiILxY5JyIiorslEQRBMHUnmprc3Fw4ODggJyeHNRKIiIhIT1MdJ5SUlCApKQk5OTnYtGkTvvnmG/zzzz9VBqZ0qdVqdOjQARMmTMDcuXONtlGpVFCpVOJ2eQHTpvY5EBERkenVdLzEmlJEREREZkAulyMgIAAA0LNnTxw8eBALFy7E119/fcdzLS0tERISgosXL1bZRqFQQKFQ1Ft/iYiIiDh9j4iIiMgMabVavcym6mg0Gpw8eRIeHh4N3CsiIiKiCsyUIiIiImrmoqOjMWzYMLRp0wZ5eXlYt24d4uPjsX37dgDAxIkT4eXlhZiYGADAnDlzcM899yAgIADZ2dn47LPPkJiYiOeee86Ut0FEREQtjEkzpXbt2oWRI0fC09MTEokEW7ZsueM58fHx6NGjBxQKBQICArBy5UqDNosXL4avry+USiVCQ0Nx4MCB+u88ERERURORkZGBiRMnIigoCIMHD8bBgwexfft2PPDAAwCApKQkpKamiu2zsrIwefJkdOjQAREREcjNzcWePXtqVH+KiIiIqL6YNFOqoKAA3bp1wzPPPIOHH374ju2vXLmC4cOH48UXX8TatWsRFxeH5557Dh4eHhg6dCgAYMOGDZg+fTqWLl2K0NBQxMbGYujQoUhISICrq2tD3xIRERFRo/v222+rPR4fH6+3vWDBAixYsKABe0RERER0Z01m9T2JRIKff/4Zo0ePrrLN//73P/z+++84deqUuG/8+PHIzs7Gtm3bAAChoaHo3bs3Fi1aBKCsnoKPjw9eeeUVzJw5s0Z9aaqr6hAREZHpcZxQhp8DERERVcUsV9/bu3cvwsPD9fYNHToU06ZNA1C2FPLhw4cRHR0tHpdKpQgPD8fevXurvK6xJY6J6iKroARqrRaudsp6u96Ph5IxIbQN7JWW4v68YjUKVBq4O1T/Pgev3sK1rEKMCfEW95WUapGaU4S2rW1q3I+8YjVyi0vh5Whl9HjyrUK0spHDRmH4T0qxWoMrmQU4npwNa4UFnG3kOJOaiydC26JIrcH59DycvJaDx0PbGD0/p1CN7afT4GKnwH3B+tmO+apSLI2/hH/O34CnoxILxnXHjTwVZm05hRPXcvDNpF7o4GGP7afSkFusRs+2TjiSmIWfj13Hq/cHwMPBCh087KDWCNh6MhXJtwoxOsQL9kpLLNh5HpczC+Biq8DNAhU6ezpgWBd3tLKRw8PBCgev3sJbm0/iWlYRWtvK8WAndxxOyoIEwMLxIdh6MhXDOnugTWtrvT7vu3wTq/cl4lJGPpxtFcgpUsNCJkFXLwf4u9giX1UKrVZAF28HdPFywIr/riA9V4Wn+/qis5cDbuSpYCGVwMlGjuW7LmPDoWQMau+CCaFt0M7FFjfzVVh/MBneTlZYGHcBl28UIMjNDm1aW2Pyvf6wlsvgYGUJn1bW2HYqFXZKS/QLcMaplBxsOZoCiQS4kadCvqoU88d1h9JCho2Hk+HpaIX7glzx74UbWLMvEcVqLVSlGnw4pgvUGi2+/Osi4s6mI3ZcCH44kIR2LraY0McHbVpb40J6Pl5eewRqjRYfjemCeTsScColF/97MBh+zjb4dNs53CwogSAIsJZbwM/ZBr39WuHxPm3gaG2JVXuu4mJGPmyVFjh0NQtje3njidC2uJCRhyA3O6RkF8HRuuzz+L/j1zGimyei7gvAtaxC2CotkJJVdtzP2QaHrt7C4r8vIi1XBX8XG/x+omw6U2cve5xKqfi3P6KLO57p54cebZxwNi0XJ6/l4MDVWzialI12Ljbo5u2IQUGuSM8tRma+Co/18sGbm07gpyPXMKyzOx7r5YNLN/LR1dsRvx5PwS/HriOvuBTu9krcF+yKj8Z0xqUbBZix6TjsrSxxM78EY3t54+Ee3khIy0M3bwdoBAFR647icGIWerV1QnJWEVrZWCKvuBRh/q0xqa8vPB2tkJFXjPNp+Th1PQcdPOxxKiUHfs426ObjiLScIng4WOFWQQn2XMrExDBfKC1lSMspxtT1R/FQd0+kZhfjfHoeRod4YeOhZNwsKEEXLwf0C3DGyj1XMb63Dx7uUfZvyLWsQsTuvIA/T6cht7gUY0K88N7IToCk7NjWk6koLNEgt6gUPx25hg4e9njqnrYYHeIJa7kF/jl/A3+cTMWp6zl4O6IjZFIJvoq/CIWFFCO6esLdQYkdZ9KxbNdl9GrrhP6BzihSa9Dd2xHtXG3hZqfE93uv4lZhCa5mFiDpViHeHdkJA9q74GpmAaauPwq1RkBIG0fILaR46p628HexrfG/ddR0ZOQWY8xXeyC3kOLvNwaZujtERETUQJpVplT79u0RGRmpF3TaunUrhg8fjsLCQmRlZcHLywt79uxBWFiY2GbGjBn4559/sH//fqPXfe+99/D+++8b7OeTP/NSWFKKSxkF6OLtYPS4WqPFqZQcHLx6C/7Otgjv6AYASM8tRk6RGu3d7JB8qxBSqUQMzhy6egvrDybj0NVbaNPaBoev3oKFTIrd/7sPdjpBpMquZRVCoxX0AkOCIGDPpZvYeTYdj/TwRmcvBzy0aDdOXMvB+N4+CGnjiO/3JmLpkz0Rte4IzqXl4a83BukFikpKtVi26xK6+Tiif4Az/KK3AgB6tHFE/0AXtHOxwZHELKzam4iVkb3hbKvAy2uPoLCkFF+MD0E7V1us+O8KJoX5Ii23GCE+jjh9PRfjl+1DvqoUTtaW2DWj7N4EQcC3u6/g4NVb2HEmHf0CnDHvsW5ISMuDh4MSWgEYvfg/FJZoavw7+uSRLvB3scXf5zLQ0dMeqdnF+HDrWfH41MGB8GllDY1Wi7d/PoVSrf4/X6+Ft8f5jDwx0FATvdo64VBilt6+8A6u2Hk2o8pz+vi1woErt2r8HgAQ5t8arw9pj/HL9hn0uypyCylKSrUAADuFBX5/9V4M//Jf5BWXGrS1U1qgq7cD/rt4847XlUqAYZ098PvJss/phYH++O14KlKyi/TaBbvbwdvJqtrP4k4iurhj68m0Op3b1dsBHdztseFQssExa7ms2u+WVALU8GM2ieUTe2Hy94eqPB7RxR2HE7OQnlv1ymkWUgkmD/DHit1XoLr9PWkowe52AIBzaXkGxzp42EOt0eJiRn6113i2vx9W7rkKTT3/YpSWUhSrjd//2udC0S/AuV7fD2CGULmG/BxSc4oQFvMX5DIpzn84rF6vTURERA2vpuMEBqVgPFPKx8enxQ82zUWxWoOdZ9PxwW9nkZZbjAXjuomZQ4k3C5BdqIaVXIbpPx7Ty5R4oKMbdp2/AVWpFhIJsPjxHnhj43EUlmjw2yv90cpGjvvnxRv9Y+j7Z/pgQHsXaLUC/ruUiW2n0pBVWIKTKTn4dlJvTFi2D1mFJfj55X5i9kvEF//iVkGJeI22ra2ReLPQ4NpO1pbIKlQDAJxt5Zg6OBD7Lt+CRAIUlWgQd64sgDAoyAXxCTeq/FwCXG3v+EdkVT4f2w2tbeSIXHlQb/+dAgXmaHCwq/iZ15SlTIKQNk44eS0HEgka9DMLcrNDcanG6Hfpbtzj3wr7LtcuMFcVqQR47l5/LNt1uV6uVxP9AlrD39kWa/YnQhDKgpPn0/Nwb3sX5BWX4sz1HGTmlxg994WB/vj6n5r31cvRyiDg19B0A5qNbWgnNzjbKnD5RgGyi9Q4m3rn7ONgdzuDgJeFVAJHa0ujv4en+/pi/5VbVV57yn3tAACP9fKpVVZoTTEoVaYxglKWMgkufBhRr9cmIiKihmeW0/fc3d2Rnp6uty89PR329vawsrKCTCaDTCYz2sbd3b3K6yoUCigUigbpM9WvHw4k4XBiFj5+uAssZGWLRxaoSmEhk0BhITN6zifbzuG7/66K269tOI73/+8M+rVzFjNFjNlxpuJ7JAjAy2uPiNsjvtwNP2ebKp/O7zp/A2dSczH/z/Mo0ei3GbJgl/jzqMX/Vfn+VQURygNSAJCZX4J3fjlttF11ASkAdQ5IAcAbG48b3W8suCKXSfH6kPY4cS0HR5KykJpTrHf84R5e2Hwkpc59GdfLB8evZRv8QfvTS32x8VAy1h+syLIJ9WuF6Q+0x+6LmVi556pextH0B9rjUGIWdp0v+9wcrCxxaFY4sgpK8PLaIwbZVADw8qB2eHNoEIrVWggQYCmTIvDtP8TjQzu5wd1eiVPXc3FY5/xn+vshelgHcfvQ1VvQaAX4OdvgTGounv6uItjXo40jXO2U2HbaeLbRjy+E4Yu4C9h9MRNAWTCig4c91KVaPNzDC8/d6w9BEJBbVIoX1hzC5RsFyMgznn1jp7DA3NGdEerfCjM2ncC/F8qu+c3EXlgcfxFHk7IR6GqLDS+EoZWNHG9uPI6Nh6+JvwdbpQXW7U9CkdrwezB7REf8evw6jiVnAwB+mHwP1h1IwuBgVwzt5F4WGH6gPSykEljIpPCd+bt47r2Bzlj2VC+UarXo8t6f4n5LmQRqTcVzlWGd3fHUPW3x+DfGH0AMDnZF1P0BCGnjJO6bO7qz0bbxCRl6v4e1z4UiM1+FQUGucLCyxNiePgif/4/BeR097PFIT28cScrCa+HtobCQwtvJCufS8nAlswDf/HsZR5Ky9c6JHdcdH/x+psog2PKJvdAvoDUUFjL83/Hr6NnWCY7Wlngw9l8x2PXD5HvQxdsBuUVquNsroREEZOSpsP5AEr7866LR65Yb0dUDMQ93wZPfHsDx5Gx8F9kbQW52VQbdHa0tsS96MJSWMmw8lIw3N50Qj30X2Rv3BVVMsy3VaBGg898EUJbRuPdyJrIL1TiXloe3Izpg8gB/5BSpMW39UfydcAMPdfPEFxNCAAC/nbiOqHVHAZQFvkd09cB7D3XCmeu5iPjiX4P+zRvbDY/09DbYT82LBBJTd4GIiIgaQbMKSoWFhWHr1q16+3bs2CFmRcnlcvTs2RNxcXFixpVWq0VcXByioqIau7tUC8VqDTYcTMbA9i7wdbbBzjPpkEqB+4Pd9NpFbz4JAOgf4IzRIV7YcykTz648BH8XG/z2Sn9IJBKs3nsV+6/cwvzHukNuIdULSJXLLlRXG5CqiSuZBQCAUd09cTEjH6evVzyx/2b3lbu6drkhHd3w55n0O7ZztLZEtk6wStebQ4Pw2fYEcbu2WRvP9ffD28M7QBCAnWfT8fzqw3rHJ/RpA6AsYGiM7rSLvxMyEPndQdzj3wp+zrbwaWWFZ/r5Icy/tfiH7dzRnZFbpMb3e6+io4c9vpgQgo+2nsUPBwyncF2JiYBEIkFGbjH6fBQn7g92t0PPtk7o2dYJg4Jc8OKaI3p/5Ib6t8bA9i54dGlZrbn7g13x6uBA/HEyVQxKPdjJHZYyKVztlfjh+Xsw78/zyFepsWZf2X0+HOKFGQ8GAwCs5BUB0VcHB+KLuAuQSSX4+qleAACtVsCwhf8iIb0scNarbSu9++jlW7Htaq/EFxNC8OoPZX+E9/ZtBV9nG72g1PAuHjicmIVvJvVCZy8HhPq1EoNSCXMfhESi/8ecRCKBg7Ul1j13DwAg7OM4g2lhT/f1xb2Bzhjcoey/uRcGtMPZ1Fy8MSQI4R3d0LOtE06m5KB/gDOk0rLrf/poV2QVlqBIrcGHYzpDJpVg1vAOkEgkyCooQcjcHQDKgh7P9PdDvwBnfL/3Kl4dHAg3eyXC2rXW64PSsuJznNCnjfid8mllffszlmHOqE6Y/ctpvDSoHf73YDAOXb0FN3slvJ2sxPveOX0Adp3PxJzfzojfh5A2Toh5uAtqqrNXxTTf3r5OBlPAAlxt0cnTXu+/ewDYOvVeAMCz8NPb38HDHh087HFfkCtGLtqNixn5YjAGAHKK1Hj3V8MA86WPIiCTVvw+R4d4iT9/MKYzIm8Hzrp6O8BGYQHb23XZpCibZvz6kCC9oNS/M+6Dt1PFlN9SbVkwFQB+mdIPgiCIn+PZOQ+WnXM7OLnzbDruDXSBv4uN+Lt6tKc3itQa7Lt8E8/089P7LgMQHx6I/e/uianhgZiKQIN7dbCyxLKJvfDvhRvooRM4jOjsgdfCC+DvYoOILh7i5+HTquI+hnR0w/xx3XEsKRv9AlobXJuar6aRz09EREQNxaRBqfz8fFy8WDFYvnLlCo4dO4ZWrVqhTZs2iI6ORkpKCr7//nsAwIsvvohFixZhxowZeOaZZ/DXX3/hxx9/xO+/VzxRnz59OiZNmoRevXqhT58+iI2NRUFBASIjIxv9/qh6ecVqTFl3FH3btYZWEPDptgRYyiQ4/M4DeO52rRU/ZxssebIHgt3tkaaTYfPHqVREdPHAor8uokitwenruUjNKYaTtVzMHPqtFnWFAMDTQYnrlbJ4AGBMiBfizqYj10gdHwAY0dUTD+jUnwrVCY7cjfg3BsHX2QZHkrLw8Fd7jLYJdreDi50C30zqhT2XbuKF7w+jRKNFFy8HLHo8RJy2ohuU+m/m/YhadwS/nUiFq50C//dKfzhYWaLr+38ane7zyv2BkEgkkEiAIZ0MMw6fH+CPvZdu4ofb228MaY/P/zxvtL/3Bbli27R74e1kLf7xDOgHdcb29IbSUoYp9wWI+2YO64Dtp9Nhq7DAzukDsXLPFXT3cRL/eHaxU2Bgexf8czug9OQ9bcVzH+zsgT+m3ou2lQqOh7RxQqhfK+y/cgtP9/UFoB8cGtal4l4tZVLMHBaMM9dzxaBUO1fjxZOj7guAhVSCIZ0qAqpSqQSbX+6Lp787gABXOwyuVLC9sjD/ij+qe/u2wn3BrvhsewJuFZTgwU7uWPxED732z93rD1WpFqO6exoEpHSVB5O+eqInojefwPn0smw5n1ZWeO+hTnpt+wc649CsB8RtJxs5BrR30WsjkUjwzaTeRt/L0bqiplonz7IAT5C7HT4cU7PA0DsjOkAqAU6m5GDq4IoAxhOhbdHN21EMGlUOggBAgKsdAlztMKSTGyyk0jsuCGCMs60Cwe52uJZVJAYXK1vzbKgYlHv9x+OIjuhgtJ0uK7kM/xfVH5du5KOTZ0Uac6Bbxffp8dA22H/5JuaO7qwXkKpsUHsXfDSmC5ysLY0uElCuvG7aiK4e8Gml/9+BpcwwgFn55/Lfe+Xff3mbiWG+mBjmW+X7b5nSD3sv3Syrc+dS/VQ6S5nU4GGEVCrB1HDDIJad0hKPh7bBrfwSLHo8BBYyKfoH1n/9KDKNav4pIyIiIjNi0ppS8fHxuO+++wz2T5o0CStXrsTTTz+Nq1evIj4+Xu+c1157DWfOnIG3tzfeeecdPP3003rnL1q0CJ999hnS0tLQvXt3fPHFFwgNDa1xv1grov5dyypEdqFaL/sg5o+zYl2W+4Nd8dftujw7XhuAB3SmuAHAY7288c/5G9UW/ZXLpOjl64Q9lwwLPZevEGWjkOlNJdHNdIgeFoxvdl+Bj5OVOL2mtY0c/828HxOW78PR2/vmje2Gw0lZWLe/LDhx8O1wuNhVTP98YfUhbD9dlt00vIuH0YysfgGt8XCIN16vNA1uWngg/rtYtkLWyG6e4v4beSooLKVIzS7G0Niyz8ZYAd+0nGLYKGQGRdZ/PJSMGZtO4MMxnfFEaFsU3w7kBbnbicGhf87fQHZhCX44kCTWCro30Bmrn9X/b0d3WhVQlsmRVViCl9ccQY+2Tvjfg0FigXUAuPrxcIP7ryyroAT3fvo3gt3tsOmlvkbb3MxXQSaVwNFaXuV1fj1+HYIg4KFu1QdnypWUanEtq1Bvda6YP84iM68EnzzSxSDLo0BVik7vbgdQliX0WC+fO75HXZUX3Z8U5gupVIK8YjV+OJCEsT194GRT9WdQG3suZeLLuIuIebgLfJ3rv+7OE9/sw5HEbPzz5iC42tfPipSNKa9YDVWpFs62DT+9+2a+Cj0/2AkA+HZSLzFjrT6k5hRhy9HreLxPGzhYV70AA9UcxwllGvJzKH/II5NKcOkj1pQiIiJqbppdofOmhIPN+iUIAgZ+Fo+kW4VY8XQv8Sl4+cpyAPBQN0/8evw6gLLATOzOC/X2/t5OVvhj6r1ioEY3qPLtpF54dlVZVtbSJ3tiUFBZJsC4r/fi+LUcLBzfHaO6e+H1H4/jpyNltXNWP9sHVpYyPLp0L9zsFdj/Vrje++27fBPjl+0DAGybdi+sLGV4MPZfjOnhBX9nG5xLy8Mnj3TFjTwV7okpy6paOL47fj+Ris/GdoODVfV/NF7JLMCF9DyjWUvVycxX1eiP65wiNf48nYYhndyhtJQa1Op6++eTWLs/CW1bW+PLCSHo6u1ocA3dz7gmQany97WylEFuIb1zYxMqv7cdrw1AoJudiXvTtKk1WhSWaO74naYy5d+tv98YBL8GCBJS/eE4oUxDfg7l07IZlCIiImqezLLQOTVPFzPykXSrrGj3or8uikGp69kVU+XKA1IAah2QGtXdE78cu2702IUPh0EC/bomXbwccDIlB129HfSmsrjYycU6Kcsn9cKF9HwxE6l8OfSydgoEu9vjxxfC4GFkWpCXY0WdE9/WZbVXjs5+AAoLqV72jruDEj++EAYHK0sEudthVHcvg2sZ4+dsU6c/WGua7eFgZYmx1WQAvT28A/oHOGNgkAus5cb/CQlp44ijSdnwv8NUncrv2xzEvT4Q6TnFDEjVgKVMCgerph1kbEp2Th+IjLxiBqSIdPDZKRERkXljUIoa3FGdlaaOX8tBXrEaljIpbhZUPRWvKp297HEqpaKwcI82jujbrrUYlBrV3RPHkrPFlessZYZ/EEdHBCPubAZeGOivV9dId8qbq50SrnYVAaeIrh74cOtZAICHfVnQqY+fYS0boKwo8zsjOsJeaSEGuXQLOOuq6hpNmbXcAsO6eFTbZvHjPfDNv1cwqW/bats1R+1cbNHOxXg9KaK7EeBqi4AqapURtTisKUVERNQiMChFDaZ8FadMneCTRivgwJVb+HDr2TqtqONur0SAiy223A5CvfZAe9zQWd5+/mPdsf/KTTy+fD/GVZHt07edM/q2q6jF9OQ9bZCRq0JANYEGL0crfDOxF0o02hrVZHm2v98d25gzT0crzB7Z0dTdICKiZo55UkREROaNQSlqEMt3XcbSfy5hwwv3ILtQrXesvIZTdbZPG4C8YjUeXbpXb7+DlRyfPNJFDEo52yrQxcsB9koLdPNxhEwqQd92ztgXPViv+Hh1Phhds9XAwjvWX+FhIiIiqpqEqVJEREQtAoNS1CDKp7q9/fMptG1tXWU7W4UF8lWl4vbUwYHoF+CMIHc7CIKASWFt4WqvxGfbEwAACkspLGRSvB3RARl5xQh2t4NEIsG+twbrFeSuyxLwRERE1LSwpBQREZF5YwVaqjf/XriBfy/c0Nu3/8otZFXKlCrXydMe307qBaVlxdewZ1snsc6SRCLB+6M64+VB7cTj5QVPJw/wx9vDO4qFw63lFpBJ+VSViIjIHEj4f+lEREQtAjOl6K4IgoCfjqQgM1+Fj/84BwD4d8Z9em12nEkHAHg4KJGaU7binsJCil+j+kMmleDHF8Lw0KL/IJHA6GptuivWabUNdSdERERERERE1JgYlKK78ndCBt7YeFxv328nUo229W1tIwalAlxtxcymrt6O+PuNQbCUSeDtVPVUPyIiImoZmChFRETUMnD6Ht2V48k5BvsS0nKNttVd6ry9m53eMT9nm2oDUk/39YWVpQwv6UzlIyIiIvMnsLAUERGR2WKmFN2VjLxig33lK+PpspBKEOhWEZTydKxdIfL3HuqE6IhgvWLmREREZJ4kLCpFRETUIjBTiqqUV6zGV/EXkXSzsMo26bmqGl3r3kBnKHUCStby2sdDGZAiIiJqeZgoRUREZL4YlKIqzfm/M/h0WwLGfr0HQFn6vEarPzJMzzXMlCoXO6473h3ZEf0CWuOzsd2g0FllT2nJABMREREZxzwpIiKiloHT96hKO8+WrZqXnquCWqPFqEX/IflWIb5/tg9C2jhh26lUnL5uvH4UAPg622C0jxci+/kB0M90smJQioiIiIiIiKhFY6YUValIrRF/TrpViDOpuchTlWLPpZsAgBfXHKn2/NY2cr1tpU6mlJWcXz0iIiK6M87eIyIiMl+MDFCVitVa8efswhLx59xitcE0PmOcDIJSzJQiIiKiO2OdcyIiopaBQSmqkawCtfjz1/9cRuhHO8VtBytL8ecJfdqIP9vI9QNPCgvWlCIiIqLaEVjpnIiIyGyxphTVSHaRWm87M78ic+rXqH74fm8isgpKMHdUJ+QUlSDAxdZgOWdmShEREVFNSFjqnIiIqEVgUIpqRHf6nq6ebZ3QtrUN3hnRUdz31RM9jbbVC0rJGZQiIiKiO2OeFBERkfni9D0y6khSlt724r8vGm3nqDN17050p+8xU4qIiIiqxEQpIiKiFoFBKTKw51ImHv5qj96+rEK10bZ2ypon2+lmSskt+NUjIiKiO2NJKSIiIvPFyAAZiNl6rsZt7WuRKaUbiJJyWR0iIiKqAocJRERELQODUmQgq4r6UeVk0oqRor2y5kEpa0sZfFpZwcVOAXcHZZ37R0RERPqWLFmCrl27wt7eHvb29ggLC8Mff/xR7TkbN25EcHAwlEolunTpgq1btzZSb2tHYFUpIiIis8WgFBnIV5VWeeyLCSF4LTxQ3K7N9D2pVIK/Xh+E//53Pyxl/OoRERHVF29vb3z88cc4fPgwDh06hPvvvx+jRo3C6dOnjbbfs2cPJkyYgGeffRZHjx7F6NGjMXr0aJw6daqRe24cE6WIiIhaBkYGSI8gCMgvrghKPRzipXfcViGDlbwiEFWb6XsAYCmTsp4UERFRPRs5ciQiIiIQGBiI9u3b48MPP4StrS327dtntP3ChQvx4IMP4s0330SHDh0wd+5c9OjRA4sWLWrknt8Za0oRERGZL0YHSI+qVItSbdno79T7Q/HSoHZ6x23kFrCWVxQsr830PSIiImp4Go0G69evR0FBAcLCwoy22bt3L8LDw/X2DR06FHv37q3yuiqVCrm5uXqvhiJhUSkiIqIWgUEp0pN3O0tKIimrAWVXKehko7CAlc4qeq72ikbtHxERERl38uRJ2NraQqFQ4MUXX8TPP/+Mjh07Gm2blpYGNzc3vX1ubm5IS0ur8voxMTFwcHAQXz4+PvXafyIiImp5GJQiPeX1pGzlFpBKJQY1o2wVFihWa8TtYHe7Ru0fERERGRcUFIRjx45h//79eOmllzBp0iScOXOm3q4fHR2NnJwc8ZWcnFxv166MeVJEREQtQ82rVFOLcDIlBwCguJ0NZS2XwUIqEaf02Sgs9LKnKmdSERERkWnI5XIEBAQAAHr27ImDBw9i4cKF+Prrrw3auru7Iz09XW9feno63N3dq7y+QqGAQtH4GdKsKUVERGS+mClFet7ceBwAkJmvAlBW08FKp4aUrcICQzu5Ieq+AKx9LtQkfSQiIqI702q1UKlURo+FhYUhLi5Ob9+OHTuqrEHV2FhSioiIqGVgphTpUZVqAQCO1hUZUGqNVvxZaSmFRCLBG0ODGr1vREREZFx0dDSGDRuGNm3aIC8vD+vWrUN8fDy2b98OAJg4cSK8vLwQExMDAJg6dSoGDhyIefPmYfjw4Vi/fj0OHTqEZcuWmfI2jBLAVCkiIiJzZfJMqcWLF8PX1xdKpRKhoaE4cOBAlW3VajXmzJmDdu3aQalUolu3bti2bZteG41Gg3feeQd+fn6wsrJCu3btMHfuXAjM/a6Rdi42AICvHu8h7itWVwSluBoOERFR05ORkYGJEyciKCgIgwcPxsGDB7F9+3Y88MADAICkpCSkpqaK7fv27Yt169Zh2bJl6NatGzZt2oQtW7agc+fOproFPRJWlSIiImoRTJoptWHDBkyfPh1Lly5FaGgoYmNjMXToUCQkJMDV1dWg/axZs7BmzRosX74cwcHB2L59O8aMGYM9e/YgJCQEAPDJJ59gyZIlWLVqFTp16oRDhw4hMjISDg4OePXVVxv7Fpud8gCUtYJJdERERM3Ft99+W+3x+Ph4g31jx47F2LFjG6hH9YfPFYmIiMyXSTOl5s+fj8mTJyMyMhIdO3bE0qVLYW1tjRUrVhhtv3r1arz11luIiIiAv78/XnrpJURERGDevHlimz179mDUqFEYPnw4fH198eijj2LIkCHVZmBRhfKV9awsK+pITR0cCAB4YaC/SfpERERELQsTs4mIiFoGkwWlSkpKcPjwYYSHh1d0RipFeHg49u7da/QclUoFpVKpt8/Kygq7d+8Wt/v27Yu4uDicP38eAHD8+HHs3r0bw4YNq7IvKpUKubm5eq+Wquh2UEppWfHVeOX+APwa1Q9vDmEdKSIiImpcTJQiIiIyXyabo5WZmQmNRgM3Nze9/W5ubjh37pzRc4YOHYr58+djwIABaNeuHeLi4rB582ZoNBqxzcyZM5Gbm4vg4GDIZDJoNBp8+OGHeOKJJ6rsS0xMDN5///36ubFmTBAEo5lSFjIpuno7mqhXRERERERERGSOTF7ovDYWLlyIwMBABAcHQy6XIyoqCpGRkZBKK27jxx9/xNq1a7Fu3TocOXIEq1atwueff45Vq1ZVed3o6Gjk5OSIr+Tk5Ma4HZMqUJUa7CvRaKG9/ThSoROUIiIiIjIVLlZDRERkvkwWlHJ2doZMJkN6erre/vT0dLi7uxs9x8XFBVu2bEFBQQESExNx7tw52Nrawt+/otbRm2++iZkzZ2L8+PHo0qULnnrqKbz22mviEsjGKBQK2Nvb673M2d5LN9Hp3e34dJt+RpruKntWDEoRERGRibCmFBERUctgsqCUXC5Hz549ERcXJ+7TarWIi4tDWFhYtecqlUp4eXmhtLQUP/30E0aNGiUeKyws1MucAgCZTAatVlv5Mi3W3N/OAAC+ir8EANBoBTy36iDe/eUUAEAqASxlHA0SERERERERUcMxWU0pAJg+fTomTZqEXr16oU+fPoiNjUVBQQEiIyMBABMnToSXl5eY5bR//36kpKSge/fuSElJwXvvvQetVosZM2aI1xw5ciQ+/PBDtGnTBp06dcLRo0cxf/58PPPMMya5x6bIolLA6VhyNnaezRC3rSxlkPARJRERETUBnLxHRERkvkwalBo3bhxu3LiB2bNnIy0tDd27d8e2bdvE4udJSUl6WU/FxcWYNWsWLl++DFtbW0RERGD16tVwdHQU23z55Zd455138PLLLyMjIwOenp544YUXMHv27Ma+vSbLQqofcKq0CSWn7hEREZEJScCHY0RERC2BSYNSABAVFYWoqCijx+Lj4/W2Bw4ciDNnzlR7PTs7O8TGxiI2Nraeemh+LGT60xullbKiGJQiIiKipoJ1zomIiMxXs1p9j+qHbr2o69lFKNHo19uyU5o8VklEREQtGKsIEBERtQwMSrVAMp0pkX0//gtFJRq9495OVo3dJSIiIiLjmClFRERkthiUaoEsKxWRupJZoLft7WTdmN0hIiIi0sNEKSIiopaBQakWorCkFFpt2aNGWaWgVEZesd42M6WIiIioqRCYKkVERGS2GJRqATLzVej87nZMXHEAAGBZqdD5jTyV3raHA4NSREREZDoSFpUiIiJqERiUagG2nkyFVgB2X8w0ejyjUlCqta28MbpFREREdEdcfY+IiMh8MSjVAlSerqcq1V9tLz7hht62M4NSREREZELMkyIiImoZGJRqAWQ6KfBarYASjbaa1kBrG0VDd4mIiIioRpgoRUREZL4YlGoBpDpBqSK1BurbmVLOtsaDTw5Wlo3SLyIiIiJjWFKKiIioZWBQqoW5klmAvZdvAgBa2xifpieVciRIRERETYPAolJERERmi0GpFkBVqhF//viPc+LPVnKZQdvvn+nTKH0iIiIiqgpX3yMiImoZGJRqAYrUFUGpzPyKlfasKwWl2rSyxoD2Lo3WLyIiIqI7YZ4UERGR+WJQqgUoVlcUNldYVgSipJWeQhaWlDZan4iIiIiIiIioZWNQqgUo1smUKinVGt0PAM/092u0PhERERHVBEtKERERmS8GpcxQVkEJvoi7gGtZhQD0M6XOpuaKPw/u4Cb+7GqnwAsD2jVeJ4mIiIiqwbJSRERE5o9BKTP02o/HMH/HeTz17QEA+jWlyv3vwWDYKiqm8vUPdIaMq+4RERFREyOwqhQREZHZYlDKDMUn3AAAXMksAACojASlbBQyyKQVv/7KRc+JiIiITImPyoiIiMyfhak7QA2vuNRIUEpuAY1OkQZrOb8KRERE1AQxUYqIiMhsMVOqBcguVBvss1HIYKEzXU9hwa8CERERNR0SFpUiIiIye4xEmLHyGlE38lQAAGdbhXjMRmGhV0PKUsavAhERERERERE1HkYizJidsmxKXmZ+WVDKy8lKPGYtt4CFTk0pBqWIiIioKeLsPSIiIvPFSIQZs5FbICOvGFm3p+95O1YEpcoKnetmSjFFnoiIqLmKiYlB7969YWdnB1dXV4wePRoJCQnVnrNy5UpIJBK9l1KpbKQe3xlHJkREROaPQSkzZqe0wJS1R8RtN/uKgaaN3EKvphQzpYiIiJqvf/75B1OmTMG+ffuwY8cOqNVqDBkyBAUFBdWeZ29vj9TUVPGVmJjYSD2uOYGpUkRERGaLS66ZmXxVqfizlVyGg1ezAABymRQKy4rAk43CAjIZg1JERETmYNu2bXrbK1euhKurKw4fPowBAwZUeZ5EIoG7u3tDd69OWOeciIjI/DESYWaSbxWKP5eUasWfD78TDq3Oo8bKq+9x+h4REZH5yMnJAQC0atWq2nb5+flo27YtfHx8MGrUKJw+fbrKtiqVCrm5uXqvxiCwqhQREZHZYlDKzCTpBKVUt4NSdgoL2CktUaqpGNTJZVKuvkdERGSGtFotpk2bhn79+qFz585VtgsKCsKKFSvwyy+/YM2aNdBqtejbty+uXbtmtH1MTAwcHBzEl4+PT0PdAgBAwqpSREREZo+RCDNjLFPK0qLs16zRVgSlJBIJV98jIiIyQ1OmTMGpU6ewfv36atuFhYVh4sSJ6N69OwYOHIjNmzfDxcUFX3/9tdH20dHRyMnJEV/JyckN0X0DrClFRERkvlhTyszoZ0ppAECcpleq1eq15ep7RERE5iUqKgq//fYbdu3aBW9v71qda2lpiZCQEFy8eNHocYVCAYVCUR/drBkOTYiIiMwe02PMjLHpe+VZULqZUgC4+h4REZGZEAQBUVFR+Pnnn/HXX3/Bz8+v1tfQaDQ4efIkPDw8GqCHdcdEKSIiIvNl8kjE4sWL4evrC6VSidDQUBw4cKDKtmq1GnPmzEG7du2gVCrRrVs3g9VmACAlJQVPPvkkWrduDSsrK3Tp0gWHDh1qyNtoEko1WlxIzxe3VeryoFRZ8MnFTqnXnjWliIiIzMOUKVOwZs0arFu3DnZ2dkhLS0NaWhqKiorENhMnTkR0dLS4PWfOHPz555+4fPkyjhw5gieffBKJiYl47rnnTHELBpgoRUREZP5MOn1vw4YNmD59OpYuXYrQ0FDExsZi6NChSEhIgKurq0H7WbNmYc2aNVi+fDmCg4Oxfft2jBkzBnv27EFISAgAICsrC/369cN9992HP/74Ay4uLrhw4QKcnJwa+/Ya3cK4C0jJrhh8lmjKglIWtwNOLwzwR+LNAgzv4nF7P6fvERERmYMlS5YAAAYNGqS3/7vvvsPTTz8NAEhKSoJUp55kVlYWJk+ejLS0NDg5OaFnz57Ys2cPOnbs2FjdrhGBRaWIiIjMlkQw4f/Th4aGonfv3li0aBGAstVifHx88Morr2DmzJkG7T09PfH2229jypQp4r5HHnkEVlZWWLNmDQBg5syZ+O+///Dvv//WuV+5ublwcHBATk4O7O3t63ydxjbg07+RdKsQg4JcEJ9wQ9zfwcMef0y916D9xYw8hM/fBQDY/HJf9Ghj/oE7IiKiu9Vcxwn1raE/h+B3/kCxWovd/7sP3k7W9X59IiIiajg1HSeYbM5WSUkJDh8+jPDw8IrOSKUIDw/H3r17jZ6jUqmgVOpPQbOyssLu3bvF7V9//RW9evXC2LFj4erqipCQECxfvrxhbqKJyStWAwBCfPSDS1VlQcl0V9+TcvoeERERNT1MlCIiIjJfJotEZGZmQqPRwM3NTW+/m5sb0tLSjJ4zdOhQzJ8/HxcuXIBWq8WOHTuwefNmpKamim0uX76MJUuWIDAwENu3b8dLL72EV199FatWraqyLyqVCrm5uXqv5ihfVQoAsFPqz8rULWhe1X5LC07fIyIioqZDwqpSREREZq9ZpccsXLgQgYGBCA4OhlwuR1RUFCIjI/XqI2i1WvTo0QMfffQRQkJC8Pzzz2Py5MlYunRpldeNiYmBg4OD+PLx8WmM26lXqlIN1JqyR4n2VpZ6x6oqYs5C50RERERERERkKiaLRDg7O0MmkyE9PV1vf3p6Otzd3Y2e4+Ligi1btqCgoACJiYk4d+4cbG1t4e/vL7bx8PAwKNDZoUMHJCUlVdmX6Oho5OTkiK/k5OS7uLOGk3SzEM+uPIgDV24ZHMsvLhV/rpwpVVXASS9TitP3iIiIqAmRMFGKiIjI7JksEiGXy9GzZ0/ExcWJ+7RaLeLi4hAWFlbtuUqlEl5eXigtLcVPP/2EUaNGicf69euHhIQEvfbnz59H27Ztq7yeQqGAvb293qspmrLuCOLOZeCxrw1rbhWoNAAAa7nMoIZU1TWlKvZbcPU9IiIiaoJYU4qIiMh8Wdy5ScOZPn06Jk2ahF69eqFPnz6IjY1FQUEBIiMjAQATJ06El5cXYmJiAAD79+9HSkoKunfvjpSUFLz33nvQarWYMWOGeM3XXnsNffv2xUcffYTHHnsMBw4cwLJly7Bs2TKT3GN9SrxZUOWxPFVZkXMbhQUklR4tWtRg+p6sirpTRERERKbAkQkREZH5M2lQaty4cbhx4wZmz56NtLQ0dO/eHdu2bROLnyclJenViyouLsasWbNw+fJl2NraIiIiAqtXr4ajo6PYpnfv3vj5558RHR2NOXPmwM/PD7GxsXjiiSca+/bqXam26keF5ZlSdgoLyCoFpeQ1qBfFgR8RERE1RQKYKkVERGSuTBqUAoCoqChERUUZPRYfH6+3PXDgQJw5c+aO1xwxYgRGjBhRH91rUqoLSuXrZEpJDTKljIecrOQy8efKxdGJiIiITKly5jcRERGZH5MHpajmSjXaKo/dzC8BADhaW6LyTDyLKoqYKyxk2D5tAAQIUFrKjLYhIiIiMiXWlCIiIjJfDEo1I9UkSiHpViEAoE0ra0grRaXkFlU/aQxyt6uXvhERERHVJ+ZJERERmT+Trb5H9evqzbKgVNvW1obT96rIlCIiIiJq6pgoRUREZL4YrWgmZmw6Xu3xZN1MqUqPFi1rUOiciIiIiIiIiKgxMVrRTPx46Fq1x4vVZavv2SosDabvWVZR6JyIiIioyeLwhYiIyOwxKNXMFZVo8MQ3+3AuLQ8AIJXCYPoeM6WIiIiouRJY6ZyIiMhsMVrRzK3ccxX/XbwpbltIpQbT92SVdxARERE1cRy9EBERmT8GpZoBbTXL7l26ka+3LTOSKWXBoBQRERE1U8yTIiIiMl8MSjUDqlJtlcfScor1tmVSqUFQqnKNKSIiIqKmTiLh+IWIiMjcMSjVDJQXMTfmek6R3rZMIoG00m+VmVJERETUXLGkFBERkfliUKoZqC5TKrtQrbctk0oMMqVYU4qIiIiaGyZKERERmT8GpZq4jNxi3BMTp7dPN8ikrhSwYlCKiIiIzAtTpYiIiMwVg1JN3PJ/Lxvs052OV6IxFpSCwT4iIiKi5oSjFyIiIvNnYeoOUPWMFSnXDUqpjQSlKp9ROXOKiIiIqLlgTSkiIiLzxaBUE2cjN/wVWcgqEty0lQZqMonEoAYDC50TERFRc8PV94iIiMwfp+81cdZymcE+S1nVgzSZzDAoZSzbioiIiKg5YKIUERGR+WKmVBNnozD8FVVXI0omkaDyWn3MlCIiIqLmhqMXIiIi88egVBNnLJ5kIa06wU0mlUBSeUofg1JERETUTLGmFBERkfni9L0mrrRy0SjcYfqe1HD6HoNSRERE1NywpBQREZH5Y1CqidMYCUqVB5kEI48OZVKJwWp7Mo7qiIiIqJkSWFWKiIjIbDEo1cSVagwHYuVBJ7WRYzKpxCAIxUwpIiIian44fiEiIjJ3tQ5K+fr6Ys6cOUhKSmqI/lAlWiPZUOVBqRJN5ZLmZUXNDTKlGJQiIiIyazExMejduzfs7Ozg6uqK0aNHIyEh4Y7nbdy4EcHBwVAqlejSpQu2bt3aCL2tHdaUIiIiMl+1DkpNmzYNmzdvhr+/Px544AGsX78eKpWqIfpGMF5TqjzmpFJrDI5JJRJIKv1WpQxKERERmbV//vkHU6ZMwb59+7Bjxw6o1WoMGTIEBQUFVZ6zZ88eTJgwAc8++yyOHj2K0aNHY/To0Th16lQj9rxqrD5ARERk/uoUlDp27BgOHDiADh064JVXXoGHhweioqJw5MiRhuhji1ZdTSlVac0ypSwYlCIiIjJr27Ztw9NPP41OnTqhW7duWLlyJZKSknD48OEqz1m4cCEefPBBvPnmm+jQoQPmzp2LHj16YNGiRY3Y8ztjphQREZH5qnNNqR49euCLL77A9evX8e677+Kbb75B79690b17d6xYscJoEW6qPWM1pcRMKSNBKamxmlJ81EhERNSi5OTkAABatWpVZZu9e/ciPDxcb9/QoUOxd+/eBu1bTXH0QkREZP4s6nqiWq3Gzz//jO+++w47duzAPffcg2effRbXrl3DW2+9hZ07d2LdunX12dcWSaM1Eni6HWQqKtGfvleeEVU5BsWaUkRERC2HVqvFtGnT0K9fP3Tu3LnKdmlpaXBzc9Pb5+bmhrS0NKPtVSqVXsmG3Nzc+unwHXD1PSIiIvNV66DUkSNH8N133+GHH36AVCrFxIkTsWDBAgQHB4ttxowZg969e9drR1sqYzWlyoNS6bnF+vtvB59Y6JyIiKjlmjJlCk6dOoXdu3fX63VjYmLw/vvv1+s1iYiIqGWr9fS93r1748KFC1iyZAlSUlLw+eef6wWkAMDPzw/jx4+vt062ZMZqSpXHmJKzCvX2l0/TqxyEYlCKiIioZYiKisJvv/2Gv//+G97e3tW2dXd3R3p6ut6+9PR0uLu7G20fHR2NnJwc8ZWcnFxv/TaG1QeIiIjMX60zpS5fvoy2bdtW28bGxgbfffddnTtFFarLlEq+VVhpv/7/lmNQioiIyLwJgoBXXnkFP//8M+Lj4+Hn53fHc8LCwhAXF4dp06aJ+3bs2IGwsDCj7RUKBRQKRX11ucZYppSIiMh81TpTKiMjA/v37zfYv3//fhw6dKheOkUVjGdKlU/fUxndL5FI9AJRDEoRERGZtylTpmDNmjVYt24d7OzskJaWhrS0NBQVFYltJk6ciOjoaHF76tSp2LZtG+bNm4dz587hvffew6FDhxAVFWWKWzAgYalzIiIis1froNSUKVOMpmunpKRgypQpderE4sWL4evrC6VSidDQUBw4cKDKtmq1GnPmzEG7du2gVCrRrVs3bNu2rcr2H3/8MSQSid5TwOak1Eih8/J09pLKq+/pjN0sGJQiIiJqMZYsWYKcnBwMGjQIHh4e4mvDhg1im6SkJKSmporbffv2xbp167Bs2TJ069YNmzZtwpYtW6otjk5ERERUn2o9fe/MmTPo0aOHwf6QkBCcOXOm1h3YsGEDpk+fjqVLlyI0NBSxsbEYOnQoEhIS4OrqatB+1qxZWLNmDZYvX47g4GBs374dY8aMwZ49exASEqLX9uDBg/j666/RtWvXWverqTCWKVUeZKocsNINPVnKpFDdDlpZMChFRERk1oQazHGLj4832Dd27FiMHTu2AXp091hTioiIyPzVOlNKoVAYFMUEgNTUVFhY1DrGhfnz52Py5MmIjIxEx44dsXTpUlhbW2PFihVG269evRpvvfUWIiIi4O/vj5deegkRERGYN2+eXrv8/Hw88cQTWL58OZycnGrdr6bCWFCqfJCm1ugfk+oEnyxkFT9XXo2PiIiIqLlgTSkiIiLzVeug1JAhQ8TVV8plZ2fjrbfewgMPPFCra5WUlODw4cMIDw+v6JBUivDwcOzdu9foOSqVCkqlUm+flZWVwbLHU6ZMwfDhw/Wu3RxVV+i8cqaUbvDJQlrxq+X0PSIiImpuOHohIiIyf7VObfr8888xYMAAtG3bVpwud+zYMbi5uWH16tW1ulZmZiY0Gg3c3Nz09ru5ueHcuXNGzxk6dCjmz5+PAQMGoF27doiLi8PmzZuh0WjENuvXr8eRI0dw8ODBGvVDpVJBpaooGp6bm1ur+2hIxjKlyhlkSrGmFBEREZkZAUyVIiIiMle1zpTy8vLCiRMn8Omnn6Jjx47o2bMnFi5ciJMnT8LHx6ch+qhn4cKFCAwMRHBwMORyOaKiohAZGQnp7cyg5ORkTJ06FWvXrjXIqKpKTEwMHBwcxFdj3EdNGcuUEo9pKhdBNz59j0EpIiIiam4kLD9ARERk9mpfBAqAjY0Nnn/++bt+c2dnZ8hkMoMaVenp6XB3dzd6jouLC7Zs2YLi4mLcvHkTnp6emDlzJvz9/QEAhw8fRkZGhl4xdo1Gg127dmHRokVQqVSQyWR614yOjsb06dPF7dzc3CYTmNJoDINS5bUVKgesdGNPljJO3yMiIqLmjzWliIiIzFedglJA2Sp8SUlJKCkp0dv/0EMP1fgacrkcPXv2RFxcHEaPHg0A0Gq1iIuLQ1RUVLXnKpVKeHl5Qa1W46effsJjjz0GABg8eDBOnjyp1zYyMhLBwcH43//+ZxCQAsqKtysUihr3uzEZy5QqT2M3nL5nPDtKxieNRERERERERNTE1DoodfnyZYwZMwYnT56ERCIRlyAuT7HWre1UE9OnT8ekSZPQq1cv9OnTB7GxsSgoKEBkZCQAYOLEifDy8kJMTAwAYP/+/UhJSUH37t2RkpKC9957D1qtFjNmzAAA2NnZoXPnznrvYWNjg9atWxvsbw402spT9CpUnr6nmxClG4bSLXpORERE1JwwUYqIiMh81TpaMXXqVPj5+SEjIwPW1tY4ffo0du3ahV69eiE+Pr7WHRg3bhw+//xzzJ49G927d8exY8ewbds2sfh5UlISUlNTxfbFxcWYNWsWOnbsiDFjxsDLywu7d++Go6Njrd+7OTCaKVXF9D3d2gu6WVOMSRERETVNycnJuHbtmrh94MABTJs2DcuWLTNhr5oGJnoTERGZv1pnSu3duxd//fUXnJ2dIZVKIZVK0b9/f8TExODVV1/F0aNHa92JqKioKqfrVQ50DRw4EGfOnKnV9esSLGsqjK2+Vx6UUlfKlNIdvEn0VuJjVIqIiKgpevzxx/H888/jqaeeQlpaGh544AF06tQJa9euRVpaGmbPnm3qLpqcwKJSREREZqvW0QqNRgM7OzsAZYXKr1+/DgBo27YtEhIS6rd3dIfV9ypnShlvx5gUERFR03Tq1Cn06dMHAPDjjz+ic+fO2LNnD9auXYuVK1eatnMmxkwpIiIi81frTKnOnTvj+PHj8PPzQ2hoKD799FPI5XIsW7ZMXAGP6o/RTKnb1RUMV9+rGL3pHpPLGJUiIiJqitRqtbjYys6dO8UFY4KDg/XKF7RkzJMiIiIyX7WOVsyaNQva28W358yZgytXruDee+/F1q1b8cUXX9R7B1u6vGJ1lcdKtZULnesEpXSm9kn4qJGIiKhJ6tSpE5YuXYp///0XO3bswIMPPggAuH79Olq3bm3i3pmWBBy/EBERmbtaZ0oNHTpU/DkgIADnzp3DrVu34OTkxOBHA0jNKQYAtLaR42ZBCQCdQufVTN9Ta/hckYiIqKn75JNPMGbMGHz22WeYNGkSunXrBgD49ddfxWl9LR1LShEREZmvWgWl1Go1rKyscOzYMXTu3Fnc36pVq3rvGAH5qlLkFZcCANzslRVBqdvHDQqd6/xcUukYERERNT2DBg1CZmYmcnNz4eTkJO5//vnnYW1tbcKemR6fdRIREZm/Wk3fs7S0RJs2baDRaBqqP6QjLacIAGCntIC1XGZwvHJNKUkV0/eIiIioaSoqKoJKpRIDUomJiYiNjUVCQgJcXV1N3LumgqlSRERE5qrWNaXefvttvPXWW7h161ZD9Id0ZOSpAACudgr9A0LZ8siVi6BLdZ4oVp7aR0RERE3PqFGj8P333wMAsrOzERoainnz5mH06NFYsmSJiXtnWkyUIiIiMn+1DkotWrQIu3btgqenJ4KCgtCjRw+9F9WfopKyjDQbhYXeM0IBgtGaUbqFzjl9j4iIqOk7cuQI7r33XgDApk2b4ObmhsTERHz//fdcQOY21pQiIiIyX7UudD569OgG6AYZU6wuCywpLWQGK+1V3gb0p+9VrjdFRERETU9hYSHs7OwAAH/++ScefvhhSKVS3HPPPUhMTDRx70yLC+gQERGZv1oHpd59992G6AcZUawuy5RSWEqhVlUEmQTB+Op6ukM3LZ8qEhERNXkBAQHYsmULxowZg+3bt+O1114DAGRkZMDe3t7EvSMiIiJqWLWevkeNp7i0LChlZalf5FyA8ULmUv42iYiImpXZs2fjjTfegK+vL/r06YOwsDAAZVlTISEhJu5d08DnbEREROar1plSUqm02nRqrsxXf8prSiktq155TyqpyIqSMs2diIioWXn00UfRv39/pKamolu3buL+wYMHY8yYMSbsmelxVENERGT+ah2U+vnnn/W21Wo1jh49ilWrVuH999+vt44RoCq9XVPKUqpX5FMQBLFmlIVMipLb7XSDhU+EtsHa/Ul4pId343WYiIiIas3d3R3u7u64du0aAMDb2xt9+vQxca+aDhY6JyIiMl+1DkqNGjXKYN+jjz6KTp06YcOGDXj22WfrpWNUUVPKylJmkLpeerumlKVUgpLb+3SfKM4e2RERXTzQs61Tg/eTiIiI6kar1eKDDz7AvHnzkJ+fDwCws7PD66+/jrfffhvSljw3n6lSREREZq/WQamq3HPPPXj++efr63KEiqBU5el7AipW37OQSQGUtZPqDN4UFjL0C3BujG4SERFRHb399tv49ttv8fHHH6Nfv34AgN27d+O9995DcXExPvzwQxP30PQEpkoRERGZrXoJShUVFeGLL76Al5dXfVyObivSDUrpDMgEoaKmlKWsIhLFmlJERETNy6pVq/DNN9/goYceEvd17doVXl5eePnll1t0UIqjGiIiIvNX66CUk5OTXu0iQRCQl5cHa2trrFmzpl4719IVq8trSlU9fc9CJ62fQSkiIqLm5datWwgODjbYHxwcjFu3bpmgR00P86SIiIjMV62DUgsWLNALSkmlUri4uCA0NBROTqxfVJ8qpu9VKnQO6BQ61wlEMSZFRETUrHTr1g2LFi3CF198obd/0aJF6Nq1q4l61TRUt9ozERERmYdaB6WefvrpBugGGVOeKVVW6Fxv+T2d6Xu6mVKN2j0iIiK6S59++imGDx+OnTt3IiwsDACwd+9eJCcnY+vWrSbuXdPAklJERETmq9ZLunz33XfYuHGjwf6NGzdi1apV9dKplipq3RE8+c1+/HbiOgZ8+jcOXLkJwLDQOaCTKaUTiZIwVYqIiKhZGThwIM6fP48xY8YgOzsb2dnZePjhh3H69GmsXr3a1N0zKY5qiIiIzF+tM6ViYmLw9ddfG+x3dXXF888/j0mTJtVLx1oatUaL306kAgB2X8zUO2ajsDCYvifWlNLNlGrBq0YTERE1V56engYFzY8fP45vv/0Wy5YtM1Gvmg6BVaWIiIjMVq3DGElJSfDz8zPY37ZtWyQlJdVLp1qiQpWmymM2cplB6nqptixTiqvvERER0a5duzBy5Eh4enpCIpFgy5Yt1baPj4+HRCIxeKWlpTVOh2uAwxoiIiLzV+uglKurK06cOGGw//jx42jdunW9dKolKigprfKYjcICT/f1FbcFAVCLq+9xxEZERNTSFRQUoFu3bli8eHGtzktISEBqaqr4cnV1baAe3gUmShEREZmtWk/fmzBhAl599VXY2dlhwIABAIB//vkHU6dOxfjx4+u9gy1FYbVBKRnG9vLGzYISfLLtHAQIxqfv8ZEiERFRizRs2DAMGzas1ue5urrC0dGx/jtUD1grk4iIyPzVOig1d+5cXL16FYMHD4aFRdnpWq0WEydOxEcffVTvHWwpCqqbvqewgEQiQbCHnbivfPqeXqFzjt2IiIiahYcffrja49nZ2Y3Sj+7du0OlUqFz585477330K9fv0Z539pgohQREZH5qnVQSi6XY8OGDfjggw9w7NgxWFlZoUuXLmjbtm1D9K/FuNP0PaBiFRq96XvMlCIiImp2HBwc7nh84sSJDfb+Hh4eWLp0KXr16gWVSoVvvvkGgwYNwv79+9GjRw+j56hUKqhUKnE7Nze3wfoH8GEbERFRS1DroFS5wMBABAYG1mdfWrTqCp1bW8r0tgUBKNXcLnQu1S103jB9IyIiovr13XffmfT9g4KCEBQUJG737dsXly5dwoIFC7B69Wqj58TExOD9999vrC6KKi/2QkREROaj1oXOH3nkEXzyyScG+z/99FOMHTu2XjrVElWXKVWeDSXReWSo1pZnSulO32NUioiIiOqmT58+uHjxYpXHo6OjkZOTI76Sk5MbsXdERERkjmodlNq1axciIiIM9g8bNgy7du2ql061NFkFJYjefPKO7cTpe6jIlNKdvseQFBEREdXVsWPH4OHhUeVxhUIBe3t7vVdjEFhVioiIyGzVevpefn4+5HK5wX5LS8sGry1grr6Kv4jCEuPT9+Qy43HD8tX39KfvMSxFRETUEuXn5+tlOV25cgXHjh1Dq1at0KZNG0RHRyMlJQXff/89ACA2NhZ+fn7o1KkTiouL8c033+Cvv/7Cn3/+aapbMMAMcCIiIvNX60ypLl26YMOGDQb7169fj44dO9apE4sXL4avry+USiVCQ0Nx4MCBKtuq1WrMmTMH7dq1g1KpRLdu3bBt2za9NjExMejduzfs7Ozg6uqK0aNHIyEhoU59awzXc4qrPLb62T7iz+VjM0EQUKo1Uui81r9NIiIiMgeHDh1CSEgIQkJCAADTp09HSEgIZs+eDQBITU1FUlKS2L6kpASvv/46unTpgoEDB+L48ePYuXMnBg8ebJL+V4c1pYiIiMxXrTOl3nnnHTz88MO4dOkS7r//fgBAXFwc1q1bh02bNtW6Axs2bMD06dOxdOlShIaGIjY2FkOHDkVCQgJcXV0N2s+aNQtr1qzB8uXLERwcjO3bt2PMmDHYs2ePOBD7559/MGXKFPTu3RulpaV46623MGTIEJw5cwY2Nja17mND83K0qvKYndLS6H6x0DlrShEREbV4gwYNglBN9GblypV62zNmzMCMGTMauFd3h6MaIiIi81fr3JqRI0diy5YtuHjxIl5++WW8/vrrSElJwV9//YWAgIBad2D+/PmYPHkyIiMj0bFjRyxduhTW1tZYsWKF0farV6/GW2+9hYiICPj7++Oll15CREQE5s2bJ7bZtm0bnn76aXTq1AndunXDypUrkZSUhMOHD9e6f40hX1V1kXM7ZUXcUAIjhc510qNa2xhOqyQiIiJqzpgoRUREZL7qNOFr+PDh+O+//1BQUIDLly/jsccewxtvvIFu3brV6jolJSU4fPgwwsPDKzoklSI8PBx79+41eo5KpYJSqdTbZ2Vlhd27d1f5Pjk5OQCAVq1a1ap/jSGnSI11+5OqPG6j0AlKidP3dAudS/DlhBAMbO+C18LbN2hfiYiIiIiIiIjqS52rEO3atQuTJk2Cp6cn5s2bh/vvvx/79u2r1TUyMzOh0Wjg5uamt9/NzQ1paWlGzxk6dCjmz5+PCxcuQKvVYseOHdi8eTNSU1ONttdqtZg2bRr69euHzp07G22jUqmQm5ur92osX/1d9dLLAGCjkBnsE1BRU8pSJsXIbp5Y9UwfODFTioiIiMwEqxIQERGZv1oFpdLS0vDxxx8jMDAQY8eOhb29PVQqFbZs2YKPP/4YvXv3bqh+ihYuXIjAwEAEBwdDLpcjKioKkZGRkFZR5XvKlCk4deoU1q9fX+U1Y2Ji4ODgIL58fHwaqvsG0nKrLnIOAAqLiqCU7thMXZ4pJeWIjYiIiMxXdbWyiIiIqHmrcVBq5MiRCAoKwokTJxAbG4vr16/jyy+/vKs3d3Z2hkwmQ3p6ut7+9PR0uLu7Gz3HxcUFW7ZsQUFBARITE3Hu3DnY2trC39/foG1UVBR+++03/P333/D29q6yH9HR0cjJyRFfycnJd3VfteFqpxB/1q0fBQAKi0q/Hr3pe4ar7xERERGZC2ZKERERmb8aRzT++OMPPPvss3j//fcxfPhwyGSG08pqSy6Xo2fPnoiLixP3abVaxMXFISwsrNpzlUolvLy8UFpaip9++gmjRo0SjwmCgKioKPz888/466+/4OfnV+21FAoF7O3t9V6Nxdm2Iiil+yDwzaFBODQr3MgZZUq1t1ffY6YUERERmTHmSREREZmvGgeldu/ejby8PPTs2ROhoaFYtGgRMjMz77oD06dPx/Lly7Fq1SqcPXsWL730EgoKChAZGQkAmDhxIqKjo8X2+/fvx+bNm3H58mX8+++/ePDBB6HVavWWNZ4yZQrWrFmDdevWwc7ODmlpaUhLS0NRUdFd97chBbnbiT/7traBndJS73j56nsCygqkA4bZVURERETmQAI+eCMiIjJ3NQ5K3XPPPVi+fDlSU1PxwgsvYP369fD09BSLjefl5dWpA+PGjcPnn3+O2bNno3v37jh27Bi2bdsmFj9PSkrSK2JeXFyMWbNmoWPHjhgzZgy8vLywe/duODo6im2WLFmCnJwcDBo0CB4eHuJrw4YNdepjQyovWO7TygodPSoytKzkhr+aitX3BNzMLwEAtNLJtCIiIiIyO0yVIiIiMlu1TrOxsbHBM888g2eeeQYJCQn49ttv8fHHH2PmzJl44IEH8Ouvv9a6E1FRUYiKijJ6LD4+Xm974MCBOHPmTLXXa04FMcsLlg8IdIGFrOKJoNKi+umRtwrKglKtueIeERERmSHWlCIiIjJ/d1UlOygoCJ9++imuXbuGH374ob761KKUFyy3lEkh1ylarpQbBqXKx2YCgKzCsqCUkzWDUkRERGS+BKZKERERma16WbpNJpNh9OjRdcqSaunUtwuWW0glsFFUJK5Vlyml1QrIKiyrKdXalkEpIiIiMj9MlCIiIjJ/9RKUororz5SSySRwd1CK+62MZUrdzmO/WVACze1aVI7WlgbtiIiIiMxFM6rKQERERLXEoJSJld6uKWUplcJDJyiltKy60HlecSkAoJ2LDRR3qD1FRERE1CyxqBQREZHZY1DKxNS3M54sZBI466ykZ2V552BTdx+nBusXERERUVPATCkiIiLzxaCUiYmZUjIpPB2txP1Gp+9V2tbNrCIiIiIyJ8yTIiIiMn8Wd25CDam8ppSFVAIHK0usey4UAIxOy6ucxS6TcrhGRERE5o2JUkREROaLQSkTq5i+V5a01jfAucbnWsoYlCIiIiLzxJJSRERE5o/T90ysYvpeTUZe+m1kUv76iIiIyLwJLCpFRERktpgpZSKr9yVi9d6rUN4uaG5RgwBT5SeGzJQiIiIic8VRDhERkfljUMpE3tlySm/bog4BJgvWlCIiIiIzxzwpIiIi88X5X01ETbKeKreQyfjrIyIiIvMkYVEpIiIis8eoRhNRk+l7lVkyU4qIiIjMHEtKERERmS8GpZqIGmVKSSoXOmdQioiIiMwTRzlERETmj0GpJqJGhc4rbVty+h4RERGZPaZKERERmStGNZqIuhQ6Z6YUERERERERETVXDEo1ETXJeqpc77MmU/6IiIiImiPWOSciIjJ/DEo1ERY1yHqSoHJNKf76iIiIyLyx0DkREZH5YlSjiajL9L26nENERETUHFR+GEdERETmh0GpJqLyynrG2+hvWzJTioiIiMwcE6WIiIjMF6MaTYS0DoUTWOiciIiIzBaHOURERGaPQakmQlaHoBQLnRMREREA7Nq1CyNHjoSnpyckEgm2bNlyx3Pi4+PRo0cPKBQKBAQEYOXKlQ3ez7pgTSkiIiLzxaBUE1GTmFTlNsyUIiIiIgAoKChAt27dsHjx4hq1v3LlCoYPH4777rsPx44dw7Rp0/Dcc89h+/btDdzTmuMoh4iIyPxZmLoDVKYu0/csZYwpEhERETBs2DAMGzasxu2XLl0KPz8/zJs3DwDQoUMH7N69GwsWLMDQoUMbqpt1IrCqFBERkdliVKOJqEnN8sqr0DBTioiIiOpi7969CA8P19s3dOhQ7N27t8pzVCoVcnNz9V4NqQ7P64iIiKiZYVCqiahJTSmD1fdYU4qIiIjqIC0tDW5ubnr73NzckJubi6KiIqPnxMTEwMHBQXz5+Pg0RldZU4qIiMiMMSjVREjqtPoef31ERETUOKKjo5GTkyO+kpOTG/T9KmeIExERkflhTakmoiYz8SrHrSw4fY+IiIjqwN3dHenp6Xr70tPTYW9vDysrK6PnKBQKKBSKxuieHiZKERERmS+m2jQRNSl0XvmJoQWn7xEREVEdhIWFIS4uTm/fjh07EBYWZqIeGWJNKSIiIvPHoFQTUZei5RacvkdEREQA8vPzcezYMRw7dgwAcOXKFRw7dgxJSUkAyqbeTZw4UWz/4osv4vLly5gxYwbOnTuHr776Cj/++CNee+01U3S/WgKLShEREZmtJhHVWLx4MXx9faFUKhEaGooDBw5U2VatVmPOnDlo164dlEolunXrhm3btt3VNZuCmjwNZKFzIiIiMubQoUMICQlBSEgIAGD69OkICQnB7NmzAQCpqaligAoA/Pz88Pvvv2PHjh3o1q0b5s2bh2+++QZDhw41Sf+NYaYUERGR+TN5TakNGzZg+vTpWLp0KUJDQxEbG4uhQ4ciISEBrq6uBu1nzZqFNWvWYPny5QgODsb27dsxZswY7NmzRxyI1faajU2rNXziV5PpewbnsKYUERERARg0aFC1GUUrV640es7Ro0cbsFdERERE1TN5ptT8+fMxefJkREZGomPHjli6dCmsra2xYsUKo+1Xr16Nt956CxEREfD398dLL72EiIgIzJs3r87XbGwaI4PGmtWU0ifjI0QiIiIyU1x9j4iIyPyZNChVUlKCw4cPIzw8XNwnlUoRHh6OvXv3Gj1HpVJBqVTq7bOyssLu3bvrfM3GpjGWKVWD30TlGFRdsquIiIiImhOWlCIiIjJfJg1KZWZmQqPRwM3NTW+/m5sb0tLSjJ4zdOhQzJ8/HxcuXIBWq8WOHTuwefNmpKam1vmaKpUKubm5eq+GpK1jplRljEkRERGRueI4h4iIyPyZfPpebS1cuBCBgYEIDg6GXC5HVFQUIiMjIb2LlehiYmLg4OAgvnx8fOqxx4aMZkrVaOSl34aZUkRERGTuBDBVioiIyFyZNCjl7OwMmUyG9PR0vf3p6elwd3c3eo6Liwu2bNmCgoICJCYm4ty5c7C1tYW/v3+drxkdHY2cnBzxlZycXA93VzWt1nBfTWqWG07fq5/+EBERERERERE1NpMGpeRyOXr27Im4uDhxn1arRVxcHMLCwqo9V6lUwsvLC6Wlpfjpp58watSoOl9ToVDA3t5e79WQjBY6r0OEScJMKSIiIjJzrClFRERkvixM3YHp06dj0qRJ6NWrF/r06YPY2FgUFBQgMjISADBx4kR4eXkhJiYGALB//36kpKSge/fuSElJwXvvvQetVosZM2bU+JqmVtfpe5VbMFOKiIiIzBUfvhEREZk/kwelxo0bhxs3bmD27NlIS0tD9+7dsW3bNrFQeVJSkl69qOLiYsyaNQuXL1+Gra0tIiIisHr1ajg6Otb4mqZmvND5nc+rPDjjYI2IiIiIiIiImiuTB6UAICoqClFRUUaPxcfH620PHDgQZ86cuatrmlrdC53rtq+v3hARERE1XZy+R0REZL6a3ep75qA+pu9x5T0iIiIyZxzpEBERmT8GpUzAeFCqdtdgUIqIiIhaAiZKERERmS8GpUzA6Op7NcmU0m3CmBQRERGZMT5/IyIiMn8MSpmASq012FeTgZdEJxLFmlJERETUEggsKkVERGS2GJQygVfXHzXYV9uV9Dh9j4iIiMwZRzpERETmj0EpE7iYkV+n83TjUAxKERERUUvAPCkiIiLzxaBUM8WYFBEREZmz2maRExERUfPDoFQzxUwpIiIiahGYKkVERGS2GJRqRnTjUIxJERERkTnjUIeIiMj8MShlAj3bOt31NZgpRURERC2BwFQpIiIis8WglAlYyuoWUNKtrSBlTIqIiIjMGJ+/ERERmT8GpUxAq63bebpjMxb/JCIiopZAYKIUERGR2WJQygS09TC6YqYUERERmTcOdoiIiMwdg1ImUNeglG5yFGtKERERUUvARCkiIiLzxaCUCWjrOLqSQLemFINSREREZL441CEiIjJ/DEqZQH1M3yMiIiJqCThsIiIiMl8MSplAvUzf42+OiIiIzBgTpYiIiMwfQxsmUB+r73H6HhEREbUEAqtKERERmS0GpUygflbfY1CKiIiIzBeHOkREROaPQSkTqHNQSmdwxoEaERERtQSsKUVERGS+GJQygbquvqeLmVJERERkziSsKkVERGT2GJQygToXOtcZnHGYRkRERLoWL14MX19fKJVKhIaG4sCBA1W2XblyJSQSid5LqVQ2Ym9rjolSRERE5otBKROo8+w93dX3mClFREREt23YsAHTp0/Hu+++iyNHjqBbt24YOnQoMjIyqjzH3t4eqamp4isxMbERe0xERETEoJRJaOph/h5jUkRERFRu/vz5mDx5MiIjI9GxY0csXboU1tbWWLFiRZXnSCQSuLu7iy83N7dG7PGdcaxDRERk/hiUMoG6T9/T+ZkjNSIiIgJQUlKCw4cPIzw8XNwnlUoRHh6OvXv3Vnlefn4+2rZtCx8fH4waNQqnT5+u9n1UKhVyc3P1Xo2Clc6JiIjMFoNSJlD36XsVgSgpY1JEREQEIDMzExqNxiDTyc3NDWlpaUbPCQoKwooVK/DLL79gzZo10Gq16Nu3L65du1bl+8TExMDBwUF8+fj41Ot9VMbnb0REROaPQSkTqGumlC4O1IiIiKiuwsLCMHHiRHTv3h0DBw7E5s2b4eLigq+//rrKc6Kjo5GTkyO+kpOTG6WvzJMiIiIyXxam7kBLVNeaUnrT97j+HhEREQFwdnaGTCZDenq63v709HS4u7vX6BqWlpYICQnBxYsXq2yjUCigUCjuqq+1wbEOERGR+WOmlAnUtc65bnYUM6WIiIgIAORyOXr27Im4uDhxn1arRVxcHMLCwmp0DY1Gg5MnT8LDw6OhullndUkwn/dnAiatOIBSjbb+O0RERET1hplSJiDUx/S9eugHERERmYfp06dj0qRJ6NWrF/r06YPY2FgUFBQgMjISADBx4kR4eXkhJiYGADBnzhzcc889CAgIQHZ2Nj777DMkJibiueeeM+Vt6LuLwc6Xf5VlfP11LgNDOtUsW4yIiIgan8kzpRYvXgxfX18olUqEhobiwIED1baPjY1FUFAQrKys4OPjg9deew3FxcXicY1Gg3feeQd+fn6wsrJCu3btMHfu3HoJBNWXuq++x1QpIiIiMjRu3Dh8/vnnmD17Nrp3745jx45h27ZtYvHzpKQkpKamiu2zsrIwefJkdOjQAREREcjNzcWePXvQsWNHU91Cle5mDFdcykwpIiKipsykmVIbNmzA9OnTsXTpUoSGhiI2NhZDhw5FQkICXF1dDdqvW7cOM2fOxIoVK9C3b1+cP38eTz/9NCQSCebPnw8A+OSTT7BkyRKsWrUKnTp1wqFDhxAZGQkHBwe8+uqrjX2LRlWuKbVt2r21vgZX3yMiIiJdUVFRiIqKMnosPj5eb3vBggVYsGBBI/Sq7upjqKOta80EIiIiahQmzZSaP38+Jk+ejMjISHTs2BFLly6FtbU1VqxYYbT9nj170K9fPzz++OPw9fXFkCFDMGHCBL3sqj179mDUqFEYPnw4fH198eijj2LIkCF3zMBqTJUf+AW729fsRInRH4mIiIjM1t2ElepjxWMiIiJqOCYLSpWUlODw4cMIDw+v6IxUivDwcOzdu9foOX379sXhw4fFANPly5exdetWRERE6LWJi4vD+fPnAQDHjx/H7t27MWzYsCr7olKpkJubq/dqSHWevqc3e49hKSIiIjJf9THWYaIUERFR02ay6XuZmZnQaDRirYNybm5uOHfunNFzHn/8cWRmZqJ///4QBAGlpaV48cUX8dZbb4ltZs6cidzcXAQHB0Mmk0Gj0eDDDz/EE088UWVfYmJi8P7779fPjdVAfQyQGJIiIiKilqC2z/J0a1Bx+h4REVHTZvJC57URHx+Pjz76CF999RWOHDmCzZs34/fff8fcuXPFNj/++CPWrl2LdevW4ciRI1i1ahU+//xzrFq1qsrrRkdHIycnR3wlJyc36H1o6lzoXOdnRqWIiIjIjNV1qFOqE4ji9D0iIqKmzWSZUs7OzpDJZEhPT9fbn56eDnd340v3vvPOO3jqqafE5Yq7dOmCgoICPP/883j77bchlUrx5ptvYubMmRg/frzYJjExETExMZg0aZLR6yoUCigUinq8u+rVdRUZ3TR2Tt8jIiKilkCt0WLWlpMYEOiCIZ2MjxF16S4oU9cHgURERNQ4TJYpJZfL0bNnT8TFxYn7tFot4uLiEBYWZvScwsJCSKX6XZbJZAAqAj1VtdFqm86SwJy+R0RERFS98udvGw4lY82+JDy/+nCNztPPlGqInhEREVF9MVmmFABMnz4dkyZNQq9evdCnTx/ExsaioKAAkZGRAICJEyfCy8sLMTExAICRI0di/vz5CAkJQWhoKC5evIh33nkHI0eOFINTI0eOxIcffog2bdqgU6dOOHr0KObPn49nnnnGZPdZWZ0Lnev+zKgUERERtQBpOcW1aq/RVIyz6pqdTkRERI3DpEGpcePG4caNG5g9ezbS0tLQvXt3bNu2TSx+npSUpJf1NGvWLEgkEsyaNQspKSlwcXERg1DlvvzyS7zzzjt4+eWXkZGRAU9PT7zwwguYPXt2o9+fMYIg6BXs9HexqdN1pIxKERERkRkrH+nUdsxTqpMdz0LnRERETZtJg1IAEBUVhaioKKPH4uPj9bYtLCzw7rvv4t13363yenZ2doiNjUVsbGw99rL+6I6NfnulPwJcbWt8ru6YjDEpIiIiaglqO+bRrSml1jAoRURE1JQ1q9X3zIHu1D2fVtZQWspqfK5EZwKfhFWliIiIyIyVL+qimylVk8wn3ZpSJZqmU1OUiIiIDDEo1ch0g1LSu4grMVOKiIiIWgLdMU+RWnPH9rqZUiWlDEoRERE1ZQxKNTLdelK1rZHAQBQRERG1FNbysmzyQlVFIKqw5M5BKbVOdpSamVJERERNGoNSjUz36d3dFCtnoXMiIiIyZ61s5AD0p+AV1SAopV9TikEpIiKipoxBqUamN33vLj59xqSIiIjInJUHpXQVqkvveF4pp+8RERE1GwxKNTJtPU3fY0yKiIiIzJnRoFQtM6VKuPoeERFRk8agVCMThLpP39NbfY+pUkRERGTGjAWlajJ9r7Sa6Xu64zAiIiIyPQalGpl+Tam6X4chKSIiIjJnrW0UBvtyi9QAgD9Pp2HL0RSj52m0FYGonNvtASCroAQDP4vHrC0n67mnREREVFcMSjWy8piURFL7bCe96XuMShEREZEZC3a3Q/8AZ7196bnFSM8txvOrD2PahmPIyCvWO16gKsXbP58St5NvFYo/L//3MpJuFWLNvqSG7TgRERHVGINSjaw8bfxuV8/j9D0iIiIyZ1KpBKuf7aO3LzW3GNtOpYnb17P1g1Irdl/BubQ8cTvpVqE49jqTmtuAvSUiIqK6YFCqkZVnStVl6p6kip+JiIiIzJFEIkEXLwdxOy2nGNdzisTtqHVHcCNPJW5fz9EPUhWWaJBx+3iazrHycgrLdl1C9OaT0GpZa4qIiMgUGJRqZJrbT+vqkumkew4TpYiIiKglWP/8PXhhgD8AICWrCLfyS8Rj17KK8PzqQ+J2ayPF0XeeTQcA5KtKxX3lP3+09Rx+OJCEXRduNEjfiYiIqHoMSjWy8idxsrudvsdcKSIiImoBbBQWGNPDCwBwLi0PNwtK9I4fTcoWfxZgmPH09s+nsCT+ErJ0zstXlUJVWrGS34X0/HruNREREdUEg1KNTKiv6XuMSREREVELEeBiC6WlFPmqUvx1LsPgePnUvPziUr393k5WAIBPtp1DQUlFECq/uBR5Om0TbxU0RLeJiIjoDhiUamTauyh0rnvK3RZKJyIiImouLGRSRHTxqPL4t7sv49DVW3qBJgD4Naq/0fZ5xWrkFqnF7QSd4ui7L2Ti8g1mThERETUGBqUaWUVNqbu7jrQuqVZEREREzdQnj3RFmH9rcXvji2H434PBAIDl/17Bo0v3YvPRFL1zWtnI8cfUew2udSNPpRfAOpWSi1KNFqev5+DJb/fj/nn/NNBdEBERkS4GpRpZ+bLEsjoElXQLndvIZfXWJyIiIqKmzlImxYJx3TG0kxtmPBiEXm2d8Fgv7zue18HD3mDfwrgL2H0xU9wuUmsQufIglu+6LO67mFGRLbX7QiZ+PJiMfFUpHl2yB9PWH73LuyEiIiKAQalGpxVrSt1dppO13KIeekNERETUfLg7KPH1U73w8qAASCQStLZV4I0h7e943j3+rQAA9wY6AygrmP7Z9gS9Nv9eyMSWY9fF7fD5/+BWQQlyCtV4ZuVBzPjpBB5dsgeHErOw5dh15KtKIQgC/jiZipTsonq8S2opiko0+PFgMm7kqUzdFSIik2Fko5Fpxel7dxeUslEwU4qIiIgo6v5AvDwoAHmqUqw/kISNh6/BQirBq4MDxTZLn+yJ3RczMayzB+77PB5JtwrFY272CqTnGg8KvPLDEdgrLVGi0QIoC2aVu3KjAGfTcjFj0wl4OVrhv5n3I7dYDXulZQPdafNTWFKKo0nZCPVrBQsZn4VX9un2c/juv6vo7GWP314xnGZKRNQSMCjVyNq52OLAW4Pv+jrMlCIiIiIqI5VK4GBliRcGtsMLA9sZHHe0lmNEV08AwMePdMGvx67jcmYBjiRm4Zl+fth5Nh0Hr2YZnPffxZtVvudvJ6/jeHI2ACAluwi/nbiOqHVH8Vx/P8wa0RGCIGDjoWvILFDhuf7+kFtIIQgCVKVaKC1bxsPF6RuOY9vpNMx4MAgvDwowdXeanF9uZ+adSslt1PctKtFAKwiwUfDviZoqLCnl319EDYSPLBqZpUwKV3slXO2Vd3UdW2ZKERERkY7FixfD19cXSqUSoaGhOHDgQLXtN27ciODgYCiVSnTp0gVbt25tpJ6aVt92zvj4ka748YUwnJv7IF4Y2A4bX+yLQ7PC4WwrR5CbHXZOH4Cu3g7iOf0DnDFreAe8NKgdXr2/LLjy9T+Xse/yLbFN1LqyOlPf7L6CTYevwS96K2b8dAKfbkvAhoNJSM8txn2fx2PAp3/j0o18cfrfzXwVdp5JF+uOAsD0H4/hsaV7UazWNNKn0jC2nU4DUPZZ3Ylao8XbP5/E/x2/fse2dyNfVYr/O34dJaXaO7YtUJXicOItvd9NTak1Wvzf8evILVbfuXEj0moFDFu4C/fPi2/236/G8uPBZHR6dzt+O9Ew380L6Xn45VhKnb5nVSlWa7D5yDXcKiipt2sSNRSGe5spK0bqiYiI6LYNGzZg+vTpWLp0KUJDQxEbG4uhQ4ciISEBrq6uBu337NmDCRMmICYmBiNGjMC6deswevRoHDlyBJ07dzbBHZiG7pQyZ1sF/pt5P6QSCSxlUmx8MQxr9iWhf4AzgtztxHZarYCTKTn4O+FGldd9Y+Nxve13fjmNd345LW4Pvr26n4OVJXKKyoIWk8LaYsr9AZBAgs1HylYR/OtcBga2dwEAnE3NxcGrWejm7QBfZxvcyFOhm48jAKCkVAuJBLiSWYCtJ1PxeJ82d/0AtLJFf13AxYx8fDa2GyxrORVPEASUlGpRoCqFk43caJv/O34da/cnYe3+JDzQ0Q1FJZoq29bG9ewitLKRi9lpb/xYlr31/AB/vBXRodpz3/r5JH45dh2fPdoVY3v5AACyC0tgr7SEWqvFrvOZGNjeBXILw8/j8z8T8PU/lxHewRXfTOp91/dRX9LzinH1Ztn01Qvp+eiiE3ytjWW7LuFCej4+erhLrb8PDenQ1VuI/O4gZo/sKP7O6qqoRINVe6/i4z/OASgLPJdnXNanBxbsAgDYKiwwuINbvVxzYdwFLIm/hHv8W2H982E1Pq9Uo8WtwhK42tXvvx+mJAgCMvJUcLVT3HUJnYa04WASvvvvKr5+qifatrYxdXcaFSMbzRRX3yMiIqJy8+fPx+TJkxEZGQkAWLp0KX7//XesWLECM2fONGi/cOFCPPjgg3jzzTcBAHPnzsWOHTuwaNEiLF26tFH73pQoLGR6Pz/b38+gjVQqwZIne+LTbQk4n56H9NxiXLi9Ut8LA/zx9a47ZwWVKw9IAcCqvYnYcCgZIT5O4r6X1x6p9vyebZ0Q5G6HdfuT4OmghAAgNacYsTsvYEIfH1zLKkIXLwdYWcrg5qDEor8uQm4hRQcPe1zLKsTRpGxMDGsLT0crtHOxxb2BzmLw5o+Tqdh4+BreGdERrazl+PzP8wCA+4Jd4WKngFwmRZvW1th9IRPhHd1gr7TE3+cyMPe3M3CxU2DVM33EfpZotJj50wn834nr+DWqPzp42EMQBMTuvICbBSr878FgfPnXRbH9+GX7kJCWh23T7kXb1jb4dvcVWEglGNHVA+m5KnT0tIdGK+DEtWwkZxVhYHsX5KtKsf/yTYS1a41zaXnYfCQFw7u446W1R/BwiDc+H9sVEolEzN5atusynrvXz+CP7/PpeUhIy0O/AGdxet0Hv5/FmBAv/HUuAy+sOYzJ9/pDrdHiu/+u4um+vnhnREeDlbXLV3LceTYD59JyEexetgrkxYx8ONvKYae0rDKLRRAE/J2QgUBXO/i0stY7diWzAEpLKTwcrAzOU2u0WLXnKmwVFhjfpw00WsGgX2v2JYo/X71ZUKOglCAIen/MF6s1+GhrWaDm/mBXDOviodf+Zr4KU9cfg8JCioUTQmBby2mCqlINLqTno5OnfbVBhIzcYoxftg9dvR2wYFx3JN4sxKNL9wIA3tx0Ao/08IZU5/6LSjRYsPM8Hujoht6+re7Yj/d+PY0Nh5KrbSMIAk5cy0FHT3sxOFf586qORluRHfXvhUwM7uAGVamm2oBn5fcvLNHAWi7Te891+5MAQC+b05iMvGKo1Frxe/bJtnP4ZvcVrHk2FP0CnO/Yf0EQsO/yLSgspejRxumO7WsjM1+F7afT8NXfl/DFhBD0bOuEo0lZeHX9UVhKpdjwQhi+iLuAUq0WH47uove7Lleq0eKltUew40w63hwahCn3VT2NuFSjRalWgFQiwdnUXHT1doBEIkFRiQaL/76IBzu7o7OX8f9eNFoBf5xKRc+2TnC1Uxr8d6fVCihUa6CwkFYZxP3fTycBAAM/i8d3kb1xX5DhA6VyhSWluJiRjyB3O73/3yrVaCGTSgy+f2qNFhKgydb2kwj1mSdoJnJzc+Hg4ICcnBzY2xsuI2xKvjN/BwB8/0wfDLj95IyIiIgaT1MbJ5SUlMDa2hqbNm3C6NGjxf2TJk1CdnY2fvnlF4Nz2rRpg+nTp2PatGnivnfffRdbtmzB8ePHDdob09Q+B1PKyCuGs40CUqkEuy9kQiMIYoZT8q1CrD+YhINXs1BUUjZd6mRKDtq52MDDwQoXM/KRlluM1jZy3GwCU208HJTQCkKVxd91yS2k4jQ4bycrXMuq2SqED4d44UhSlpixU+17yKRioflyUknFitYA4GRtiazCO0+Tc7aVIzNf/zMOdLVFSBtHWMstcDQpC8ev5Rg9105hgTxVaRXXVeD+YBdcvlGAQ4lZ8He2weXMAr02j/TwhpVcirX7k2CvtEQrGzmu6LTp1dYJA9u7wNPRCpcz87H470sIdLXFq4MDkV1YAoWFDPHnM7D1ZJp4ziv3ByD5ViFyitTwdLTC2tuBCABwtVMgI0+FYHc7DOvsAWu5DMVqDebtOC+26RfQGmN7+iC3WI2EtDzEnc1AsIcduno5wN3BCsVqDS5k5OGXY9fhZC3HfcEu6NW2FU6m5ODb3VcAAIOCXPBMPz9YyCRIySrCDweScCQpW3yPPn6tMCnMF/4uNsgqLMHN/BI4WFniaFI2/u/EdQS726GzlwMspBJIJRJczy7CX+cycDmzAE/39cUjPbxRpNZAEAT8dzET6bkqWMllWLs/EWpNxZfgjSHtsXJPIjLz9b+3j/TwRptW1gh0s8Wvx66LQUlnWzkiunhAKpGgtY0cof6tIZOW1fdSlWpgo7DA2z+fMvhdR3RxR1dvR/i2toaNwgLbT6dhzb4kBLvb4Zl+fvj9ZCpOpuRgdHcvDApygY3CAkm3CvD7iTRoBQEeDkqkZBfBxVYBjSDgVkEJ4m9nXQa72+G9hzph+a7LiDuXAU8HJSb29UVOkRpaQUB7Vzu0d7NDcakGKrUWaq0Wf5xMxY+HrsHTQYlxvdsg0M0WJaVaTNtwTOzziK4e+CfhBjp42sPTQQlfZxt09XbAd/9dxb8XMgEArWzkcLS2xOUbZd9Je6UFljzZE1pBgFqjhVojQGEhhb2VJYpLyj6fgpJS7DiTju/+uwoAUFhI8eGYLtBotXCzV8LZVoHcYjW+35MIVakGSksZDl69hZJSLR7q7omu3o64fKMsyOrtZA03ewUKVBrcyFfhVn4JFuw8r/fZLxzfHVPXV9yXrcIC+bf/m2zTyhrP3esHR2s58otL8d1/V9DJ0x7XsopwKLGiXuAHozuj9e0MTIkEyCsuRU6RGlcyC/T++yk3rpcPtp9JQ/btf1++nBCCw4lZ8HBQQmkpg5VchozcYjFoDwAWUgnc7JV4uq8vgj3sUKotC8AfT86GRAKE+bfGhD5t4O1khZJSLYpLtUjPLcaMTSf03jvY3Q5DOrkjyM0OB6/egqejEm1b2+BCeh5id15AqVZAKxs55o7qjEs38mEpk2LNvkSkZBehf4AzerR1wn1BLtBoBbz24zFkFagxtpc33OyVuJpZID5gUKm1aO9mi9a2CoP7v1s1HScwKGVEUx5klQelNr/ct96j0URERHRnTW2ccP36dXh5eWHPnj0IC6uYpjFjxgz8888/2L9/v8E5crkcq1atwoQJE8R9X331Fd5//32kp6cbfR+VSgWVquIPvtzcXPj4+DSZz6E5MZbBUlhSinl/nsfVzAL08m2Fkd08yqYICgI+//M8corUGNXdU8ze8XRQQmEp0wtseDoo4WynwInbgRWJBHCylhtk5Pg52+idBxgGeoiIqGVY+mRPPNjZvd6vW9PxEqfvNTMT+rRBWk4Runs7mrorRERE1ILExMTg/fffN3U3zELlgBRQtrLyOyM66u176v/bu/Ooqq67feDPnQfkMnNBBUGlzkmJCAFMbCpvnH62ptY0hhhMW11OiUObxiEmtlmKnaxtVoIlq5quX1RaW7XG8aUYk5oqKIpKNGjqRJRBZJ4ucM/3/YN4m1s1MRXOAX0+a+215Jx9L3t/r+Cztvuc83AfAMCTIyJg0uuh1+vwqykPwvi5yzNuXCr0+UuGmlvduFbn8lySIyKoaWqF1WTwXJ7X0qagtrkVfjYTXG0K9Dpg54kSXKluQnObG30CfTAgzBc1TS1QFMBgaP8en1Y1Ifd8JVxtCiICbUiIDsIn5XWwmgxwtSn4fw+EI+9CJUpqmhEV7IOE6EBsOVqMMyV1OF1SizCHFQ6bERajAVPjIzEwzBfnKxpw8tNqVDW2IriHGUE+FlQ2uHC5shFmox79Q3vAbjbCbNDjyMVKVDe1oriyEf1CeuBrTl+U1TYj98J1LEj5GiobWnChogEj+wdje8EVfPhJBcYODYdbUdDgcqNfiA+ig3vgg3PXEPLZTo6SmmaU1jQjKtiOw+crMWaIEwadDqdL6vDC6P7IPV+Jj67WoKzWhYf7BqF/aA8UVzV6dmjVNLXier0LFfUtyL9UhcS+QYgK9kEvfyssRgOuN7SgqrF9XL0DbIgMtKO2qQ2tbgVXq5ugiGB7wVWMiAqAyaBHZUMLPq1qQoivBSE9LLCaDWhwtaHB1Yb46ED881/XYTcbEO5nRVmtCwF2E5pbFRw6fx2PD3YiOsQHzS1uXKlugkGvQ72rfTfIpYpG9LAaMSDMF4/GhOD/H74Ei1GPEF8LrCYDsk+XISrIjoToIFypbkJJTRMcNhMUAR6K9EdxZRPK65rR0qZgYJgvIoN8sK+wFHq9Dm1uBSaD3vMZPzkiAjoAh/51HVdrmtDcqkARQQ+LEcpneyJMhvadN738rTAb9HBL+8Oc+gT5YEfBVdQ0tcKtCIwGHXQ6oLiyfSeeUa+D0aBDc6uC+KhADOvth4PnKtDiVtDSpuDRrwXjfz8qw6BwB5pa3TDo23dgGfU6BPewoKe/DR+X1sJhNeFf1+rhalMQ6mtB/Wd/P+zm9s/M12pERV0LAn3MMBp0GBTuQG1TK/IuVMLPbkJdc/tn6G8zoX+oL86W1cHpsKK2uRUGnQ7ldc1oblXgVgRtigK72Qh/uwknP63BIzHBuF7fgsqGFgzu6UCgjxnX610oKq2DTqfDleomDA534Fq9C30C7YgItOPY5Sq4WhXYPruNi0j7pWb/M8QJX4sRfz9TjvLaZoQ4rKioc6He1YYxQ5y4UNGA8joX/G0mDOnlh6LSOpRUN6F3gB3J/YOxp7AE9a42fFrVBJNBh+hgH4T52XC1ugkmgx5mgw6uNgUV9S0wGXRodQvcSvtTRB1WE4J9zWhpU3DkYhWG9fKDQa9DSU37Z2U26lHX3IbqxlZ8PcIfBcXVsJr0aG5V0MvfhnpXG3ytRviYjdDpgOsNLWhqccPHYkC4nw0jPxtfmyIwGfRwtbnx1IhIXK9vab/ELsIP5681IPt0GfqF+KBNab9/XUlNM8xGPSID7ahsaMGrEwfj6MUqFJXWtdcO7X8H3Yqg1S3oE2TH8c92+IX7WdHY4sbpklok9w/ChWsN8LEYYTMbUO9qn4vNZEBVY/uuP4fVhE+rGuH0s+LhvkFobnGjqrEFpbUuiLSP22TQ4bEBoTAa9Hj/bDmuVjfDrQgsJj3a3IIGVxuuN7TA6bDgfwY78c7hy/CzmTw/n40tblTUudDT34aIQDvqmltx6XojfCztv9Pb3ILKxhZcq3MhzGHFA739UNnQgivVTTAadGh0uTEo3AE/mwmnS2pxoaIBQT5m2Mztr7eYtL2sjzulbqGr/Q8oERERdR1dLSeodfked0oRERHRnbrTvNQ173RFRERERHfEbDZj+PDhyMnJ8RxTFAU5OTlel/N9XmJiold/AMjOzr5tfwCwWCxwOBxejYiIiOhu8PI9IiIiom5u0aJFSEtLQ1xcHOLj47F27Vo0NDR4nsb37LPPolevXkhPTwcAzJ8/H6NGjcKvf/1rTJgwAVlZWTh69CgyMzO1nAYRERHdZ7goRURERNTNfe9738O1a9fwyiuvoLS0FF//+texd+9eOJ1OAMDly5eh1/97g3xSUhI2bdqEl19+GUuXLkVMTAy2b9+OoUOHajUFIiIiug9pfvneG2+8gaioKFitViQkJCAvL+8L+69duxYDBgyAzWZDREQEFi5ciObmZq8+V65cwTPPPIOgoCDYbDYMGzYMR48e7cxpEBEREWlq3rx5uHTpElwuF3Jzc5GQkOA5d+DAAbz99tte/adMmYKioiK4XC4UFhZi/PjxKo+YiIiI7nea7pT605/+hEWLFmHdunVISEjA2rVrMWbMGBQVFSE0NPSm/ps2bcLixYuxfv16JCUl4ezZs5g+fTp0Oh3WrFkDAKiqqkJycjIee+wx7NmzByEhITh37hwCAgLUnh4REREREREREd2GpotSa9aswYwZMzz3O1i3bh127dqF9evXY/HixTf1/+c//4nk5GQ8/fTTAICoqChMnToVubm5nj4///nPERERgQ0bNniORUdHd/JMiIiIiIiIiIjoq9Ds8r2Wlhbk5+cjJSXl34PR65GSkoJDhw7d8jVJSUnIz8/3XOJ3/vx57N6922u7+Y4dOxAXF4cpU6YgNDQUsbGxeOutt75wLC6XC7W1tV6NiIiIiIiIiIg6j2aLUhUVFXC73Z4bcN7gdDpRWlp6y9c8/fTT+NnPfoaRI0fCZDKhX79++MY3voGlS5d6+pw/fx4ZGRmIiYnBvn37MHv2bLzwwgv44x//eNuxpKenw8/Pz9MiIiI6ZpJERERERERERHRLmt/o/Ks4cOAAVq1ahTfffBPHjh3D1q1bsWvXLrz22muePoqi4KGHHsKqVasQGxuLmTNnYsaMGVi3bt1t33fJkiWoqanxtOLiYjWmQ0RERERERER039LsnlLBwcEwGAwoKyvzOl5WVoawsLBbvmb58uWYNm0afvjDHwIAhg0bhoaGBsycORPLli2DXq9HeHg4Bg8e7PW6QYMG4a9//ettx2KxWGCxWO5yRkREREREREREdKc02yllNpsxfPhw5OTkeI4pioKcnBwkJibe8jWNjY3Q672HbDAYAAAiAgBITk5GUVGRV5+zZ8+iT58+HTl8IiIiIiIiIiK6C5o+fW/RokVIS0tDXFwc4uPjsXbtWjQ0NHiexvfss8+iV69eSE9PBwBMnDgRa9asQWxsLBISEvDJJ59g+fLlmDhxomdxauHChUhKSsKqVavw5JNPIi8vD5mZmcjMzLzjcd1Y4OINz4mIiOg/3cgHN/LC/Yp5iYiIiG7njvOSaOz111+XyMhIMZvNEh8fL4cPH/acGzVqlKSlpXm+bm1tlRUrVki/fv3EarVKRESEzJkzR6qqqrze891335WhQ4eKxWKRgQMHSmZm5lcaU3FxsQBgY2NjY2NjY7ttKy4uvpsI1O0xL7GxsbGxsbF9WfuyvKQTuc//m+8WFEXB1atX4evrC51O1+HvX1tbi4iICBQXF8PhcHT4+9PtsfbaYe21w9prh7XXTmfWXkRQV1eHnj173nRbgfsJ89K9i7XXDmuvHdZeO6y9drpCXtL08r2uSq/Xo3fv3p3+fRwOB3/oNMLaa4e11w5rrx3WXjudVXs/P78Of8/uhnnp3sfaa4e11w5rrx3WXjta5qX797/3iIiIiIiIiIhIM1yUIiIiIiIiIiIi1XFRSgMWiwWvvvoqLBaL1kO577D22mHttcPaa4e11w5r3/3xM9QOa68d1l47rL12WHvtdIXa80bnRERERERERESkOu6UIiIiIiIiIiIi1XFRioiIiIiIiIiIVMdFKSIiIiIiIiIiUh0XpVT2xhtvICoqClarFQkJCcjLy9N6SN1eeno6RowYAV9fX4SGhmLSpEkoKiry6tPc3Iy5c+ciKCgIPXr0wOTJk1FWVubV5/Lly5gwYQLsdjtCQ0Px4osvoq2tTc2pdGurV6+GTqfDggULPMdY98515coVPPPMMwgKCoLNZsOwYcNw9OhRz3kRwSuvvILw8HDYbDakpKTg3LlzXu9RWVmJ1NRUOBwO+Pv74wc/+AHq6+vVnkq34na7sXz5ckRHR8Nms6Ffv3547bXX8PlbNLL2HeODDz7AxIkT0bNnT+h0Omzfvt3rfEfV+eTJk3jkkUdgtVoRERGBX/ziF509NfoSzEsdj3mpa2BeUh/zkjaYl9TT7fOSkGqysrLEbDbL+vXr5aOPPpIZM2aIv7+/lJWVaT20bm3MmDGyYcMGKSwslIKCAhk/frxERkZKfX29p8+sWbMkIiJCcnJy5OjRo/Lwww9LUlKS53xbW5sMHTpUUlJS5Pjx47J7924JDg6WJUuWaDGlbicvL0+ioqLkgQcekPnz53uOs+6dp7KyUvr06SPTp0+X3NxcOX/+vOzbt08++eQTT5/Vq1eLn5+fbN++XU6cOCHf+ta3JDo6Wpqamjx9xo4dKw8++KAcPnxY/vGPf0j//v1l6tSpWkyp21i5cqUEBQXJzp075cKFC7Jlyxbp0aOH/Pa3v/X0Ye07xu7du2XZsmWydetWASDbtm3zOt8Rda6pqRGn0ympqalSWFgomzdvFpvNJr///e/Vmib9B+alzsG8pD3mJfUxL2mHeUk93T0vcVFKRfHx8TJ37lzP1263W3r27Cnp6ekajureU15eLgDk/fffFxGR6upqMZlMsmXLFk+fM2fOCAA5dOiQiLT/IOv1eiktLfX0ycjIEIfDIS6XS90JdDN1dXUSExMj2dnZMmrUKE/IYt0710svvSQjR4687XlFUSQsLEx++ctfeo5VV1eLxWKRzZs3i4jI6dOnBYAcOXLE02fPnj2i0+nkypUrnTf4bm7ChAny/e9/3+vYd77zHUlNTRUR1r6z/GfI6qg6v/nmmxIQEOD1O+ell16SAQMGdPKM6HaYl9TBvKQu5iVtMC9ph3lJG90xL/HyPZW0tLQgPz8fKSkpnmN6vR4pKSk4dOiQhiO799TU1AAAAgMDAQD5+flobW31qv3AgQMRGRnpqf2hQ4cwbNgwOJ1OT58xY8agtrYWH330kYqj737mzp2LCRMmeNUXYN07244dOxAXF4cpU6YgNDQUsbGxeOuttzznL1y4gNLSUq/6+/n5ISEhwav+/v7+iIuL8/RJSUmBXq9Hbm6uepPpZpKSkpCTk4OzZ88CAE6cOIGDBw9i3LhxAFh7tXRUnQ8dOoRHH30UZrPZ02fMmDEoKipCVVWVSrOhG5iX1MO8pC7mJW0wL2mHealr6A55yXhXr6Y7VlFRAbfb7fWPCQA4nU58/PHHGo3q3qMoChYsWIDk5GQMHToUAFBaWgqz2Qx/f3+vvk6nE6WlpZ4+t/psbpyjW8vKysKxY8dw5MiRm86x7p3r/PnzyMjIwKJFi7B06VIcOXIEL7zwAsxmM9LS0jz1u1V9P1//0NBQr/NGoxGBgYGs/xdYvHgxamtrMXDgQBgMBrjdbqxcuRKpqakAwNqrpKPqXFpaiujo6Jve48a5gICAThk/3RrzkjqYl9TFvKQd5iXtMC91Dd0hL3FRiu4pc+fORWFhIQ4ePKj1UO55xcXFmD9/PrKzs2G1WrUezn1HURTExcVh1apVAIDY2FgUFhZi3bp1SEtL03h097Y///nP2LhxIzZt2oQhQ4agoKAACxYsQM+ePVl7IuoWmJfUw7ykLeYl7TAv0Z3i5XsqCQ4OhsFguOlJGmVlZQgLC9NoVPeWefPmYefOnXjvvffQu3dvz/GwsDC0tLSgurraq//nax8WFnbLz+bGObpZfn4+ysvL8dBDD8FoNMJoNOL999/H7373OxiNRjidTta9E4WHh2Pw4MFexwYNGoTLly8D+Hf9vuh3TlhYGMrLy73Ot7W1obKykvX/Ai+++CIWL16Mp556CsOGDcO0adOwcOFCpKenA2Dt1dJRdebvoa6FeanzMS+pi3lJW8xL2mFe6hq6Q17iopRKzGYzhg8fjpycHM8xRVGQk5ODxMREDUfW/YkI5s2bh23btmH//v03bSscPnw4TCaTV+2Liopw+fJlT+0TExNx6tQprx/G7OxsOByOm/4ho3ajR4/GqVOnUFBQ4GlxcXFITU31/Jl17zzJyck3Pcr77Nmz6NOnDwAgOjoaYWFhXvWvra1Fbm6uV/2rq6uRn5/v6bN//34oioKEhAQVZtE9NTY2Qq/3/ufTYDBAURQArL1aOqrOiYmJ+OCDD9Da2urpk52djQEDBvDSPQ0wL3Ue5iVtMC9pi3lJO8xLXUO3yEt3fat0umNZWVlisVjk7bffltOnT8vMmTPF39/f60ka9NXNnj1b/Pz85MCBA1JSUuJpjY2Nnj6zZs2SyMhI2b9/vxw9elQSExMlMTHRc/7Go3Yff/xxKSgokL1790pISAgftfsVff5pMiKse2fKy8sTo9EoK1eulHPnzsnGjRvFbrfLO++84+mzevVq8ff3l7/97W9y8uRJ+fa3v33Lx7/GxsZKbm6uHDx4UGJiYviY3S+RlpYmvXr18jzieOvWrRIcHCw/+clPPH1Y+45RV1cnx48fl+PHjwsAWbNmjRw/flwuXbokIh1T5+rqanE6nTJt2jQpLCyUrKwssdvtHfKIY/rvMC91DualroN5ST3MS9phXlJPd89LXJRS2euvvy6RkZFiNpslPj5eDh8+rPWQuj0At2wbNmzw9GlqapI5c+ZIQECA2O12eeKJJ6SkpMTrfS5evCjjxo0Tm80mwcHB8qMf/UhaW1tVnk339p8hi3XvXO+++64MHTpULBaLDBw4UDIzM73OK4oiy5cvF6fTKRaLRUaPHi1FRUVefa5fvy5Tp06VHj16iMPhkOeee07q6urUnEa3U1tbK/Pnz5fIyEixWq3St29fWbZsmdcjcln7jvHee+/d8vd7WlqaiHRcnU+cOCEjR44Ui8UivXr1ktWrV6s1RboN5qWOx7zUdTAvqYt5SRvMS+rp7nlJJyJyd3utiIiIiIiIiIiIvhreU4qIiIiIiIiIiFTHRSkiIiIiIiIiIlIdF6WIiIiIiIiIiEh1XJQiIiIiIiIiIiLVcVGKiIiIiIiIiIhUx0UpIiIiIiIiIiJSHReliIiIiIiIiIhIdVyUIiIiIiIiIiIi1XFRioioA+l0Omzfvl3rYRARERF1WcxLRHQDF6WI6J4xffp06HS6m9rYsWO1HhoRERFRl8C8RERdiVHrARARdaSxY8diw4YNXscsFotGoyEiIiLqepiXiKir4E4pIrqnWCwWhIWFebWAgAAA7VvFMzIyMG7cONhsNvTt2xd/+ctfvF5/6tQpfPOb34TNZkNQUBBmzpyJ+vp6rz7r16/HkCFDYLFYEB4ejnnz5nmdr6iowBNPPAG73Y6YmBjs2LHDc66qqgqpqakICQmBzWZDTEzMTaGQiIiIqDMxLxFRV8FFKSK6ryxfvhyTJ0/GiRMnkJqaiqeeegpnzpwBADQ0NGDMmDEICAjAkSNHsGXLFvz973/3ClEZGRmYO3cuZs6ciVOnTmHHjh3o37+/1/f46U9/iieffBInT57E+PHjkZqaisrKSs/3P336NPbs2YMzZ84gIyMDwcHB6hWAiIiI6EswLxGRaoSI6B6RlpYmBoNBfHx8vNrKlStFRASAzJo1y+s1CQkJMnv2bBERyczMlICAAKmvr/ec37Vrl+j1eiktLRURkZ49e8qyZctuOwYA8vLLL3u+rq+vFwCyZ88eERGZOHGiPPfccx0zYSIiIqKviHmJiLoS3lOKiO4pjz32GDIyMryOBQYGev6cmJjodS4xMREFBQUAgDNnzuDBBx+Ej4+P53xycjIURUFRURF0Oh2uXr2K0aNHf+EYHnjgAc+ffXx84HA4UF5eDgCYPXs2Jk+ejGPHjuHxxx/HpEmTkJSU9F/NlYiIiOi/wbxERF0FF6WI6J7i4+Nz0/bwjmKz2e6on8lk8vpap9NBURQAwLhx43Dp0iXs3r0b2dnZGD16NObOnYtf/epXHT5eIiIiolthXiKiroL3lCKi+8rhw4dv+nrQoEEAgEGDBuHEiRNoaGjwnP/www+h1+sxYMAA+Pr6IioqCjk5OXc1hpCQEKSlpeGdd97B2rVrkZmZeVfvR0RERNSRmJeISC3cKUVE9xSXy4XS0lKvY0aj0XNzzC1btiAuLg4jR47Exo0bkZeXhz/84Q8AgNTUVLz66qtIS0vDihUrcO3aNTz//POYNm0anE4nAGDFihWYNWsWQkNDMW7cONTV1eHDDz/E888/f0fje+WVVzB8+HAMGTIELpcLO3fu9IQ8IiIiIjUwLxFRV8FFKSK6p+zduxfh4eFexwYMGICPP/4YQPuTXrKysjBnzhyEh4dj8+bNGDx4MADAbrdj3759mD9/PkaMGAG73Y7JkydjzZo1nvdKS0tDc3MzfvOb3+DHP/4xgoOD8d3vfveOx2c2m7FkyRJcvHgRNpsNjzzyCLKysjpg5kRERER3hnmJiLoKnYiI1oMgIlKDTqfDtm3bMGnSJK2HQkRERNQlMS8RkZp4TykiIiIiIiIiIlIdF6WIiIiIiIiIiEh1vHyPiIiIiIiIiIhUx51SRERERERERESkOi5KERERERERERGR6rgoRUREREREREREquOiFBERERERERERqY6LUkREREREREREpDouShERERERERERkeq4KEVERERERERERKrjohQREREREREREamOi1JERERERERERKS6/wMpJpwe5Oj71wAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 1200x400 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "206/206 [==============================] - 12s 47ms/step - loss: 2.7440 - accuracy: 0.8895 - val_loss: 1.0428 - val_accuracy: 0.9138\n",
            "Epoch 2/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 1.1702 - accuracy: 0.8920 - val_loss: 2.4933 - val_accuracy: 0.8635\n",
            "Epoch 3/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.5268 - accuracy: 0.8930 - val_loss: 0.7055 - val_accuracy: 0.9132\n",
            "Epoch 4/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.3682 - accuracy: 0.9088 - val_loss: 8.4987 - val_accuracy: 0.8629\n",
            "Epoch 5/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.3067 - accuracy: 0.9126 - val_loss: 0.1525 - val_accuracy: 0.9460\n",
            "Epoch 6/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.3596 - accuracy: 0.9131 - val_loss: 1.6862 - val_accuracy: 0.9023\n",
            "Epoch 7/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.1942 - accuracy: 0.8906 - val_loss: 0.1244 - val_accuracy: 0.9357\n",
            "Epoch 8/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.1652 - accuracy: 0.9079 - val_loss: 0.1275 - val_accuracy: 0.9460\n",
            "Epoch 9/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.2117 - accuracy: 0.9102 - val_loss: 0.1679 - val_accuracy: 0.9278\n",
            "Epoch 10/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.1516 - accuracy: 0.9146 - val_loss: 0.1214 - val_accuracy: 0.9478\n",
            "Epoch 11/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.1500 - accuracy: 0.9150 - val_loss: 0.1382 - val_accuracy: 0.9484\n",
            "Epoch 12/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.1387 - accuracy: 0.9200 - val_loss: 0.1108 - val_accuracy: 0.9575\n",
            "Epoch 13/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.2578 - accuracy: 0.9146 - val_loss: 0.1704 - val_accuracy: 0.9515\n",
            "Epoch 14/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.1556 - accuracy: 0.9140 - val_loss: 0.1273 - val_accuracy: 0.9363\n",
            "Epoch 15/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.2003 - accuracy: 0.9124 - val_loss: 0.1611 - val_accuracy: 0.9454\n",
            "Epoch 16/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.1688 - accuracy: 0.9153 - val_loss: 0.1001 - val_accuracy: 0.9563\n",
            "Epoch 17/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.1338 - accuracy: 0.9165 - val_loss: 0.1284 - val_accuracy: 0.9600\n",
            "Epoch 18/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.1427 - accuracy: 0.9223 - val_loss: 0.1109 - val_accuracy: 0.9557\n",
            "Epoch 19/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.1778 - accuracy: 0.9202 - val_loss: 0.1408 - val_accuracy: 0.9339\n",
            "Epoch 20/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1741 - accuracy: 0.9123 - val_loss: 0.2558 - val_accuracy: 0.9284\n",
            "Epoch 21/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1561 - accuracy: 0.9155 - val_loss: 0.1023 - val_accuracy: 0.9557\n",
            "Epoch 22/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1845 - accuracy: 0.9161 - val_loss: 0.1000 - val_accuracy: 0.9545\n",
            "Epoch 23/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.2705 - accuracy: 0.9234 - val_loss: 1.0546 - val_accuracy: 0.8792\n",
            "Epoch 24/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1571 - accuracy: 0.9146 - val_loss: 0.1407 - val_accuracy: 0.9515\n",
            "Epoch 25/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1811 - accuracy: 0.9138 - val_loss: 0.1507 - val_accuracy: 0.9193\n",
            "Epoch 26/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1627 - accuracy: 0.9144 - val_loss: 0.1635 - val_accuracy: 0.9521\n",
            "Epoch 27/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1370 - accuracy: 0.9211 - val_loss: 0.1298 - val_accuracy: 0.9593\n",
            "Epoch 28/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1759 - accuracy: 0.9200 - val_loss: 0.8632 - val_accuracy: 0.9290\n",
            "Epoch 29/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.3098 - accuracy: 0.9129 - val_loss: 0.1292 - val_accuracy: 0.9448\n",
            "Epoch 30/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.1685 - accuracy: 0.9129 - val_loss: 0.1186 - val_accuracy: 0.9612\n",
            "Epoch 31/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1404 - accuracy: 0.9132 - val_loss: 0.1097 - val_accuracy: 0.9387\n",
            "Epoch 32/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.2053 - accuracy: 0.9134 - val_loss: 3.7783 - val_accuracy: 0.8101\n",
            "Epoch 33/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1980 - accuracy: 0.9165 - val_loss: 0.1193 - val_accuracy: 0.9515\n",
            "Epoch 34/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1438 - accuracy: 0.9191 - val_loss: 0.1240 - val_accuracy: 0.9575\n",
            "Epoch 35/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1411 - accuracy: 0.9212 - val_loss: 0.1679 - val_accuracy: 0.9521\n",
            "Epoch 36/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1588 - accuracy: 0.9212 - val_loss: 0.0998 - val_accuracy: 0.9539\n",
            "Epoch 37/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.1369 - accuracy: 0.9214 - val_loss: 0.1148 - val_accuracy: 0.9581\n",
            "Epoch 38/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1183 - accuracy: 0.9234 - val_loss: 0.1573 - val_accuracy: 0.9466\n",
            "Epoch 39/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1125 - accuracy: 0.9352 - val_loss: 0.0928 - val_accuracy: 0.9636\n",
            "Epoch 40/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.1247 - accuracy: 0.9322 - val_loss: 0.1144 - val_accuracy: 0.9308\n",
            "Epoch 41/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1213 - accuracy: 0.9337 - val_loss: 0.0956 - val_accuracy: 0.9539\n",
            "Epoch 42/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1077 - accuracy: 0.9470 - val_loss: 0.1420 - val_accuracy: 0.9672\n",
            "Epoch 43/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1108 - accuracy: 0.9410 - val_loss: 0.1686 - val_accuracy: 0.9563\n",
            "Epoch 44/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.1160 - accuracy: 0.9413 - val_loss: 0.1173 - val_accuracy: 0.9557\n",
            "Epoch 45/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.1060 - accuracy: 0.9451 - val_loss: 0.0808 - val_accuracy: 0.9660\n",
            "Epoch 46/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1014 - accuracy: 0.9481 - val_loss: 0.0900 - val_accuracy: 0.9672\n",
            "Epoch 47/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0970 - accuracy: 0.9549 - val_loss: 0.1305 - val_accuracy: 0.9624\n",
            "Epoch 48/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1353 - accuracy: 0.9428 - val_loss: 0.1307 - val_accuracy: 0.9442\n",
            "Epoch 49/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0939 - accuracy: 0.9555 - val_loss: 0.0925 - val_accuracy: 0.9624\n",
            "Epoch 50/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0917 - accuracy: 0.9554 - val_loss: 0.2279 - val_accuracy: 0.9678\n",
            "Epoch 51/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0871 - accuracy: 0.9610 - val_loss: 0.0994 - val_accuracy: 0.9666\n",
            "Epoch 52/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0870 - accuracy: 0.9580 - val_loss: 0.0944 - val_accuracy: 0.9684\n",
            "Epoch 53/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0838 - accuracy: 0.9653 - val_loss: 0.1415 - val_accuracy: 0.9684\n",
            "Epoch 54/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0903 - accuracy: 0.9642 - val_loss: 0.1056 - val_accuracy: 0.9563\n",
            "Epoch 55/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0934 - accuracy: 0.9571 - val_loss: 0.1044 - val_accuracy: 0.9721\n",
            "Epoch 56/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0775 - accuracy: 0.9636 - val_loss: 0.1043 - val_accuracy: 0.9715\n",
            "Epoch 57/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0851 - accuracy: 0.9642 - val_loss: 0.1024 - val_accuracy: 0.9575\n",
            "Epoch 58/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1575 - accuracy: 0.9460 - val_loss: 2.6514 - val_accuracy: 0.9254\n",
            "Epoch 59/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.2219 - accuracy: 0.9187 - val_loss: 0.1503 - val_accuracy: 0.9672\n",
            "Epoch 60/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1060 - accuracy: 0.9517 - val_loss: 0.1590 - val_accuracy: 0.9405\n",
            "Epoch 61/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0980 - accuracy: 0.9475 - val_loss: 0.1010 - val_accuracy: 0.9648\n",
            "Epoch 62/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1784 - accuracy: 0.9376 - val_loss: 0.1173 - val_accuracy: 0.9630\n",
            "Epoch 63/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1234 - accuracy: 0.9448 - val_loss: 0.7271 - val_accuracy: 0.9593\n",
            "Epoch 64/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1264 - accuracy: 0.9519 - val_loss: 0.2400 - val_accuracy: 0.9211\n",
            "Epoch 65/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1099 - accuracy: 0.9476 - val_loss: 0.0974 - val_accuracy: 0.9581\n",
            "Epoch 66/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0814 - accuracy: 0.9616 - val_loss: 0.1002 - val_accuracy: 0.9660\n",
            "Epoch 67/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0879 - accuracy: 0.9628 - val_loss: 0.1009 - val_accuracy: 0.9721\n",
            "Epoch 68/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0809 - accuracy: 0.9637 - val_loss: 0.1241 - val_accuracy: 0.9672\n",
            "Epoch 69/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0844 - accuracy: 0.9653 - val_loss: 0.1252 - val_accuracy: 0.9715\n",
            "Epoch 70/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0994 - accuracy: 0.9674 - val_loss: 0.1174 - val_accuracy: 0.9314\n",
            "Epoch 71/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0989 - accuracy: 0.9619 - val_loss: 0.1199 - val_accuracy: 0.9600\n",
            "Epoch 72/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0782 - accuracy: 0.9636 - val_loss: 0.1039 - val_accuracy: 0.9660\n",
            "Epoch 73/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0715 - accuracy: 0.9681 - val_loss: 0.1019 - val_accuracy: 0.9630\n",
            "Epoch 74/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0692 - accuracy: 0.9719 - val_loss: 0.1375 - val_accuracy: 0.9703\n",
            "Epoch 75/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0650 - accuracy: 0.9748 - val_loss: 0.1382 - val_accuracy: 0.9672\n",
            "Epoch 76/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0623 - accuracy: 0.9756 - val_loss: 0.1882 - val_accuracy: 0.9715\n",
            "Epoch 77/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0640 - accuracy: 0.9734 - val_loss: 0.1613 - val_accuracy: 0.9709\n",
            "Epoch 78/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0576 - accuracy: 0.9763 - val_loss: 0.1061 - val_accuracy: 0.9733\n",
            "Epoch 79/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0623 - accuracy: 0.9747 - val_loss: 0.1236 - val_accuracy: 0.9703\n",
            "Epoch 80/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0732 - accuracy: 0.9725 - val_loss: 0.2535 - val_accuracy: 0.9666\n",
            "Epoch 81/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.2590 - accuracy: 0.9590 - val_loss: 0.3962 - val_accuracy: 0.9624\n",
            "Epoch 82/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0935 - accuracy: 0.9654 - val_loss: 0.1550 - val_accuracy: 0.9666\n",
            "Epoch 83/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0994 - accuracy: 0.9575 - val_loss: 0.1189 - val_accuracy: 0.9569\n",
            "Epoch 84/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0771 - accuracy: 0.9681 - val_loss: 0.1608 - val_accuracy: 0.9697\n",
            "Epoch 85/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0767 - accuracy: 0.9648 - val_loss: 0.1643 - val_accuracy: 0.9666\n",
            "Epoch 86/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0659 - accuracy: 0.9728 - val_loss: 0.1490 - val_accuracy: 0.9648\n",
            "Epoch 87/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0593 - accuracy: 0.9781 - val_loss: 0.1613 - val_accuracy: 0.9691\n",
            "Epoch 88/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0571 - accuracy: 0.9781 - val_loss: 0.2326 - val_accuracy: 0.9691\n",
            "Epoch 89/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0595 - accuracy: 0.9780 - val_loss: 0.1560 - val_accuracy: 0.9697\n",
            "Epoch 90/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0553 - accuracy: 0.9785 - val_loss: 0.1501 - val_accuracy: 0.9727\n",
            "Epoch 91/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0526 - accuracy: 0.9798 - val_loss: 0.2034 - val_accuracy: 0.9709\n",
            "Epoch 92/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0606 - accuracy: 0.9818 - val_loss: 0.3579 - val_accuracy: 0.9703\n",
            "Epoch 93/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0646 - accuracy: 0.9742 - val_loss: 0.2140 - val_accuracy: 0.9709\n",
            "Epoch 94/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0583 - accuracy: 0.9774 - val_loss: 0.1999 - val_accuracy: 0.9703\n",
            "Epoch 95/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0524 - accuracy: 0.9825 - val_loss: 0.1647 - val_accuracy: 0.9715\n",
            "Epoch 96/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0491 - accuracy: 0.9812 - val_loss: 0.1362 - val_accuracy: 0.9739\n",
            "Epoch 97/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0565 - accuracy: 0.9815 - val_loss: 0.1408 - val_accuracy: 0.9691\n",
            "Epoch 98/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0477 - accuracy: 0.9824 - val_loss: 0.2423 - val_accuracy: 0.9703\n",
            "Epoch 99/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0521 - accuracy: 0.9816 - val_loss: 0.1301 - val_accuracy: 0.9733\n",
            "Epoch 100/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0551 - accuracy: 0.9800 - val_loss: 0.1690 - val_accuracy: 0.9745\n",
            "Epoch 101/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0495 - accuracy: 0.9798 - val_loss: 0.1701 - val_accuracy: 0.9721\n",
            "Epoch 102/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0464 - accuracy: 0.9839 - val_loss: 0.1951 - val_accuracy: 0.9763\n",
            "Epoch 103/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0496 - accuracy: 0.9836 - val_loss: 0.1412 - val_accuracy: 0.9739\n",
            "Epoch 104/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0447 - accuracy: 0.9832 - val_loss: 0.1652 - val_accuracy: 0.9769\n",
            "Epoch 105/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0438 - accuracy: 0.9845 - val_loss: 0.1586 - val_accuracy: 0.9763\n",
            "Epoch 106/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0466 - accuracy: 0.9832 - val_loss: 0.1560 - val_accuracy: 0.9739\n",
            "Epoch 107/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0463 - accuracy: 0.9851 - val_loss: 0.1669 - val_accuracy: 0.9715\n",
            "Epoch 108/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0514 - accuracy: 0.9816 - val_loss: 0.1426 - val_accuracy: 0.9745\n",
            "Epoch 109/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0519 - accuracy: 0.9841 - val_loss: 0.1153 - val_accuracy: 0.9672\n",
            "Epoch 110/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0719 - accuracy: 0.9819 - val_loss: 0.2277 - val_accuracy: 0.9727\n",
            "Epoch 111/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0391 - accuracy: 0.9871 - val_loss: 0.1056 - val_accuracy: 0.9727\n",
            "Epoch 112/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0387 - accuracy: 0.9859 - val_loss: 0.2258 - val_accuracy: 0.9769\n",
            "Epoch 113/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0340 - accuracy: 0.9891 - val_loss: 0.2265 - val_accuracy: 0.9757\n",
            "Epoch 114/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0515 - accuracy: 0.9859 - val_loss: 0.1900 - val_accuracy: 0.9794\n",
            "Epoch 115/1000\n",
            "206/206 [==============================] - 8s 40ms/step - loss: 0.0445 - accuracy: 0.9848 - val_loss: 0.2175 - val_accuracy: 0.9751\n",
            "Epoch 116/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0370 - accuracy: 0.9869 - val_loss: 0.1962 - val_accuracy: 0.9757\n",
            "Epoch 117/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0465 - accuracy: 0.9874 - val_loss: 0.1336 - val_accuracy: 0.9739\n",
            "Epoch 118/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0442 - accuracy: 0.9845 - val_loss: 0.2027 - val_accuracy: 0.9769\n",
            "Epoch 119/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0534 - accuracy: 0.9819 - val_loss: 0.2140 - val_accuracy: 0.9745\n",
            "Epoch 120/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0446 - accuracy: 0.9860 - val_loss: 0.2284 - val_accuracy: 0.9745\n",
            "Epoch 121/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0505 - accuracy: 0.9836 - val_loss: 0.1456 - val_accuracy: 0.9739\n",
            "Epoch 122/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0381 - accuracy: 0.9880 - val_loss: 0.1646 - val_accuracy: 0.9733\n",
            "Epoch 123/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0410 - accuracy: 0.9866 - val_loss: 0.1877 - val_accuracy: 0.9727\n",
            "Epoch 124/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0425 - accuracy: 0.9842 - val_loss: 0.2371 - val_accuracy: 0.9775\n",
            "Epoch 125/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0384 - accuracy: 0.9879 - val_loss: 0.2758 - val_accuracy: 0.9709\n",
            "Epoch 126/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0417 - accuracy: 0.9866 - val_loss: 0.1712 - val_accuracy: 0.9769\n",
            "Epoch 127/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0322 - accuracy: 0.9898 - val_loss: 0.2001 - val_accuracy: 0.9775\n",
            "Epoch 128/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0740 - accuracy: 0.9877 - val_loss: 11.5465 - val_accuracy: 0.8871\n",
            "Epoch 129/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0803 - accuracy: 0.9765 - val_loss: 0.1167 - val_accuracy: 0.9691\n",
            "Epoch 130/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0511 - accuracy: 0.9827 - val_loss: 0.1779 - val_accuracy: 0.9751\n",
            "Epoch 131/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0426 - accuracy: 0.9857 - val_loss: 0.2367 - val_accuracy: 0.9745\n",
            "Epoch 132/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0371 - accuracy: 0.9873 - val_loss: 0.2063 - val_accuracy: 0.9745\n",
            "Epoch 133/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0308 - accuracy: 0.9904 - val_loss: 0.1957 - val_accuracy: 0.9763\n",
            "Epoch 134/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0591 - accuracy: 0.9888 - val_loss: 0.5741 - val_accuracy: 0.9703\n",
            "Epoch 135/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0473 - accuracy: 0.9829 - val_loss: 0.2492 - val_accuracy: 0.9763\n",
            "Epoch 136/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0430 - accuracy: 0.9868 - val_loss: 0.3276 - val_accuracy: 0.9751\n",
            "Epoch 137/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0788 - accuracy: 0.9839 - val_loss: 0.2048 - val_accuracy: 0.9709\n",
            "Epoch 138/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0580 - accuracy: 0.9813 - val_loss: 0.2594 - val_accuracy: 0.9733\n",
            "Epoch 139/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0445 - accuracy: 0.9885 - val_loss: 0.2959 - val_accuracy: 0.9721\n",
            "Epoch 140/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0343 - accuracy: 0.9886 - val_loss: 0.2684 - val_accuracy: 0.9733\n",
            "Epoch 141/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0383 - accuracy: 0.9869 - val_loss: 0.3742 - val_accuracy: 0.9763\n",
            "Epoch 142/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0453 - accuracy: 0.9863 - val_loss: 0.2823 - val_accuracy: 0.9727\n",
            "Epoch 143/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0381 - accuracy: 0.9885 - val_loss: 0.1569 - val_accuracy: 0.9703\n",
            "Epoch 144/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0368 - accuracy: 0.9882 - val_loss: 0.2020 - val_accuracy: 0.9775\n",
            "Epoch 145/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0323 - accuracy: 0.9900 - val_loss: 0.2528 - val_accuracy: 0.9763\n",
            "Epoch 146/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0334 - accuracy: 0.9895 - val_loss: 0.2759 - val_accuracy: 0.9721\n",
            "Epoch 147/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0283 - accuracy: 0.9909 - val_loss: 0.2717 - val_accuracy: 0.9769\n",
            "Epoch 148/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0281 - accuracy: 0.9912 - val_loss: 0.2327 - val_accuracy: 0.9788\n",
            "Epoch 149/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0315 - accuracy: 0.9901 - val_loss: 0.2481 - val_accuracy: 0.9757\n",
            "Epoch 150/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0292 - accuracy: 0.9907 - val_loss: 0.2246 - val_accuracy: 0.9782\n",
            "Epoch 151/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0442 - accuracy: 0.9885 - val_loss: 0.1562 - val_accuracy: 0.9757\n",
            "Epoch 152/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0362 - accuracy: 0.9874 - val_loss: 0.2091 - val_accuracy: 0.9788\n",
            "Epoch 153/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0345 - accuracy: 0.9903 - val_loss: 0.3540 - val_accuracy: 0.9757\n",
            "Epoch 154/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0383 - accuracy: 0.9880 - val_loss: 0.2239 - val_accuracy: 0.9775\n",
            "Epoch 155/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0355 - accuracy: 0.9897 - val_loss: 0.1977 - val_accuracy: 0.9782\n",
            "Epoch 156/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0320 - accuracy: 0.9900 - val_loss: 0.5308 - val_accuracy: 0.9672\n",
            "Epoch 157/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0498 - accuracy: 0.9879 - val_loss: 0.2905 - val_accuracy: 0.9782\n",
            "Epoch 158/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0362 - accuracy: 0.9889 - val_loss: 0.3783 - val_accuracy: 0.9800\n",
            "Epoch 159/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0283 - accuracy: 0.9915 - val_loss: 0.2219 - val_accuracy: 0.9788\n",
            "Epoch 160/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0475 - accuracy: 0.9873 - val_loss: 0.4298 - val_accuracy: 0.9727\n",
            "Epoch 161/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0367 - accuracy: 0.9885 - val_loss: 0.1864 - val_accuracy: 0.9818\n",
            "Epoch 162/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0288 - accuracy: 0.9906 - val_loss: 0.2757 - val_accuracy: 0.9812\n",
            "Epoch 163/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0219 - accuracy: 0.9944 - val_loss: 0.2746 - val_accuracy: 0.9794\n",
            "Epoch 164/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0268 - accuracy: 0.9930 - val_loss: 0.2116 - val_accuracy: 0.9818\n",
            "Epoch 165/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0234 - accuracy: 0.9930 - val_loss: 0.2943 - val_accuracy: 0.9824\n",
            "Epoch 166/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0281 - accuracy: 0.9923 - val_loss: 0.1855 - val_accuracy: 0.9812\n",
            "Epoch 167/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0253 - accuracy: 0.9938 - val_loss: 0.2270 - val_accuracy: 0.9806\n",
            "Epoch 168/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0255 - accuracy: 0.9923 - val_loss: 0.2137 - val_accuracy: 0.9842\n",
            "Epoch 169/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0283 - accuracy: 0.9915 - val_loss: 0.2809 - val_accuracy: 0.9751\n",
            "Epoch 170/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0442 - accuracy: 0.9891 - val_loss: 0.4968 - val_accuracy: 0.9782\n",
            "Epoch 171/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0301 - accuracy: 0.9900 - val_loss: 0.2097 - val_accuracy: 0.9812\n",
            "Epoch 172/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0267 - accuracy: 0.9914 - val_loss: 0.3662 - val_accuracy: 0.9818\n",
            "Epoch 173/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0221 - accuracy: 0.9941 - val_loss: 0.2160 - val_accuracy: 0.9806\n",
            "Epoch 174/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0338 - accuracy: 0.9906 - val_loss: 0.3721 - val_accuracy: 0.9769\n",
            "Epoch 175/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0214 - accuracy: 0.9939 - val_loss: 0.3331 - val_accuracy: 0.9794\n",
            "Epoch 176/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0259 - accuracy: 0.9917 - val_loss: 0.3225 - val_accuracy: 0.9818\n",
            "Epoch 177/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0233 - accuracy: 0.9930 - val_loss: 0.3161 - val_accuracy: 0.9806\n",
            "Epoch 178/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0314 - accuracy: 0.9920 - val_loss: 0.1604 - val_accuracy: 0.9800\n",
            "Epoch 179/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0255 - accuracy: 0.9923 - val_loss: 0.1785 - val_accuracy: 0.9775\n",
            "Epoch 180/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0322 - accuracy: 0.9912 - val_loss: 0.4060 - val_accuracy: 0.9775\n",
            "Epoch 181/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0248 - accuracy: 0.9924 - val_loss: 0.1801 - val_accuracy: 0.9775\n",
            "Epoch 182/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0228 - accuracy: 0.9929 - val_loss: 0.2695 - val_accuracy: 0.9824\n",
            "Epoch 183/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0507 - accuracy: 0.9895 - val_loss: 0.5400 - val_accuracy: 0.9715\n",
            "Epoch 184/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0476 - accuracy: 0.9845 - val_loss: 0.1625 - val_accuracy: 0.9812\n",
            "Epoch 185/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0320 - accuracy: 0.9917 - val_loss: 0.2322 - val_accuracy: 0.9824\n",
            "Epoch 186/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0313 - accuracy: 0.9921 - val_loss: 0.2742 - val_accuracy: 0.9727\n",
            "Epoch 187/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0421 - accuracy: 0.9882 - val_loss: 0.1799 - val_accuracy: 0.9769\n",
            "Epoch 188/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0333 - accuracy: 0.9933 - val_loss: 0.2485 - val_accuracy: 0.9751\n",
            "Epoch 189/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0240 - accuracy: 0.9927 - val_loss: 0.3822 - val_accuracy: 0.9794\n",
            "Epoch 190/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0231 - accuracy: 0.9936 - val_loss: 0.4138 - val_accuracy: 0.9824\n",
            "Epoch 191/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0175 - accuracy: 0.9950 - val_loss: 0.4592 - val_accuracy: 0.9788\n",
            "Epoch 192/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0234 - accuracy: 0.9942 - val_loss: 0.2303 - val_accuracy: 0.9788\n",
            "Epoch 193/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0242 - accuracy: 0.9936 - val_loss: 0.2863 - val_accuracy: 0.9830\n",
            "Epoch 194/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0202 - accuracy: 0.9948 - val_loss: 0.3340 - val_accuracy: 0.9824\n",
            "Epoch 195/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0211 - accuracy: 0.9942 - val_loss: 0.2407 - val_accuracy: 0.9836\n",
            "Epoch 196/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0207 - accuracy: 0.9944 - val_loss: 0.2665 - val_accuracy: 0.9812\n",
            "Epoch 197/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0194 - accuracy: 0.9947 - val_loss: 0.3408 - val_accuracy: 0.9812\n",
            "Epoch 198/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0378 - accuracy: 0.9914 - val_loss: 0.6085 - val_accuracy: 0.9745\n",
            "Epoch 199/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0256 - accuracy: 0.9924 - val_loss: 0.5318 - val_accuracy: 0.9751\n",
            "Epoch 200/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0190 - accuracy: 0.9945 - val_loss: 0.4603 - val_accuracy: 0.9794\n",
            "Epoch 201/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0167 - accuracy: 0.9959 - val_loss: 0.1954 - val_accuracy: 0.9763\n",
            "Epoch 202/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0186 - accuracy: 0.9945 - val_loss: 0.2193 - val_accuracy: 0.9782\n",
            "Epoch 203/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0192 - accuracy: 0.9947 - val_loss: 0.2688 - val_accuracy: 0.9806\n",
            "Epoch 204/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0161 - accuracy: 0.9958 - val_loss: 0.3279 - val_accuracy: 0.9824\n",
            "Epoch 205/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0156 - accuracy: 0.9958 - val_loss: 0.2686 - val_accuracy: 0.9806\n",
            "Epoch 206/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0261 - accuracy: 0.9926 - val_loss: 0.3391 - val_accuracy: 0.9806\n",
            "Epoch 207/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0221 - accuracy: 0.9945 - val_loss: 0.2671 - val_accuracy: 0.9794\n",
            "Epoch 208/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0227 - accuracy: 0.9930 - val_loss: 0.2605 - val_accuracy: 0.9818\n",
            "Epoch 209/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0208 - accuracy: 0.9954 - val_loss: 0.5136 - val_accuracy: 0.9824\n",
            "Epoch 210/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0210 - accuracy: 0.9953 - val_loss: 0.4615 - val_accuracy: 0.9788\n",
            "Epoch 211/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0451 - accuracy: 0.9898 - val_loss: 0.5236 - val_accuracy: 0.9757\n",
            "Epoch 212/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0289 - accuracy: 0.9907 - val_loss: 0.2419 - val_accuracy: 0.9788\n",
            "Epoch 213/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0215 - accuracy: 0.9944 - val_loss: 0.2907 - val_accuracy: 0.9800\n",
            "Epoch 214/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0234 - accuracy: 0.9936 - val_loss: 0.2754 - val_accuracy: 0.9775\n",
            "Epoch 215/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0328 - accuracy: 0.9926 - val_loss: 0.2523 - val_accuracy: 0.9812\n",
            "Epoch 216/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0210 - accuracy: 0.9959 - val_loss: 0.4244 - val_accuracy: 0.9794\n",
            "Epoch 217/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0233 - accuracy: 0.9942 - val_loss: 0.3092 - val_accuracy: 0.9782\n",
            "Epoch 218/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0213 - accuracy: 0.9948 - val_loss: 0.2945 - val_accuracy: 0.9818\n",
            "Epoch 219/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0168 - accuracy: 0.9954 - val_loss: 0.2592 - val_accuracy: 0.9800\n",
            "Epoch 220/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0146 - accuracy: 0.9965 - val_loss: 0.3388 - val_accuracy: 0.9818\n",
            "Epoch 221/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0133 - accuracy: 0.9965 - val_loss: 0.3929 - val_accuracy: 0.9806\n",
            "Epoch 222/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0174 - accuracy: 0.9956 - val_loss: 0.3653 - val_accuracy: 0.9806\n",
            "Epoch 223/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0272 - accuracy: 0.9945 - val_loss: 0.1862 - val_accuracy: 0.9763\n",
            "Epoch 224/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0393 - accuracy: 0.9929 - val_loss: 0.2619 - val_accuracy: 0.9769\n",
            "Epoch 225/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0336 - accuracy: 0.9917 - val_loss: 0.2406 - val_accuracy: 0.9794\n",
            "Epoch 226/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0221 - accuracy: 0.9933 - val_loss: 0.3842 - val_accuracy: 0.9818\n",
            "Epoch 227/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0156 - accuracy: 0.9958 - val_loss: 0.2454 - val_accuracy: 0.9788\n",
            "Epoch 228/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0145 - accuracy: 0.9964 - val_loss: 0.3112 - val_accuracy: 0.9824\n",
            "Epoch 229/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0201 - accuracy: 0.9950 - val_loss: 0.1996 - val_accuracy: 0.9782\n",
            "Epoch 230/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0206 - accuracy: 0.9942 - val_loss: 0.2569 - val_accuracy: 0.9830\n",
            "Epoch 231/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0214 - accuracy: 0.9941 - val_loss: 0.4798 - val_accuracy: 0.9812\n",
            "Epoch 232/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0296 - accuracy: 0.9948 - val_loss: 0.3218 - val_accuracy: 0.9624\n",
            "Epoch 233/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0234 - accuracy: 0.9944 - val_loss: 0.2368 - val_accuracy: 0.9830\n",
            "Epoch 234/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0131 - accuracy: 0.9964 - val_loss: 0.2679 - val_accuracy: 0.9818\n",
            "Epoch 235/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0184 - accuracy: 0.9958 - val_loss: 0.2388 - val_accuracy: 0.9818\n",
            "Epoch 236/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0171 - accuracy: 0.9953 - val_loss: 0.2757 - val_accuracy: 0.9824\n",
            "Epoch 237/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0195 - accuracy: 0.9951 - val_loss: 0.2544 - val_accuracy: 0.9818\n",
            "Epoch 238/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0131 - accuracy: 0.9965 - val_loss: 0.3013 - val_accuracy: 0.9836\n",
            "Epoch 239/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0178 - accuracy: 0.9953 - val_loss: 0.2097 - val_accuracy: 0.9842\n",
            "Epoch 240/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0131 - accuracy: 0.9965 - val_loss: 0.3108 - val_accuracy: 0.9848\n",
            "Epoch 241/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0180 - accuracy: 0.9950 - val_loss: 0.1900 - val_accuracy: 0.9818\n",
            "Epoch 242/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0146 - accuracy: 0.9962 - val_loss: 0.4018 - val_accuracy: 0.9812\n",
            "Epoch 243/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0138 - accuracy: 0.9968 - val_loss: 0.4302 - val_accuracy: 0.9818\n",
            "Epoch 244/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0172 - accuracy: 0.9953 - val_loss: 0.3644 - val_accuracy: 0.9812\n",
            "Epoch 245/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0246 - accuracy: 0.9956 - val_loss: 0.3960 - val_accuracy: 0.9818\n",
            "Epoch 246/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0373 - accuracy: 0.9935 - val_loss: 0.2606 - val_accuracy: 0.9775\n",
            "Epoch 247/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0220 - accuracy: 0.9951 - val_loss: 0.4001 - val_accuracy: 0.9836\n",
            "Epoch 248/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0189 - accuracy: 0.9951 - val_loss: 0.6118 - val_accuracy: 0.9806\n",
            "Epoch 249/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0137 - accuracy: 0.9965 - val_loss: 0.4394 - val_accuracy: 0.9824\n",
            "Epoch 250/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0334 - accuracy: 0.9953 - val_loss: 0.4354 - val_accuracy: 0.9812\n",
            "Epoch 251/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0147 - accuracy: 0.9964 - val_loss: 0.3994 - val_accuracy: 0.9824\n",
            "Epoch 252/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0217 - accuracy: 0.9953 - val_loss: 0.2055 - val_accuracy: 0.9794\n",
            "Epoch 253/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0147 - accuracy: 0.9967 - val_loss: 0.3266 - val_accuracy: 0.9806\n",
            "Epoch 254/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0120 - accuracy: 0.9973 - val_loss: 0.2603 - val_accuracy: 0.9836\n",
            "Epoch 255/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0149 - accuracy: 0.9967 - val_loss: 0.2664 - val_accuracy: 0.9800\n",
            "Epoch 256/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0179 - accuracy: 0.9950 - val_loss: 0.2917 - val_accuracy: 0.9763\n",
            "Epoch 257/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0223 - accuracy: 0.9953 - val_loss: 0.5211 - val_accuracy: 0.9806\n",
            "Epoch 258/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0150 - accuracy: 0.9965 - val_loss: 0.3606 - val_accuracy: 0.9812\n",
            "Epoch 259/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0164 - accuracy: 0.9958 - val_loss: 0.4051 - val_accuracy: 0.9788\n",
            "Epoch 260/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0171 - accuracy: 0.9961 - val_loss: 0.4384 - val_accuracy: 0.9830\n",
            "Epoch 261/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0174 - accuracy: 0.9971 - val_loss: 0.1768 - val_accuracy: 0.9812\n",
            "Epoch 262/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0556 - accuracy: 0.9944 - val_loss: 0.3574 - val_accuracy: 0.9818\n",
            "Epoch 263/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0140 - accuracy: 0.9967 - val_loss: 0.3731 - val_accuracy: 0.9806\n",
            "Epoch 264/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0147 - accuracy: 0.9962 - val_loss: 0.3518 - val_accuracy: 0.9812\n",
            "Epoch 265/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0130 - accuracy: 0.9967 - val_loss: 0.3178 - val_accuracy: 0.9848\n",
            "Epoch 266/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0173 - accuracy: 0.9958 - val_loss: 0.2412 - val_accuracy: 0.9818\n",
            "Epoch 267/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0346 - accuracy: 0.9938 - val_loss: 0.4110 - val_accuracy: 0.9794\n",
            "Epoch 268/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0133 - accuracy: 0.9965 - val_loss: 0.3163 - val_accuracy: 0.9788\n",
            "Epoch 269/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0127 - accuracy: 0.9967 - val_loss: 0.4201 - val_accuracy: 0.9824\n",
            "Epoch 270/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0237 - accuracy: 0.9958 - val_loss: 0.4193 - val_accuracy: 0.9812\n",
            "Epoch 271/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0176 - accuracy: 0.9959 - val_loss: 0.3107 - val_accuracy: 0.9800\n",
            "Epoch 272/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0195 - accuracy: 0.9953 - val_loss: 0.2966 - val_accuracy: 0.9806\n",
            "Epoch 273/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0127 - accuracy: 0.9971 - val_loss: 0.6020 - val_accuracy: 0.9769\n",
            "Epoch 274/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0143 - accuracy: 0.9967 - val_loss: 0.3751 - val_accuracy: 0.9806\n",
            "Epoch 275/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0161 - accuracy: 0.9964 - val_loss: 0.3004 - val_accuracy: 0.9818\n",
            "Epoch 276/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0138 - accuracy: 0.9967 - val_loss: 0.3359 - val_accuracy: 0.9830\n",
            "Epoch 277/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0129 - accuracy: 0.9964 - val_loss: 0.3055 - val_accuracy: 0.9830\n",
            "Epoch 278/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0128 - accuracy: 0.9973 - val_loss: 0.3409 - val_accuracy: 0.9836\n",
            "Epoch 279/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0087 - accuracy: 0.9982 - val_loss: 0.5316 - val_accuracy: 0.9812\n",
            "Epoch 280/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0296 - accuracy: 0.9968 - val_loss: 0.4075 - val_accuracy: 0.9769\n",
            "Epoch 281/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0189 - accuracy: 0.9950 - val_loss: 0.5815 - val_accuracy: 0.9800\n",
            "Epoch 282/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0142 - accuracy: 0.9965 - val_loss: 0.2329 - val_accuracy: 0.9830\n",
            "Epoch 283/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0160 - accuracy: 0.9958 - val_loss: 0.3150 - val_accuracy: 0.9818\n",
            "Epoch 284/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0156 - accuracy: 0.9970 - val_loss: 0.4162 - val_accuracy: 0.9824\n",
            "Epoch 285/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0225 - accuracy: 0.9961 - val_loss: 0.4789 - val_accuracy: 0.9782\n",
            "Epoch 286/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0142 - accuracy: 0.9965 - val_loss: 0.3817 - val_accuracy: 0.9818\n",
            "Epoch 287/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0308 - accuracy: 0.9951 - val_loss: 0.5851 - val_accuracy: 0.9818\n",
            "Epoch 288/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0123 - accuracy: 0.9971 - val_loss: 0.4551 - val_accuracy: 0.9830\n",
            "Epoch 289/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0121 - accuracy: 0.9971 - val_loss: 0.4660 - val_accuracy: 0.9848\n",
            "Epoch 290/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0235 - accuracy: 0.9954 - val_loss: 0.2269 - val_accuracy: 0.9812\n",
            "Epoch 291/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0079 - accuracy: 0.9980 - val_loss: 0.3137 - val_accuracy: 0.9830\n",
            "Epoch 292/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0110 - accuracy: 0.9977 - val_loss: 0.2766 - val_accuracy: 0.9842\n",
            "Epoch 293/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0128 - accuracy: 0.9968 - val_loss: 0.3381 - val_accuracy: 0.9806\n",
            "Epoch 294/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0069 - accuracy: 0.9985 - val_loss: 0.4334 - val_accuracy: 0.9794\n",
            "Epoch 295/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0145 - accuracy: 0.9967 - val_loss: 0.4870 - val_accuracy: 0.9812\n",
            "Epoch 296/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0118 - accuracy: 0.9971 - val_loss: 0.4516 - val_accuracy: 0.9860\n",
            "Epoch 297/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0092 - accuracy: 0.9980 - val_loss: 0.4800 - val_accuracy: 0.9848\n",
            "Epoch 298/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0148 - accuracy: 0.9965 - val_loss: 0.4874 - val_accuracy: 0.9824\n",
            "Epoch 299/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0096 - accuracy: 0.9977 - val_loss: 0.4761 - val_accuracy: 0.9836\n",
            "Epoch 300/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0130 - accuracy: 0.9973 - val_loss: 0.4289 - val_accuracy: 0.9824\n",
            "Epoch 301/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0113 - accuracy: 0.9980 - val_loss: 0.4693 - val_accuracy: 0.9818\n",
            "Epoch 302/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0162 - accuracy: 0.9962 - val_loss: 0.5416 - val_accuracy: 0.9836\n",
            "Epoch 303/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0109 - accuracy: 0.9979 - val_loss: 0.4140 - val_accuracy: 0.9836\n",
            "Epoch 304/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0225 - accuracy: 0.9970 - val_loss: 0.4095 - val_accuracy: 0.9824\n",
            "Epoch 305/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0117 - accuracy: 0.9971 - val_loss: 0.3416 - val_accuracy: 0.9824\n",
            "Epoch 306/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0125 - accuracy: 0.9973 - val_loss: 1.0992 - val_accuracy: 0.9769\n",
            "Epoch 307/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0313 - accuracy: 0.9951 - val_loss: 0.6413 - val_accuracy: 0.9757\n",
            "Epoch 308/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0226 - accuracy: 0.9959 - val_loss: 0.2122 - val_accuracy: 0.9721\n",
            "Epoch 309/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0280 - accuracy: 0.9929 - val_loss: 0.4094 - val_accuracy: 0.9812\n",
            "Epoch 310/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0253 - accuracy: 0.9959 - val_loss: 0.4842 - val_accuracy: 0.9812\n",
            "Epoch 311/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0118 - accuracy: 0.9973 - val_loss: 0.3353 - val_accuracy: 0.9806\n",
            "Epoch 312/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0111 - accuracy: 0.9974 - val_loss: 0.4552 - val_accuracy: 0.9830\n",
            "Epoch 313/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0087 - accuracy: 0.9982 - val_loss: 0.4816 - val_accuracy: 0.9824\n",
            "Epoch 314/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0091 - accuracy: 0.9976 - val_loss: 0.5025 - val_accuracy: 0.9830\n",
            "Epoch 315/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0165 - accuracy: 0.9970 - val_loss: 0.4110 - val_accuracy: 0.9836\n",
            "Epoch 316/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0212 - accuracy: 0.9964 - val_loss: 0.2509 - val_accuracy: 0.9848\n",
            "Epoch 317/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0154 - accuracy: 0.9965 - val_loss: 0.4009 - val_accuracy: 0.9836\n",
            "Epoch 318/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0116 - accuracy: 0.9976 - val_loss: 0.3808 - val_accuracy: 0.9830\n",
            "Epoch 319/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0099 - accuracy: 0.9976 - val_loss: 0.3310 - val_accuracy: 0.9830\n",
            "Epoch 320/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0064 - accuracy: 0.9986 - val_loss: 0.4681 - val_accuracy: 0.9842\n",
            "Epoch 321/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0122 - accuracy: 0.9976 - val_loss: 0.3473 - val_accuracy: 0.9818\n",
            "Epoch 322/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0107 - accuracy: 0.9970 - val_loss: 0.6339 - val_accuracy: 0.9824\n",
            "Epoch 323/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0104 - accuracy: 0.9977 - val_loss: 0.2327 - val_accuracy: 0.9775\n",
            "Epoch 324/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0126 - accuracy: 0.9976 - val_loss: 0.3563 - val_accuracy: 0.9842\n",
            "Epoch 325/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0156 - accuracy: 0.9965 - val_loss: 0.8379 - val_accuracy: 0.9812\n",
            "Epoch 326/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0209 - accuracy: 0.9948 - val_loss: 0.4392 - val_accuracy: 0.9842\n",
            "Epoch 327/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0106 - accuracy: 0.9976 - val_loss: 0.4861 - val_accuracy: 0.9824\n",
            "Epoch 328/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0116 - accuracy: 0.9973 - val_loss: 0.5102 - val_accuracy: 0.9824\n",
            "Epoch 329/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0080 - accuracy: 0.9983 - val_loss: 0.5003 - val_accuracy: 0.9824\n",
            "Epoch 330/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0106 - accuracy: 0.9977 - val_loss: 0.4223 - val_accuracy: 0.9842\n",
            "Epoch 331/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0154 - accuracy: 0.9962 - val_loss: 0.2599 - val_accuracy: 0.9830\n",
            "Epoch 332/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0167 - accuracy: 0.9967 - val_loss: 0.1877 - val_accuracy: 0.9818\n",
            "Epoch 333/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0081 - accuracy: 0.9980 - val_loss: 0.4547 - val_accuracy: 0.9824\n",
            "Epoch 334/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0104 - accuracy: 0.9977 - val_loss: 0.5062 - val_accuracy: 0.9818\n",
            "Epoch 335/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0119 - accuracy: 0.9973 - val_loss: 0.3236 - val_accuracy: 0.9848\n",
            "Epoch 336/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0134 - accuracy: 0.9973 - val_loss: 0.2927 - val_accuracy: 0.9824\n",
            "Epoch 337/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0083 - accuracy: 0.9980 - val_loss: 0.3797 - val_accuracy: 0.9842\n",
            "Epoch 338/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0255 - accuracy: 0.9961 - val_loss: 0.2764 - val_accuracy: 0.9812\n",
            "Epoch 339/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0116 - accuracy: 0.9973 - val_loss: 0.3144 - val_accuracy: 0.9818\n",
            "Epoch 340/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0180 - accuracy: 0.9965 - val_loss: 0.4753 - val_accuracy: 0.9842\n",
            "Epoch 341/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0164 - accuracy: 0.9965 - val_loss: 0.4341 - val_accuracy: 0.9782\n",
            "Epoch 342/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0150 - accuracy: 0.9973 - val_loss: 0.3598 - val_accuracy: 0.9818\n",
            "Epoch 343/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0121 - accuracy: 0.9971 - val_loss: 0.3179 - val_accuracy: 0.9860\n",
            "Epoch 344/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0088 - accuracy: 0.9980 - val_loss: 0.4067 - val_accuracy: 0.9867\n",
            "Epoch 345/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0161 - accuracy: 0.9965 - val_loss: 0.3774 - val_accuracy: 0.9842\n",
            "Epoch 346/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0097 - accuracy: 0.9977 - val_loss: 0.3437 - val_accuracy: 0.9860\n",
            "Epoch 347/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0108 - accuracy: 0.9977 - val_loss: 0.4288 - val_accuracy: 0.9860\n",
            "Epoch 348/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0106 - accuracy: 0.9977 - val_loss: 0.6559 - val_accuracy: 0.9818\n",
            "Epoch 349/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0073 - accuracy: 0.9983 - val_loss: 0.6666 - val_accuracy: 0.9824\n",
            "Epoch 350/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0086 - accuracy: 0.9979 - val_loss: 0.8126 - val_accuracy: 0.9812\n",
            "Epoch 351/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0080 - accuracy: 0.9979 - val_loss: 0.3073 - val_accuracy: 0.9818\n",
            "Epoch 352/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0088 - accuracy: 0.9976 - val_loss: 0.3867 - val_accuracy: 0.9867\n",
            "Epoch 353/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0051 - accuracy: 0.9991 - val_loss: 0.5464 - val_accuracy: 0.9842\n",
            "Epoch 354/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0113 - accuracy: 0.9974 - val_loss: 0.5711 - val_accuracy: 0.9842\n",
            "Epoch 355/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0117 - accuracy: 0.9970 - val_loss: 0.4952 - val_accuracy: 0.9830\n",
            "Epoch 356/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0180 - accuracy: 0.9967 - val_loss: 1.4935 - val_accuracy: 0.9648\n",
            "Epoch 357/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0274 - accuracy: 0.9945 - val_loss: 0.5535 - val_accuracy: 0.9824\n",
            "Epoch 358/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0162 - accuracy: 0.9970 - val_loss: 0.6539 - val_accuracy: 0.9818\n",
            "Epoch 359/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0171 - accuracy: 0.9962 - val_loss: 0.4168 - val_accuracy: 0.9824\n",
            "Epoch 360/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0113 - accuracy: 0.9974 - val_loss: 0.4466 - val_accuracy: 0.9854\n",
            "Epoch 361/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0143 - accuracy: 0.9962 - val_loss: 0.5673 - val_accuracy: 0.9824\n",
            "Epoch 362/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0196 - accuracy: 0.9973 - val_loss: 0.5987 - val_accuracy: 0.9824\n",
            "Epoch 363/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0091 - accuracy: 0.9982 - val_loss: 0.3657 - val_accuracy: 0.9842\n",
            "Epoch 364/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0138 - accuracy: 0.9971 - val_loss: 0.3578 - val_accuracy: 0.9848\n",
            "Epoch 365/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0116 - accuracy: 0.9979 - val_loss: 0.3273 - val_accuracy: 0.9854\n",
            "Epoch 366/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0089 - accuracy: 0.9980 - val_loss: 0.4416 - val_accuracy: 0.9860\n",
            "Epoch 367/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0078 - accuracy: 0.9982 - val_loss: 0.3501 - val_accuracy: 0.9854\n",
            "Epoch 368/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0140 - accuracy: 0.9968 - val_loss: 0.8373 - val_accuracy: 0.9788\n",
            "Epoch 369/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0135 - accuracy: 0.9962 - val_loss: 0.8412 - val_accuracy: 0.9806\n",
            "Epoch 370/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0102 - accuracy: 0.9976 - val_loss: 0.5253 - val_accuracy: 0.9824\n",
            "Epoch 371/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0082 - accuracy: 0.9982 - val_loss: 0.2819 - val_accuracy: 0.9830\n",
            "Epoch 372/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0197 - accuracy: 0.9973 - val_loss: 0.3323 - val_accuracy: 0.9842\n",
            "Epoch 373/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0162 - accuracy: 0.9967 - val_loss: 0.2594 - val_accuracy: 0.9830\n",
            "Epoch 374/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0090 - accuracy: 0.9980 - val_loss: 0.2702 - val_accuracy: 0.9818\n",
            "Epoch 375/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0132 - accuracy: 0.9979 - val_loss: 0.2183 - val_accuracy: 0.9800\n",
            "Epoch 376/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0085 - accuracy: 0.9982 - val_loss: 0.3216 - val_accuracy: 0.9830\n",
            "Epoch 377/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0061 - accuracy: 0.9986 - val_loss: 0.5735 - val_accuracy: 0.9860\n",
            "Epoch 378/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0075 - accuracy: 0.9986 - val_loss: 0.5698 - val_accuracy: 0.9842\n",
            "Epoch 379/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0072 - accuracy: 0.9985 - val_loss: 0.5503 - val_accuracy: 0.9854\n",
            "Epoch 380/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0097 - accuracy: 0.9986 - val_loss: 0.5503 - val_accuracy: 0.9842\n",
            "Epoch 381/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0044 - accuracy: 0.9992 - val_loss: 0.5719 - val_accuracy: 0.9830\n",
            "Epoch 382/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0084 - accuracy: 0.9982 - val_loss: 0.5144 - val_accuracy: 0.9860\n",
            "Epoch 383/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0091 - accuracy: 0.9983 - val_loss: 0.8148 - val_accuracy: 0.9848\n",
            "Epoch 384/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0170 - accuracy: 0.9968 - val_loss: 0.3607 - val_accuracy: 0.9806\n",
            "Epoch 385/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0160 - accuracy: 0.9970 - val_loss: 0.3865 - val_accuracy: 0.9830\n",
            "Epoch 386/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0077 - accuracy: 0.9985 - val_loss: 0.4484 - val_accuracy: 0.9836\n",
            "Epoch 387/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0118 - accuracy: 0.9976 - val_loss: 0.6876 - val_accuracy: 0.9812\n",
            "Epoch 388/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0111 - accuracy: 0.9980 - val_loss: 0.5747 - val_accuracy: 0.9848\n",
            "Epoch 389/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0189 - accuracy: 0.9965 - val_loss: 1.0412 - val_accuracy: 0.9794\n",
            "Epoch 390/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0101 - accuracy: 0.9974 - val_loss: 0.5734 - val_accuracy: 0.9830\n",
            "Epoch 391/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0087 - accuracy: 0.9979 - val_loss: 0.7338 - val_accuracy: 0.9818\n",
            "Epoch 392/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0110 - accuracy: 0.9976 - val_loss: 0.3165 - val_accuracy: 0.9842\n",
            "Epoch 393/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0073 - accuracy: 0.9985 - val_loss: 0.3625 - val_accuracy: 0.9842\n",
            "Epoch 394/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0093 - accuracy: 0.9976 - val_loss: 0.5430 - val_accuracy: 0.9830\n",
            "Epoch 395/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0249 - accuracy: 0.9965 - val_loss: 0.8447 - val_accuracy: 0.9848\n",
            "Epoch 396/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0039 - accuracy: 0.9992 - val_loss: 0.6343 - val_accuracy: 0.9830\n",
            "Epoch 397/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0097 - accuracy: 0.9982 - val_loss: 0.6894 - val_accuracy: 0.9848\n",
            "Epoch 398/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0052 - accuracy: 0.9989 - val_loss: 0.5835 - val_accuracy: 0.9836\n",
            "Epoch 399/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0089 - accuracy: 0.9982 - val_loss: 0.4297 - val_accuracy: 0.9836\n",
            "Epoch 400/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0097 - accuracy: 0.9979 - val_loss: 0.4186 - val_accuracy: 0.9867\n",
            "Epoch 401/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0130 - accuracy: 0.9974 - val_loss: 0.9885 - val_accuracy: 0.9818\n",
            "Epoch 402/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0097 - accuracy: 0.9979 - val_loss: 0.9398 - val_accuracy: 0.9788\n",
            "Epoch 403/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0095 - accuracy: 0.9986 - val_loss: 0.8770 - val_accuracy: 0.9812\n",
            "Epoch 404/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0133 - accuracy: 0.9977 - val_loss: 4.2010 - val_accuracy: 0.9333\n",
            "Epoch 405/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0112 - accuracy: 0.9977 - val_loss: 0.7572 - val_accuracy: 0.9806\n",
            "Epoch 406/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0150 - accuracy: 0.9980 - val_loss: 0.5275 - val_accuracy: 0.9824\n",
            "Epoch 407/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0115 - accuracy: 0.9974 - val_loss: 0.9604 - val_accuracy: 0.9757\n",
            "Epoch 408/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0121 - accuracy: 0.9971 - val_loss: 0.2875 - val_accuracy: 0.9830\n",
            "Epoch 409/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0068 - accuracy: 0.9986 - val_loss: 0.5271 - val_accuracy: 0.9818\n",
            "Epoch 410/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0083 - accuracy: 0.9983 - val_loss: 0.5379 - val_accuracy: 0.9818\n",
            "Epoch 411/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0074 - accuracy: 0.9986 - val_loss: 0.5980 - val_accuracy: 0.9854\n",
            "Epoch 412/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0057 - accuracy: 0.9986 - val_loss: 0.6696 - val_accuracy: 0.9812\n",
            "Epoch 413/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0066 - accuracy: 0.9988 - val_loss: 0.6211 - val_accuracy: 0.9842\n",
            "Epoch 414/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0076 - accuracy: 0.9982 - val_loss: 0.7954 - val_accuracy: 0.9812\n",
            "Epoch 415/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0149 - accuracy: 0.9971 - val_loss: 0.4688 - val_accuracy: 0.9800\n",
            "Epoch 416/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0094 - accuracy: 0.9979 - val_loss: 0.7210 - val_accuracy: 0.9824\n",
            "Epoch 417/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0136 - accuracy: 0.9982 - val_loss: 0.7737 - val_accuracy: 0.9830\n",
            "Epoch 418/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0109 - accuracy: 0.9988 - val_loss: 0.7225 - val_accuracy: 0.9848\n",
            "Epoch 419/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0145 - accuracy: 0.9970 - val_loss: 0.7399 - val_accuracy: 0.9757\n",
            "Epoch 420/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0107 - accuracy: 0.9973 - val_loss: 0.5146 - val_accuracy: 0.9848\n",
            "Epoch 421/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0071 - accuracy: 0.9983 - val_loss: 0.5546 - val_accuracy: 0.9830\n",
            "Epoch 422/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0143 - accuracy: 0.9974 - val_loss: 0.5543 - val_accuracy: 0.9800\n",
            "Epoch 423/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0181 - accuracy: 0.9962 - val_loss: 0.3794 - val_accuracy: 0.9812\n",
            "Epoch 424/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0095 - accuracy: 0.9980 - val_loss: 0.4413 - val_accuracy: 0.9830\n",
            "Epoch 425/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0074 - accuracy: 0.9983 - val_loss: 0.6858 - val_accuracy: 0.9818\n",
            "Epoch 426/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0052 - accuracy: 0.9989 - val_loss: 0.8267 - val_accuracy: 0.9806\n",
            "Epoch 427/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0165 - accuracy: 0.9970 - val_loss: 0.5425 - val_accuracy: 0.9788\n",
            "Epoch 428/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0113 - accuracy: 0.9979 - val_loss: 0.6079 - val_accuracy: 0.9800\n",
            "Epoch 429/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0121 - accuracy: 0.9968 - val_loss: 0.5050 - val_accuracy: 0.9818\n",
            "Epoch 430/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0138 - accuracy: 0.9973 - val_loss: 0.2955 - val_accuracy: 0.9818\n",
            "Epoch 431/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0090 - accuracy: 0.9983 - val_loss: 0.3428 - val_accuracy: 0.9818\n",
            "Epoch 432/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0223 - accuracy: 0.9973 - val_loss: 0.2502 - val_accuracy: 0.9830\n",
            "Epoch 433/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0071 - accuracy: 0.9979 - val_loss: 0.7945 - val_accuracy: 0.9830\n",
            "Epoch 434/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0046 - accuracy: 0.9992 - val_loss: 0.5540 - val_accuracy: 0.9854\n",
            "Epoch 435/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0040 - accuracy: 0.9992 - val_loss: 0.6626 - val_accuracy: 0.9848\n",
            "Epoch 436/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0056 - accuracy: 0.9989 - val_loss: 0.6183 - val_accuracy: 0.9854\n",
            "Epoch 437/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0054 - accuracy: 0.9989 - val_loss: 0.5063 - val_accuracy: 0.9836\n",
            "Epoch 438/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0072 - accuracy: 0.9983 - val_loss: 0.6512 - val_accuracy: 0.9830\n",
            "Epoch 439/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0135 - accuracy: 0.9974 - val_loss: 0.9142 - val_accuracy: 0.9818\n",
            "Epoch 440/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0106 - accuracy: 0.9976 - val_loss: 0.6780 - val_accuracy: 0.9867\n",
            "Epoch 441/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0108 - accuracy: 0.9977 - val_loss: 1.2563 - val_accuracy: 0.9763\n",
            "Epoch 442/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0175 - accuracy: 0.9973 - val_loss: 0.5149 - val_accuracy: 0.9800\n",
            "Epoch 443/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0113 - accuracy: 0.9974 - val_loss: 0.3994 - val_accuracy: 0.9806\n",
            "Epoch 444/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0103 - accuracy: 0.9980 - val_loss: 0.7146 - val_accuracy: 0.9830\n",
            "Epoch 445/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0225 - accuracy: 0.9988 - val_loss: 1.4504 - val_accuracy: 0.9411\n",
            "Epoch 446/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0063 - accuracy: 0.9985 - val_loss: 0.4895 - val_accuracy: 0.9806\n",
            "Epoch 447/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0055 - accuracy: 0.9986 - val_loss: 0.3981 - val_accuracy: 0.9824\n",
            "Epoch 448/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0133 - accuracy: 0.9979 - val_loss: 0.5290 - val_accuracy: 0.9836\n",
            "Epoch 449/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0108 - accuracy: 0.9977 - val_loss: 0.2913 - val_accuracy: 0.9830\n",
            "Epoch 450/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0065 - accuracy: 0.9985 - val_loss: 0.4841 - val_accuracy: 0.9830\n",
            "Epoch 451/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0058 - accuracy: 0.9988 - val_loss: 0.4620 - val_accuracy: 0.9848\n",
            "Epoch 452/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0044 - accuracy: 0.9992 - val_loss: 0.5790 - val_accuracy: 0.9824\n",
            "Epoch 453/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0135 - accuracy: 0.9980 - val_loss: 0.5657 - val_accuracy: 0.9818\n",
            "Epoch 454/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0067 - accuracy: 0.9986 - val_loss: 0.6334 - val_accuracy: 0.9812\n",
            "Epoch 455/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0074 - accuracy: 0.9985 - val_loss: 0.3275 - val_accuracy: 0.9860\n",
            "Epoch 456/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0120 - accuracy: 0.9979 - val_loss: 0.5014 - val_accuracy: 0.9836\n",
            "Epoch 457/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0044 - accuracy: 0.9991 - val_loss: 0.7586 - val_accuracy: 0.9824\n",
            "Epoch 458/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0060 - accuracy: 0.9986 - val_loss: 0.5383 - val_accuracy: 0.9806\n",
            "Epoch 459/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0451 - accuracy: 0.9959 - val_loss: 0.2830 - val_accuracy: 0.9812\n",
            "Epoch 460/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0208 - accuracy: 0.9967 - val_loss: 0.4076 - val_accuracy: 0.9812\n",
            "Epoch 461/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0126 - accuracy: 0.9980 - val_loss: 0.4259 - val_accuracy: 0.9818\n",
            "Epoch 462/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0071 - accuracy: 0.9985 - val_loss: 0.3096 - val_accuracy: 0.9824\n",
            "Epoch 463/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0049 - accuracy: 0.9989 - val_loss: 0.4632 - val_accuracy: 0.9842\n",
            "Epoch 464/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0068 - accuracy: 0.9983 - val_loss: 0.6449 - val_accuracy: 0.9830\n",
            "Epoch 465/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0064 - accuracy: 0.9988 - val_loss: 0.4210 - val_accuracy: 0.9860\n",
            "Epoch 466/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0091 - accuracy: 0.9980 - val_loss: 0.4290 - val_accuracy: 0.9836\n",
            "Epoch 467/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0117 - accuracy: 0.9986 - val_loss: 0.2787 - val_accuracy: 0.9830\n",
            "Epoch 468/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0057 - accuracy: 0.9988 - val_loss: 0.3384 - val_accuracy: 0.9842\n",
            "Epoch 469/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0055 - accuracy: 0.9989 - val_loss: 0.5931 - val_accuracy: 0.9824\n",
            "Epoch 470/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0148 - accuracy: 0.9982 - val_loss: 0.1335 - val_accuracy: 0.9769\n",
            "Epoch 471/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0142 - accuracy: 0.9974 - val_loss: 0.2185 - val_accuracy: 0.9806\n",
            "Epoch 472/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0065 - accuracy: 0.9985 - val_loss: 0.3196 - val_accuracy: 0.9836\n",
            "Epoch 473/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0067 - accuracy: 0.9985 - val_loss: 0.4211 - val_accuracy: 0.9824\n",
            "Epoch 474/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 0.4858 - val_accuracy: 0.9824\n",
            "Epoch 475/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0044 - accuracy: 0.9992 - val_loss: 0.4652 - val_accuracy: 0.9818\n",
            "Epoch 476/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0069 - accuracy: 0.9983 - val_loss: 0.4054 - val_accuracy: 0.9854\n",
            "Epoch 477/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0057 - accuracy: 0.9989 - val_loss: 0.5096 - val_accuracy: 0.9848\n",
            "Epoch 478/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0091 - accuracy: 0.9982 - val_loss: 0.4035 - val_accuracy: 0.9848\n",
            "Epoch 479/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0064 - accuracy: 0.9986 - val_loss: 0.4699 - val_accuracy: 0.9836\n",
            "Epoch 480/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0081 - accuracy: 0.9980 - val_loss: 0.7069 - val_accuracy: 0.9800\n",
            "Epoch 481/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0082 - accuracy: 0.9989 - val_loss: 0.4197 - val_accuracy: 0.9836\n",
            "Epoch 482/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0114 - accuracy: 0.9977 - val_loss: 0.3251 - val_accuracy: 0.9860\n",
            "Epoch 483/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0127 - accuracy: 0.9965 - val_loss: 0.4144 - val_accuracy: 0.9818\n",
            "Epoch 484/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0059 - accuracy: 0.9985 - val_loss: 0.4837 - val_accuracy: 0.9836\n",
            "Epoch 485/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0094 - accuracy: 0.9989 - val_loss: 0.7872 - val_accuracy: 0.9794\n",
            "Epoch 486/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0072 - accuracy: 0.9983 - val_loss: 0.4905 - val_accuracy: 0.9830\n",
            "Epoch 487/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0033 - accuracy: 0.9995 - val_loss: 0.4391 - val_accuracy: 0.9818\n",
            "Epoch 488/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0060 - accuracy: 0.9988 - val_loss: 0.5126 - val_accuracy: 0.9836\n",
            "Epoch 489/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0057 - accuracy: 0.9989 - val_loss: 0.5137 - val_accuracy: 0.9830\n",
            "Epoch 490/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0100 - accuracy: 0.9980 - val_loss: 0.5470 - val_accuracy: 0.9824\n",
            "Epoch 491/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0105 - accuracy: 0.9977 - val_loss: 0.5026 - val_accuracy: 0.9848\n",
            "Epoch 492/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0045 - accuracy: 0.9992 - val_loss: 0.4904 - val_accuracy: 0.9848\n",
            "Epoch 493/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0058 - accuracy: 0.9989 - val_loss: 0.4432 - val_accuracy: 0.9854\n",
            "Epoch 494/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0066 - accuracy: 0.9986 - val_loss: 0.5219 - val_accuracy: 0.9854\n",
            "Epoch 495/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0033 - accuracy: 0.9992 - val_loss: 0.4790 - val_accuracy: 0.9860\n",
            "Epoch 496/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0063 - accuracy: 0.9986 - val_loss: 0.6955 - val_accuracy: 0.9824\n",
            "Epoch 497/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0034 - accuracy: 0.9994 - val_loss: 0.6069 - val_accuracy: 0.9848\n",
            "Epoch 498/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0166 - accuracy: 0.9976 - val_loss: 0.3966 - val_accuracy: 0.9757\n",
            "Epoch 499/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0102 - accuracy: 0.9973 - val_loss: 0.7172 - val_accuracy: 0.9818\n",
            "Epoch 500/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0148 - accuracy: 0.9979 - val_loss: 0.7633 - val_accuracy: 0.9800\n",
            "Epoch 501/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0040 - accuracy: 0.9994 - val_loss: 0.7482 - val_accuracy: 0.9806\n",
            "Epoch 502/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0061 - accuracy: 0.9986 - val_loss: 0.3301 - val_accuracy: 0.9818\n",
            "Epoch 503/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0125 - accuracy: 0.9974 - val_loss: 0.3319 - val_accuracy: 0.9836\n",
            "Epoch 504/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0049 - accuracy: 0.9989 - val_loss: 0.3668 - val_accuracy: 0.9842\n",
            "Epoch 505/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0069 - accuracy: 0.9985 - val_loss: 0.2867 - val_accuracy: 0.9842\n",
            "Epoch 506/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0077 - accuracy: 0.9986 - val_loss: 0.4236 - val_accuracy: 0.9842\n",
            "Epoch 507/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0106 - accuracy: 0.9977 - val_loss: 0.6779 - val_accuracy: 0.9830\n",
            "Epoch 508/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0068 - accuracy: 0.9985 - val_loss: 0.6305 - val_accuracy: 0.9830\n",
            "Epoch 509/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0076 - accuracy: 0.9983 - val_loss: 0.4791 - val_accuracy: 0.9830\n",
            "Epoch 510/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0250 - accuracy: 0.9979 - val_loss: 1.1550 - val_accuracy: 0.9709\n",
            "Epoch 511/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0083 - accuracy: 0.9983 - val_loss: 0.4907 - val_accuracy: 0.9824\n",
            "Epoch 512/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0081 - accuracy: 0.9986 - val_loss: 0.5683 - val_accuracy: 0.9842\n",
            "Epoch 513/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0056 - accuracy: 0.9989 - val_loss: 0.6204 - val_accuracy: 0.9824\n",
            "Epoch 514/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0057 - accuracy: 0.9989 - val_loss: 0.6089 - val_accuracy: 0.9824\n",
            "Epoch 515/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0036 - accuracy: 0.9994 - val_loss: 0.6082 - val_accuracy: 0.9830\n",
            "Epoch 516/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0323 - accuracy: 0.9961 - val_loss: 0.2778 - val_accuracy: 0.9782\n",
            "Epoch 517/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0126 - accuracy: 0.9982 - val_loss: 0.4550 - val_accuracy: 0.9860\n",
            "Epoch 518/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0069 - accuracy: 0.9986 - val_loss: 0.5663 - val_accuracy: 0.9848\n",
            "Epoch 519/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0063 - accuracy: 0.9988 - val_loss: 0.4151 - val_accuracy: 0.9848\n",
            "Epoch 520/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0069 - accuracy: 0.9986 - val_loss: 0.4824 - val_accuracy: 0.9848\n",
            "Epoch 521/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0063 - accuracy: 0.9988 - val_loss: 0.6584 - val_accuracy: 0.9848\n",
            "Epoch 522/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0070 - accuracy: 0.9985 - val_loss: 0.6636 - val_accuracy: 0.9836\n",
            "Epoch 523/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0043 - accuracy: 0.9991 - val_loss: 0.6492 - val_accuracy: 0.9854\n",
            "Epoch 524/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0123 - accuracy: 0.9973 - val_loss: 0.5800 - val_accuracy: 0.9842\n",
            "Epoch 525/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0168 - accuracy: 0.9968 - val_loss: 0.2890 - val_accuracy: 0.9836\n",
            "Epoch 526/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0064 - accuracy: 0.9988 - val_loss: 0.4742 - val_accuracy: 0.9836\n",
            "Epoch 527/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0089 - accuracy: 0.9983 - val_loss: 0.3047 - val_accuracy: 0.9848\n",
            "Epoch 528/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0049 - accuracy: 0.9991 - val_loss: 0.5455 - val_accuracy: 0.9842\n",
            "Epoch 529/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0080 - accuracy: 0.9980 - val_loss: 0.7426 - val_accuracy: 0.9818\n",
            "Epoch 530/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0295 - accuracy: 0.9974 - val_loss: 0.3009 - val_accuracy: 0.9824\n",
            "Epoch 531/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0150 - accuracy: 0.9968 - val_loss: 0.3797 - val_accuracy: 0.9830\n",
            "Epoch 532/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0083 - accuracy: 0.9982 - val_loss: 0.2812 - val_accuracy: 0.9812\n",
            "Epoch 533/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0077 - accuracy: 0.9986 - val_loss: 0.4063 - val_accuracy: 0.9830\n",
            "Epoch 534/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0087 - accuracy: 0.9980 - val_loss: 0.4470 - val_accuracy: 0.9824\n",
            "Epoch 535/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0051 - accuracy: 0.9992 - val_loss: 0.5722 - val_accuracy: 0.9830\n",
            "Epoch 536/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0048 - accuracy: 0.9992 - val_loss: 0.6049 - val_accuracy: 0.9830\n",
            "Epoch 537/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0063 - accuracy: 0.9986 - val_loss: 0.6405 - val_accuracy: 0.9836\n",
            "Epoch 538/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0046 - accuracy: 0.9992 - val_loss: 0.5639 - val_accuracy: 0.9830\n",
            "Epoch 539/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0084 - accuracy: 0.9982 - val_loss: 0.4484 - val_accuracy: 0.9830\n",
            "Epoch 540/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0061 - accuracy: 0.9988 - val_loss: 0.5721 - val_accuracy: 0.9836\n",
            "Epoch 541/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0072 - accuracy: 0.9983 - val_loss: 0.3070 - val_accuracy: 0.9860\n",
            "Epoch 542/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0072 - accuracy: 0.9985 - val_loss: 0.3900 - val_accuracy: 0.9842\n",
            "Epoch 543/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0035 - accuracy: 0.9992 - val_loss: 0.3899 - val_accuracy: 0.9848\n",
            "Epoch 544/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0113 - accuracy: 0.9973 - val_loss: 0.4642 - val_accuracy: 0.9842\n",
            "Epoch 545/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0049 - accuracy: 0.9991 - val_loss: 0.4147 - val_accuracy: 0.9860\n",
            "Epoch 546/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0047 - accuracy: 0.9991 - val_loss: 0.5714 - val_accuracy: 0.9854\n",
            "Epoch 547/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0078 - accuracy: 0.9991 - val_loss: 0.3653 - val_accuracy: 0.9854\n",
            "Epoch 548/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0067 - accuracy: 0.9986 - val_loss: 0.3767 - val_accuracy: 0.9848\n",
            "Epoch 549/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0104 - accuracy: 0.9982 - val_loss: 0.3147 - val_accuracy: 0.9854\n",
            "Epoch 550/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0079 - accuracy: 0.9988 - val_loss: 0.7899 - val_accuracy: 0.9794\n",
            "Epoch 551/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0082 - accuracy: 0.9983 - val_loss: 0.8276 - val_accuracy: 0.9812\n",
            "Epoch 552/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0057 - accuracy: 0.9988 - val_loss: 0.7004 - val_accuracy: 0.9824\n",
            "Epoch 553/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0037 - accuracy: 0.9992 - val_loss: 0.5361 - val_accuracy: 0.9842\n",
            "Epoch 554/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0029 - accuracy: 0.9995 - val_loss: 0.5443 - val_accuracy: 0.9842\n",
            "Epoch 555/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0055 - accuracy: 0.9988 - val_loss: 0.4528 - val_accuracy: 0.9842\n",
            "Epoch 556/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0182 - accuracy: 0.9980 - val_loss: 0.5853 - val_accuracy: 0.9818\n",
            "Epoch 557/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0116 - accuracy: 0.9971 - val_loss: 0.3384 - val_accuracy: 0.9842\n",
            "Epoch 558/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0185 - accuracy: 0.9977 - val_loss: 0.2583 - val_accuracy: 0.9794\n",
            "Epoch 559/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0195 - accuracy: 0.9961 - val_loss: 0.7527 - val_accuracy: 0.9800\n",
            "Epoch 560/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0078 - accuracy: 0.9986 - val_loss: 0.6405 - val_accuracy: 0.9836\n",
            "Epoch 561/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0084 - accuracy: 0.9985 - val_loss: 0.4485 - val_accuracy: 0.9824\n",
            "Epoch 562/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0043 - accuracy: 0.9992 - val_loss: 0.5433 - val_accuracy: 0.9836\n",
            "Epoch 563/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0079 - accuracy: 0.9983 - val_loss: 0.5010 - val_accuracy: 0.9830\n",
            "Epoch 564/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0024 - accuracy: 0.9997 - val_loss: 0.5833 - val_accuracy: 0.9836\n",
            "Epoch 565/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0118 - accuracy: 0.9989 - val_loss: 0.2441 - val_accuracy: 0.9842\n",
            "Epoch 566/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0101 - accuracy: 0.9982 - val_loss: 1.0153 - val_accuracy: 0.9800\n",
            "Epoch 567/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0087 - accuracy: 0.9985 - val_loss: 0.6527 - val_accuracy: 0.9842\n",
            "Epoch 568/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0055 - accuracy: 0.9989 - val_loss: 0.4990 - val_accuracy: 0.9842\n",
            "Epoch 569/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0045 - accuracy: 0.9992 - val_loss: 0.7563 - val_accuracy: 0.9848\n",
            "Epoch 570/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0083 - accuracy: 0.9988 - val_loss: 0.9064 - val_accuracy: 0.9800\n",
            "Epoch 571/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0100 - accuracy: 0.9986 - val_loss: 0.5492 - val_accuracy: 0.9782\n",
            "Epoch 572/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0095 - accuracy: 0.9982 - val_loss: 0.5569 - val_accuracy: 0.9854\n",
            "Epoch 573/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0070 - accuracy: 0.9988 - val_loss: 0.5496 - val_accuracy: 0.9848\n",
            "Epoch 574/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 0.5974 - val_accuracy: 0.9848\n",
            "Epoch 575/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0037 - accuracy: 0.9994 - val_loss: 0.6201 - val_accuracy: 0.9848\n",
            "Epoch 576/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0037 - accuracy: 0.9994 - val_loss: 0.6196 - val_accuracy: 0.9848\n",
            "Epoch 577/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0051 - accuracy: 0.9989 - val_loss: 0.6457 - val_accuracy: 0.9842\n",
            "Epoch 578/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0098 - accuracy: 0.9988 - val_loss: 0.9367 - val_accuracy: 0.9824\n",
            "Epoch 579/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0220 - accuracy: 0.9971 - val_loss: 0.3475 - val_accuracy: 0.9788\n",
            "Epoch 580/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0116 - accuracy: 0.9974 - val_loss: 0.5368 - val_accuracy: 0.9854\n",
            "Epoch 581/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0067 - accuracy: 0.9985 - val_loss: 0.8425 - val_accuracy: 0.9812\n",
            "Epoch 582/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0043 - accuracy: 0.9992 - val_loss: 0.8506 - val_accuracy: 0.9830\n",
            "Epoch 583/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0042 - accuracy: 0.9992 - val_loss: 0.8606 - val_accuracy: 0.9830\n",
            "Epoch 584/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0445 - accuracy: 0.9950 - val_loss: 0.3082 - val_accuracy: 0.9800\n",
            "Epoch 585/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0104 - accuracy: 0.9979 - val_loss: 0.5051 - val_accuracy: 0.9830\n",
            "Epoch 586/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0074 - accuracy: 0.9985 - val_loss: 0.4897 - val_accuracy: 0.9830\n",
            "Epoch 587/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0067 - accuracy: 0.9988 - val_loss: 0.5515 - val_accuracy: 0.9830\n",
            "Epoch 588/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0078 - accuracy: 0.9983 - val_loss: 0.7585 - val_accuracy: 0.9824\n",
            "Epoch 589/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0193 - accuracy: 0.9965 - val_loss: 0.3384 - val_accuracy: 0.9806\n",
            "Epoch 590/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0136 - accuracy: 0.9967 - val_loss: 0.8327 - val_accuracy: 0.9806\n",
            "Epoch 591/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0104 - accuracy: 0.9980 - val_loss: 0.5299 - val_accuracy: 0.9800\n",
            "Epoch 592/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0066 - accuracy: 0.9988 - val_loss: 0.7175 - val_accuracy: 0.9800\n",
            "Epoch 593/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0106 - accuracy: 0.9980 - val_loss: 0.5965 - val_accuracy: 0.9794\n",
            "Epoch 594/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0087 - accuracy: 0.9983 - val_loss: 0.5555 - val_accuracy: 0.9824\n",
            "Epoch 595/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0074 - accuracy: 0.9988 - val_loss: 0.6080 - val_accuracy: 0.9800\n",
            "Epoch 596/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0173 - accuracy: 0.9979 - val_loss: 0.4090 - val_accuracy: 0.9812\n",
            "Epoch 597/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0165 - accuracy: 0.9971 - val_loss: 0.4578 - val_accuracy: 0.9782\n",
            "Epoch 598/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0146 - accuracy: 0.9971 - val_loss: 0.4584 - val_accuracy: 0.9842\n",
            "Epoch 599/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0082 - accuracy: 0.9991 - val_loss: 0.3689 - val_accuracy: 0.9818\n",
            "Epoch 600/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0100 - accuracy: 0.9979 - val_loss: 0.6641 - val_accuracy: 0.9794\n",
            "Epoch 601/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0063 - accuracy: 0.9989 - val_loss: 0.4423 - val_accuracy: 0.9812\n",
            "Epoch 602/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0086 - accuracy: 0.9983 - val_loss: 0.5404 - val_accuracy: 0.9812\n",
            "Epoch 603/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0067 - accuracy: 0.9988 - val_loss: 0.5365 - val_accuracy: 0.9812\n",
            "Epoch 604/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0080 - accuracy: 0.9985 - val_loss: 0.5177 - val_accuracy: 0.9812\n",
            "Epoch 605/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0076 - accuracy: 0.9985 - val_loss: 0.4776 - val_accuracy: 0.9818\n",
            "Epoch 606/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0099 - accuracy: 0.9979 - val_loss: 0.4045 - val_accuracy: 0.9812\n",
            "Epoch 607/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0070 - accuracy: 0.9985 - val_loss: 0.5228 - val_accuracy: 0.9842\n",
            "Epoch 608/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0054 - accuracy: 0.9989 - val_loss: 0.6462 - val_accuracy: 0.9830\n",
            "Epoch 609/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0133 - accuracy: 0.9979 - val_loss: 0.4665 - val_accuracy: 0.9782\n",
            "Epoch 610/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0145 - accuracy: 0.9976 - val_loss: 1.4002 - val_accuracy: 0.9703\n",
            "Epoch 611/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0282 - accuracy: 0.9970 - val_loss: 0.7192 - val_accuracy: 0.9782\n",
            "Epoch 612/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0094 - accuracy: 0.9982 - val_loss: 0.9155 - val_accuracy: 0.9794\n",
            "Epoch 613/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0106 - accuracy: 0.9985 - val_loss: 0.6467 - val_accuracy: 0.9812\n",
            "Epoch 614/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0087 - accuracy: 0.9980 - val_loss: 0.5839 - val_accuracy: 0.9824\n",
            "Epoch 615/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0100 - accuracy: 0.9980 - val_loss: 0.8929 - val_accuracy: 0.9824\n",
            "Epoch 616/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0081 - accuracy: 0.9988 - val_loss: 0.6355 - val_accuracy: 0.9848\n",
            "Epoch 617/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0061 - accuracy: 0.9988 - val_loss: 0.6979 - val_accuracy: 0.9818\n",
            "Epoch 618/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0059 - accuracy: 0.9989 - val_loss: 0.7481 - val_accuracy: 0.9818\n",
            "Epoch 619/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0053 - accuracy: 0.9989 - val_loss: 0.7683 - val_accuracy: 0.9812\n",
            "Epoch 620/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0047 - accuracy: 0.9994 - val_loss: 0.7796 - val_accuracy: 0.9812\n",
            "Epoch 621/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0067 - accuracy: 0.9989 - val_loss: 0.7419 - val_accuracy: 0.9812\n",
            "Epoch 622/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0040 - accuracy: 0.9992 - val_loss: 1.0371 - val_accuracy: 0.9806\n",
            "Epoch 623/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0056 - accuracy: 0.9989 - val_loss: 0.8546 - val_accuracy: 0.9842\n",
            "Epoch 624/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0063 - accuracy: 0.9986 - val_loss: 0.6313 - val_accuracy: 0.9836\n",
            "Epoch 625/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0072 - accuracy: 0.9985 - val_loss: 0.5980 - val_accuracy: 0.9782\n",
            "Epoch 626/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0075 - accuracy: 0.9985 - val_loss: 0.5045 - val_accuracy: 0.9812\n",
            "Epoch 627/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0081 - accuracy: 0.9985 - val_loss: 1.1734 - val_accuracy: 0.9788\n",
            "Epoch 628/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0249 - accuracy: 0.9973 - val_loss: 0.3393 - val_accuracy: 0.9818\n",
            "Epoch 629/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0144 - accuracy: 0.9979 - val_loss: 0.4107 - val_accuracy: 0.9818\n",
            "Epoch 630/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0055 - accuracy: 0.9988 - val_loss: 0.7090 - val_accuracy: 0.9824\n",
            "Epoch 631/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0093 - accuracy: 0.9980 - val_loss: 0.4454 - val_accuracy: 0.9812\n",
            "Epoch 632/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0064 - accuracy: 0.9988 - val_loss: 0.1472 - val_accuracy: 0.9775\n",
            "Epoch 633/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0150 - accuracy: 0.9976 - val_loss: 0.7440 - val_accuracy: 0.9769\n",
            "Epoch 634/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0060 - accuracy: 0.9989 - val_loss: 0.5191 - val_accuracy: 0.9806\n",
            "Epoch 635/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0068 - accuracy: 0.9986 - val_loss: 0.5000 - val_accuracy: 0.9794\n",
            "Epoch 636/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0142 - accuracy: 0.9968 - val_loss: 0.4729 - val_accuracy: 0.9812\n",
            "Epoch 637/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0071 - accuracy: 0.9986 - val_loss: 0.4525 - val_accuracy: 0.9739\n",
            "Epoch 638/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0063 - accuracy: 0.9988 - val_loss: 0.4845 - val_accuracy: 0.9788\n",
            "Epoch 639/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0077 - accuracy: 0.9985 - val_loss: 0.9183 - val_accuracy: 0.9806\n",
            "Epoch 640/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0043 - accuracy: 0.9992 - val_loss: 0.5089 - val_accuracy: 0.9775\n",
            "Epoch 641/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0066 - accuracy: 0.9986 - val_loss: 1.1898 - val_accuracy: 0.9794\n",
            "Epoch 642/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0106 - accuracy: 0.9982 - val_loss: 0.5131 - val_accuracy: 0.9806\n",
            "Epoch 643/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0102 - accuracy: 0.9985 - val_loss: 0.4487 - val_accuracy: 0.9824\n",
            "Epoch 644/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0076 - accuracy: 0.9989 - val_loss: 0.7535 - val_accuracy: 0.9806\n",
            "Epoch 645/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0085 - accuracy: 0.9982 - val_loss: 0.8630 - val_accuracy: 0.9800\n",
            "Epoch 646/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0122 - accuracy: 0.9982 - val_loss: 0.2260 - val_accuracy: 0.9769\n",
            "Epoch 647/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0312 - accuracy: 0.9977 - val_loss: 0.4923 - val_accuracy: 0.9830\n",
            "Epoch 648/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0104 - accuracy: 0.9976 - val_loss: 0.4392 - val_accuracy: 0.9812\n",
            "Epoch 649/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0074 - accuracy: 0.9985 - val_loss: 0.6147 - val_accuracy: 0.9836\n",
            "Epoch 650/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0047 - accuracy: 0.9992 - val_loss: 0.5550 - val_accuracy: 0.9830\n",
            "Epoch 651/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0091 - accuracy: 0.9991 - val_loss: 0.6859 - val_accuracy: 0.9836\n",
            "Epoch 652/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0131 - accuracy: 0.9994 - val_loss: 0.3371 - val_accuracy: 0.9806\n",
            "Epoch 653/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0047 - accuracy: 0.9991 - val_loss: 0.5357 - val_accuracy: 0.9806\n",
            "Epoch 654/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0057 - accuracy: 0.9989 - val_loss: 0.5298 - val_accuracy: 0.9836\n",
            "Epoch 655/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0534 - accuracy: 0.9959 - val_loss: 0.3728 - val_accuracy: 0.9812\n",
            "Epoch 656/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0089 - accuracy: 0.9982 - val_loss: 0.3063 - val_accuracy: 0.9788\n",
            "Epoch 657/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0074 - accuracy: 0.9985 - val_loss: 0.5105 - val_accuracy: 0.9812\n",
            "Epoch 658/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0043 - accuracy: 0.9992 - val_loss: 0.6510 - val_accuracy: 0.9824\n",
            "Epoch 659/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0149 - accuracy: 0.9980 - val_loss: 0.3397 - val_accuracy: 0.9830\n",
            "Epoch 660/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0060 - accuracy: 0.9985 - val_loss: 0.4186 - val_accuracy: 0.9824\n",
            "Epoch 661/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0083 - accuracy: 0.9983 - val_loss: 0.4796 - val_accuracy: 0.9824\n",
            "Epoch 662/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0051 - accuracy: 0.9991 - val_loss: 0.3892 - val_accuracy: 0.9836\n",
            "Epoch 663/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0087 - accuracy: 0.9986 - val_loss: 0.3318 - val_accuracy: 0.9830\n",
            "Epoch 664/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0033 - accuracy: 0.9995 - val_loss: 0.3522 - val_accuracy: 0.9830\n",
            "Epoch 665/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0048 - accuracy: 0.9992 - val_loss: 0.5301 - val_accuracy: 0.9830\n",
            "Epoch 666/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0035 - accuracy: 0.9994 - val_loss: 0.3577 - val_accuracy: 0.9824\n",
            "Epoch 667/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0070 - accuracy: 0.9986 - val_loss: 0.5306 - val_accuracy: 0.9836\n",
            "Epoch 668/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0040 - accuracy: 0.9994 - val_loss: 0.5850 - val_accuracy: 0.9836\n",
            "Epoch 669/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0065 - accuracy: 0.9988 - val_loss: 0.4561 - val_accuracy: 0.9824\n",
            "Epoch 670/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0102 - accuracy: 0.9980 - val_loss: 0.2083 - val_accuracy: 0.9769\n",
            "Epoch 671/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0243 - accuracy: 0.9948 - val_loss: 0.5411 - val_accuracy: 0.9800\n",
            "Epoch 672/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0045 - accuracy: 0.9992 - val_loss: 0.4461 - val_accuracy: 0.9824\n",
            "Epoch 673/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0090 - accuracy: 0.9988 - val_loss: 0.4721 - val_accuracy: 0.9806\n",
            "Epoch 674/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0105 - accuracy: 0.9979 - val_loss: 0.3522 - val_accuracy: 0.9800\n",
            "Epoch 675/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0092 - accuracy: 0.9979 - val_loss: 0.4348 - val_accuracy: 0.9806\n",
            "Epoch 676/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0099 - accuracy: 0.9980 - val_loss: 0.4178 - val_accuracy: 0.9812\n",
            "Epoch 677/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0078 - accuracy: 0.9992 - val_loss: 0.2788 - val_accuracy: 0.9812\n",
            "Epoch 678/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0163 - accuracy: 0.9983 - val_loss: 0.3130 - val_accuracy: 0.9842\n",
            "Epoch 679/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0078 - accuracy: 0.9983 - val_loss: 0.4629 - val_accuracy: 0.9836\n",
            "Epoch 680/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0053 - accuracy: 0.9991 - val_loss: 0.4666 - val_accuracy: 0.9830\n",
            "Epoch 681/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0047 - accuracy: 0.9991 - val_loss: 0.6899 - val_accuracy: 0.9836\n",
            "Epoch 682/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0075 - accuracy: 0.9985 - val_loss: 0.4734 - val_accuracy: 0.9818\n",
            "Epoch 683/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0037 - accuracy: 0.9994 - val_loss: 0.7353 - val_accuracy: 0.9842\n",
            "Epoch 684/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0205 - accuracy: 0.9983 - val_loss: 0.1677 - val_accuracy: 0.9824\n",
            "Epoch 685/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0056 - accuracy: 0.9994 - val_loss: 0.4706 - val_accuracy: 0.9830\n",
            "Epoch 686/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0074 - accuracy: 0.9989 - val_loss: 0.2293 - val_accuracy: 0.9812\n",
            "Epoch 687/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0243 - accuracy: 0.9961 - val_loss: 0.4759 - val_accuracy: 0.9836\n",
            "Epoch 688/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0052 - accuracy: 0.9989 - val_loss: 0.8512 - val_accuracy: 0.9806\n",
            "Epoch 689/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0054 - accuracy: 0.9991 - val_loss: 0.9418 - val_accuracy: 0.9824\n",
            "Epoch 690/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0056 - accuracy: 0.9989 - val_loss: 0.6023 - val_accuracy: 0.9824\n",
            "Epoch 691/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0079 - accuracy: 0.9989 - val_loss: 0.5918 - val_accuracy: 0.9830\n",
            "Epoch 692/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0027 - accuracy: 0.9995 - val_loss: 0.6582 - val_accuracy: 0.9824\n",
            "Epoch 693/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0086 - accuracy: 0.9982 - val_loss: 0.3740 - val_accuracy: 0.9830\n",
            "Epoch 694/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0061 - accuracy: 0.9988 - val_loss: 0.4866 - val_accuracy: 0.9836\n",
            "Epoch 695/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0037 - accuracy: 0.9994 - val_loss: 0.7194 - val_accuracy: 0.9830\n",
            "Epoch 696/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0055 - accuracy: 0.9989 - val_loss: 0.7006 - val_accuracy: 0.9806\n",
            "Epoch 697/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0065 - accuracy: 0.9992 - val_loss: 0.3379 - val_accuracy: 0.9830\n",
            "Epoch 698/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0067 - accuracy: 0.9986 - val_loss: 0.4731 - val_accuracy: 0.9818\n",
            "Epoch 699/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0048 - accuracy: 0.9991 - val_loss: 1.0642 - val_accuracy: 0.9806\n",
            "Epoch 700/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0048 - accuracy: 0.9991 - val_loss: 0.7319 - val_accuracy: 0.9812\n",
            "Epoch 701/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0053 - accuracy: 0.9991 - val_loss: 1.0017 - val_accuracy: 0.9812\n",
            "Epoch 702/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0099 - accuracy: 0.9985 - val_loss: 0.2208 - val_accuracy: 0.9800\n",
            "Epoch 703/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0201 - accuracy: 0.9980 - val_loss: 0.7012 - val_accuracy: 0.9806\n",
            "Epoch 704/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0119 - accuracy: 0.9979 - val_loss: 0.2872 - val_accuracy: 0.9806\n",
            "Epoch 705/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0169 - accuracy: 0.9971 - val_loss: 0.2099 - val_accuracy: 0.9824\n",
            "Epoch 706/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0086 - accuracy: 0.9979 - val_loss: 0.5368 - val_accuracy: 0.9848\n",
            "Epoch 707/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0076 - accuracy: 0.9985 - val_loss: 0.4926 - val_accuracy: 0.9860\n",
            "Epoch 708/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0044 - accuracy: 0.9992 - val_loss: 0.7830 - val_accuracy: 0.9854\n",
            "Epoch 709/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0031 - accuracy: 0.9995 - val_loss: 0.6717 - val_accuracy: 0.9848\n",
            "Epoch 710/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0038 - accuracy: 0.9994 - val_loss: 0.6662 - val_accuracy: 0.9848\n",
            "Epoch 711/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0031 - accuracy: 0.9995 - val_loss: 0.7477 - val_accuracy: 0.9842\n",
            "Epoch 712/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0038 - accuracy: 0.9994 - val_loss: 0.9057 - val_accuracy: 0.9848\n",
            "Epoch 713/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0064 - accuracy: 0.9985 - val_loss: 0.6418 - val_accuracy: 0.9824\n",
            "Epoch 714/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0045 - accuracy: 0.9992 - val_loss: 0.6778 - val_accuracy: 0.9824\n",
            "Epoch 715/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0024 - accuracy: 0.9997 - val_loss: 0.4937 - val_accuracy: 0.9830\n",
            "Epoch 716/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0076 - accuracy: 0.9982 - val_loss: 0.3898 - val_accuracy: 0.9860\n",
            "Epoch 717/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0047 - accuracy: 0.9991 - val_loss: 0.4388 - val_accuracy: 0.9848\n",
            "Epoch 718/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0038 - accuracy: 0.9994 - val_loss: 0.6848 - val_accuracy: 0.9836\n",
            "Epoch 719/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.6946 - val_accuracy: 0.9836\n",
            "Epoch 720/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0070 - accuracy: 0.9986 - val_loss: 1.2111 - val_accuracy: 0.9691\n",
            "Epoch 721/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0198 - accuracy: 0.9986 - val_loss: 0.3172 - val_accuracy: 0.9818\n",
            "Epoch 722/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0122 - accuracy: 0.9989 - val_loss: 0.2692 - val_accuracy: 0.9824\n",
            "Epoch 723/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0057 - accuracy: 0.9989 - val_loss: 0.3158 - val_accuracy: 0.9842\n",
            "Epoch 724/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0041 - accuracy: 0.9992 - val_loss: 0.7829 - val_accuracy: 0.9806\n",
            "Epoch 725/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0081 - accuracy: 0.9985 - val_loss: 0.3440 - val_accuracy: 0.9836\n",
            "Epoch 726/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0076 - accuracy: 0.9986 - val_loss: 0.4100 - val_accuracy: 0.9879\n",
            "Epoch 727/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0051 - accuracy: 0.9991 - val_loss: 0.6344 - val_accuracy: 0.9848\n",
            "Epoch 728/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0090 - accuracy: 0.9980 - val_loss: 0.5262 - val_accuracy: 0.9842\n",
            "Epoch 729/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0051 - accuracy: 0.9991 - val_loss: 0.7840 - val_accuracy: 0.9867\n",
            "Epoch 730/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0112 - accuracy: 0.9985 - val_loss: 1.0048 - val_accuracy: 0.9812\n",
            "Epoch 731/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0061 - accuracy: 0.9988 - val_loss: 0.2208 - val_accuracy: 0.9836\n",
            "Epoch 732/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0069 - accuracy: 0.9985 - val_loss: 0.3888 - val_accuracy: 0.9830\n",
            "Epoch 733/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0047 - accuracy: 0.9989 - val_loss: 0.5729 - val_accuracy: 0.9830\n",
            "Epoch 734/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0099 - accuracy: 0.9985 - val_loss: 0.2981 - val_accuracy: 0.9824\n",
            "Epoch 735/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0100 - accuracy: 0.9979 - val_loss: 0.4130 - val_accuracy: 0.9824\n",
            "Epoch 736/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0053 - accuracy: 0.9991 - val_loss: 0.5368 - val_accuracy: 0.9836\n",
            "Epoch 737/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0052 - accuracy: 0.9991 - val_loss: 0.5869 - val_accuracy: 0.9830\n",
            "Epoch 738/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0059 - accuracy: 0.9989 - val_loss: 0.5681 - val_accuracy: 0.9824\n",
            "Epoch 739/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0045 - accuracy: 0.9992 - val_loss: 0.5743 - val_accuracy: 0.9824\n",
            "Epoch 740/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0122 - accuracy: 0.9985 - val_loss: 0.3886 - val_accuracy: 0.9812\n",
            "Epoch 741/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0055 - accuracy: 0.9991 - val_loss: 0.6809 - val_accuracy: 0.9830\n",
            "Epoch 742/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0113 - accuracy: 0.9985 - val_loss: 0.6501 - val_accuracy: 0.9824\n",
            "Epoch 743/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0061 - accuracy: 0.9989 - val_loss: 0.7030 - val_accuracy: 0.9830\n",
            "Epoch 744/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0055 - accuracy: 0.9991 - val_loss: 0.8403 - val_accuracy: 0.9830\n",
            "Epoch 745/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0045 - accuracy: 0.9992 - val_loss: 0.9472 - val_accuracy: 0.9812\n",
            "Epoch 746/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0048 - accuracy: 0.9991 - val_loss: 0.8781 - val_accuracy: 0.9824\n",
            "Epoch 747/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0071 - accuracy: 0.9986 - val_loss: 0.4371 - val_accuracy: 0.9836\n",
            "Epoch 748/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0061 - accuracy: 0.9986 - val_loss: 1.0621 - val_accuracy: 0.9812\n",
            "Epoch 749/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0066 - accuracy: 0.9986 - val_loss: 0.8018 - val_accuracy: 0.9836\n",
            "Epoch 750/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0046 - accuracy: 0.9992 - val_loss: 0.8222 - val_accuracy: 0.9842\n",
            "Epoch 751/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0053 - accuracy: 0.9991 - val_loss: 0.8106 - val_accuracy: 0.9842\n",
            "Epoch 752/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0039 - accuracy: 0.9994 - val_loss: 0.8372 - val_accuracy: 0.9848\n",
            "Epoch 753/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0031 - accuracy: 0.9995 - val_loss: 0.8298 - val_accuracy: 0.9854\n",
            "Epoch 754/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0090 - accuracy: 0.9983 - val_loss: 0.3018 - val_accuracy: 0.9848\n",
            "Epoch 755/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0042 - accuracy: 0.9991 - val_loss: 0.9813 - val_accuracy: 0.9830\n",
            "Epoch 756/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0058 - accuracy: 0.9989 - val_loss: 0.6957 - val_accuracy: 0.9854\n",
            "Epoch 757/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0199 - accuracy: 0.9985 - val_loss: 17.5940 - val_accuracy: 0.8956\n",
            "Epoch 758/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0128 - accuracy: 0.9977 - val_loss: 0.8923 - val_accuracy: 0.9830\n",
            "Epoch 759/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0091 - accuracy: 0.9983 - val_loss: 1.1733 - val_accuracy: 0.9806\n",
            "Epoch 760/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0166 - accuracy: 0.9968 - val_loss: 0.4860 - val_accuracy: 0.9842\n",
            "Epoch 761/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0088 - accuracy: 0.9983 - val_loss: 0.8627 - val_accuracy: 0.9818\n",
            "Epoch 762/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0058 - accuracy: 0.9989 - val_loss: 0.8732 - val_accuracy: 0.9818\n",
            "Epoch 763/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0066 - accuracy: 0.9988 - val_loss: 0.8757 - val_accuracy: 0.9818\n",
            "Epoch 764/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0074 - accuracy: 0.9989 - val_loss: 0.7764 - val_accuracy: 0.9818\n",
            "Epoch 765/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0104 - accuracy: 0.9980 - val_loss: 0.5280 - val_accuracy: 0.9830\n",
            "Epoch 766/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0148 - accuracy: 0.9980 - val_loss: 0.3385 - val_accuracy: 0.9830\n",
            "Epoch 767/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0087 - accuracy: 0.9989 - val_loss: 0.2608 - val_accuracy: 0.9812\n",
            "Epoch 768/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0122 - accuracy: 0.9979 - val_loss: 0.9412 - val_accuracy: 0.9830\n",
            "Epoch 769/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0159 - accuracy: 0.9986 - val_loss: 0.4113 - val_accuracy: 0.9830\n",
            "Epoch 770/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0137 - accuracy: 0.9982 - val_loss: 1.3611 - val_accuracy: 0.9775\n",
            "Epoch 771/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0045 - accuracy: 0.9992 - val_loss: 0.7112 - val_accuracy: 0.9812\n",
            "Epoch 772/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0074 - accuracy: 0.9985 - val_loss: 0.6118 - val_accuracy: 0.9818\n",
            "Epoch 773/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0039 - accuracy: 0.9992 - val_loss: 0.8360 - val_accuracy: 0.9830\n",
            "Epoch 774/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0057 - accuracy: 0.9989 - val_loss: 0.8618 - val_accuracy: 0.9836\n",
            "Epoch 775/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0045 - accuracy: 0.9992 - val_loss: 0.9275 - val_accuracy: 0.9842\n",
            "Epoch 776/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0060 - accuracy: 0.9989 - val_loss: 0.9066 - val_accuracy: 0.9818\n",
            "Epoch 777/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0046 - accuracy: 0.9992 - val_loss: 1.0284 - val_accuracy: 0.9818\n",
            "Epoch 778/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0069 - accuracy: 0.9986 - val_loss: 0.8905 - val_accuracy: 0.9824\n",
            "Epoch 779/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0086 - accuracy: 0.9983 - val_loss: 0.9583 - val_accuracy: 0.9806\n",
            "Epoch 780/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0089 - accuracy: 0.9983 - val_loss: 0.6226 - val_accuracy: 0.9806\n",
            "Epoch 781/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0069 - accuracy: 0.9988 - val_loss: 0.7501 - val_accuracy: 0.9818\n",
            "Epoch 782/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.7288 - val_accuracy: 0.9824\n",
            "Epoch 783/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0066 - accuracy: 0.9988 - val_loss: 0.5827 - val_accuracy: 0.9836\n",
            "Epoch 784/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0031 - accuracy: 0.9995 - val_loss: 0.9065 - val_accuracy: 0.9836\n",
            "Epoch 785/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0058 - accuracy: 0.9989 - val_loss: 0.4708 - val_accuracy: 0.9836\n",
            "Epoch 786/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0081 - accuracy: 0.9983 - val_loss: 0.6439 - val_accuracy: 0.9818\n",
            "Epoch 787/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0044 - accuracy: 0.9991 - val_loss: 0.6236 - val_accuracy: 0.9836\n",
            "Epoch 788/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0281 - accuracy: 0.9954 - val_loss: 0.5060 - val_accuracy: 0.9769\n",
            "Epoch 789/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0270 - accuracy: 0.9965 - val_loss: 1.0715 - val_accuracy: 0.9800\n",
            "Epoch 790/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0057 - accuracy: 0.9988 - val_loss: 0.9440 - val_accuracy: 0.9818\n",
            "Epoch 791/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0078 - accuracy: 0.9983 - val_loss: 0.5278 - val_accuracy: 0.9794\n",
            "Epoch 792/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0241 - accuracy: 0.9982 - val_loss: 0.5492 - val_accuracy: 0.9812\n",
            "Epoch 793/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0054 - accuracy: 0.9988 - val_loss: 0.6803 - val_accuracy: 0.9836\n",
            "Epoch 794/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0069 - accuracy: 0.9992 - val_loss: 0.7001 - val_accuracy: 0.9848\n",
            "Epoch 795/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0156 - accuracy: 0.9986 - val_loss: 0.3934 - val_accuracy: 0.9812\n",
            "Epoch 796/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0065 - accuracy: 0.9991 - val_loss: 0.5473 - val_accuracy: 0.9830\n",
            "Epoch 797/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0033 - accuracy: 0.9995 - val_loss: 0.5150 - val_accuracy: 0.9830\n",
            "Epoch 798/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0165 - accuracy: 0.9988 - val_loss: 0.6221 - val_accuracy: 0.9836\n",
            "Epoch 799/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0052 - accuracy: 0.9988 - val_loss: 0.3878 - val_accuracy: 0.9818\n",
            "Epoch 800/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0044 - accuracy: 0.9991 - val_loss: 0.5077 - val_accuracy: 0.9830\n",
            "Epoch 801/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0068 - accuracy: 0.9989 - val_loss: 0.4039 - val_accuracy: 0.9824\n",
            "Epoch 802/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0050 - accuracy: 0.9991 - val_loss: 0.8490 - val_accuracy: 0.9763\n",
            "Epoch 803/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0039 - accuracy: 0.9994 - val_loss: 0.4032 - val_accuracy: 0.9848\n",
            "Epoch 804/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0047 - accuracy: 0.9991 - val_loss: 0.5212 - val_accuracy: 0.9836\n",
            "Epoch 805/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0035 - accuracy: 0.9994 - val_loss: 0.6044 - val_accuracy: 0.9830\n",
            "Epoch 806/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0052 - accuracy: 0.9988 - val_loss: 0.9388 - val_accuracy: 0.9818\n",
            "Epoch 807/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0125 - accuracy: 0.9992 - val_loss: 0.3491 - val_accuracy: 0.9812\n",
            "Epoch 808/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0055 - accuracy: 0.9991 - val_loss: 0.5602 - val_accuracy: 0.9818\n",
            "Epoch 809/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0061 - accuracy: 0.9989 - val_loss: 0.6008 - val_accuracy: 0.9818\n",
            "Epoch 810/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0052 - accuracy: 0.9991 - val_loss: 0.6192 - val_accuracy: 0.9818\n",
            "Epoch 811/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0040 - accuracy: 0.9992 - val_loss: 1.4489 - val_accuracy: 0.9782\n",
            "Epoch 812/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0065 - accuracy: 0.9991 - val_loss: 0.8131 - val_accuracy: 0.9794\n",
            "Epoch 813/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0054 - accuracy: 0.9991 - val_loss: 0.8470 - val_accuracy: 0.9818\n",
            "Epoch 814/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0053 - accuracy: 0.9991 - val_loss: 0.8080 - val_accuracy: 0.9824\n",
            "Epoch 815/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0040 - accuracy: 0.9992 - val_loss: 0.7996 - val_accuracy: 0.9794\n",
            "Epoch 816/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0092 - accuracy: 0.9982 - val_loss: 0.9014 - val_accuracy: 0.9848\n",
            "Epoch 817/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.6921 - val_accuracy: 0.9806\n",
            "Epoch 818/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0059 - accuracy: 0.9988 - val_loss: 1.0551 - val_accuracy: 0.9782\n",
            "Epoch 819/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0098 - accuracy: 0.9985 - val_loss: 0.6214 - val_accuracy: 0.9830\n",
            "Epoch 820/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0093 - accuracy: 0.9983 - val_loss: 0.5875 - val_accuracy: 0.9830\n",
            "Epoch 821/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0064 - accuracy: 0.9988 - val_loss: 0.6054 - val_accuracy: 0.9830\n",
            "Epoch 822/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0058 - accuracy: 0.9986 - val_loss: 1.0009 - val_accuracy: 0.9824\n",
            "Epoch 823/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0067 - accuracy: 0.9988 - val_loss: 0.7440 - val_accuracy: 0.9824\n",
            "Epoch 824/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0067 - accuracy: 0.9985 - val_loss: 0.6351 - val_accuracy: 0.9812\n",
            "Epoch 825/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0055 - accuracy: 0.9989 - val_loss: 0.8443 - val_accuracy: 0.9836\n",
            "Epoch 826/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0155 - accuracy: 0.9989 - val_loss: 0.8067 - val_accuracy: 0.9836\n",
            "Epoch 827/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0345 - accuracy: 0.9970 - val_loss: 0.7687 - val_accuracy: 0.9812\n",
            "Epoch 828/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0103 - accuracy: 0.9980 - val_loss: 0.5005 - val_accuracy: 0.9794\n",
            "Epoch 829/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0092 - accuracy: 0.9983 - val_loss: 0.4920 - val_accuracy: 0.9836\n",
            "Epoch 830/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0054 - accuracy: 0.9988 - val_loss: 0.6779 - val_accuracy: 0.9824\n",
            "Epoch 831/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 0.5246 - val_accuracy: 0.9812\n",
            "Epoch 832/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0037 - accuracy: 0.9994 - val_loss: 0.5619 - val_accuracy: 0.9824\n",
            "Epoch 833/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0076 - accuracy: 0.9986 - val_loss: 0.5181 - val_accuracy: 0.9800\n",
            "Epoch 834/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0099 - accuracy: 0.9980 - val_loss: 0.7669 - val_accuracy: 0.9818\n",
            "Epoch 835/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0065 - accuracy: 0.9986 - val_loss: 0.6414 - val_accuracy: 0.9842\n",
            "Epoch 836/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0045 - accuracy: 0.9992 - val_loss: 0.6734 - val_accuracy: 0.9842\n",
            "Epoch 837/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0052 - accuracy: 0.9994 - val_loss: 0.7011 - val_accuracy: 0.9848\n",
            "Epoch 838/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0059 - accuracy: 0.9989 - val_loss: 0.5623 - val_accuracy: 0.9867\n",
            "Epoch 839/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0042 - accuracy: 0.9992 - val_loss: 0.5857 - val_accuracy: 0.9842\n",
            "Epoch 840/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0047 - accuracy: 0.9991 - val_loss: 0.5581 - val_accuracy: 0.9842\n",
            "Epoch 841/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0068 - accuracy: 0.9989 - val_loss: 0.4150 - val_accuracy: 0.9836\n",
            "Epoch 842/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0075 - accuracy: 0.9985 - val_loss: 0.6875 - val_accuracy: 0.9788\n",
            "Epoch 843/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0095 - accuracy: 0.9980 - val_loss: 0.5182 - val_accuracy: 0.9836\n",
            "Epoch 844/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0182 - accuracy: 0.9976 - val_loss: 0.1985 - val_accuracy: 0.9806\n",
            "Epoch 845/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0045 - accuracy: 0.9992 - val_loss: 0.3527 - val_accuracy: 0.9854\n",
            "Epoch 846/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0055 - accuracy: 0.9989 - val_loss: 0.4280 - val_accuracy: 0.9848\n",
            "Epoch 847/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0092 - accuracy: 0.9994 - val_loss: 0.2706 - val_accuracy: 0.9806\n",
            "Epoch 848/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0130 - accuracy: 0.9971 - val_loss: 0.3657 - val_accuracy: 0.9824\n",
            "Epoch 849/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0067 - accuracy: 0.9986 - val_loss: 0.4868 - val_accuracy: 0.9830\n",
            "Epoch 850/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0095 - accuracy: 0.9983 - val_loss: 0.5456 - val_accuracy: 0.9824\n",
            "Epoch 851/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0189 - accuracy: 0.9977 - val_loss: 0.5569 - val_accuracy: 0.9800\n",
            "Epoch 852/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0221 - accuracy: 0.9967 - val_loss: 0.4625 - val_accuracy: 0.9824\n",
            "Epoch 853/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0093 - accuracy: 0.9982 - val_loss: 0.3007 - val_accuracy: 0.9836\n",
            "Epoch 854/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0092 - accuracy: 0.9985 - val_loss: 0.2676 - val_accuracy: 0.9824\n",
            "Epoch 855/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0075 - accuracy: 0.9986 - val_loss: 0.3141 - val_accuracy: 0.9830\n",
            "Epoch 856/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0049 - accuracy: 0.9991 - val_loss: 0.4304 - val_accuracy: 0.9842\n",
            "Epoch 857/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0053 - accuracy: 0.9989 - val_loss: 0.5865 - val_accuracy: 0.9842\n",
            "Epoch 858/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0056 - accuracy: 0.9991 - val_loss: 0.4483 - val_accuracy: 0.9812\n",
            "Epoch 859/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0085 - accuracy: 0.9982 - val_loss: 0.9449 - val_accuracy: 0.9800\n",
            "Epoch 860/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0074 - accuracy: 0.9989 - val_loss: 0.7370 - val_accuracy: 0.9769\n",
            "Epoch 861/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0082 - accuracy: 0.9986 - val_loss: 0.4528 - val_accuracy: 0.9800\n",
            "Epoch 862/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0107 - accuracy: 0.9977 - val_loss: 0.2541 - val_accuracy: 0.9812\n",
            "Epoch 863/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0058 - accuracy: 0.9986 - val_loss: 0.2787 - val_accuracy: 0.9830\n",
            "Epoch 864/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0045 - accuracy: 0.9991 - val_loss: 0.5676 - val_accuracy: 0.9830\n",
            "Epoch 865/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0053 - accuracy: 0.9991 - val_loss: 0.4710 - val_accuracy: 0.9830\n",
            "Epoch 866/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0052 - accuracy: 0.9991 - val_loss: 0.4109 - val_accuracy: 0.9788\n",
            "Epoch 867/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0084 - accuracy: 0.9982 - val_loss: 0.3251 - val_accuracy: 0.9830\n",
            "Epoch 868/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0028 - accuracy: 0.9995 - val_loss: 0.5473 - val_accuracy: 0.9836\n",
            "Epoch 869/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0060 - accuracy: 0.9988 - val_loss: 1.8249 - val_accuracy: 0.9678\n",
            "Epoch 870/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0034 - accuracy: 0.9994 - val_loss: 0.6066 - val_accuracy: 0.9854\n",
            "Epoch 871/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0047 - accuracy: 0.9991 - val_loss: 0.7862 - val_accuracy: 0.9836\n",
            "Epoch 872/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0022 - accuracy: 0.9997 - val_loss: 0.7946 - val_accuracy: 0.9830\n",
            "Epoch 873/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0385 - accuracy: 0.9986 - val_loss: 0.1995 - val_accuracy: 0.9818\n",
            "Epoch 874/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0179 - accuracy: 0.9965 - val_loss: 0.4414 - val_accuracy: 0.9830\n",
            "Epoch 875/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0097 - accuracy: 0.9982 - val_loss: 0.4629 - val_accuracy: 0.9824\n",
            "Epoch 876/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0109 - accuracy: 0.9982 - val_loss: 0.5852 - val_accuracy: 0.9824\n",
            "Epoch 877/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0063 - accuracy: 0.9988 - val_loss: 0.7460 - val_accuracy: 0.9830\n",
            "Epoch 878/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0073 - accuracy: 0.9988 - val_loss: 0.4756 - val_accuracy: 0.9842\n",
            "Epoch 879/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0095 - accuracy: 0.9988 - val_loss: 0.5150 - val_accuracy: 0.9842\n",
            "Epoch 880/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0080 - accuracy: 0.9988 - val_loss: 0.5236 - val_accuracy: 0.9824\n",
            "Epoch 881/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0116 - accuracy: 0.9988 - val_loss: 0.4497 - val_accuracy: 0.9830\n",
            "Epoch 882/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0046 - accuracy: 0.9991 - val_loss: 0.5391 - val_accuracy: 0.9854\n",
            "Epoch 883/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0044 - accuracy: 0.9992 - val_loss: 0.5826 - val_accuracy: 0.9854\n",
            "Epoch 884/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0029 - accuracy: 0.9995 - val_loss: 0.5825 - val_accuracy: 0.9848\n",
            "Epoch 885/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 0.6429 - val_accuracy: 0.9818\n",
            "Epoch 886/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0051 - accuracy: 0.9991 - val_loss: 0.6166 - val_accuracy: 0.9830\n",
            "Epoch 887/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0044 - accuracy: 0.9992 - val_loss: 0.6480 - val_accuracy: 0.9836\n",
            "Epoch 888/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0061 - accuracy: 0.9988 - val_loss: 0.6303 - val_accuracy: 0.9842\n",
            "Epoch 889/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0049 - accuracy: 0.9988 - val_loss: 0.6363 - val_accuracy: 0.9824\n",
            "Epoch 890/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0112 - accuracy: 0.9989 - val_loss: 0.6921 - val_accuracy: 0.9794\n",
            "Epoch 891/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0039 - accuracy: 0.9992 - val_loss: 0.4360 - val_accuracy: 0.9794\n",
            "Epoch 892/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0292 - accuracy: 0.9965 - val_loss: 0.6413 - val_accuracy: 0.9812\n",
            "Epoch 893/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0096 - accuracy: 0.9982 - val_loss: 0.5847 - val_accuracy: 0.9812\n",
            "Epoch 894/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0102 - accuracy: 0.9979 - val_loss: 0.3899 - val_accuracy: 0.9830\n",
            "Epoch 895/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0077 - accuracy: 0.9983 - val_loss: 0.4244 - val_accuracy: 0.9842\n",
            "Epoch 896/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0114 - accuracy: 0.9979 - val_loss: 0.4436 - val_accuracy: 0.9830\n",
            "Epoch 897/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0073 - accuracy: 0.9991 - val_loss: 0.3216 - val_accuracy: 0.9812\n",
            "Epoch 898/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0046 - accuracy: 0.9992 - val_loss: 0.4668 - val_accuracy: 0.9830\n",
            "Epoch 899/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0075 - accuracy: 0.9986 - val_loss: 0.5848 - val_accuracy: 0.9818\n",
            "Epoch 900/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0091 - accuracy: 0.9985 - val_loss: 0.4549 - val_accuracy: 0.9842\n",
            "Epoch 901/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0053 - accuracy: 0.9991 - val_loss: 0.4764 - val_accuracy: 0.9848\n",
            "Epoch 902/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0047 - accuracy: 0.9991 - val_loss: 0.3926 - val_accuracy: 0.9836\n",
            "Epoch 903/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0090 - accuracy: 0.9983 - val_loss: 0.2676 - val_accuracy: 0.9842\n",
            "Epoch 904/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0333 - accuracy: 0.9973 - val_loss: 0.8144 - val_accuracy: 0.9818\n",
            "Epoch 905/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0062 - accuracy: 0.9986 - val_loss: 0.6880 - val_accuracy: 0.9806\n",
            "Epoch 906/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0099 - accuracy: 0.9989 - val_loss: 0.6647 - val_accuracy: 0.9818\n",
            "Epoch 907/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0036 - accuracy: 0.9994 - val_loss: 0.8003 - val_accuracy: 0.9818\n",
            "Epoch 908/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0049 - accuracy: 0.9991 - val_loss: 0.7327 - val_accuracy: 0.9818\n",
            "Epoch 909/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0050 - accuracy: 0.9991 - val_loss: 1.0549 - val_accuracy: 0.9818\n",
            "Epoch 910/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0104 - accuracy: 0.9985 - val_loss: 0.6110 - val_accuracy: 0.9824\n",
            "Epoch 911/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0054 - accuracy: 0.9989 - val_loss: 0.7060 - val_accuracy: 0.9806\n",
            "Epoch 912/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0078 - accuracy: 0.9986 - val_loss: 0.5582 - val_accuracy: 0.9818\n",
            "Epoch 913/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0073 - accuracy: 0.9988 - val_loss: 0.6421 - val_accuracy: 0.9800\n",
            "Epoch 914/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0092 - accuracy: 0.9985 - val_loss: 0.4512 - val_accuracy: 0.9824\n",
            "Epoch 915/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0135 - accuracy: 0.9976 - val_loss: 0.3258 - val_accuracy: 0.9836\n",
            "Epoch 916/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0050 - accuracy: 0.9991 - val_loss: 0.9263 - val_accuracy: 0.9806\n",
            "Epoch 917/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0063 - accuracy: 0.9989 - val_loss: 0.5864 - val_accuracy: 0.9818\n",
            "Epoch 918/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0051 - accuracy: 0.9991 - val_loss: 0.5511 - val_accuracy: 0.9830\n",
            "Epoch 919/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0051 - accuracy: 0.9991 - val_loss: 0.6846 - val_accuracy: 0.9824\n",
            "Epoch 920/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0035 - accuracy: 0.9992 - val_loss: 0.9832 - val_accuracy: 0.9812\n",
            "Epoch 921/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0082 - accuracy: 0.9991 - val_loss: 0.6311 - val_accuracy: 0.9830\n",
            "Epoch 922/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0109 - accuracy: 0.9985 - val_loss: 0.9314 - val_accuracy: 0.9800\n",
            "Epoch 923/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0052 - accuracy: 0.9989 - val_loss: 0.6381 - val_accuracy: 0.9818\n",
            "Epoch 924/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0149 - accuracy: 0.9988 - val_loss: 0.5045 - val_accuracy: 0.9812\n",
            "Epoch 925/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0036 - accuracy: 0.9994 - val_loss: 0.9045 - val_accuracy: 0.9818\n",
            "Epoch 926/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0064 - accuracy: 0.9991 - val_loss: 0.5803 - val_accuracy: 0.9824\n",
            "Epoch 927/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0085 - accuracy: 0.9985 - val_loss: 0.5436 - val_accuracy: 0.9830\n",
            "Epoch 928/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0081 - accuracy: 0.9988 - val_loss: 0.4648 - val_accuracy: 0.9854\n",
            "Epoch 929/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0068 - accuracy: 0.9986 - val_loss: 0.3114 - val_accuracy: 0.9830\n",
            "Epoch 930/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0113 - accuracy: 0.9977 - val_loss: 0.4732 - val_accuracy: 0.9818\n",
            "Epoch 931/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0105 - accuracy: 0.9983 - val_loss: 0.5454 - val_accuracy: 0.9824\n",
            "Epoch 932/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0054 - accuracy: 0.9991 - val_loss: 0.9283 - val_accuracy: 0.9794\n",
            "Epoch 933/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0061 - accuracy: 0.9989 - val_loss: 0.8317 - val_accuracy: 0.9806\n",
            "Epoch 934/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.6863 - val_accuracy: 0.9818\n",
            "Epoch 935/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0039 - accuracy: 0.9994 - val_loss: 0.6857 - val_accuracy: 0.9824\n",
            "Epoch 936/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0048 - accuracy: 0.9991 - val_loss: 0.3314 - val_accuracy: 0.9806\n",
            "Epoch 937/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0036 - accuracy: 0.9994 - val_loss: 0.5523 - val_accuracy: 0.9818\n",
            "Epoch 938/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0058 - accuracy: 0.9988 - val_loss: 0.4432 - val_accuracy: 0.9818\n",
            "Epoch 939/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0062 - accuracy: 0.9988 - val_loss: 0.7421 - val_accuracy: 0.9830\n",
            "Epoch 940/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0023 - accuracy: 0.9997 - val_loss: 1.1206 - val_accuracy: 0.9812\n",
            "Epoch 941/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0130 - accuracy: 0.9982 - val_loss: 0.2843 - val_accuracy: 0.9824\n",
            "Epoch 942/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0125 - accuracy: 0.9977 - val_loss: 0.6528 - val_accuracy: 0.9812\n",
            "Epoch 943/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0052 - accuracy: 0.9991 - val_loss: 0.6614 - val_accuracy: 0.9818\n",
            "Epoch 944/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0197 - accuracy: 0.9973 - val_loss: 0.5497 - val_accuracy: 0.9830\n",
            "Epoch 945/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0073 - accuracy: 0.9985 - val_loss: 0.6748 - val_accuracy: 0.9775\n",
            "Epoch 946/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0052 - accuracy: 0.9989 - val_loss: 0.7624 - val_accuracy: 0.9818\n",
            "Epoch 947/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0055 - accuracy: 0.9991 - val_loss: 0.3711 - val_accuracy: 0.9873\n",
            "Epoch 948/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0039 - accuracy: 0.9994 - val_loss: 0.3946 - val_accuracy: 0.9873\n",
            "Epoch 949/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0018 - accuracy: 0.9998 - val_loss: 0.4666 - val_accuracy: 0.9867\n",
            "Epoch 950/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0040 - accuracy: 0.9991 - val_loss: 0.5602 - val_accuracy: 0.9830\n",
            "Epoch 951/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0031 - accuracy: 0.9995 - val_loss: 0.4551 - val_accuracy: 0.9854\n",
            "Epoch 952/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.4693 - val_accuracy: 0.9860\n",
            "Epoch 953/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0031 - accuracy: 0.9995 - val_loss: 0.6664 - val_accuracy: 0.9848\n",
            "Epoch 954/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0069 - accuracy: 0.9989 - val_loss: 0.5337 - val_accuracy: 0.9867\n",
            "Epoch 955/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0038 - accuracy: 0.9994 - val_loss: 0.5402 - val_accuracy: 0.9860\n",
            "Epoch 956/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0044 - accuracy: 0.9992 - val_loss: 0.3408 - val_accuracy: 0.9830\n",
            "Epoch 957/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0045 - accuracy: 0.9992 - val_loss: 0.3924 - val_accuracy: 0.9854\n",
            "Epoch 958/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0043 - accuracy: 0.9992 - val_loss: 0.3296 - val_accuracy: 0.9848\n",
            "Epoch 959/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.7833 - val_accuracy: 0.9812\n",
            "Epoch 960/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0084 - accuracy: 0.9986 - val_loss: 0.8323 - val_accuracy: 0.9842\n",
            "Epoch 961/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0054 - accuracy: 0.9991 - val_loss: 0.5269 - val_accuracy: 0.9836\n",
            "Epoch 962/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0037 - accuracy: 0.9994 - val_loss: 0.5264 - val_accuracy: 0.9848\n",
            "Epoch 963/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0072 - accuracy: 0.9991 - val_loss: 0.2287 - val_accuracy: 0.9830\n",
            "Epoch 964/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0216 - accuracy: 0.9971 - val_loss: 0.5504 - val_accuracy: 0.9812\n",
            "Epoch 965/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0056 - accuracy: 0.9991 - val_loss: 0.3937 - val_accuracy: 0.9848\n",
            "Epoch 966/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0047 - accuracy: 0.9991 - val_loss: 0.3139 - val_accuracy: 0.9854\n",
            "Epoch 967/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0039 - accuracy: 0.9992 - val_loss: 0.3919 - val_accuracy: 0.9842\n",
            "Epoch 968/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0029 - accuracy: 0.9995 - val_loss: 0.3806 - val_accuracy: 0.9848\n",
            "Epoch 969/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0108 - accuracy: 0.9991 - val_loss: 0.3660 - val_accuracy: 0.9854\n",
            "Epoch 970/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0040 - accuracy: 0.9992 - val_loss: 0.5780 - val_accuracy: 0.9848\n",
            "Epoch 971/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0078 - accuracy: 0.9989 - val_loss: 0.4814 - val_accuracy: 0.9848\n",
            "Epoch 972/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0045 - accuracy: 0.9992 - val_loss: 0.5459 - val_accuracy: 0.9848\n",
            "Epoch 973/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 0.5682 - val_accuracy: 0.9848\n",
            "Epoch 974/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0039 - accuracy: 0.9994 - val_loss: 0.4683 - val_accuracy: 0.9854\n",
            "Epoch 975/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0073 - accuracy: 0.9985 - val_loss: 0.7041 - val_accuracy: 0.9830\n",
            "Epoch 976/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0055 - accuracy: 0.9992 - val_loss: 0.8181 - val_accuracy: 0.9836\n",
            "Epoch 977/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0039 - accuracy: 0.9992 - val_loss: 0.4972 - val_accuracy: 0.9860\n",
            "Epoch 978/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0092 - accuracy: 0.9991 - val_loss: 0.3826 - val_accuracy: 0.9842\n",
            "Epoch 979/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0078 - accuracy: 0.9983 - val_loss: 0.5903 - val_accuracy: 0.9824\n",
            "Epoch 980/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0031 - accuracy: 0.9995 - val_loss: 0.5096 - val_accuracy: 0.9836\n",
            "Epoch 981/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0038 - accuracy: 0.9992 - val_loss: 0.8567 - val_accuracy: 0.9848\n",
            "Epoch 982/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0313 - accuracy: 0.9982 - val_loss: 0.1724 - val_accuracy: 0.9782\n",
            "Epoch 983/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0055 - accuracy: 0.9988 - val_loss: 0.2848 - val_accuracy: 0.9794\n",
            "Epoch 984/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0059 - accuracy: 0.9991 - val_loss: 1.1603 - val_accuracy: 0.9751\n",
            "Epoch 985/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0031 - accuracy: 0.9995 - val_loss: 0.6760 - val_accuracy: 0.9848\n",
            "Epoch 986/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0038 - accuracy: 0.9994 - val_loss: 0.6664 - val_accuracy: 0.9848\n",
            "Epoch 987/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0031 - accuracy: 0.9995 - val_loss: 0.4938 - val_accuracy: 0.9824\n",
            "Epoch 988/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0047 - accuracy: 0.9992 - val_loss: 0.4026 - val_accuracy: 0.9818\n",
            "Epoch 989/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0077 - accuracy: 0.9988 - val_loss: 0.3949 - val_accuracy: 0.9824\n",
            "Epoch 990/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0111 - accuracy: 0.9986 - val_loss: 0.8831 - val_accuracy: 0.9812\n",
            "Epoch 991/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0084 - accuracy: 0.9983 - val_loss: 0.6323 - val_accuracy: 0.9824\n",
            "Epoch 992/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0091 - accuracy: 0.9985 - val_loss: 1.2812 - val_accuracy: 0.9830\n",
            "Epoch 993/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0098 - accuracy: 0.9989 - val_loss: 0.7853 - val_accuracy: 0.9860\n",
            "Epoch 994/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0046 - accuracy: 0.9992 - val_loss: 0.6729 - val_accuracy: 0.9848\n",
            "Epoch 995/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0092 - accuracy: 0.9983 - val_loss: 0.8675 - val_accuracy: 0.9806\n",
            "Epoch 996/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0042 - accuracy: 0.9991 - val_loss: 1.0292 - val_accuracy: 0.9812\n",
            "Epoch 997/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0037 - accuracy: 0.9992 - val_loss: 0.7296 - val_accuracy: 0.9848\n",
            "Epoch 998/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0038 - accuracy: 0.9994 - val_loss: 0.8400 - val_accuracy: 0.9830\n",
            "Epoch 999/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0065 - accuracy: 0.9988 - val_loss: 0.4370 - val_accuracy: 0.9842\n",
            "Epoch 1000/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0104 - accuracy: 0.9985 - val_loss: 0.5147 - val_accuracy: 0.9836\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1200x400 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "26/26 [==============================] - 4s 54ms/step - loss: 9.4076 - accuracy: 0.9002 - val_loss: 9.6019 - val_accuracy: 0.9038\n",
            "Epoch 2/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 1.4898 - accuracy: 0.9399 - val_loss: 7.7223 - val_accuracy: 0.8990\n",
            "Epoch 3/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.8048 - accuracy: 0.9459 - val_loss: 1.5049 - val_accuracy: 0.8942\n",
            "Epoch 4/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.3583 - accuracy: 0.9591 - val_loss: 1.1181 - val_accuracy: 0.8413\n",
            "Epoch 5/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.2848 - accuracy: 0.9579 - val_loss: 4.1791 - val_accuracy: 0.7212\n",
            "Epoch 6/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.4733 - accuracy: 0.9760 - val_loss: 1.9304 - val_accuracy: 0.7404\n",
            "Epoch 7/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.1033 - accuracy: 0.9579 - val_loss: 0.5428 - val_accuracy: 0.8654\n",
            "Epoch 8/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0702 - accuracy: 0.9675 - val_loss: 0.5411 - val_accuracy: 0.9038\n",
            "Epoch 9/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0751 - accuracy: 0.9639 - val_loss: 0.0939 - val_accuracy: 0.9663\n",
            "Epoch 10/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0763 - accuracy: 0.9675 - val_loss: 0.0309 - val_accuracy: 0.9904\n",
            "Epoch 11/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0354 - accuracy: 0.9748 - val_loss: 0.0842 - val_accuracy: 0.9663\n",
            "Epoch 12/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0437 - accuracy: 0.9772 - val_loss: 0.2349 - val_accuracy: 0.9567\n",
            "Epoch 13/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0469 - accuracy: 0.9784 - val_loss: 0.1155 - val_accuracy: 0.9712\n",
            "Epoch 14/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0460 - accuracy: 0.9736 - val_loss: 0.0598 - val_accuracy: 0.9760\n",
            "Epoch 15/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0359 - accuracy: 0.9772 - val_loss: 0.0176 - val_accuracy: 0.9952\n",
            "Epoch 16/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0312 - accuracy: 0.9916 - val_loss: 0.0087 - val_accuracy: 1.0000\n",
            "Epoch 17/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0333 - accuracy: 0.9916 - val_loss: 0.0095 - val_accuracy: 0.9952\n",
            "Epoch 18/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0450 - accuracy: 0.9868 - val_loss: 0.2270 - val_accuracy: 0.9567\n",
            "Epoch 19/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0532 - accuracy: 0.9772 - val_loss: 0.0378 - val_accuracy: 0.9904\n",
            "Epoch 20/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0484 - accuracy: 0.9760 - val_loss: 0.0096 - val_accuracy: 1.0000\n",
            "Epoch 21/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0400 - accuracy: 0.9712 - val_loss: 0.0098 - val_accuracy: 0.9904\n",
            "Epoch 22/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0831 - accuracy: 0.9844 - val_loss: 0.2418 - val_accuracy: 0.9279\n",
            "Epoch 23/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0353 - accuracy: 0.9904 - val_loss: 0.1505 - val_accuracy: 0.9663\n",
            "Epoch 24/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.4444 - accuracy: 0.9712 - val_loss: 13.5542 - val_accuracy: 0.9038\n",
            "Epoch 25/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.4973 - accuracy: 0.9531 - val_loss: 2.9552 - val_accuracy: 0.9087\n",
            "Epoch 26/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.1425 - accuracy: 0.9579 - val_loss: 2.6730 - val_accuracy: 0.9279\n",
            "Epoch 27/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.1360 - accuracy: 0.9579 - val_loss: 0.3986 - val_accuracy: 0.9567\n",
            "Epoch 28/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 2.0818 - accuracy: 0.9279 - val_loss: 3.1836 - val_accuracy: 0.9712\n",
            "Epoch 29/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.8151 - accuracy: 0.9411 - val_loss: 25.2182 - val_accuracy: 0.9038\n",
            "Epoch 30/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.2490 - accuracy: 0.9495 - val_loss: 0.6371 - val_accuracy: 0.9567\n",
            "Epoch 31/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.1799 - accuracy: 0.9519 - val_loss: 3.1718 - val_accuracy: 0.9279\n",
            "Epoch 32/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.1092 - accuracy: 0.9519 - val_loss: 2.0382 - val_accuracy: 0.9471\n",
            "Epoch 33/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.1243 - accuracy: 0.9471 - val_loss: 1.7581 - val_accuracy: 0.9183\n",
            "Epoch 34/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0924 - accuracy: 0.9375 - val_loss: 1.2573 - val_accuracy: 0.9471\n",
            "Epoch 35/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.1092 - accuracy: 0.9159 - val_loss: 1.5548 - val_accuracy: 0.9327\n",
            "Epoch 36/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0804 - accuracy: 0.9603 - val_loss: 0.2880 - val_accuracy: 0.9760\n",
            "Epoch 37/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0632 - accuracy: 0.9675 - val_loss: 0.0186 - val_accuracy: 0.9856\n",
            "Epoch 38/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0585 - accuracy: 0.9639 - val_loss: 0.0207 - val_accuracy: 0.9952\n",
            "Epoch 39/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0625 - accuracy: 0.9615 - val_loss: 0.0161 - val_accuracy: 0.9904\n",
            "Epoch 40/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0554 - accuracy: 0.9675 - val_loss: 0.0184 - val_accuracy: 0.9856\n",
            "Epoch 41/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0559 - accuracy: 0.9796 - val_loss: 0.0837 - val_accuracy: 0.9856\n",
            "Epoch 42/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0517 - accuracy: 0.9832 - val_loss: 0.0113 - val_accuracy: 0.9904\n",
            "Epoch 43/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0436 - accuracy: 0.9832 - val_loss: 0.0295 - val_accuracy: 0.9856\n",
            "Epoch 44/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0531 - accuracy: 0.9820 - val_loss: 0.0275 - val_accuracy: 0.9904\n",
            "Epoch 45/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0473 - accuracy: 0.9796 - val_loss: 0.0056 - val_accuracy: 0.9952\n",
            "Epoch 46/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0399 - accuracy: 0.9784 - val_loss: 0.2053 - val_accuracy: 0.9567\n",
            "Epoch 47/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0920 - accuracy: 0.9844 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
            "Epoch 48/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0287 - accuracy: 0.9892 - val_loss: 0.0607 - val_accuracy: 0.9712\n",
            "Epoch 49/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0283 - accuracy: 0.9856 - val_loss: 0.0435 - val_accuracy: 0.9712\n",
            "Epoch 50/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0246 - accuracy: 0.9856 - val_loss: 0.1225 - val_accuracy: 0.9856\n",
            "Epoch 51/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0351 - accuracy: 0.9892 - val_loss: 0.8844 - val_accuracy: 0.9375\n",
            "Epoch 52/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0629 - accuracy: 0.9820 - val_loss: 0.0331 - val_accuracy: 0.9952\n",
            "Epoch 53/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0593 - accuracy: 0.9820 - val_loss: 0.1122 - val_accuracy: 0.9760\n",
            "Epoch 54/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.1409 - accuracy: 0.9820 - val_loss: 16.5651 - val_accuracy: 0.6827\n",
            "Epoch 55/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0572 - accuracy: 0.9868 - val_loss: 6.4359 - val_accuracy: 0.7933\n",
            "Epoch 56/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0279 - accuracy: 0.9832 - val_loss: 0.2348 - val_accuracy: 0.9760\n",
            "Epoch 57/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0481 - accuracy: 0.9880 - val_loss: 0.2139 - val_accuracy: 0.9663\n",
            "Epoch 58/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0374 - accuracy: 0.9880 - val_loss: 0.2215 - val_accuracy: 0.9663\n",
            "Epoch 59/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0772 - accuracy: 0.9880 - val_loss: 0.4641 - val_accuracy: 0.9615\n",
            "Epoch 60/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0197 - accuracy: 0.9964 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
            "Epoch 61/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0486 - accuracy: 0.9928 - val_loss: 0.0108 - val_accuracy: 0.9952\n",
            "Epoch 62/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0364 - accuracy: 0.9868 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
            "Epoch 63/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0410 - accuracy: 0.9832 - val_loss: 0.0246 - val_accuracy: 0.9952\n",
            "Epoch 64/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0442 - accuracy: 0.9820 - val_loss: 0.0307 - val_accuracy: 0.9904\n",
            "Epoch 65/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0266 - accuracy: 0.9856 - val_loss: 1.0963 - val_accuracy: 0.9279\n",
            "Epoch 66/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0476 - accuracy: 0.9796 - val_loss: 0.1784 - val_accuracy: 0.9856\n",
            "Epoch 67/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0279 - accuracy: 0.9844 - val_loss: 9.7483e-04 - val_accuracy: 1.0000\n",
            "Epoch 68/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0262 - accuracy: 0.9868 - val_loss: 2.0252e-04 - val_accuracy: 1.0000\n",
            "Epoch 69/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0590 - accuracy: 0.9892 - val_loss: 0.4067 - val_accuracy: 0.9760\n",
            "Epoch 70/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0142 - accuracy: 0.9916 - val_loss: 0.6228 - val_accuracy: 0.9615\n",
            "Epoch 71/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0240 - accuracy: 0.9844 - val_loss: 0.2448 - val_accuracy: 0.9904\n",
            "Epoch 72/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0214 - accuracy: 0.9832 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
            "Epoch 73/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0168 - accuracy: 0.9904 - val_loss: 5.5198e-06 - val_accuracy: 1.0000\n",
            "Epoch 74/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0186 - accuracy: 0.9820 - val_loss: 3.2910e-07 - val_accuracy: 1.0000\n",
            "Epoch 75/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0309 - accuracy: 0.9832 - val_loss: 3.5520e-05 - val_accuracy: 1.0000\n",
            "Epoch 76/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0212 - accuracy: 0.9856 - val_loss: 9.3213e-04 - val_accuracy: 1.0000\n",
            "Epoch 77/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.1213 - accuracy: 0.9820 - val_loss: 151.8379 - val_accuracy: 0.9038\n",
            "Epoch 78/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.2348 - accuracy: 0.9603 - val_loss: 11.8614 - val_accuracy: 0.8846\n",
            "Epoch 79/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.1919 - accuracy: 0.9483 - val_loss: 4.5998 - val_accuracy: 0.9038\n",
            "Epoch 80/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.2383 - accuracy: 0.9639 - val_loss: 0.0883 - val_accuracy: 0.9712\n",
            "Epoch 81/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.1720 - accuracy: 0.9663 - val_loss: 0.2258 - val_accuracy: 0.9423\n",
            "Epoch 82/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.1560 - accuracy: 0.9736 - val_loss: 1.1010 - val_accuracy: 0.9087\n",
            "Epoch 83/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0892 - accuracy: 0.9784 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 84/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0626 - accuracy: 0.9675 - val_loss: 0.0222 - val_accuracy: 0.9952\n",
            "Epoch 85/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0546 - accuracy: 0.9543 - val_loss: 0.0335 - val_accuracy: 0.9856\n",
            "Epoch 86/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0713 - accuracy: 0.9567 - val_loss: 9.9011e-04 - val_accuracy: 1.0000\n",
            "Epoch 87/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0492 - accuracy: 0.9784 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 88/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0351 - accuracy: 0.9772 - val_loss: 0.0123 - val_accuracy: 1.0000\n",
            "Epoch 89/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0586 - accuracy: 0.9736 - val_loss: 0.0369 - val_accuracy: 0.9808\n",
            "Epoch 90/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.1292 - accuracy: 0.9712 - val_loss: 0.0143 - val_accuracy: 0.9904\n",
            "Epoch 91/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0313 - accuracy: 0.9760 - val_loss: 0.0055 - val_accuracy: 0.9952\n",
            "Epoch 92/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0207 - accuracy: 0.9772 - val_loss: 0.0044 - val_accuracy: 0.9952\n",
            "Epoch 93/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0275 - accuracy: 0.9832 - val_loss: 1.2952e-04 - val_accuracy: 1.0000\n",
            "Epoch 94/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0329 - accuracy: 0.9880 - val_loss: 5.1870e-04 - val_accuracy: 1.0000\n",
            "Epoch 95/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0283 - accuracy: 0.9856 - val_loss: 3.6898 - val_accuracy: 0.9038\n",
            "Epoch 96/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.2046 - accuracy: 0.9760 - val_loss: 4.4788 - val_accuracy: 0.9135\n",
            "Epoch 97/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.2253 - accuracy: 0.9784 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 98/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 1.0078 - accuracy: 0.9724 - val_loss: 0.2968 - val_accuracy: 0.9712\n",
            "Epoch 99/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.4795 - accuracy: 0.9724 - val_loss: 0.0639 - val_accuracy: 0.9904\n",
            "Epoch 100/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.3789 - accuracy: 0.9700 - val_loss: 0.5283 - val_accuracy: 0.9615\n",
            "Epoch 101/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0657 - accuracy: 0.9856 - val_loss: 0.2326 - val_accuracy: 0.9856\n",
            "Epoch 102/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0570 - accuracy: 0.9760 - val_loss: 0.1749 - val_accuracy: 0.9760\n",
            "Epoch 103/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0408 - accuracy: 0.9796 - val_loss: 0.1089 - val_accuracy: 0.9904\n",
            "Epoch 104/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0529 - accuracy: 0.9760 - val_loss: 0.0917 - val_accuracy: 0.9904\n",
            "Epoch 105/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0547 - accuracy: 0.9748 - val_loss: 0.0104 - val_accuracy: 0.9952\n",
            "Epoch 106/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0298 - accuracy: 0.9820 - val_loss: 0.0046 - val_accuracy: 0.9952\n",
            "Epoch 107/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0305 - accuracy: 0.9760 - val_loss: 3.8751e-04 - val_accuracy: 1.0000\n",
            "Epoch 108/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0519 - accuracy: 0.9784 - val_loss: 0.0072 - val_accuracy: 0.9952\n",
            "Epoch 109/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0452 - accuracy: 0.9808 - val_loss: 0.0079 - val_accuracy: 0.9952\n",
            "Epoch 110/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0234 - accuracy: 0.9892 - val_loss: 0.0068 - val_accuracy: 0.9952\n",
            "Epoch 111/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0214 - accuracy: 0.9940 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
            "Epoch 112/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0237 - accuracy: 0.9844 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
            "Epoch 113/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0437 - accuracy: 0.9868 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
            "Epoch 114/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0288 - accuracy: 0.9784 - val_loss: 2.5255e-04 - val_accuracy: 1.0000\n",
            "Epoch 115/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0492 - accuracy: 0.9940 - val_loss: 0.1851 - val_accuracy: 0.9712\n",
            "Epoch 116/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0262 - accuracy: 0.9892 - val_loss: 0.0473 - val_accuracy: 0.9760\n",
            "Epoch 117/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0230 - accuracy: 0.9880 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 118/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0120 - accuracy: 0.9904 - val_loss: 6.0035e-04 - val_accuracy: 1.0000\n",
            "Epoch 119/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0148 - accuracy: 0.9940 - val_loss: 3.9959e-04 - val_accuracy: 1.0000\n",
            "Epoch 120/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0254 - accuracy: 0.9940 - val_loss: 1.2840e-04 - val_accuracy: 1.0000\n",
            "Epoch 121/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0134 - accuracy: 0.9940 - val_loss: 4.3311e-05 - val_accuracy: 1.0000\n",
            "Epoch 122/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0167 - accuracy: 0.9940 - val_loss: 1.3364e-05 - val_accuracy: 1.0000\n",
            "Epoch 123/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0184 - accuracy: 0.9892 - val_loss: 3.0918e-06 - val_accuracy: 1.0000\n",
            "Epoch 124/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0220 - accuracy: 0.9892 - val_loss: 5.0778 - val_accuracy: 0.9135\n",
            "Epoch 125/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.1368 - accuracy: 0.9820 - val_loss: 0.6410 - val_accuracy: 0.9856\n",
            "Epoch 126/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0184 - accuracy: 0.9928 - val_loss: 0.5627 - val_accuracy: 0.9856\n",
            "Epoch 127/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0062 - accuracy: 0.9952 - val_loss: 0.1913 - val_accuracy: 0.9952\n",
            "Epoch 128/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0781 - accuracy: 0.9916 - val_loss: 0.0605 - val_accuracy: 0.9904\n",
            "Epoch 129/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.1014 - accuracy: 0.9844 - val_loss: 0.0338 - val_accuracy: 0.9952\n",
            "Epoch 130/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0274 - accuracy: 0.9784 - val_loss: 0.0064 - val_accuracy: 0.9952\n",
            "Epoch 131/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.1841 - accuracy: 0.9880 - val_loss: 0.0101 - val_accuracy: 0.9952\n",
            "Epoch 132/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0249 - accuracy: 0.9928 - val_loss: 0.0254 - val_accuracy: 0.9952\n",
            "Epoch 133/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0276 - accuracy: 0.9940 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 134/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0083 - accuracy: 0.9952 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 135/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0101 - accuracy: 0.9904 - val_loss: 7.0777e-04 - val_accuracy: 1.0000\n",
            "Epoch 136/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0112 - accuracy: 0.9904 - val_loss: 2.3806e-04 - val_accuracy: 1.0000\n",
            "Epoch 137/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0096 - accuracy: 0.9904 - val_loss: 8.7470e-05 - val_accuracy: 1.0000\n",
            "Epoch 138/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0054 - accuracy: 0.9964 - val_loss: 3.0074e-05 - val_accuracy: 1.0000\n",
            "Epoch 139/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0100 - accuracy: 0.9928 - val_loss: 5.2715e-06 - val_accuracy: 1.0000\n",
            "Epoch 140/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0055 - accuracy: 0.9952 - val_loss: 2.5193e-06 - val_accuracy: 1.0000\n",
            "Epoch 141/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0079 - accuracy: 0.9964 - val_loss: 2.6281e-06 - val_accuracy: 1.0000\n",
            "Epoch 142/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0087 - accuracy: 0.9952 - val_loss: 1.2208e-06 - val_accuracy: 1.0000\n",
            "Epoch 143/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0056 - accuracy: 0.9952 - val_loss: 1.6230e-07 - val_accuracy: 1.0000\n",
            "Epoch 144/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0062 - accuracy: 0.9976 - val_loss: 4.8753e-09 - val_accuracy: 1.0000\n",
            "Epoch 145/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0122 - accuracy: 0.9940 - val_loss: 9.3494e-09 - val_accuracy: 1.0000\n",
            "Epoch 146/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0067 - accuracy: 0.9940 - val_loss: 1.8720e-08 - val_accuracy: 1.0000\n",
            "Epoch 147/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0076 - accuracy: 0.9940 - val_loss: 4.9755e-09 - val_accuracy: 1.0000\n",
            "Epoch 148/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0539 - accuracy: 0.9952 - val_loss: 2.7474e-05 - val_accuracy: 1.0000\n",
            "Epoch 149/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0140 - accuracy: 0.9904 - val_loss: 3.5516e-06 - val_accuracy: 1.0000\n",
            "Epoch 150/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0122 - accuracy: 0.9952 - val_loss: 1.1535e-05 - val_accuracy: 1.0000\n",
            "Epoch 151/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0098 - accuracy: 0.9952 - val_loss: 6.1867e-07 - val_accuracy: 1.0000\n",
            "Epoch 152/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0064 - accuracy: 0.9964 - val_loss: 2.4593e-06 - val_accuracy: 1.0000\n",
            "Epoch 153/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0168 - accuracy: 0.9928 - val_loss: 1.1696e-07 - val_accuracy: 1.0000\n",
            "Epoch 154/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0055 - accuracy: 0.9964 - val_loss: 6.7767e-08 - val_accuracy: 1.0000\n",
            "Epoch 155/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0086 - accuracy: 0.9916 - val_loss: 7.1681e-08 - val_accuracy: 1.0000\n",
            "Epoch 156/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0277 - accuracy: 0.9892 - val_loss: 4.3338e-12 - val_accuracy: 1.0000\n",
            "Epoch 157/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0371 - accuracy: 0.9940 - val_loss: 1.5766e-05 - val_accuracy: 1.0000\n",
            "Epoch 158/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0098 - accuracy: 0.9940 - val_loss: 1.4158e-06 - val_accuracy: 1.0000\n",
            "Epoch 159/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0244 - accuracy: 0.9856 - val_loss: 7.9982e-09 - val_accuracy: 1.0000\n",
            "Epoch 160/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0088 - accuracy: 0.9904 - val_loss: 9.3025e-09 - val_accuracy: 1.0000\n",
            "Epoch 161/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0212 - accuracy: 0.9916 - val_loss: 0.0036 - val_accuracy: 0.9952\n",
            "Epoch 162/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0096 - accuracy: 0.9940 - val_loss: 0.0214 - val_accuracy: 0.9904\n",
            "Epoch 163/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0107 - accuracy: 0.9904 - val_loss: 2.4426e-06 - val_accuracy: 1.0000\n",
            "Epoch 164/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.1231 - accuracy: 0.9832 - val_loss: 2.1258e-04 - val_accuracy: 1.0000\n",
            "Epoch 165/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0250 - accuracy: 0.9904 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
            "Epoch 166/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0705 - accuracy: 0.9952 - val_loss: 2.7334e-04 - val_accuracy: 1.0000\n",
            "Epoch 167/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0177 - accuracy: 0.9964 - val_loss: 5.1304e-04 - val_accuracy: 1.0000\n",
            "Epoch 168/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0188 - accuracy: 0.9904 - val_loss: 1.0731e-04 - val_accuracy: 1.0000\n",
            "Epoch 169/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0124 - accuracy: 0.9892 - val_loss: 1.1995e-05 - val_accuracy: 1.0000\n",
            "Epoch 170/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0163 - accuracy: 0.9916 - val_loss: 9.4937e-07 - val_accuracy: 1.0000\n",
            "Epoch 171/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0092 - accuracy: 0.9940 - val_loss: 5.5682e-05 - val_accuracy: 1.0000\n",
            "Epoch 172/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0113 - accuracy: 0.9928 - val_loss: 8.2360e-05 - val_accuracy: 1.0000\n",
            "Epoch 173/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0131 - accuracy: 0.9892 - val_loss: 2.1737e-09 - val_accuracy: 1.0000\n",
            "Epoch 174/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0106 - accuracy: 0.9928 - val_loss: 3.9620e-08 - val_accuracy: 1.0000\n",
            "Epoch 175/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0102 - accuracy: 0.9904 - val_loss: 4.4582e-08 - val_accuracy: 1.0000\n",
            "Epoch 176/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0103 - accuracy: 0.9940 - val_loss: 1.4379e-08 - val_accuracy: 1.0000\n",
            "Epoch 177/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0054 - accuracy: 0.9928 - val_loss: 6.8953e-09 - val_accuracy: 1.0000\n",
            "Epoch 178/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0312 - accuracy: 0.9916 - val_loss: 2.3613e-09 - val_accuracy: 1.0000\n",
            "Epoch 179/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0067 - accuracy: 0.9964 - val_loss: 7.6761e-09 - val_accuracy: 1.0000\n",
            "Epoch 180/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0184 - accuracy: 0.9904 - val_loss: 2.7715e-05 - val_accuracy: 1.0000\n",
            "Epoch 181/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0104 - accuracy: 0.9916 - val_loss: 3.8822e-06 - val_accuracy: 1.0000\n",
            "Epoch 182/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0052 - accuracy: 0.9940 - val_loss: 1.9785e-07 - val_accuracy: 1.0000\n",
            "Epoch 183/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0065 - accuracy: 0.9952 - val_loss: 6.7588e-08 - val_accuracy: 1.0000\n",
            "Epoch 184/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0143 - accuracy: 0.9904 - val_loss: 2.6968e-08 - val_accuracy: 1.0000\n",
            "Epoch 185/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0052 - accuracy: 0.9952 - val_loss: 2.5416e-05 - val_accuracy: 1.0000\n",
            "Epoch 186/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0103 - accuracy: 0.9892 - val_loss: 1.4101e-05 - val_accuracy: 1.0000\n",
            "Epoch 187/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0088 - accuracy: 0.9928 - val_loss: 4.3770e-05 - val_accuracy: 1.0000\n",
            "Epoch 188/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0072 - accuracy: 0.9916 - val_loss: 6.2646e-05 - val_accuracy: 1.0000\n",
            "Epoch 189/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0075 - accuracy: 0.9964 - val_loss: 3.3860e-07 - val_accuracy: 1.0000\n",
            "Epoch 190/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0100 - accuracy: 0.9916 - val_loss: 7.5728e-10 - val_accuracy: 1.0000\n",
            "Epoch 191/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0118 - accuracy: 0.9928 - val_loss: 7.0923e-09 - val_accuracy: 1.0000\n",
            "Epoch 192/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0060 - accuracy: 0.9952 - val_loss: 8.3590e-09 - val_accuracy: 1.0000\n",
            "Epoch 193/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0060 - accuracy: 0.9988 - val_loss: 4.4980e-08 - val_accuracy: 1.0000\n",
            "Epoch 194/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0055 - accuracy: 0.9976 - val_loss: 5.7917e-05 - val_accuracy: 1.0000\n",
            "Epoch 195/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.5716e-11 - val_accuracy: 1.0000\n",
            "Epoch 196/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0030 - accuracy: 0.9976 - val_loss: 1.5847e-14 - val_accuracy: 1.0000\n",
            "Epoch 197/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0457 - accuracy: 0.9940 - val_loss: 6.2621e-09 - val_accuracy: 1.0000\n",
            "Epoch 198/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0124 - accuracy: 0.9952 - val_loss: 6.5093e-04 - val_accuracy: 1.0000\n",
            "Epoch 199/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0074 - accuracy: 0.9940 - val_loss: 0.0054 - val_accuracy: 0.9952\n",
            "Epoch 200/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0084 - accuracy: 0.9940 - val_loss: 5.9391e-04 - val_accuracy: 1.0000\n",
            "Epoch 201/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0072 - accuracy: 0.9952 - val_loss: 3.0125e-05 - val_accuracy: 1.0000\n",
            "Epoch 202/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0049 - accuracy: 0.9976 - val_loss: 2.0212e-06 - val_accuracy: 1.0000\n",
            "Epoch 203/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0049 - accuracy: 0.9976 - val_loss: 1.8707e-07 - val_accuracy: 1.0000\n",
            "Epoch 204/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0085 - accuracy: 0.9928 - val_loss: 3.0368e-08 - val_accuracy: 1.0000\n",
            "Epoch 205/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0060 - accuracy: 0.9964 - val_loss: 1.8283e-09 - val_accuracy: 1.0000\n",
            "Epoch 206/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0049 - accuracy: 0.9988 - val_loss: 1.4964e-10 - val_accuracy: 1.0000\n",
            "Epoch 207/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0042 - accuracy: 0.9964 - val_loss: 1.5907e-11 - val_accuracy: 1.0000\n",
            "Epoch 208/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0034 - accuracy: 0.9976 - val_loss: 1.3392e-12 - val_accuracy: 1.0000\n",
            "Epoch 209/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0036 - accuracy: 0.9964 - val_loss: 9.1467e-13 - val_accuracy: 1.0000\n",
            "Epoch 210/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.0571e-12 - val_accuracy: 1.0000\n",
            "Epoch 211/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0044 - accuracy: 0.9976 - val_loss: 5.0076e-13 - val_accuracy: 1.0000\n",
            "Epoch 212/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0025 - accuracy: 0.9976 - val_loss: 7.7194e-13 - val_accuracy: 1.0000\n",
            "Epoch 213/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0100 - accuracy: 0.9928 - val_loss: 5.1346e-13 - val_accuracy: 1.0000\n",
            "Epoch 214/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0056 - accuracy: 0.9952 - val_loss: 5.6488e-16 - val_accuracy: 1.0000\n",
            "Epoch 215/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0033 - accuracy: 0.9976 - val_loss: 1.2220e-15 - val_accuracy: 1.0000\n",
            "Epoch 216/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0025 - accuracy: 0.9976 - val_loss: 6.4795e-16 - val_accuracy: 1.0000\n",
            "Epoch 217/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 7.9882e-04 - accuracy: 1.0000 - val_loss: 9.8489e-16 - val_accuracy: 1.0000\n",
            "Epoch 218/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0029 - accuracy: 0.9988 - val_loss: 3.3114e-15 - val_accuracy: 1.0000\n",
            "Epoch 219/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0050 - accuracy: 0.9964 - val_loss: 4.2557e-15 - val_accuracy: 1.0000\n",
            "Epoch 220/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 4.9859e-15 - val_accuracy: 1.0000\n",
            "Epoch 221/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0041 - accuracy: 0.9976 - val_loss: 5.2541e-15 - val_accuracy: 1.0000\n",
            "Epoch 222/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0033 - accuracy: 0.9976 - val_loss: 5.3924e-15 - val_accuracy: 1.0000\n",
            "Epoch 223/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0029 - accuracy: 0.9976 - val_loss: 8.7109e-17 - val_accuracy: 1.0000\n",
            "Epoch 224/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0034 - accuracy: 0.9964 - val_loss: 2.4620e-16 - val_accuracy: 1.0000\n",
            "Epoch 225/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0014 - accuracy: 0.9988 - val_loss: 1.1603e-17 - val_accuracy: 1.0000\n",
            "Epoch 226/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 8.6926e-04 - accuracy: 0.9988 - val_loss: 4.4936e-18 - val_accuracy: 1.0000\n",
            "Epoch 227/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.1604e-21 - val_accuracy: 1.0000\n",
            "Epoch 228/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0053 - accuracy: 0.9964 - val_loss: 0.0900 - val_accuracy: 0.9952\n",
            "Epoch 229/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.4122 - accuracy: 0.9892 - val_loss: 19.4960 - val_accuracy: 0.9135\n",
            "Epoch 230/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0547 - accuracy: 0.9952 - val_loss: 6.5050 - val_accuracy: 0.9327\n",
            "Epoch 231/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0816 - accuracy: 0.9976 - val_loss: 1.9748 - val_accuracy: 0.9471\n",
            "Epoch 232/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0529 - accuracy: 0.9976 - val_loss: 0.4026 - val_accuracy: 0.9808\n",
            "Epoch 233/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.5578 - accuracy: 0.9880 - val_loss: 7.5261 - val_accuracy: 0.9279\n",
            "Epoch 234/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0043 - accuracy: 0.9952 - val_loss: 13.4140 - val_accuracy: 0.9183\n",
            "Epoch 235/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0812 - accuracy: 0.9904 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 236/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.1033 - accuracy: 0.9964 - val_loss: 7.1774e-08 - val_accuracy: 1.0000\n",
            "Epoch 237/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0713 - accuracy: 0.9940 - val_loss: 1.2856 - val_accuracy: 0.9856\n",
            "Epoch 238/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0915 - accuracy: 0.9952 - val_loss: 0.4732 - val_accuracy: 0.9712\n",
            "Epoch 239/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0202 - accuracy: 0.9952 - val_loss: 0.2499 - val_accuracy: 0.9904\n",
            "Epoch 240/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0516 - accuracy: 0.9940 - val_loss: 48.3693 - val_accuracy: 0.9038\n",
            "Epoch 241/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.2323 - accuracy: 0.9880 - val_loss: 0.3058 - val_accuracy: 0.9808\n",
            "Epoch 242/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.3322 - accuracy: 0.9892 - val_loss: 2.8453 - val_accuracy: 0.9423\n",
            "Epoch 243/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.1823 - accuracy: 0.9952 - val_loss: 1.9804e-20 - val_accuracy: 1.0000\n",
            "Epoch 244/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.1428 - accuracy: 0.9976 - val_loss: 0.5943 - val_accuracy: 0.9760\n",
            "Epoch 245/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0091 - accuracy: 0.9964 - val_loss: 0.2685 - val_accuracy: 0.9808\n",
            "Epoch 246/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0044 - accuracy: 0.9988 - val_loss: 0.0359 - val_accuracy: 0.9952\n",
            "Epoch 247/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 2.9653e-06 - accuracy: 1.0000 - val_loss: 9.7610e-11 - val_accuracy: 1.0000\n",
            "Epoch 248/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0017 - accuracy: 0.9988 - val_loss: 9.7759e-30 - val_accuracy: 1.0000\n",
            "Epoch 249/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 8.1680e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 250/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0558 - accuracy: 0.9952 - val_loss: 1.3893 - val_accuracy: 0.9375\n",
            "Epoch 251/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.7740 - accuracy: 0.9820 - val_loss: 0.1944 - val_accuracy: 0.9856\n",
            "Epoch 252/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 1.5668 - val_accuracy: 0.9952\n",
            "Epoch 253/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.5899 - accuracy: 0.9904 - val_loss: 0.4478 - val_accuracy: 0.9904\n",
            "Epoch 254/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0918 - accuracy: 0.9952 - val_loss: 38.6072 - val_accuracy: 0.9038\n",
            "Epoch 255/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0500 - accuracy: 0.9904 - val_loss: 8.2766 - val_accuracy: 0.9279\n",
            "Epoch 256/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0361 - accuracy: 0.9952 - val_loss: 0.0462 - val_accuracy: 0.9952\n",
            "Epoch 257/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0052 - accuracy: 0.9964 - val_loss: 1.4436e-19 - val_accuracy: 1.0000\n",
            "Epoch 258/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0042 - accuracy: 0.9988 - val_loss: 4.9787e-27 - val_accuracy: 1.0000\n",
            "Epoch 259/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0085 - accuracy: 0.9976 - val_loss: 5.0828e-29 - val_accuracy: 1.0000\n",
            "Epoch 260/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0034 - accuracy: 0.9988 - val_loss: 1.1039e-33 - val_accuracy: 1.0000\n",
            "Epoch 261/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0075 - accuracy: 0.9964 - val_loss: 4.2544e-38 - val_accuracy: 1.0000\n",
            "Epoch 262/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0050 - accuracy: 0.9976 - val_loss: 5.9027e-37 - val_accuracy: 1.0000\n",
            "Epoch 263/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0132 - accuracy: 0.9964 - val_loss: 1.7846e-36 - val_accuracy: 1.0000\n",
            "Epoch 264/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 2.7376e-32 - val_accuracy: 1.0000\n",
            "Epoch 265/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0029 - accuracy: 0.9964 - val_loss: 5.1650e-30 - val_accuracy: 1.0000\n",
            "Epoch 266/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.1372 - accuracy: 0.9940 - val_loss: 1.8328e-33 - val_accuracy: 1.0000\n",
            "Epoch 267/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0086 - accuracy: 0.9988 - val_loss: 5.4202e-38 - val_accuracy: 1.0000\n",
            "Epoch 268/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0034 - accuracy: 0.9988 - val_loss: 3.7666e-31 - val_accuracy: 1.0000\n",
            "Epoch 269/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 8.1114e-04 - accuracy: 1.0000 - val_loss: 4.0544e-27 - val_accuracy: 1.0000\n",
            "Epoch 270/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0048 - accuracy: 0.9964 - val_loss: 1.7029e-25 - val_accuracy: 1.0000\n",
            "Epoch 271/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 6.5300e-24 - val_accuracy: 1.0000\n",
            "Epoch 272/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0099 - accuracy: 0.9952 - val_loss: 7.6110e-24 - val_accuracy: 1.0000\n",
            "Epoch 273/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0148 - accuracy: 0.9952 - val_loss: 2.9147e-30 - val_accuracy: 1.0000\n",
            "Epoch 274/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.8118e-30 - val_accuracy: 1.0000\n",
            "Epoch 275/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.9075e-27 - val_accuracy: 1.0000\n",
            "Epoch 276/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0017 - accuracy: 0.9988 - val_loss: 7.2232e-25 - val_accuracy: 1.0000\n",
            "Epoch 277/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0041 - accuracy: 0.9976 - val_loss: 2.0388e-23 - val_accuracy: 1.0000\n",
            "Epoch 278/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0025 - accuracy: 0.9988 - val_loss: 1.7023e-22 - val_accuracy: 1.0000\n",
            "Epoch 279/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0051 - accuracy: 0.9964 - val_loss: 2.1425e-22 - val_accuracy: 1.0000\n",
            "Epoch 280/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0024 - accuracy: 0.9988 - val_loss: 1.4112e-22 - val_accuracy: 1.0000\n",
            "Epoch 281/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 7.8667e-25 - val_accuracy: 1.0000\n",
            "Epoch 282/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0041 - accuracy: 0.9988 - val_loss: 1.2758e-25 - val_accuracy: 1.0000\n",
            "Epoch 283/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0031 - accuracy: 0.9964 - val_loss: 5.5144e-26 - val_accuracy: 1.0000\n",
            "Epoch 284/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0032 - accuracy: 0.9988 - val_loss: 5.1008e-29 - val_accuracy: 1.0000\n",
            "Epoch 285/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 5.0003e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 286/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0974 - accuracy: 0.9952 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 287/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 3.6053e-06 - accuracy: 1.0000 - val_loss: 8.6744e-37 - val_accuracy: 1.0000\n",
            "Epoch 288/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0017 - accuracy: 0.9976 - val_loss: 7.2666e-34 - val_accuracy: 1.0000\n",
            "Epoch 289/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0017 - accuracy: 0.9988 - val_loss: 4.4132e-33 - val_accuracy: 1.0000\n",
            "Epoch 290/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.1472 - accuracy: 0.9988 - val_loss: 1.1631e-24 - val_accuracy: 1.0000\n",
            "Epoch 291/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0372 - accuracy: 0.9988 - val_loss: 3.1378e-05 - val_accuracy: 1.0000\n",
            "Epoch 292/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0283 - accuracy: 0.9940 - val_loss: 3.5525e-28 - val_accuracy: 1.0000\n",
            "Epoch 293/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0831 - accuracy: 0.9952 - val_loss: 2.6336e-29 - val_accuracy: 1.0000\n",
            "Epoch 294/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0402 - accuracy: 0.9964 - val_loss: 2.6578e-22 - val_accuracy: 1.0000\n",
            "Epoch 295/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0027 - accuracy: 0.9988 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 296/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0030 - accuracy: 0.9976 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 297/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 298/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 1.9707e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 299/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0013 - accuracy: 0.9988 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 300/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0017 - accuracy: 0.9988 - val_loss: 1.8330e-38 - val_accuracy: 1.0000\n",
            "Epoch 301/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0307 - accuracy: 0.9988 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 302/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0012 - accuracy: 0.9988 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 303/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0048 - accuracy: 0.9976 - val_loss: 3.0508e-37 - val_accuracy: 1.0000\n",
            "Epoch 304/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0025 - accuracy: 0.9976 - val_loss: 3.7098e-36 - val_accuracy: 1.0000\n",
            "Epoch 305/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 7.9974e-04 - accuracy: 1.0000 - val_loss: 2.1382e-35 - val_accuracy: 1.0000\n",
            "Epoch 306/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.2973 - accuracy: 0.9952 - val_loss: 0.0102 - val_accuracy: 0.9952\n",
            "Epoch 307/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.1475 - accuracy: 0.9964 - val_loss: 0.0778 - val_accuracy: 0.9952\n",
            "Epoch 308/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 2.3983e-10 - accuracy: 1.0000 - val_loss: 2.0537e-38 - val_accuracy: 1.0000\n",
            "Epoch 309/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 8.7349e-04 - accuracy: 0.9988 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 310/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0153 - accuracy: 0.9988 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 311/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.1479 - accuracy: 0.9964 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 312/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 8.6909e-04 - accuracy: 0.9988 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 313/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 1.2002e-08 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 314/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0178 - accuracy: 0.9988 - val_loss: 1.3002e-20 - val_accuracy: 1.0000\n",
            "Epoch 315/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0017 - accuracy: 0.9988 - val_loss: 2.6713e-15 - val_accuracy: 1.0000\n",
            "Epoch 316/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.3537 - accuracy: 0.9988 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 317/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.1625 - accuracy: 0.9976 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 318/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 9.3863e-04 - accuracy: 0.9988 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 319/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0320 - accuracy: 0.9988 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 320/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.1100 - accuracy: 0.9976 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 321/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 8.6598e-04 - accuracy: 0.9988 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 322/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 4.6046e-12 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 323/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 3.6511e-08 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 324/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.1103 - accuracy: 0.9988 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 325/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0058 - accuracy: 0.9976 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 326/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 8.0785e-04 - accuracy: 1.0000 - val_loss: 1.1744e-37 - val_accuracy: 1.0000\n",
            "Epoch 327/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0298 - accuracy: 0.9976 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 328/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 1.4961e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 329/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 4.0647e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 330/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 2.2588e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 331/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0487 - accuracy: 0.9964 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 332/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0011 - accuracy: 0.9988 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 333/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 7.8895e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 334/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 2.0288e-15 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 335/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 2.1743e-13 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 336/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 8.6256e-04 - accuracy: 0.9988 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 337/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 2.1896e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 338/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 8.6205e-04 - accuracy: 0.9988 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 339/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 4.3292e-14 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 340/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 8.5973e-04 - accuracy: 0.9988 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 341/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0118 - accuracy: 0.9976 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 342/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0010 - accuracy: 0.9988 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 343/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0438 - accuracy: 0.9976 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 344/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0026 - accuracy: 0.9988 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 345/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 9.3658e-04 - accuracy: 0.9988 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 346/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 347/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 7.3665e-08 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 348/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 8.2342e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 349/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0025 - accuracy: 0.9988 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 350/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 3.2680e-12 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 351/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 6.5441e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 352/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 9.4330e-12 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 353/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 2.2267e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 354/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 8.5462e-04 - accuracy: 0.9988 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 355/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0299 - accuracy: 0.9964 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 356/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 8.1271e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 357/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 8.5551e-04 - accuracy: 0.9988 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 358/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 8.5410e-04 - accuracy: 0.9988 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 359/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 1.0118e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 360/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 3.1427e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 361/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0082 - accuracy: 0.9988 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 362/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 2.1196e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 363/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 1.0388e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 364/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 1.7437e-14 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 365/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 1.3030e-12 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 366/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 1.9903e-16 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 367/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 368/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 2.5571e-26 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 369/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0010 - accuracy: 0.9988 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 370/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 6.9127e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 371/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 3.8597e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 372/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0017 - accuracy: 0.9976 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 373/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 8.4490e-04 - accuracy: 0.9988 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 374/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0358 - accuracy: 0.9988 - val_loss: 304.4427 - val_accuracy: 0.9038\n",
            "Epoch 375/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0389 - accuracy: 0.9964 - val_loss: 104.8170 - val_accuracy: 0.9038\n",
            "Epoch 376/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0062 - accuracy: 0.9976 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 377/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 2.2028e-30 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 378/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0681 - accuracy: 0.9988 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 379/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 2.7911e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 380/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 8.3511e-04 - accuracy: 0.9988 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 381/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0338 - accuracy: 0.9988 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 382/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 1.2933e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 383/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.1965 - accuracy: 0.9964 - val_loss: 4.2822 - val_accuracy: 0.9567\n",
            "Epoch 384/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0370 - accuracy: 0.9964 - val_loss: 0.2635 - val_accuracy: 0.9952\n",
            "Epoch 385/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0555 - accuracy: 0.9976 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "Epoch 386/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 5.8583e-24 - accuracy: 1.0000 - val_loss: 1.8559e-23 - val_accuracy: 1.0000\n",
            "Epoch 387/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.2112 - accuracy: 0.9988 - val_loss: 2.7641e-17 - val_accuracy: 1.0000\n",
            "Epoch 388/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0204 - accuracy: 0.9964 - val_loss: 0.0694 - val_accuracy: 0.9952\n",
            "Epoch 389/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0843 - accuracy: 0.9964 - val_loss: 12.5221 - val_accuracy: 0.9375\n",
            "Epoch 390/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.1064 - accuracy: 0.9976 - val_loss: 2.7684 - val_accuracy: 0.9615\n",
            "Epoch 391/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0438 - accuracy: 0.9976 - val_loss: 6.0574e-24 - val_accuracy: 1.0000\n",
            "Epoch 392/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.1527 - accuracy: 0.9976 - val_loss: 2.5960 - val_accuracy: 0.9663\n",
            "Epoch 393/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0271 - accuracy: 0.9988 - val_loss: 13.0807 - val_accuracy: 0.9279\n",
            "Epoch 394/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 3.0793e-05 - accuracy: 1.0000 - val_loss: 5.5525 - val_accuracy: 0.9615\n",
            "Epoch 395/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 2.2650e-06 - accuracy: 1.0000 - val_loss: 1.2089 - val_accuracy: 0.9856\n",
            "Epoch 396/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 2.1910e-10 - accuracy: 1.0000 - val_loss: 0.2578 - val_accuracy: 0.9952\n",
            "Epoch 397/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0062 - accuracy: 0.9988 - val_loss: 3.9058e-05 - val_accuracy: 1.0000\n",
            "Epoch 398/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0857 - accuracy: 0.9988 - val_loss: 0.6991 - val_accuracy: 0.9904\n",
            "Epoch 399/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0406 - accuracy: 0.9988 - val_loss: 0.4544 - val_accuracy: 0.9952\n",
            "Epoch 400/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.1043 - val_accuracy: 0.9952\n",
            "Epoch 401/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 3.3445e-29 - accuracy: 1.0000 - val_loss: 1.8492e-31 - val_accuracy: 1.0000\n",
            "Epoch 402/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 403/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 1.4850e-36 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 404/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 4.9796e-14 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 405/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0333 - accuracy: 0.9988 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 406/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 8.9611e-22 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 407/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 408/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 2.0254e-12 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 409/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 2.8318e-19 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 410/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 1.1179e-22 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 411/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 1.2087e-11 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 412/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 1.8847e-12 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 413/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 8.4000e-04 - accuracy: 0.9988 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 414/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 6.5316e-19 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 415/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 1.1380e-30 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 416/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 4.7435e-23 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 417/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 8.6782e-13 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 418/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 6.2321e-13 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 419/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0367 - accuracy: 0.9988 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 420/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 1.4093e-24 - accuracy: 1.0000 - val_loss: 0.0224 - val_accuracy: 0.9952\n",
            "Epoch 421/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0577 - accuracy: 0.9976 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 422/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 6.7983e-26 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 423/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 1.6465e-13 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 424/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 8.4363e-04 - accuracy: 0.9988 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 425/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 9.9729e-20 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 426/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 3.9511e-19 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 427/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 7.8287e-14 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 428/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 9.9151e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 429/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 3.1228e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 430/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 3.7727e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 431/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 8.2471e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 432/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 8.2261e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 433/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 3.9332e-08 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 434/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 435/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 8.2784e-08 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 436/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 2.2895e-25 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 437/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 2.2548e-29 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 438/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0272 - accuracy: 0.9988 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 439/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 1.0723e-12 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 440/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 8.1576e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 441/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 3.6110e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 442/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 1.0328e-18 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 443/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 8.0799e-24 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 444/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0017 - accuracy: 0.9976 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 445/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 6.9558e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 446/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 4.0462e-17 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 447/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 2.5855e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 448/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 8.1921e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 449/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 2.4360e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 450/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 3.7729e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 451/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 8.1764e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 452/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 8.1612e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 453/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 2.2002e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 454/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 8.9039e-19 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 455/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 6.7102e-12 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 456/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 457/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 2.7720e-23 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 458/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 459/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 8.5951e-04 - accuracy: 0.9988 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 460/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 2.2117e-16 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 461/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 8.0451e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 462/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 3.9168e-22 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 463/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 1.4142e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 464/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 2.1809e-28 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 465/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 8.0978e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 466/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 3.7248e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 467/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 6.1937e-23 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 468/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 4.6436e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 469/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 6.5198e-29 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 470/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 8.6009e-04 - accuracy: 0.9988 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 471/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 1.4555e-13 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 472/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 8.0984e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 473/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 8.0745e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 474/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0215 - accuracy: 0.9988 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 475/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 2.0064e-31 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 476/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 7.9785e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 477/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0132 - accuracy: 0.9988 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 478/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 6.9680e-15 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 479/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.1093 - accuracy: 0.9988 - val_loss: 43.4185 - val_accuracy: 0.9327\n",
            "Epoch 480/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0500 - accuracy: 0.9988 - val_loss: 64.4870 - val_accuracy: 0.9279\n",
            "Epoch 481/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 2.3204e-22 - accuracy: 1.0000 - val_loss: 197.1073 - val_accuracy: 0.9038\n",
            "Epoch 482/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0830 - accuracy: 0.9976 - val_loss: 0.6001 - val_accuracy: 0.9952\n",
            "Epoch 483/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0402 - accuracy: 0.9988 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 484/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 3.9824e-20 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 485/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 2.2385e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 486/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 5.1908e-23 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 487/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 2.9342e-29 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 488/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 8.0571e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 489/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0390 - accuracy: 0.9988 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 490/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 8.2401e-10 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 491/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 492/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0243 - accuracy: 0.9988 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 493/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0010 - accuracy: 0.9988 - val_loss: 1.0161e-35 - val_accuracy: 1.0000\n",
            "Epoch 494/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 1.8429e-26 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 495/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 1.8228e-28 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 496/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 2.7325e-32 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 497/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 3.2467e-21 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 498/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0094 - accuracy: 0.9988 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 499/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.2316 - accuracy: 0.9952 - val_loss: 483.8676 - val_accuracy: 0.9038\n",
            "Epoch 500/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0128 - accuracy: 0.9976 - val_loss: 1.8543 - val_accuracy: 0.9856\n",
            "Epoch 501/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 6.6846e-18 - accuracy: 1.0000 - val_loss: 7.1392e-09 - val_accuracy: 1.0000\n",
            "Epoch 502/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 1.4621e-10 - accuracy: 1.0000 - val_loss: 2.2541e-12 - val_accuracy: 1.0000\n",
            "Epoch 503/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0300 - accuracy: 0.9988 - val_loss: 4.5809e-22 - val_accuracy: 1.0000\n",
            "Epoch 504/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 1.5483e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 505/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 506/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 7.8045e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 507/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 7.5338e-15 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 508/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 8.3174e-14 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 509/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 7.7822e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 510/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 6.4007e-18 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 511/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 2.4964e-14 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 512/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 2.9908e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 513/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0010 - accuracy: 0.9988 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 514/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 6.4517e-22 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 515/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 516/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 1.0133e-21 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 517/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 1.1337e-14 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 518/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 1.3623e-36 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 519/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 6.2178e-12 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 520/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 1.1667e-12 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 521/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 522/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 523/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 1.9851e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 524/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 1.4180e-17 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 525/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0858 - accuracy: 0.9976 - val_loss: 8.9083 - val_accuracy: 0.9712\n",
            "Epoch 526/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 8.9123e-04 - accuracy: 0.9988 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 527/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 1.4056e-25 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 528/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 529/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 3.8226e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 530/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 1.2251e-17 - accuracy: 1.0000 - val_loss: 6.2374e-32 - val_accuracy: 1.0000\n",
            "Epoch 531/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0145 - accuracy: 0.9988 - val_loss: 0.2789 - val_accuracy: 0.9952\n",
            "Epoch 532/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 533/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 3.3958e-38 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 534/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 9.0363e-37 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 535/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 2.3937e-16 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 536/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 2.0069e-11 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 537/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 5.8170e-08 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 538/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 3.8001e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 539/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 8.5851e-29 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 540/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 5.4186e-13 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 541/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 2.5393e-34 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 542/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 6.1311e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 543/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 3.1589e-38 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 544/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 9.9430e-30 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 545/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 7.8576e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 546/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 2.2908e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 547/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 1.4709e-23 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 548/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 1.0892e-21 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 549/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 3.9274e-16 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 550/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 551/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 2.1791e-30 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 552/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0401 - accuracy: 0.9988 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 553/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 1.6661e-15 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 554/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 1.7765e-12 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 555/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.2054 - accuracy: 0.9976 - val_loss: 0.6290 - val_accuracy: 0.9952\n",
            "Epoch 556/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0366 - accuracy: 0.9988 - val_loss: 1.1093 - val_accuracy: 0.9904\n",
            "Epoch 557/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 5.6629e-29 - accuracy: 1.0000 - val_loss: 8.1848 - val_accuracy: 0.9663\n",
            "Epoch 558/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0194 - accuracy: 0.9988 - val_loss: 0.4719 - val_accuracy: 0.9952\n",
            "Epoch 559/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 8.2087e-25 - accuracy: 1.0000 - val_loss: 0.0576 - val_accuracy: 0.9952\n",
            "Epoch 560/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 3.8027 - accuracy: 0.9940 - val_loss: 3.1296 - val_accuracy: 0.9712\n",
            "Epoch 561/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.2879 - accuracy: 0.9988 - val_loss: 1.7383 - val_accuracy: 0.9952\n",
            "Epoch 562/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.1439 - accuracy: 0.9988 - val_loss: 11.8282 - val_accuracy: 0.9519\n",
            "Epoch 563/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0457 - accuracy: 0.9988 - val_loss: 440.5879 - val_accuracy: 0.9038\n",
            "Epoch 564/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.1447 - accuracy: 0.9964 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 565/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.1938 - accuracy: 0.9988 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 566/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 5.7056e-28 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 567/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 6.6483e-38 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 568/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0381 - accuracy: 0.9988 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 569/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 6.2887e-22 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 570/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 571/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 7.1173e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 572/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0778 - accuracy: 0.9988 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 573/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0736 - accuracy: 0.9988 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 574/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 575/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 3.7741e-31 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 576/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 577/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 578/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0914 - accuracy: 0.9988 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 579/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 1.2042e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 580/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 3.5412e-34 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 581/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 1.9918e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 582/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 583/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 584/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 585/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 5.1184e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 586/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 587/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 588/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 589/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 590/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 6.9500e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 591/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 592/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 4.6761e-12 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 593/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 1.5461e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 594/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 3.0987e-24 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 595/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 5.4015e-18 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 596/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 2.2996e-28 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 597/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 598/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 1.3127e-20 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 599/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 6.5930e-22 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 600/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 2.3184e-22 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 601/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.1329 - accuracy: 0.9988 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 602/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 5.4089e-14 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 603/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 9.1098e-16 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 604/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 605/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 606/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 1.6323e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 607/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 608/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 609/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 2.4194e-37 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 610/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 611/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 3.0701e-21 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 612/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 1.7655e-38 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 613/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 1.4324e-10 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 614/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0330 - accuracy: 0.9988 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 615/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 4.5430e-11 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 616/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 9.5473e-14 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 617/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 9.5261e-32 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 618/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 4.1317e-36 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 619/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0313 - accuracy: 0.9988 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 620/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 621/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 1.1758e-21 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 622/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 623/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 624/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 1.0397e-23 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 625/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 626/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 9.0954e-30 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 627/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 628/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 2.4188e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 629/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 630/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 631/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 7.5787e-33 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 632/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 633/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 634/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 635/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 636/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 637/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 638/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.1277 - accuracy: 0.9988 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 639/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 640/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 641/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 9.4150e-26 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 642/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 643/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 644/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 645/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 6.1204e-32 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 646/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 647/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 648/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 649/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 1.4537e-30 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 650/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 651/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 652/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 4.3017e-23 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 653/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 5.1034e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 654/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 655/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 656/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 3.1226e-27 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 657/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 6.8433e-28 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 658/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 4.9213e-34 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 659/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 1.6077e-26 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 660/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 661/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 662/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 663/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 664/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 6.6372e-22 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 665/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 666/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 1.5541e-37 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 667/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 668/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 1.1095e-25 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 669/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 670/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 671/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 672/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 1.1742e-35 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 673/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 674/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 1.8915e-36 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 675/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 4.4145e-13 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 676/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 677/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 1.4274e-29 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 678/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 4.3517e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 679/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 680/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 1.2156e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 681/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 7.1326e-23 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 682/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 4.5118e-34 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 683/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 684/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 1.5440e-16 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 685/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 686/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 687/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 7.7295e-27 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 688/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 689/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 5.7169e-28 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 690/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 1.1110e-29 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 691/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 1.3297e-18 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 692/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 693/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 694/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 695/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 696/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 6.4367e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 697/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 698/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 699/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 700/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 1.7118e-25 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 701/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 2.0421e-11 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 702/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 703/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 704/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 705/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 706/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 707/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 708/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 709/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 710/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 711/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 712/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 713/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 714/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 4.5606e-31 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 715/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 5.6758e-23 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 716/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 9.0895e-04 - accuracy: 0.9988 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 717/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0251 - accuracy: 0.9988 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 718/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 4.7299e-15 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 719/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 1.6680e-27 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 720/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0014 - accuracy: 0.9988 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 721/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 722/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 723/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 724/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 2.3047e-28 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 725/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 9.0130e-04 - accuracy: 0.9988 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 726/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 727/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 3.4995e-18 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 728/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 729/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 730/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 4.5819e-25 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 731/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 732/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 1.1891e-26 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 733/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 734/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 735/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 736/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 737/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 738/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 739/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 3.7815e-37 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 740/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 741/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 7.1129e-33 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 742/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 7.1594e-25 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 743/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 9.8404e-28 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 744/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 1.5151e-36 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 745/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 746/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0651 - accuracy: 0.9988 - val_loss: 1.2438e-23 - val_accuracy: 1.0000\n",
            "Epoch 747/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 748/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0711 - accuracy: 0.9988 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 749/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 750/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 751/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 752/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 753/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 754/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 755/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 756/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 757/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.2949 - accuracy: 0.9952 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 758/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.1696 - accuracy: 0.9988 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 759/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0151 - accuracy: 0.9988 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 760/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 761/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 762/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 763/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 4.0284e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 764/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 765/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 7.1285e-11 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 766/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 3.5153e-31 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 767/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 6.1118e-26 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 768/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 1.1663e-12 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 769/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0256 - accuracy: 0.9988 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 770/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 8.4597e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 771/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 772/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 773/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 774/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 775/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 776/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 6.0354e-18 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 777/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0463 - accuracy: 0.9988 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 778/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 1.1179e-34 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 779/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.3046 - accuracy: 0.9976 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 780/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 781/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 782/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 2.9421e-32 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 783/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 784/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 785/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 786/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.1306 - accuracy: 0.9976 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 787/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.1718 - accuracy: 0.9988 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 788/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.6512 - accuracy: 0.9988 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 789/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 790/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.3568 - accuracy: 0.9988 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 791/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 792/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 793/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 794/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 795/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 796/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 797/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 798/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 799/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 9.7137e-25 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 800/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 801/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0460 - accuracy: 0.9988 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 802/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.6029e-16 - val_accuracy: 1.0000\n",
            "Epoch 803/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 804/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 805/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 806/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 807/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.8294 - accuracy: 0.9952 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 808/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 809/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 810/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 6.2600e-14 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 811/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 812/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 813/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 814/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 815/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 816/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 817/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.7462 - accuracy: 0.9988 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 818/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 819/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 1.1013e-19 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 820/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 821/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 1.7692e-19 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 822/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 823/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 824/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 825/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 2.0911e-34 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 826/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 827/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 3.8872e-35 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 828/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 829/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 1.2846e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 830/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 831/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 2.3641e-13 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 832/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 833/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 2.3917e-29 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 834/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 835/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 836/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 837/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 838/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 7.1553e-29 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 839/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 1.8780e-12 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 840/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 1.9117e-37 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 841/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 842/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 843/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 844/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0274 - accuracy: 0.9988 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 845/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 846/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 847/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 848/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 849/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 2.9082e-32 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 850/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 851/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 852/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 853/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 854/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 855/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 2.0268e-21 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 856/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 857/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 858/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 2.7589e-37 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 859/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 860/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 861/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 862/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 863/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 864/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 865/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 866/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 867/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 868/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 869/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 870/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 5.0852e-08 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 871/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 872/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 873/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 874/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 875/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 6.1886e-20 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 876/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 877/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 878/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 879/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 1.8513e-21 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 880/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 881/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0878 - accuracy: 0.9988 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 882/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 883/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 884/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 885/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 886/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 887/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 888/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 889/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 890/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 891/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 892/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 893/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 894/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 895/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 896/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 897/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 898/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 899/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 900/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 901/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 1.5013e-13 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 902/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 903/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 904/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 905/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 906/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 907/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 908/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 909/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 910/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 911/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 9.9238e-10 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 912/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 913/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 1.4397e-20 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 914/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 915/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 916/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 917/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 918/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 919/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 920/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 921/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 922/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 923/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 924/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 925/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 926/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 927/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 928/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 929/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 930/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 931/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 1.1507e-28 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 932/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 933/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 934/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 935/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 936/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 937/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 2.9228e-38 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 938/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 1.8844e-33 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 939/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 940/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 941/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 6.9463e-15 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 942/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 943/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 944/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 945/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 946/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 947/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 948/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 949/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 950/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 951/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 952/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 953/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 954/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 955/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 956/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 957/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 958/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 6.8051e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 959/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 960/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 961/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 962/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 963/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 964/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 7.5209e-22 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 965/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 7.8196e-25 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 966/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 967/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 968/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 969/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 970/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 971/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 972/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 973/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 974/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 975/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 976/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 977/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 978/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 979/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 980/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 981/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 982/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 9.2891e-22 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 983/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 984/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 985/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 986/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 1.2911e-34 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 987/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 988/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 2.7401e-10 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 989/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 990/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 991/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 992/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 993/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 994/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 995/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 996/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 1.6405e-13 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 997/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 998/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 999/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 2.3814e-21 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 1000/1000\n",
            "26/26 [==============================] - 1s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1200x400 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "206/206 [==============================] - 12s 46ms/step - loss: 3.3109 - accuracy: 0.8622 - val_loss: 0.4362 - val_accuracy: 0.8956\n",
            "Epoch 2/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.3197 - accuracy: 0.8775 - val_loss: 0.3315 - val_accuracy: 0.8908\n",
            "Epoch 3/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.2935 - accuracy: 0.8759 - val_loss: 0.2170 - val_accuracy: 0.8883\n",
            "Epoch 4/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.2725 - accuracy: 0.8762 - val_loss: 0.2356 - val_accuracy: 0.8883\n",
            "Epoch 5/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.2459 - accuracy: 0.8763 - val_loss: 0.2391 - val_accuracy: 0.8883\n",
            "Epoch 6/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.2869 - accuracy: 0.8756 - val_loss: 0.2465 - val_accuracy: 0.8883\n",
            "Epoch 7/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.2354 - accuracy: 0.8765 - val_loss: 0.2234 - val_accuracy: 0.8883\n",
            "Epoch 8/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.2829 - accuracy: 0.8760 - val_loss: 0.2989 - val_accuracy: 0.8871\n",
            "Epoch 9/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.2573 - accuracy: 0.8756 - val_loss: 0.2516 - val_accuracy: 0.8883\n",
            "Epoch 10/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.2374 - accuracy: 0.8760 - val_loss: 0.2088 - val_accuracy: 0.8883\n",
            "Epoch 11/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.2346 - accuracy: 0.8762 - val_loss: 1.5986 - val_accuracy: 0.8319\n",
            "Epoch 12/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.2057 - accuracy: 0.8762 - val_loss: 0.1715 - val_accuracy: 0.8883\n",
            "Epoch 13/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1878 - accuracy: 0.8762 - val_loss: 0.1838 - val_accuracy: 0.8883\n",
            "Epoch 14/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.1821 - accuracy: 0.8762 - val_loss: 0.1791 - val_accuracy: 0.8865\n",
            "Epoch 15/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1895 - accuracy: 0.8759 - val_loss: 0.1685 - val_accuracy: 0.8883\n",
            "Epoch 16/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1880 - accuracy: 0.8991 - val_loss: 0.2020 - val_accuracy: 0.9284\n",
            "Epoch 17/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1845 - accuracy: 0.9039 - val_loss: 0.2436 - val_accuracy: 0.9302\n",
            "Epoch 18/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.2089 - accuracy: 0.8995 - val_loss: 0.3907 - val_accuracy: 0.9187\n",
            "Epoch 19/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1765 - accuracy: 0.9067 - val_loss: 0.1846 - val_accuracy: 0.9132\n",
            "Epoch 20/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1531 - accuracy: 0.9297 - val_loss: 0.1862 - val_accuracy: 0.9333\n",
            "Epoch 21/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1623 - accuracy: 0.9202 - val_loss: 0.1480 - val_accuracy: 0.9551\n",
            "Epoch 22/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1551 - accuracy: 0.9247 - val_loss: 0.2825 - val_accuracy: 0.9308\n",
            "Epoch 23/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.6066 - accuracy: 0.8209 - val_loss: 1027.4646 - val_accuracy: 0.8883\n",
            "Epoch 24/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.3198 - accuracy: 0.8009 - val_loss: 0.1865 - val_accuracy: 0.8883\n",
            "Epoch 25/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.2191 - accuracy: 0.8757 - val_loss: 0.1598 - val_accuracy: 0.8883\n",
            "Epoch 26/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.2178 - accuracy: 0.8760 - val_loss: 0.1518 - val_accuracy: 0.8883\n",
            "Epoch 27/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1971 - accuracy: 0.8762 - val_loss: 0.1655 - val_accuracy: 0.8883\n",
            "Epoch 28/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1792 - accuracy: 0.8762 - val_loss: 0.1597 - val_accuracy: 0.8883\n",
            "Epoch 29/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1738 - accuracy: 0.8886 - val_loss: 0.3049 - val_accuracy: 0.9254\n",
            "Epoch 30/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1744 - accuracy: 0.9047 - val_loss: 0.1358 - val_accuracy: 0.9545\n",
            "Epoch 31/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1617 - accuracy: 0.9131 - val_loss: 0.1469 - val_accuracy: 0.9484\n",
            "Epoch 32/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1679 - accuracy: 0.9042 - val_loss: 0.1816 - val_accuracy: 0.9424\n",
            "Epoch 33/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1981 - accuracy: 0.8994 - val_loss: 0.4492 - val_accuracy: 0.9072\n",
            "Epoch 34/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.2358 - accuracy: 0.8649 - val_loss: 0.3302 - val_accuracy: 0.9102\n",
            "Epoch 35/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1779 - accuracy: 0.9132 - val_loss: 0.4252 - val_accuracy: 0.9023\n",
            "Epoch 36/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1545 - accuracy: 0.9253 - val_loss: 0.1779 - val_accuracy: 0.9436\n",
            "Epoch 37/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1470 - accuracy: 0.9291 - val_loss: 0.1494 - val_accuracy: 0.9593\n",
            "Epoch 38/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1639 - accuracy: 0.9124 - val_loss: 0.1368 - val_accuracy: 0.9405\n",
            "Epoch 39/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1468 - accuracy: 0.9291 - val_loss: 0.1551 - val_accuracy: 0.9508\n",
            "Epoch 40/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1339 - accuracy: 0.9382 - val_loss: 0.3164 - val_accuracy: 0.9533\n",
            "Epoch 41/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1477 - accuracy: 0.9307 - val_loss: 0.1234 - val_accuracy: 0.9630\n",
            "Epoch 42/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1332 - accuracy: 0.9376 - val_loss: 0.2298 - val_accuracy: 0.9502\n",
            "Epoch 43/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1265 - accuracy: 0.9401 - val_loss: 0.1452 - val_accuracy: 0.9411\n",
            "Epoch 44/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1364 - accuracy: 0.9364 - val_loss: 0.5184 - val_accuracy: 0.9132\n",
            "Epoch 45/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1460 - accuracy: 0.9361 - val_loss: 0.3954 - val_accuracy: 0.9417\n",
            "Epoch 46/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1292 - accuracy: 0.9402 - val_loss: 0.3111 - val_accuracy: 0.9521\n",
            "Epoch 47/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1562 - accuracy: 0.9214 - val_loss: 0.1716 - val_accuracy: 0.9642\n",
            "Epoch 48/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1623 - accuracy: 0.9313 - val_loss: 0.3142 - val_accuracy: 0.9454\n",
            "Epoch 49/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1316 - accuracy: 0.9520 - val_loss: 0.1566 - val_accuracy: 0.9654\n",
            "Epoch 50/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1214 - accuracy: 0.9489 - val_loss: 0.7869 - val_accuracy: 0.9175\n",
            "Epoch 51/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1669 - accuracy: 0.9375 - val_loss: 0.2841 - val_accuracy: 0.9381\n",
            "Epoch 52/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1129 - accuracy: 0.9516 - val_loss: 0.1865 - val_accuracy: 0.9630\n",
            "Epoch 53/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1237 - accuracy: 0.9542 - val_loss: 0.1052 - val_accuracy: 0.9678\n",
            "Epoch 54/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1167 - accuracy: 0.9493 - val_loss: 0.1224 - val_accuracy: 0.9648\n",
            "Epoch 55/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1003 - accuracy: 0.9602 - val_loss: 0.1402 - val_accuracy: 0.9612\n",
            "Epoch 56/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1097 - accuracy: 0.9549 - val_loss: 0.1411 - val_accuracy: 0.9691\n",
            "Epoch 57/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1125 - accuracy: 0.9528 - val_loss: 2.9863 - val_accuracy: 0.9381\n",
            "Epoch 58/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0998 - accuracy: 0.9581 - val_loss: 0.1431 - val_accuracy: 0.9709\n",
            "Epoch 59/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0959 - accuracy: 0.9613 - val_loss: 0.1708 - val_accuracy: 0.9678\n",
            "Epoch 60/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0877 - accuracy: 0.9687 - val_loss: 0.1400 - val_accuracy: 0.9739\n",
            "Epoch 61/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0960 - accuracy: 0.9602 - val_loss: 0.2864 - val_accuracy: 0.9508\n",
            "Epoch 62/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0985 - accuracy: 0.9601 - val_loss: 0.1151 - val_accuracy: 0.9751\n",
            "Epoch 63/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0877 - accuracy: 0.9683 - val_loss: 0.4494 - val_accuracy: 0.9448\n",
            "Epoch 64/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1038 - accuracy: 0.9593 - val_loss: 0.1469 - val_accuracy: 0.9763\n",
            "Epoch 65/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1054 - accuracy: 0.9689 - val_loss: 1.1968 - val_accuracy: 0.8975\n",
            "Epoch 66/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0833 - accuracy: 0.9683 - val_loss: 0.1087 - val_accuracy: 0.9739\n",
            "Epoch 67/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0878 - accuracy: 0.9701 - val_loss: 0.2291 - val_accuracy: 0.9715\n",
            "Epoch 68/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0797 - accuracy: 0.9712 - val_loss: 0.1142 - val_accuracy: 0.9757\n",
            "Epoch 69/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0676 - accuracy: 0.9768 - val_loss: 0.2077 - val_accuracy: 0.9703\n",
            "Epoch 70/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0843 - accuracy: 0.9698 - val_loss: 0.1495 - val_accuracy: 0.9733\n",
            "Epoch 71/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0757 - accuracy: 0.9733 - val_loss: 0.3578 - val_accuracy: 0.9575\n",
            "Epoch 72/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0811 - accuracy: 0.9697 - val_loss: 0.1157 - val_accuracy: 0.9624\n",
            "Epoch 73/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0831 - accuracy: 0.9701 - val_loss: 106.2953 - val_accuracy: 0.9290\n",
            "Epoch 74/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0771 - accuracy: 0.9716 - val_loss: 0.0944 - val_accuracy: 0.9794\n",
            "Epoch 75/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0771 - accuracy: 0.9713 - val_loss: 0.1176 - val_accuracy: 0.9818\n",
            "Epoch 76/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0938 - accuracy: 0.9656 - val_loss: 0.1622 - val_accuracy: 0.9727\n",
            "Epoch 77/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0732 - accuracy: 0.9753 - val_loss: 0.1070 - val_accuracy: 0.9684\n",
            "Epoch 78/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0786 - accuracy: 0.9709 - val_loss: 0.2063 - val_accuracy: 0.9666\n",
            "Epoch 79/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0671 - accuracy: 0.9771 - val_loss: 0.1985 - val_accuracy: 0.9715\n",
            "Epoch 80/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0693 - accuracy: 0.9768 - val_loss: 0.1893 - val_accuracy: 0.9782\n",
            "Epoch 81/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1198 - accuracy: 0.9660 - val_loss: 1.0233 - val_accuracy: 0.9248\n",
            "Epoch 82/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0755 - accuracy: 0.9734 - val_loss: 0.1608 - val_accuracy: 0.9788\n",
            "Epoch 83/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0581 - accuracy: 0.9822 - val_loss: 0.1363 - val_accuracy: 0.9751\n",
            "Epoch 84/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0641 - accuracy: 0.9781 - val_loss: 0.1569 - val_accuracy: 0.9721\n",
            "Epoch 85/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0577 - accuracy: 0.9813 - val_loss: 0.1585 - val_accuracy: 0.9757\n",
            "Epoch 86/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0593 - accuracy: 0.9806 - val_loss: 0.1280 - val_accuracy: 0.9788\n",
            "Epoch 87/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0854 - accuracy: 0.9797 - val_loss: 0.1339 - val_accuracy: 0.9763\n",
            "Epoch 88/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0604 - accuracy: 0.9794 - val_loss: 0.1622 - val_accuracy: 0.9757\n",
            "Epoch 89/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0542 - accuracy: 0.9821 - val_loss: 0.1108 - val_accuracy: 0.9794\n",
            "Epoch 90/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0746 - accuracy: 0.9777 - val_loss: 0.1276 - val_accuracy: 0.9575\n",
            "Epoch 91/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0899 - accuracy: 0.9759 - val_loss: 0.1731 - val_accuracy: 0.9254\n",
            "Epoch 92/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0694 - accuracy: 0.9753 - val_loss: 0.0983 - val_accuracy: 0.9745\n",
            "Epoch 93/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0592 - accuracy: 0.9815 - val_loss: 0.2484 - val_accuracy: 0.9733\n",
            "Epoch 94/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0676 - accuracy: 0.9762 - val_loss: 0.1552 - val_accuracy: 0.9757\n",
            "Epoch 95/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0532 - accuracy: 0.9825 - val_loss: 0.1354 - val_accuracy: 0.9757\n",
            "Epoch 96/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0464 - accuracy: 0.9857 - val_loss: 0.3499 - val_accuracy: 0.9709\n",
            "Epoch 97/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0476 - accuracy: 0.9856 - val_loss: 0.2015 - val_accuracy: 0.9782\n",
            "Epoch 98/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0688 - accuracy: 0.9795 - val_loss: 0.7515 - val_accuracy: 0.9478\n",
            "Epoch 99/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0502 - accuracy: 0.9845 - val_loss: 0.0872 - val_accuracy: 0.9703\n",
            "Epoch 100/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0601 - accuracy: 0.9812 - val_loss: 0.2055 - val_accuracy: 0.9721\n",
            "Epoch 101/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0442 - accuracy: 0.9865 - val_loss: 0.2217 - val_accuracy: 0.9788\n",
            "Epoch 102/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0485 - accuracy: 0.9851 - val_loss: 0.1198 - val_accuracy: 0.9794\n",
            "Epoch 103/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0504 - accuracy: 0.9850 - val_loss: 0.2207 - val_accuracy: 0.9715\n",
            "Epoch 104/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0411 - accuracy: 0.9883 - val_loss: 0.2389 - val_accuracy: 0.9684\n",
            "Epoch 105/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0473 - accuracy: 0.9851 - val_loss: 0.6172 - val_accuracy: 0.9496\n",
            "Epoch 106/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0552 - accuracy: 0.9839 - val_loss: 0.2305 - val_accuracy: 0.9733\n",
            "Epoch 107/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0576 - accuracy: 0.9818 - val_loss: 0.1839 - val_accuracy: 0.9769\n",
            "Epoch 108/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0572 - accuracy: 0.9851 - val_loss: 0.1804 - val_accuracy: 0.9666\n",
            "Epoch 109/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0500 - accuracy: 0.9868 - val_loss: 0.4518 - val_accuracy: 0.9691\n",
            "Epoch 110/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0421 - accuracy: 0.9883 - val_loss: 0.2941 - val_accuracy: 0.9751\n",
            "Epoch 111/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0438 - accuracy: 0.9871 - val_loss: 0.1748 - val_accuracy: 0.9666\n",
            "Epoch 112/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0473 - accuracy: 0.9871 - val_loss: 0.1975 - val_accuracy: 0.9806\n",
            "Epoch 113/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0484 - accuracy: 0.9871 - val_loss: 0.1530 - val_accuracy: 0.9794\n",
            "Epoch 114/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0398 - accuracy: 0.9895 - val_loss: 0.2290 - val_accuracy: 0.9830\n",
            "Epoch 115/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0423 - accuracy: 0.9873 - val_loss: 0.2427 - val_accuracy: 0.9806\n",
            "Epoch 116/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0384 - accuracy: 0.9891 - val_loss: 0.1602 - val_accuracy: 0.9812\n",
            "Epoch 117/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0527 - accuracy: 0.9854 - val_loss: 0.1956 - val_accuracy: 0.9757\n",
            "Epoch 118/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0494 - accuracy: 0.9847 - val_loss: 2615.8030 - val_accuracy: 0.8883\n",
            "Epoch 119/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0550 - accuracy: 0.9853 - val_loss: 0.2359 - val_accuracy: 0.9721\n",
            "Epoch 120/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0377 - accuracy: 0.9889 - val_loss: 0.1407 - val_accuracy: 0.9782\n",
            "Epoch 121/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0415 - accuracy: 0.9871 - val_loss: 0.4759 - val_accuracy: 0.9715\n",
            "Epoch 122/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0397 - accuracy: 0.9886 - val_loss: 0.2791 - val_accuracy: 0.9739\n",
            "Epoch 123/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0426 - accuracy: 0.9888 - val_loss: 0.3331 - val_accuracy: 0.9715\n",
            "Epoch 124/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0487 - accuracy: 0.9856 - val_loss: 0.1356 - val_accuracy: 0.9769\n",
            "Epoch 125/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0419 - accuracy: 0.9876 - val_loss: 0.1976 - val_accuracy: 0.9739\n",
            "Epoch 126/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0521 - accuracy: 0.9860 - val_loss: 0.2654 - val_accuracy: 0.9763\n",
            "Epoch 127/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0494 - accuracy: 0.9866 - val_loss: 0.5761 - val_accuracy: 0.9569\n",
            "Epoch 128/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0384 - accuracy: 0.9898 - val_loss: 0.1158 - val_accuracy: 0.9794\n",
            "Epoch 129/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0431 - accuracy: 0.9891 - val_loss: 0.1781 - val_accuracy: 0.9751\n",
            "Epoch 130/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0446 - accuracy: 0.9877 - val_loss: 0.3485 - val_accuracy: 0.9727\n",
            "Epoch 131/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0331 - accuracy: 0.9910 - val_loss: 0.3606 - val_accuracy: 0.9678\n",
            "Epoch 132/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0351 - accuracy: 0.9894 - val_loss: 0.2008 - val_accuracy: 0.9763\n",
            "Epoch 133/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0356 - accuracy: 0.9906 - val_loss: 0.6833 - val_accuracy: 0.9624\n",
            "Epoch 134/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0389 - accuracy: 0.9904 - val_loss: 17.6394 - val_accuracy: 0.9011\n",
            "Epoch 135/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0441 - accuracy: 0.9897 - val_loss: 0.1464 - val_accuracy: 0.9775\n",
            "Epoch 136/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0315 - accuracy: 0.9909 - val_loss: 0.1645 - val_accuracy: 0.9812\n",
            "Epoch 137/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0279 - accuracy: 0.9923 - val_loss: 0.2682 - val_accuracy: 0.9782\n",
            "Epoch 138/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0268 - accuracy: 0.9930 - val_loss: 0.1453 - val_accuracy: 0.9800\n",
            "Epoch 139/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0386 - accuracy: 0.9897 - val_loss: 1.2984 - val_accuracy: 0.9363\n",
            "Epoch 140/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0346 - accuracy: 0.9914 - val_loss: 0.2051 - val_accuracy: 0.9205\n",
            "Epoch 141/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0471 - accuracy: 0.9874 - val_loss: 0.3923 - val_accuracy: 0.9757\n",
            "Epoch 142/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0543 - accuracy: 0.9848 - val_loss: 0.2194 - val_accuracy: 0.9739\n",
            "Epoch 143/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0388 - accuracy: 0.9903 - val_loss: 0.3663 - val_accuracy: 0.9745\n",
            "Epoch 144/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0399 - accuracy: 0.9889 - val_loss: 0.1811 - val_accuracy: 0.9733\n",
            "Epoch 145/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0279 - accuracy: 0.9930 - val_loss: 0.2195 - val_accuracy: 0.9818\n",
            "Epoch 146/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0433 - accuracy: 0.9900 - val_loss: 0.2435 - val_accuracy: 0.9788\n",
            "Epoch 147/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0425 - accuracy: 0.9933 - val_loss: 0.2588 - val_accuracy: 0.9721\n",
            "Epoch 148/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0450 - accuracy: 0.9880 - val_loss: 0.3521 - val_accuracy: 0.9757\n",
            "Epoch 149/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0285 - accuracy: 0.9927 - val_loss: 0.2856 - val_accuracy: 0.9812\n",
            "Epoch 150/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0263 - accuracy: 0.9933 - val_loss: 0.2080 - val_accuracy: 0.9800\n",
            "Epoch 151/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0173 - accuracy: 0.9964 - val_loss: 0.2262 - val_accuracy: 0.9818\n",
            "Epoch 152/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0504 - accuracy: 0.9903 - val_loss: 0.1248 - val_accuracy: 0.9678\n",
            "Epoch 153/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0286 - accuracy: 0.9926 - val_loss: 0.2826 - val_accuracy: 0.9757\n",
            "Epoch 154/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0309 - accuracy: 0.9914 - val_loss: 0.3258 - val_accuracy: 0.9769\n",
            "Epoch 155/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0282 - accuracy: 0.9927 - val_loss: 0.1698 - val_accuracy: 0.9812\n",
            "Epoch 156/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0270 - accuracy: 0.9939 - val_loss: 0.2597 - val_accuracy: 0.9757\n",
            "Epoch 157/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0269 - accuracy: 0.9927 - val_loss: 0.2861 - val_accuracy: 0.9727\n",
            "Epoch 158/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0317 - accuracy: 0.9923 - val_loss: 0.3159 - val_accuracy: 0.9727\n",
            "Epoch 159/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0227 - accuracy: 0.9942 - val_loss: 0.1806 - val_accuracy: 0.9788\n",
            "Epoch 160/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0256 - accuracy: 0.9933 - val_loss: 0.1718 - val_accuracy: 0.9794\n",
            "Epoch 161/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0225 - accuracy: 0.9945 - val_loss: 0.1686 - val_accuracy: 0.9782\n",
            "Epoch 162/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0259 - accuracy: 0.9942 - val_loss: 0.1452 - val_accuracy: 0.9763\n",
            "Epoch 163/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0263 - accuracy: 0.9930 - val_loss: 0.9490 - val_accuracy: 0.9648\n",
            "Epoch 164/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0452 - accuracy: 0.9904 - val_loss: 0.1359 - val_accuracy: 0.9788\n",
            "Epoch 165/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0304 - accuracy: 0.9932 - val_loss: 0.1704 - val_accuracy: 0.9775\n",
            "Epoch 166/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0201 - accuracy: 0.9950 - val_loss: 0.2903 - val_accuracy: 0.9751\n",
            "Epoch 167/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0263 - accuracy: 0.9936 - val_loss: 0.2045 - val_accuracy: 0.9745\n",
            "Epoch 168/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0242 - accuracy: 0.9953 - val_loss: 0.2773 - val_accuracy: 0.9782\n",
            "Epoch 169/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0237 - accuracy: 0.9936 - val_loss: 0.3570 - val_accuracy: 0.9745\n",
            "Epoch 170/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0277 - accuracy: 0.9930 - val_loss: 0.4352 - val_accuracy: 0.9727\n",
            "Epoch 171/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0179 - accuracy: 0.9956 - val_loss: 0.2642 - val_accuracy: 0.9751\n",
            "Epoch 172/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0245 - accuracy: 0.9935 - val_loss: 0.3368 - val_accuracy: 0.9745\n",
            "Epoch 173/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0303 - accuracy: 0.9923 - val_loss: 0.1018 - val_accuracy: 0.9769\n",
            "Epoch 174/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0254 - accuracy: 0.9935 - val_loss: 0.1524 - val_accuracy: 0.9775\n",
            "Epoch 175/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0261 - accuracy: 0.9935 - val_loss: 0.3200 - val_accuracy: 0.9739\n",
            "Epoch 176/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0196 - accuracy: 0.9950 - val_loss: 0.4342 - val_accuracy: 0.9745\n",
            "Epoch 177/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0340 - accuracy: 0.9929 - val_loss: 0.2085 - val_accuracy: 0.9800\n",
            "Epoch 178/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0193 - accuracy: 0.9948 - val_loss: 0.1820 - val_accuracy: 0.9830\n",
            "Epoch 179/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0193 - accuracy: 0.9953 - val_loss: 0.2874 - val_accuracy: 0.9775\n",
            "Epoch 180/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0257 - accuracy: 0.9938 - val_loss: 0.2458 - val_accuracy: 0.9818\n",
            "Epoch 181/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0340 - accuracy: 0.9933 - val_loss: 0.5580 - val_accuracy: 0.9715\n",
            "Epoch 182/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0350 - accuracy: 0.9906 - val_loss: 0.7655 - val_accuracy: 0.9581\n",
            "Epoch 183/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0205 - accuracy: 0.9951 - val_loss: 0.2464 - val_accuracy: 0.9812\n",
            "Epoch 184/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1230 - accuracy: 0.9803 - val_loss: 0.5137 - val_accuracy: 0.9612\n",
            "Epoch 185/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0619 - accuracy: 0.9833 - val_loss: 5.3923 - val_accuracy: 0.9187\n",
            "Epoch 186/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0974 - accuracy: 0.9862 - val_loss: 21.7638 - val_accuracy: 0.7039\n",
            "Epoch 187/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0415 - accuracy: 0.9885 - val_loss: 0.3222 - val_accuracy: 0.9769\n",
            "Epoch 188/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0277 - accuracy: 0.9920 - val_loss: 0.4561 - val_accuracy: 0.9715\n",
            "Epoch 189/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0443 - accuracy: 0.9929 - val_loss: 0.2856 - val_accuracy: 0.9782\n",
            "Epoch 190/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0161 - accuracy: 0.9964 - val_loss: 0.2866 - val_accuracy: 0.9800\n",
            "Epoch 191/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0191 - accuracy: 0.9948 - val_loss: 0.5297 - val_accuracy: 0.9775\n",
            "Epoch 192/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0449 - accuracy: 0.9927 - val_loss: 1.5748 - val_accuracy: 0.9508\n",
            "Epoch 193/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0426 - accuracy: 0.9906 - val_loss: 0.1751 - val_accuracy: 0.9733\n",
            "Epoch 194/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0315 - accuracy: 0.9920 - val_loss: 0.6774 - val_accuracy: 0.9751\n",
            "Epoch 195/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0183 - accuracy: 0.9959 - val_loss: 0.4428 - val_accuracy: 0.9806\n",
            "Epoch 196/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0245 - accuracy: 0.9951 - val_loss: 0.4500 - val_accuracy: 0.9775\n",
            "Epoch 197/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0252 - accuracy: 0.9944 - val_loss: 0.1927 - val_accuracy: 0.9794\n",
            "Epoch 198/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0563 - accuracy: 0.9941 - val_loss: 0.2965 - val_accuracy: 0.9800\n",
            "Epoch 199/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0280 - accuracy: 0.9939 - val_loss: 0.6653 - val_accuracy: 0.9739\n",
            "Epoch 200/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0223 - accuracy: 0.9945 - val_loss: 0.2167 - val_accuracy: 0.9769\n",
            "Epoch 201/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0306 - accuracy: 0.9936 - val_loss: 0.1137 - val_accuracy: 0.9763\n",
            "Epoch 202/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0250 - accuracy: 0.9951 - val_loss: 0.4274 - val_accuracy: 0.9782\n",
            "Epoch 203/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0479 - accuracy: 0.9961 - val_loss: 1.0757 - val_accuracy: 0.9618\n",
            "Epoch 204/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0350 - accuracy: 0.9932 - val_loss: 0.1591 - val_accuracy: 0.9769\n",
            "Epoch 205/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0177 - accuracy: 0.9956 - val_loss: 0.2587 - val_accuracy: 0.9782\n",
            "Epoch 206/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0225 - accuracy: 0.9954 - val_loss: 0.2155 - val_accuracy: 0.9733\n",
            "Epoch 207/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0257 - accuracy: 0.9930 - val_loss: 0.4540 - val_accuracy: 0.9782\n",
            "Epoch 208/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0182 - accuracy: 0.9958 - val_loss: 0.2808 - val_accuracy: 0.9775\n",
            "Epoch 209/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0159 - accuracy: 0.9961 - val_loss: 0.4292 - val_accuracy: 0.9751\n",
            "Epoch 210/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0212 - accuracy: 0.9945 - val_loss: 0.6493 - val_accuracy: 0.9684\n",
            "Epoch 211/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0168 - accuracy: 0.9961 - val_loss: 0.5441 - val_accuracy: 0.9782\n",
            "Epoch 212/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0251 - accuracy: 0.9950 - val_loss: 0.1596 - val_accuracy: 0.9739\n",
            "Epoch 213/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0157 - accuracy: 0.9961 - val_loss: 0.3955 - val_accuracy: 0.9775\n",
            "Epoch 214/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0475 - accuracy: 0.9912 - val_loss: 0.9962 - val_accuracy: 0.9569\n",
            "Epoch 215/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0393 - accuracy: 0.9883 - val_loss: 0.6126 - val_accuracy: 0.9624\n",
            "Epoch 216/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0639 - accuracy: 0.9869 - val_loss: 1.5365 - val_accuracy: 0.9296\n",
            "Epoch 217/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0453 - accuracy: 0.9894 - val_loss: 0.1348 - val_accuracy: 0.9642\n",
            "Epoch 218/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0390 - accuracy: 0.9920 - val_loss: 0.2264 - val_accuracy: 0.9691\n",
            "Epoch 219/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0560 - accuracy: 0.9932 - val_loss: 0.7268 - val_accuracy: 0.9678\n",
            "Epoch 220/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0259 - accuracy: 0.9936 - val_loss: 7.3981 - val_accuracy: 0.8653\n",
            "Epoch 221/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0237 - accuracy: 0.9944 - val_loss: 0.3655 - val_accuracy: 0.9794\n",
            "Epoch 222/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0189 - accuracy: 0.9954 - val_loss: 0.4758 - val_accuracy: 0.9745\n",
            "Epoch 223/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0223 - accuracy: 0.9945 - val_loss: 0.5505 - val_accuracy: 0.9636\n",
            "Epoch 224/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0216 - accuracy: 0.9947 - val_loss: 0.4834 - val_accuracy: 0.9751\n",
            "Epoch 225/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0331 - accuracy: 0.9938 - val_loss: 0.4099 - val_accuracy: 0.9812\n",
            "Epoch 226/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0210 - accuracy: 0.9947 - val_loss: 0.2540 - val_accuracy: 0.9782\n",
            "Epoch 227/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0411 - accuracy: 0.9920 - val_loss: 0.3053 - val_accuracy: 0.9757\n",
            "Epoch 228/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0344 - accuracy: 0.9932 - val_loss: 0.5054 - val_accuracy: 0.9709\n",
            "Epoch 229/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0239 - accuracy: 0.9953 - val_loss: 0.2984 - val_accuracy: 0.9757\n",
            "Epoch 230/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0283 - accuracy: 0.9941 - val_loss: 0.7884 - val_accuracy: 0.9660\n",
            "Epoch 231/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0223 - accuracy: 0.9944 - val_loss: 0.3155 - val_accuracy: 0.9769\n",
            "Epoch 232/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0209 - accuracy: 0.9948 - val_loss: 0.2562 - val_accuracy: 0.9763\n",
            "Epoch 233/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0189 - accuracy: 0.9958 - val_loss: 0.4395 - val_accuracy: 0.9745\n",
            "Epoch 234/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0222 - accuracy: 0.9941 - val_loss: 0.6509 - val_accuracy: 0.9709\n",
            "Epoch 235/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0345 - accuracy: 0.9939 - val_loss: 0.5506 - val_accuracy: 0.9678\n",
            "Epoch 236/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0479 - accuracy: 0.9926 - val_loss: 0.5810 - val_accuracy: 0.9739\n",
            "Epoch 237/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0253 - accuracy: 0.9947 - val_loss: 0.5565 - val_accuracy: 0.9697\n",
            "Epoch 238/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0319 - accuracy: 0.9927 - val_loss: 0.1693 - val_accuracy: 0.9763\n",
            "Epoch 239/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0340 - accuracy: 0.9953 - val_loss: 1.4990 - val_accuracy: 0.9593\n",
            "Epoch 240/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0260 - accuracy: 0.9945 - val_loss: 0.3319 - val_accuracy: 0.9812\n",
            "Epoch 241/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0182 - accuracy: 0.9956 - val_loss: 0.6380 - val_accuracy: 0.9733\n",
            "Epoch 242/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0263 - accuracy: 0.9950 - val_loss: 0.3377 - val_accuracy: 0.9806\n",
            "Epoch 243/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0137 - accuracy: 0.9967 - val_loss: 0.2501 - val_accuracy: 0.9763\n",
            "Epoch 244/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0225 - accuracy: 0.9954 - val_loss: 0.3001 - val_accuracy: 0.9763\n",
            "Epoch 245/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0414 - accuracy: 0.9932 - val_loss: 0.1910 - val_accuracy: 0.9733\n",
            "Epoch 246/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0322 - accuracy: 0.9917 - val_loss: 0.5333 - val_accuracy: 0.9739\n",
            "Epoch 247/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0205 - accuracy: 0.9965 - val_loss: 0.3127 - val_accuracy: 0.9782\n",
            "Epoch 248/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0144 - accuracy: 0.9965 - val_loss: 0.7607 - val_accuracy: 0.9678\n",
            "Epoch 249/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0245 - accuracy: 0.9947 - val_loss: 0.2288 - val_accuracy: 0.9806\n",
            "Epoch 250/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0187 - accuracy: 0.9954 - val_loss: 0.2637 - val_accuracy: 0.9812\n",
            "Epoch 251/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0163 - accuracy: 0.9967 - val_loss: 0.3233 - val_accuracy: 0.9794\n",
            "Epoch 252/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0117 - accuracy: 0.9977 - val_loss: 0.2976 - val_accuracy: 0.9806\n",
            "Epoch 253/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0095 - accuracy: 0.9983 - val_loss: 0.3831 - val_accuracy: 0.9769\n",
            "Epoch 254/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0119 - accuracy: 0.9973 - val_loss: 0.5452 - val_accuracy: 0.9739\n",
            "Epoch 255/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0277 - accuracy: 0.9945 - val_loss: 0.1854 - val_accuracy: 0.9757\n",
            "Epoch 256/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0130 - accuracy: 0.9971 - val_loss: 0.3097 - val_accuracy: 0.9794\n",
            "Epoch 257/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0161 - accuracy: 0.9968 - val_loss: 0.2142 - val_accuracy: 0.9830\n",
            "Epoch 258/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0156 - accuracy: 0.9967 - val_loss: 0.3705 - val_accuracy: 0.9794\n",
            "Epoch 259/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0291 - accuracy: 0.9947 - val_loss: 0.1969 - val_accuracy: 0.9775\n",
            "Epoch 260/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0216 - accuracy: 0.9956 - val_loss: 0.7427 - val_accuracy: 0.9678\n",
            "Epoch 261/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0259 - accuracy: 0.9941 - val_loss: 0.3848 - val_accuracy: 0.9745\n",
            "Epoch 262/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0243 - accuracy: 0.9942 - val_loss: 0.2186 - val_accuracy: 0.9794\n",
            "Epoch 263/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0134 - accuracy: 0.9973 - val_loss: 0.3893 - val_accuracy: 0.9769\n",
            "Epoch 264/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0181 - accuracy: 0.9962 - val_loss: 0.6234 - val_accuracy: 0.9739\n",
            "Epoch 265/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0221 - accuracy: 0.9953 - val_loss: 0.2167 - val_accuracy: 0.9806\n",
            "Epoch 266/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0173 - accuracy: 0.9962 - val_loss: 0.1690 - val_accuracy: 0.9800\n",
            "Epoch 267/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0298 - accuracy: 0.9936 - val_loss: 1.6547 - val_accuracy: 0.9478\n",
            "Epoch 268/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0160 - accuracy: 0.9967 - val_loss: 0.3260 - val_accuracy: 0.9788\n",
            "Epoch 269/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0158 - accuracy: 0.9964 - val_loss: 0.6257 - val_accuracy: 0.9745\n",
            "Epoch 270/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0123 - accuracy: 0.9974 - val_loss: 0.4680 - val_accuracy: 0.9757\n",
            "Epoch 271/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0140 - accuracy: 0.9965 - val_loss: 0.3719 - val_accuracy: 0.9830\n",
            "Epoch 272/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0166 - accuracy: 0.9962 - val_loss: 0.2695 - val_accuracy: 0.9782\n",
            "Epoch 273/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0408 - accuracy: 0.9936 - val_loss: 0.4422 - val_accuracy: 0.9745\n",
            "Epoch 274/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0403 - accuracy: 0.9932 - val_loss: 0.4028 - val_accuracy: 0.9672\n",
            "Epoch 275/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0327 - accuracy: 0.9935 - val_loss: 0.3282 - val_accuracy: 0.9800\n",
            "Epoch 276/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0207 - accuracy: 0.9951 - val_loss: 0.3562 - val_accuracy: 0.9806\n",
            "Epoch 277/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0195 - accuracy: 0.9956 - val_loss: 0.3830 - val_accuracy: 0.9806\n",
            "Epoch 278/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0135 - accuracy: 0.9968 - val_loss: 0.6188 - val_accuracy: 0.9775\n",
            "Epoch 279/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0154 - accuracy: 0.9964 - val_loss: 0.5353 - val_accuracy: 0.9800\n",
            "Epoch 280/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0153 - accuracy: 0.9970 - val_loss: 0.7795 - val_accuracy: 0.9733\n",
            "Epoch 281/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0110 - accuracy: 0.9979 - val_loss: 0.4280 - val_accuracy: 0.9794\n",
            "Epoch 282/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0250 - accuracy: 0.9947 - val_loss: 3.6254 - val_accuracy: 0.9399\n",
            "Epoch 283/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0170 - accuracy: 0.9973 - val_loss: 0.4947 - val_accuracy: 0.9751\n",
            "Epoch 284/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0407 - accuracy: 0.9924 - val_loss: 0.1984 - val_accuracy: 0.9733\n",
            "Epoch 285/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0265 - accuracy: 0.9929 - val_loss: 2.4898 - val_accuracy: 0.9430\n",
            "Epoch 286/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0320 - accuracy: 0.9942 - val_loss: 0.4383 - val_accuracy: 0.9757\n",
            "Epoch 287/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0290 - accuracy: 0.9941 - val_loss: 0.7001 - val_accuracy: 0.9672\n",
            "Epoch 288/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0178 - accuracy: 0.9959 - val_loss: 0.4198 - val_accuracy: 0.9806\n",
            "Epoch 289/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0084 - accuracy: 0.9983 - val_loss: 0.7606 - val_accuracy: 0.9757\n",
            "Epoch 290/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0068 - accuracy: 0.9989 - val_loss: 0.4220 - val_accuracy: 0.9782\n",
            "Epoch 291/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0165 - accuracy: 0.9961 - val_loss: 0.2824 - val_accuracy: 0.9812\n",
            "Epoch 292/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0127 - accuracy: 0.9974 - val_loss: 0.4872 - val_accuracy: 0.9763\n",
            "Epoch 293/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0282 - accuracy: 0.9944 - val_loss: 0.7538 - val_accuracy: 0.9709\n",
            "Epoch 294/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0264 - accuracy: 0.9953 - val_loss: 0.2333 - val_accuracy: 0.9818\n",
            "Epoch 295/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0183 - accuracy: 0.9958 - val_loss: 0.3215 - val_accuracy: 0.9842\n",
            "Epoch 296/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0130 - accuracy: 0.9971 - val_loss: 0.2655 - val_accuracy: 0.9842\n",
            "Epoch 297/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0233 - accuracy: 0.9944 - val_loss: 0.2232 - val_accuracy: 0.9824\n",
            "Epoch 298/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0336 - accuracy: 0.9956 - val_loss: 0.3333 - val_accuracy: 0.9751\n",
            "Epoch 299/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0287 - accuracy: 0.9962 - val_loss: 0.4715 - val_accuracy: 0.9788\n",
            "Epoch 300/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0147 - accuracy: 0.9973 - val_loss: 0.1452 - val_accuracy: 0.9800\n",
            "Epoch 301/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0178 - accuracy: 0.9965 - val_loss: 0.3315 - val_accuracy: 0.9733\n",
            "Epoch 302/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0172 - accuracy: 0.9964 - val_loss: 0.2341 - val_accuracy: 0.9800\n",
            "Epoch 303/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0140 - accuracy: 0.9973 - val_loss: 0.2178 - val_accuracy: 0.9836\n",
            "Epoch 304/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0140 - accuracy: 0.9968 - val_loss: 0.1933 - val_accuracy: 0.9830\n",
            "Epoch 305/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0097 - accuracy: 0.9982 - val_loss: 0.3108 - val_accuracy: 0.9800\n",
            "Epoch 306/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0090 - accuracy: 0.9982 - val_loss: 0.3873 - val_accuracy: 0.9800\n",
            "Epoch 307/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0137 - accuracy: 0.9973 - val_loss: 9.1232 - val_accuracy: 0.9606\n",
            "Epoch 308/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0459 - accuracy: 0.9938 - val_loss: 0.4334 - val_accuracy: 0.9739\n",
            "Epoch 309/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0288 - accuracy: 0.9936 - val_loss: 0.2362 - val_accuracy: 0.9842\n",
            "Epoch 310/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0228 - accuracy: 0.9951 - val_loss: 0.1853 - val_accuracy: 0.9812\n",
            "Epoch 311/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0160 - accuracy: 0.9965 - val_loss: 0.3447 - val_accuracy: 0.9818\n",
            "Epoch 312/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0091 - accuracy: 0.9979 - val_loss: 0.5170 - val_accuracy: 0.9775\n",
            "Epoch 313/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0231 - accuracy: 0.9959 - val_loss: 0.2792 - val_accuracy: 0.9812\n",
            "Epoch 314/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0146 - accuracy: 0.9971 - val_loss: 0.3455 - val_accuracy: 0.9800\n",
            "Epoch 315/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0145 - accuracy: 0.9962 - val_loss: 0.4522 - val_accuracy: 0.9800\n",
            "Epoch 316/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0306 - accuracy: 0.9961 - val_loss: 0.3116 - val_accuracy: 0.9775\n",
            "Epoch 317/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0171 - accuracy: 0.9964 - val_loss: 0.6190 - val_accuracy: 0.9721\n",
            "Epoch 318/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0260 - accuracy: 0.9950 - val_loss: 0.4791 - val_accuracy: 0.9763\n",
            "Epoch 319/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0223 - accuracy: 0.9950 - val_loss: 0.2128 - val_accuracy: 0.9824\n",
            "Epoch 320/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0166 - accuracy: 0.9964 - val_loss: 0.3655 - val_accuracy: 0.9739\n",
            "Epoch 321/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0142 - accuracy: 0.9967 - val_loss: 0.1863 - val_accuracy: 0.9800\n",
            "Epoch 322/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0132 - accuracy: 0.9973 - val_loss: 0.2470 - val_accuracy: 0.9806\n",
            "Epoch 323/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0139 - accuracy: 0.9970 - val_loss: 0.8634 - val_accuracy: 0.9672\n",
            "Epoch 324/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0377 - accuracy: 0.9967 - val_loss: 0.2234 - val_accuracy: 0.9794\n",
            "Epoch 325/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0096 - accuracy: 0.9982 - val_loss: 0.4442 - val_accuracy: 0.9782\n",
            "Epoch 326/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0360 - accuracy: 0.9936 - val_loss: 0.1884 - val_accuracy: 0.9703\n",
            "Epoch 327/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0388 - accuracy: 0.9923 - val_loss: 0.4748 - val_accuracy: 0.9763\n",
            "Epoch 328/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0375 - accuracy: 0.9948 - val_loss: 0.4389 - val_accuracy: 0.9800\n",
            "Epoch 329/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0188 - accuracy: 0.9961 - val_loss: 0.2457 - val_accuracy: 0.9800\n",
            "Epoch 330/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0146 - accuracy: 0.9964 - val_loss: 0.5581 - val_accuracy: 0.9739\n",
            "Epoch 331/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0158 - accuracy: 0.9965 - val_loss: 0.3511 - val_accuracy: 0.9806\n",
            "Epoch 332/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0097 - accuracy: 0.9986 - val_loss: 0.4602 - val_accuracy: 0.9800\n",
            "Epoch 333/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0090 - accuracy: 0.9982 - val_loss: 0.4427 - val_accuracy: 0.9794\n",
            "Epoch 334/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0121 - accuracy: 0.9973 - val_loss: 0.4918 - val_accuracy: 0.9824\n",
            "Epoch 335/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0145 - accuracy: 0.9979 - val_loss: 0.6305 - val_accuracy: 0.9763\n",
            "Epoch 336/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0150 - accuracy: 0.9974 - val_loss: 0.1949 - val_accuracy: 0.9618\n",
            "Epoch 337/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0189 - accuracy: 0.9964 - val_loss: 0.5147 - val_accuracy: 0.9788\n",
            "Epoch 338/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0059 - accuracy: 0.9988 - val_loss: 0.4081 - val_accuracy: 0.9818\n",
            "Epoch 339/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0059 - accuracy: 0.9989 - val_loss: 0.9314 - val_accuracy: 0.9733\n",
            "Epoch 340/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0103 - accuracy: 0.9979 - val_loss: 0.4646 - val_accuracy: 0.9800\n",
            "Epoch 341/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0345 - accuracy: 0.9953 - val_loss: 101.4035 - val_accuracy: 0.8950\n",
            "Epoch 342/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0159 - accuracy: 0.9962 - val_loss: 0.8614 - val_accuracy: 0.9763\n",
            "Epoch 343/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0099 - accuracy: 0.9977 - val_loss: 0.6030 - val_accuracy: 0.9806\n",
            "Epoch 344/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0170 - accuracy: 0.9968 - val_loss: 0.6343 - val_accuracy: 0.9788\n",
            "Epoch 345/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0105 - accuracy: 0.9979 - val_loss: 0.4891 - val_accuracy: 0.9782\n",
            "Epoch 346/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0073 - accuracy: 0.9986 - val_loss: 1.0211 - val_accuracy: 0.9709\n",
            "Epoch 347/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0150 - accuracy: 0.9970 - val_loss: 1.0066 - val_accuracy: 0.9757\n",
            "Epoch 348/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0122 - accuracy: 0.9976 - val_loss: 0.2492 - val_accuracy: 0.9824\n",
            "Epoch 349/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0144 - accuracy: 0.9970 - val_loss: 0.2232 - val_accuracy: 0.9812\n",
            "Epoch 350/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0092 - accuracy: 0.9982 - val_loss: 0.5502 - val_accuracy: 0.9824\n",
            "Epoch 351/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0220 - accuracy: 0.9962 - val_loss: 0.4215 - val_accuracy: 0.9812\n",
            "Epoch 352/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0362 - accuracy: 0.9933 - val_loss: 0.3131 - val_accuracy: 0.9812\n",
            "Epoch 353/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0249 - accuracy: 0.9951 - val_loss: 0.1994 - val_accuracy: 0.9794\n",
            "Epoch 354/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0226 - accuracy: 0.9954 - val_loss: 0.8847 - val_accuracy: 0.9769\n",
            "Epoch 355/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0113 - accuracy: 0.9974 - val_loss: 0.5084 - val_accuracy: 0.9824\n",
            "Epoch 356/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0189 - accuracy: 0.9973 - val_loss: 0.7112 - val_accuracy: 0.9769\n",
            "Epoch 357/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0159 - accuracy: 0.9964 - val_loss: 0.4090 - val_accuracy: 0.9818\n",
            "Epoch 358/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0130 - accuracy: 0.9974 - val_loss: 0.4491 - val_accuracy: 0.9788\n",
            "Epoch 359/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0203 - accuracy: 0.9976 - val_loss: 1.9285 - val_accuracy: 0.9593\n",
            "Epoch 360/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0299 - accuracy: 0.9942 - val_loss: 0.5610 - val_accuracy: 0.9775\n",
            "Epoch 361/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0137 - accuracy: 0.9968 - val_loss: 0.9071 - val_accuracy: 0.9769\n",
            "Epoch 362/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0194 - accuracy: 0.9968 - val_loss: 0.4084 - val_accuracy: 0.9751\n",
            "Epoch 363/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0298 - accuracy: 0.9929 - val_loss: 0.2420 - val_accuracy: 0.9775\n",
            "Epoch 364/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0234 - accuracy: 0.9950 - val_loss: 0.2692 - val_accuracy: 0.9775\n",
            "Epoch 365/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0113 - accuracy: 0.9976 - val_loss: 0.4895 - val_accuracy: 0.9782\n",
            "Epoch 366/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0106 - accuracy: 0.9979 - val_loss: 0.8787 - val_accuracy: 0.9709\n",
            "Epoch 367/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0314 - accuracy: 0.9967 - val_loss: 0.4258 - val_accuracy: 0.9715\n",
            "Epoch 368/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0213 - accuracy: 0.9976 - val_loss: 0.2923 - val_accuracy: 0.9806\n",
            "Epoch 369/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0223 - accuracy: 0.9953 - val_loss: 1.0385 - val_accuracy: 0.9721\n",
            "Epoch 370/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0141 - accuracy: 0.9974 - val_loss: 0.5567 - val_accuracy: 0.9775\n",
            "Epoch 371/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0096 - accuracy: 0.9980 - val_loss: 0.3731 - val_accuracy: 0.9775\n",
            "Epoch 372/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0280 - accuracy: 0.9956 - val_loss: 0.2033 - val_accuracy: 0.9642\n",
            "Epoch 373/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0175 - accuracy: 0.9961 - val_loss: 0.9235 - val_accuracy: 0.9782\n",
            "Epoch 374/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0207 - accuracy: 0.9964 - val_loss: 0.4370 - val_accuracy: 0.9794\n",
            "Epoch 375/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0215 - accuracy: 0.9958 - val_loss: 1.0530 - val_accuracy: 0.9642\n",
            "Epoch 376/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0124 - accuracy: 0.9971 - val_loss: 0.7406 - val_accuracy: 0.9794\n",
            "Epoch 377/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0222 - accuracy: 0.9962 - val_loss: 5.1019 - val_accuracy: 0.9672\n",
            "Epoch 378/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0161 - accuracy: 0.9964 - val_loss: 0.6402 - val_accuracy: 0.9775\n",
            "Epoch 379/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0076 - accuracy: 0.9983 - val_loss: 0.5453 - val_accuracy: 0.9812\n",
            "Epoch 380/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0085 - accuracy: 0.9982 - val_loss: 0.6194 - val_accuracy: 0.9812\n",
            "Epoch 381/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0079 - accuracy: 0.9980 - val_loss: 0.5983 - val_accuracy: 0.9818\n",
            "Epoch 382/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0083 - accuracy: 0.9983 - val_loss: 0.6473 - val_accuracy: 0.9812\n",
            "Epoch 383/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0100 - accuracy: 0.9980 - val_loss: 0.5506 - val_accuracy: 0.9812\n",
            "Epoch 384/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0093 - accuracy: 0.9985 - val_loss: 0.6848 - val_accuracy: 0.9782\n",
            "Epoch 385/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0068 - accuracy: 0.9986 - val_loss: 0.6761 - val_accuracy: 0.9806\n",
            "Epoch 386/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0140 - accuracy: 0.9971 - val_loss: 1.0042 - val_accuracy: 0.9763\n",
            "Epoch 387/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0095 - accuracy: 0.9982 - val_loss: 0.8421 - val_accuracy: 0.9806\n",
            "Epoch 388/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0105 - accuracy: 0.9977 - val_loss: 0.4637 - val_accuracy: 0.9800\n",
            "Epoch 389/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0106 - accuracy: 0.9976 - val_loss: 0.6076 - val_accuracy: 0.9751\n",
            "Epoch 390/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0758 - accuracy: 0.9959 - val_loss: 197.6726 - val_accuracy: 0.9205\n",
            "Epoch 391/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0346 - accuracy: 0.9924 - val_loss: 0.4943 - val_accuracy: 0.9800\n",
            "Epoch 392/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0937 - accuracy: 0.9915 - val_loss: 0.2038 - val_accuracy: 0.9824\n",
            "Epoch 393/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0303 - accuracy: 0.9944 - val_loss: 0.5382 - val_accuracy: 0.9794\n",
            "Epoch 394/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0249 - accuracy: 0.9950 - val_loss: 0.4126 - val_accuracy: 0.9775\n",
            "Epoch 395/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0138 - accuracy: 0.9974 - val_loss: 0.5934 - val_accuracy: 0.9769\n",
            "Epoch 396/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0073 - accuracy: 0.9985 - val_loss: 0.6537 - val_accuracy: 0.9782\n",
            "Epoch 397/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0162 - accuracy: 0.9976 - val_loss: 0.7115 - val_accuracy: 0.9715\n",
            "Epoch 398/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0177 - accuracy: 0.9976 - val_loss: 0.2995 - val_accuracy: 0.9763\n",
            "Epoch 399/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0131 - accuracy: 0.9973 - val_loss: 0.6651 - val_accuracy: 0.9782\n",
            "Epoch 400/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0155 - accuracy: 0.9970 - val_loss: 0.3832 - val_accuracy: 0.9788\n",
            "Epoch 401/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0229 - accuracy: 0.9959 - val_loss: 0.7064 - val_accuracy: 0.9794\n",
            "Epoch 402/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0146 - accuracy: 0.9968 - val_loss: 0.4634 - val_accuracy: 0.9794\n",
            "Epoch 403/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0342 - accuracy: 0.9968 - val_loss: 0.3590 - val_accuracy: 0.9812\n",
            "Epoch 404/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0125 - accuracy: 0.9974 - val_loss: 0.4808 - val_accuracy: 0.9842\n",
            "Epoch 405/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0132 - accuracy: 0.9971 - val_loss: 0.8553 - val_accuracy: 0.9806\n",
            "Epoch 406/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0084 - accuracy: 0.9980 - val_loss: 0.5093 - val_accuracy: 0.9806\n",
            "Epoch 407/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0142 - accuracy: 0.9980 - val_loss: 0.8885 - val_accuracy: 0.9769\n",
            "Epoch 408/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0118 - accuracy: 0.9983 - val_loss: 0.9057 - val_accuracy: 0.9697\n",
            "Epoch 409/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0180 - accuracy: 0.9976 - val_loss: 0.7474 - val_accuracy: 0.9709\n",
            "Epoch 410/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0168 - accuracy: 0.9965 - val_loss: 0.2910 - val_accuracy: 0.9818\n",
            "Epoch 411/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0102 - accuracy: 0.9976 - val_loss: 10.5963 - val_accuracy: 0.9126\n",
            "Epoch 412/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0103 - accuracy: 0.9983 - val_loss: 1.3837 - val_accuracy: 0.9697\n",
            "Epoch 413/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0159 - accuracy: 0.9968 - val_loss: 0.6068 - val_accuracy: 0.9794\n",
            "Epoch 414/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0198 - accuracy: 0.9967 - val_loss: 0.4736 - val_accuracy: 0.9763\n",
            "Epoch 415/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0071 - accuracy: 0.9988 - val_loss: 0.7627 - val_accuracy: 0.9775\n",
            "Epoch 416/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0151 - accuracy: 0.9971 - val_loss: 0.4791 - val_accuracy: 0.9812\n",
            "Epoch 417/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0122 - accuracy: 0.9973 - val_loss: 0.3662 - val_accuracy: 0.9782\n",
            "Epoch 418/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0161 - accuracy: 0.9968 - val_loss: 0.6136 - val_accuracy: 0.9666\n",
            "Epoch 419/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0527 - accuracy: 0.9939 - val_loss: 0.5252 - val_accuracy: 0.9782\n",
            "Epoch 420/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0143 - accuracy: 0.9968 - val_loss: 0.6551 - val_accuracy: 0.9775\n",
            "Epoch 421/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0137 - accuracy: 0.9977 - val_loss: 1.0109 - val_accuracy: 0.9684\n",
            "Epoch 422/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0177 - accuracy: 0.9954 - val_loss: 1.0312 - val_accuracy: 0.9678\n",
            "Epoch 423/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0177 - accuracy: 0.9965 - val_loss: 0.3813 - val_accuracy: 0.9788\n",
            "Epoch 424/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0056 - accuracy: 0.9991 - val_loss: 0.4981 - val_accuracy: 0.9775\n",
            "Epoch 425/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0084 - accuracy: 0.9983 - val_loss: 0.6403 - val_accuracy: 0.9775\n",
            "Epoch 426/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0214 - accuracy: 0.9979 - val_loss: 0.4664 - val_accuracy: 0.9775\n",
            "Epoch 427/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0138 - accuracy: 0.9973 - val_loss: 0.2949 - val_accuracy: 0.9812\n",
            "Epoch 428/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0112 - accuracy: 0.9977 - val_loss: 0.2500 - val_accuracy: 0.9769\n",
            "Epoch 429/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0219 - accuracy: 0.9958 - val_loss: 0.6274 - val_accuracy: 0.9654\n",
            "Epoch 430/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0081 - accuracy: 0.9985 - val_loss: 0.4743 - val_accuracy: 0.9782\n",
            "Epoch 431/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0107 - accuracy: 0.9973 - val_loss: 0.4627 - val_accuracy: 0.9782\n",
            "Epoch 432/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0138 - accuracy: 0.9971 - val_loss: 0.3645 - val_accuracy: 0.9806\n",
            "Epoch 433/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0125 - accuracy: 0.9971 - val_loss: 0.4012 - val_accuracy: 0.9806\n",
            "Epoch 434/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0073 - accuracy: 0.9988 - val_loss: 0.4908 - val_accuracy: 0.9806\n",
            "Epoch 435/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0066 - accuracy: 0.9991 - val_loss: 0.5715 - val_accuracy: 0.9794\n",
            "Epoch 436/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0384 - accuracy: 0.9920 - val_loss: 0.1070 - val_accuracy: 0.9830\n",
            "Epoch 437/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0125 - accuracy: 0.9973 - val_loss: 0.3605 - val_accuracy: 0.9800\n",
            "Epoch 438/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0109 - accuracy: 0.9979 - val_loss: 0.3068 - val_accuracy: 0.9836\n",
            "Epoch 439/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0108 - accuracy: 0.9977 - val_loss: 0.3438 - val_accuracy: 0.9818\n",
            "Epoch 440/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0108 - accuracy: 0.9979 - val_loss: 0.2994 - val_accuracy: 0.9830\n",
            "Epoch 441/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0167 - accuracy: 0.9967 - val_loss: 0.2588 - val_accuracy: 0.9836\n",
            "Epoch 442/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0080 - accuracy: 0.9982 - val_loss: 0.3107 - val_accuracy: 0.9842\n",
            "Epoch 443/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0081 - accuracy: 0.9979 - val_loss: 0.3995 - val_accuracy: 0.9818\n",
            "Epoch 444/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0316 - accuracy: 0.9959 - val_loss: 1.3206 - val_accuracy: 0.9691\n",
            "Epoch 445/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0162 - accuracy: 0.9967 - val_loss: 0.7042 - val_accuracy: 0.9800\n",
            "Epoch 446/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0102 - accuracy: 0.9974 - val_loss: 0.5842 - val_accuracy: 0.9812\n",
            "Epoch 447/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0156 - accuracy: 0.9974 - val_loss: 0.9281 - val_accuracy: 0.9757\n",
            "Epoch 448/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0099 - accuracy: 0.9979 - val_loss: 0.4317 - val_accuracy: 0.9818\n",
            "Epoch 449/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0288 - accuracy: 0.9956 - val_loss: 0.2640 - val_accuracy: 0.9794\n",
            "Epoch 450/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0083 - accuracy: 0.9982 - val_loss: 0.4506 - val_accuracy: 0.9806\n",
            "Epoch 451/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0266 - accuracy: 0.9970 - val_loss: 0.6031 - val_accuracy: 0.9678\n",
            "Epoch 452/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0207 - accuracy: 0.9954 - val_loss: 0.4241 - val_accuracy: 0.9769\n",
            "Epoch 453/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0151 - accuracy: 0.9970 - val_loss: 0.4073 - val_accuracy: 0.9775\n",
            "Epoch 454/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0088 - accuracy: 0.9982 - val_loss: 0.4599 - val_accuracy: 0.9769\n",
            "Epoch 455/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0097 - accuracy: 0.9980 - val_loss: 0.4203 - val_accuracy: 0.9800\n",
            "Epoch 456/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0089 - accuracy: 0.9988 - val_loss: 1.6179 - val_accuracy: 0.9593\n",
            "Epoch 457/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0162 - accuracy: 0.9967 - val_loss: 0.9637 - val_accuracy: 0.9745\n",
            "Epoch 458/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0149 - accuracy: 0.9971 - val_loss: 0.4669 - val_accuracy: 0.9806\n",
            "Epoch 459/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0335 - accuracy: 0.9959 - val_loss: 0.3949 - val_accuracy: 0.9806\n",
            "Epoch 460/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0162 - accuracy: 0.9976 - val_loss: 0.4276 - val_accuracy: 0.9769\n",
            "Epoch 461/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0144 - accuracy: 0.9968 - val_loss: 0.6085 - val_accuracy: 0.9788\n",
            "Epoch 462/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0155 - accuracy: 0.9968 - val_loss: 0.5341 - val_accuracy: 0.9812\n",
            "Epoch 463/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0063 - accuracy: 0.9985 - val_loss: 0.6028 - val_accuracy: 0.9800\n",
            "Epoch 464/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0179 - accuracy: 0.9970 - val_loss: 0.3384 - val_accuracy: 0.9812\n",
            "Epoch 465/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0329 - accuracy: 0.9959 - val_loss: 0.4729 - val_accuracy: 0.9830\n",
            "Epoch 466/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0103 - accuracy: 0.9974 - val_loss: 0.7209 - val_accuracy: 0.9818\n",
            "Epoch 467/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0099 - accuracy: 0.9980 - val_loss: 1.4968 - val_accuracy: 0.9782\n",
            "Epoch 468/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0653 - accuracy: 0.9956 - val_loss: 0.4555 - val_accuracy: 0.9824\n",
            "Epoch 469/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0245 - accuracy: 0.9974 - val_loss: 0.4800 - val_accuracy: 0.9775\n",
            "Epoch 470/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0298 - accuracy: 0.9951 - val_loss: 1.1420 - val_accuracy: 0.9769\n",
            "Epoch 471/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0185 - accuracy: 0.9979 - val_loss: 0.6515 - val_accuracy: 0.9782\n",
            "Epoch 472/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0128 - accuracy: 0.9973 - val_loss: 0.5035 - val_accuracy: 0.9818\n",
            "Epoch 473/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0111 - accuracy: 0.9976 - val_loss: 1.0325 - val_accuracy: 0.9794\n",
            "Epoch 474/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0099 - accuracy: 0.9979 - val_loss: 1.3348 - val_accuracy: 0.9769\n",
            "Epoch 475/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0149 - accuracy: 0.9974 - val_loss: 0.5431 - val_accuracy: 0.9782\n",
            "Epoch 476/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0379 - accuracy: 0.9964 - val_loss: 0.2345 - val_accuracy: 0.9800\n",
            "Epoch 477/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0285 - accuracy: 0.9976 - val_loss: 0.2752 - val_accuracy: 0.9751\n",
            "Epoch 478/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0109 - accuracy: 0.9976 - val_loss: 0.7203 - val_accuracy: 0.9794\n",
            "Epoch 479/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0194 - accuracy: 0.9961 - val_loss: 0.3994 - val_accuracy: 0.9800\n",
            "Epoch 480/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0124 - accuracy: 0.9974 - val_loss: 0.4298 - val_accuracy: 0.9806\n",
            "Epoch 481/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0082 - accuracy: 0.9980 - val_loss: 1.0792 - val_accuracy: 0.9763\n",
            "Epoch 482/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0051 - accuracy: 0.9991 - val_loss: 0.9708 - val_accuracy: 0.9763\n",
            "Epoch 483/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0114 - accuracy: 0.9979 - val_loss: 0.6439 - val_accuracy: 0.9769\n",
            "Epoch 484/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0301 - accuracy: 0.9948 - val_loss: 0.9266 - val_accuracy: 0.9739\n",
            "Epoch 485/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0265 - accuracy: 0.9945 - val_loss: 0.6233 - val_accuracy: 0.9715\n",
            "Epoch 486/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0133 - accuracy: 0.9971 - val_loss: 1.2140 - val_accuracy: 0.9757\n",
            "Epoch 487/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0215 - accuracy: 0.9965 - val_loss: 0.8964 - val_accuracy: 0.9757\n",
            "Epoch 488/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0373 - accuracy: 0.9933 - val_loss: 0.5415 - val_accuracy: 0.9757\n",
            "Epoch 489/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0074 - accuracy: 0.9988 - val_loss: 0.7332 - val_accuracy: 0.9721\n",
            "Epoch 490/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0121 - accuracy: 0.9974 - val_loss: 0.8613 - val_accuracy: 0.9757\n",
            "Epoch 491/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0076 - accuracy: 0.9985 - val_loss: 2.2821 - val_accuracy: 0.9624\n",
            "Epoch 492/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0051 - accuracy: 0.9991 - val_loss: 0.7063 - val_accuracy: 0.9794\n",
            "Epoch 493/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0142 - accuracy: 0.9979 - val_loss: 0.3413 - val_accuracy: 0.9769\n",
            "Epoch 494/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0114 - accuracy: 0.9976 - val_loss: 0.4259 - val_accuracy: 0.9812\n",
            "Epoch 495/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0117 - accuracy: 0.9976 - val_loss: 0.8711 - val_accuracy: 0.9800\n",
            "Epoch 496/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0099 - accuracy: 0.9985 - val_loss: 1.2246 - val_accuracy: 0.9733\n",
            "Epoch 497/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0082 - accuracy: 0.9982 - val_loss: 0.9921 - val_accuracy: 0.9745\n",
            "Epoch 498/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0117 - accuracy: 0.9973 - val_loss: 0.6185 - val_accuracy: 0.9757\n",
            "Epoch 499/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0257 - accuracy: 0.9951 - val_loss: 0.4868 - val_accuracy: 0.9703\n",
            "Epoch 500/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0175 - accuracy: 0.9983 - val_loss: 0.5477 - val_accuracy: 0.9733\n",
            "Epoch 501/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0153 - accuracy: 0.9967 - val_loss: 0.4440 - val_accuracy: 0.9763\n",
            "Epoch 502/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0242 - accuracy: 0.9967 - val_loss: 0.4251 - val_accuracy: 0.9794\n",
            "Epoch 503/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0303 - accuracy: 0.9976 - val_loss: 0.7262 - val_accuracy: 0.9751\n",
            "Epoch 504/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0144 - accuracy: 0.9980 - val_loss: 0.7119 - val_accuracy: 0.9763\n",
            "Epoch 505/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0123 - accuracy: 0.9968 - val_loss: 0.4599 - val_accuracy: 0.9782\n",
            "Epoch 506/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0124 - accuracy: 0.9977 - val_loss: 0.7637 - val_accuracy: 0.9751\n",
            "Epoch 507/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0133 - accuracy: 0.9971 - val_loss: 0.6839 - val_accuracy: 0.9757\n",
            "Epoch 508/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0080 - accuracy: 0.9983 - val_loss: 0.8102 - val_accuracy: 0.9800\n",
            "Epoch 509/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0193 - accuracy: 0.9977 - val_loss: 0.2754 - val_accuracy: 0.9678\n",
            "Epoch 510/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0154 - accuracy: 0.9968 - val_loss: 1.0142 - val_accuracy: 0.9757\n",
            "Epoch 511/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0273 - accuracy: 0.9970 - val_loss: 1.0735 - val_accuracy: 0.9715\n",
            "Epoch 512/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0153 - accuracy: 0.9970 - val_loss: 0.3020 - val_accuracy: 0.9812\n",
            "Epoch 513/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0085 - accuracy: 0.9979 - val_loss: 0.4823 - val_accuracy: 0.9818\n",
            "Epoch 514/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0148 - accuracy: 0.9971 - val_loss: 0.5358 - val_accuracy: 0.9775\n",
            "Epoch 515/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0407 - accuracy: 0.9961 - val_loss: 0.7543 - val_accuracy: 0.9739\n",
            "Epoch 516/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0120 - accuracy: 0.9976 - val_loss: 0.6572 - val_accuracy: 0.9678\n",
            "Epoch 517/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0128 - accuracy: 0.9985 - val_loss: 0.4678 - val_accuracy: 0.9775\n",
            "Epoch 518/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0087 - accuracy: 0.9988 - val_loss: 0.6707 - val_accuracy: 0.9775\n",
            "Epoch 519/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0066 - accuracy: 0.9986 - val_loss: 0.8888 - val_accuracy: 0.9757\n",
            "Epoch 520/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0133 - accuracy: 0.9967 - val_loss: 0.6662 - val_accuracy: 0.9763\n",
            "Epoch 521/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0495 - accuracy: 0.9971 - val_loss: 0.3474 - val_accuracy: 0.9812\n",
            "Epoch 522/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0096 - accuracy: 0.9977 - val_loss: 0.6063 - val_accuracy: 0.9806\n",
            "Epoch 523/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0102 - accuracy: 0.9974 - val_loss: 0.5164 - val_accuracy: 0.9775\n",
            "Epoch 524/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0118 - accuracy: 0.9977 - val_loss: 0.3527 - val_accuracy: 0.9727\n",
            "Epoch 525/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0202 - accuracy: 0.9954 - val_loss: 0.5779 - val_accuracy: 0.9751\n",
            "Epoch 526/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0539 - accuracy: 0.9950 - val_loss: 0.9618 - val_accuracy: 0.9697\n",
            "Epoch 527/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0075 - accuracy: 0.9985 - val_loss: 0.8151 - val_accuracy: 0.9763\n",
            "Epoch 528/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0169 - accuracy: 0.9967 - val_loss: 0.3345 - val_accuracy: 0.9739\n",
            "Epoch 529/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0100 - accuracy: 0.9985 - val_loss: 1.2636 - val_accuracy: 0.9672\n",
            "Epoch 530/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0556 - accuracy: 0.9953 - val_loss: 0.4260 - val_accuracy: 0.9794\n",
            "Epoch 531/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0097 - accuracy: 0.9985 - val_loss: 0.4191 - val_accuracy: 0.9788\n",
            "Epoch 532/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0149 - accuracy: 0.9974 - val_loss: 0.3330 - val_accuracy: 0.9836\n",
            "Epoch 533/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0153 - accuracy: 0.9973 - val_loss: 0.3455 - val_accuracy: 0.9812\n",
            "Epoch 534/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0101 - accuracy: 0.9977 - val_loss: 1.0194 - val_accuracy: 0.9733\n",
            "Epoch 535/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0100 - accuracy: 0.9983 - val_loss: 0.5160 - val_accuracy: 0.9830\n",
            "Epoch 536/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0336 - accuracy: 0.9982 - val_loss: 0.3562 - val_accuracy: 0.9812\n",
            "Epoch 537/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0093 - accuracy: 0.9982 - val_loss: 0.7350 - val_accuracy: 0.9800\n",
            "Epoch 538/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0072 - accuracy: 0.9986 - val_loss: 0.9467 - val_accuracy: 0.9775\n",
            "Epoch 539/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0059 - accuracy: 0.9989 - val_loss: 0.6659 - val_accuracy: 0.9818\n",
            "Epoch 540/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0066 - accuracy: 0.9983 - val_loss: 0.7912 - val_accuracy: 0.9788\n",
            "Epoch 541/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0079 - accuracy: 0.9985 - val_loss: 0.7354 - val_accuracy: 0.9788\n",
            "Epoch 542/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0055 - accuracy: 0.9991 - val_loss: 0.6721 - val_accuracy: 0.9794\n",
            "Epoch 543/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0073 - accuracy: 0.9986 - val_loss: 0.5098 - val_accuracy: 0.9751\n",
            "Epoch 544/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0194 - accuracy: 0.9962 - val_loss: 0.3487 - val_accuracy: 0.9800\n",
            "Epoch 545/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0094 - accuracy: 0.9983 - val_loss: 0.7503 - val_accuracy: 0.9763\n",
            "Epoch 546/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0135 - accuracy: 0.9971 - val_loss: 0.5433 - val_accuracy: 0.9818\n",
            "Epoch 547/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0132 - accuracy: 0.9980 - val_loss: 0.7744 - val_accuracy: 0.9739\n",
            "Epoch 548/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0146 - accuracy: 0.9973 - val_loss: 0.6204 - val_accuracy: 0.9794\n",
            "Epoch 549/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0090 - accuracy: 0.9983 - val_loss: 0.3191 - val_accuracy: 0.9769\n",
            "Epoch 550/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0092 - accuracy: 0.9982 - val_loss: 0.4223 - val_accuracy: 0.9763\n",
            "Epoch 551/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0077 - accuracy: 0.9985 - val_loss: 2.1555 - val_accuracy: 0.9593\n",
            "Epoch 552/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0321 - accuracy: 0.9954 - val_loss: 0.6413 - val_accuracy: 0.9691\n",
            "Epoch 553/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0113 - accuracy: 0.9976 - val_loss: 0.4500 - val_accuracy: 0.9836\n",
            "Epoch 554/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0225 - accuracy: 0.9982 - val_loss: 0.6283 - val_accuracy: 0.9775\n",
            "Epoch 555/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0054 - accuracy: 0.9991 - val_loss: 0.6319 - val_accuracy: 0.9782\n",
            "Epoch 556/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0111 - accuracy: 0.9982 - val_loss: 1.6028 - val_accuracy: 0.9721\n",
            "Epoch 557/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0090 - accuracy: 0.9985 - val_loss: 0.4601 - val_accuracy: 0.9751\n",
            "Epoch 558/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0040 - accuracy: 0.9994 - val_loss: 0.6241 - val_accuracy: 0.9812\n",
            "Epoch 559/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0075 - accuracy: 0.9985 - val_loss: 0.5244 - val_accuracy: 0.9806\n",
            "Epoch 560/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0132 - accuracy: 0.9976 - val_loss: 0.6628 - val_accuracy: 0.9763\n",
            "Epoch 561/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0084 - accuracy: 0.9986 - val_loss: 0.5455 - val_accuracy: 0.9788\n",
            "Epoch 562/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0196 - accuracy: 0.9971 - val_loss: 0.6325 - val_accuracy: 0.9812\n",
            "Epoch 563/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0136 - accuracy: 0.9976 - val_loss: 1.1562 - val_accuracy: 0.9757\n",
            "Epoch 564/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0842 - accuracy: 0.9917 - val_loss: 0.4978 - val_accuracy: 0.9636\n",
            "Epoch 565/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0212 - accuracy: 0.9950 - val_loss: 0.3953 - val_accuracy: 0.9794\n",
            "Epoch 566/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0127 - accuracy: 0.9971 - val_loss: 0.5035 - val_accuracy: 0.9830\n",
            "Epoch 567/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0042 - accuracy: 0.9994 - val_loss: 0.6030 - val_accuracy: 0.9794\n",
            "Epoch 568/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0140 - accuracy: 0.9976 - val_loss: 0.4212 - val_accuracy: 0.9824\n",
            "Epoch 569/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0202 - accuracy: 0.9964 - val_loss: 0.8942 - val_accuracy: 0.9775\n",
            "Epoch 570/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0085 - accuracy: 0.9979 - val_loss: 1.0644 - val_accuracy: 0.9757\n",
            "Epoch 571/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0097 - accuracy: 0.9979 - val_loss: 0.5108 - val_accuracy: 0.9818\n",
            "Epoch 572/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0052 - accuracy: 0.9991 - val_loss: 0.5422 - val_accuracy: 0.9830\n",
            "Epoch 573/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0053 - accuracy: 0.9989 - val_loss: 0.6362 - val_accuracy: 0.9812\n",
            "Epoch 574/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0187 - accuracy: 0.9989 - val_loss: 0.6451 - val_accuracy: 0.9745\n",
            "Epoch 575/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0225 - accuracy: 0.9961 - val_loss: 0.4942 - val_accuracy: 0.9794\n",
            "Epoch 576/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0215 - accuracy: 0.9951 - val_loss: 0.2975 - val_accuracy: 0.9733\n",
            "Epoch 577/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0121 - accuracy: 0.9976 - val_loss: 0.4753 - val_accuracy: 0.9782\n",
            "Epoch 578/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0287 - accuracy: 0.9965 - val_loss: 0.2356 - val_accuracy: 0.9818\n",
            "Epoch 579/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0174 - accuracy: 0.9968 - val_loss: 0.7466 - val_accuracy: 0.9788\n",
            "Epoch 580/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0049 - accuracy: 0.9989 - val_loss: 0.7929 - val_accuracy: 0.9806\n",
            "Epoch 581/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0101 - accuracy: 0.9985 - val_loss: 0.4674 - val_accuracy: 0.9806\n",
            "Epoch 582/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0055 - accuracy: 0.9991 - val_loss: 0.5540 - val_accuracy: 0.9824\n",
            "Epoch 583/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0187 - accuracy: 0.9973 - val_loss: 0.2662 - val_accuracy: 0.9842\n",
            "Epoch 584/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0097 - accuracy: 0.9980 - val_loss: 0.3858 - val_accuracy: 0.9836\n",
            "Epoch 585/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0085 - accuracy: 0.9982 - val_loss: 0.4129 - val_accuracy: 0.9848\n",
            "Epoch 586/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0048 - accuracy: 0.9992 - val_loss: 0.3927 - val_accuracy: 0.9854\n",
            "Epoch 587/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0043 - accuracy: 0.9992 - val_loss: 0.3225 - val_accuracy: 0.9854\n",
            "Epoch 588/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0078 - accuracy: 0.9985 - val_loss: 0.3141 - val_accuracy: 0.9848\n",
            "Epoch 589/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0087 - accuracy: 0.9980 - val_loss: 0.7312 - val_accuracy: 0.9733\n",
            "Epoch 590/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0126 - accuracy: 0.9980 - val_loss: 0.5245 - val_accuracy: 0.9842\n",
            "Epoch 591/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0070 - accuracy: 0.9982 - val_loss: 0.3735 - val_accuracy: 0.9848\n",
            "Epoch 592/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0043 - accuracy: 0.9991 - val_loss: 0.8765 - val_accuracy: 0.9727\n",
            "Epoch 593/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0464 - accuracy: 0.9950 - val_loss: 0.1646 - val_accuracy: 0.9806\n",
            "Epoch 594/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0285 - accuracy: 0.9939 - val_loss: 0.3056 - val_accuracy: 0.9769\n",
            "Epoch 595/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0162 - accuracy: 0.9967 - val_loss: 0.5370 - val_accuracy: 0.9739\n",
            "Epoch 596/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0038 - accuracy: 0.9991 - val_loss: 0.9749 - val_accuracy: 0.9751\n",
            "Epoch 597/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0062 - accuracy: 0.9989 - val_loss: 0.5615 - val_accuracy: 0.9782\n",
            "Epoch 598/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0058 - accuracy: 0.9989 - val_loss: 0.5625 - val_accuracy: 0.9782\n",
            "Epoch 599/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0361 - accuracy: 0.9973 - val_loss: 0.6502 - val_accuracy: 0.9751\n",
            "Epoch 600/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0272 - accuracy: 0.9961 - val_loss: 0.2235 - val_accuracy: 0.9794\n",
            "Epoch 601/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0162 - accuracy: 0.9970 - val_loss: 0.3557 - val_accuracy: 0.9824\n",
            "Epoch 602/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0119 - accuracy: 0.9976 - val_loss: 0.3134 - val_accuracy: 0.9806\n",
            "Epoch 603/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0069 - accuracy: 0.9986 - val_loss: 0.3069 - val_accuracy: 0.9818\n",
            "Epoch 604/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0032 - accuracy: 0.9992 - val_loss: 0.4786 - val_accuracy: 0.9818\n",
            "Epoch 605/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0086 - accuracy: 0.9985 - val_loss: 0.4640 - val_accuracy: 0.9824\n",
            "Epoch 606/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0051 - accuracy: 0.9989 - val_loss: 0.5754 - val_accuracy: 0.9782\n",
            "Epoch 607/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0040 - accuracy: 0.9992 - val_loss: 0.3508 - val_accuracy: 0.9830\n",
            "Epoch 608/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0086 - accuracy: 0.9988 - val_loss: 0.3101 - val_accuracy: 0.9836\n",
            "Epoch 609/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0057 - accuracy: 0.9989 - val_loss: 0.7152 - val_accuracy: 0.9782\n",
            "Epoch 610/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0080 - accuracy: 0.9982 - val_loss: 0.3194 - val_accuracy: 0.9848\n",
            "Epoch 611/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0067 - accuracy: 0.9988 - val_loss: 0.5607 - val_accuracy: 0.9800\n",
            "Epoch 612/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0046 - accuracy: 0.9989 - val_loss: 0.6616 - val_accuracy: 0.9775\n",
            "Epoch 613/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0065 - accuracy: 0.9985 - val_loss: 0.8940 - val_accuracy: 0.9769\n",
            "Epoch 614/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0224 - accuracy: 0.9961 - val_loss: 0.3869 - val_accuracy: 0.9842\n",
            "Epoch 615/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0170 - accuracy: 0.9973 - val_loss: 0.1816 - val_accuracy: 0.9818\n",
            "Epoch 616/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0080 - accuracy: 0.9983 - val_loss: 0.4138 - val_accuracy: 0.9836\n",
            "Epoch 617/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0144 - accuracy: 0.9971 - val_loss: 0.4041 - val_accuracy: 0.9806\n",
            "Epoch 618/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0058 - accuracy: 0.9989 - val_loss: 0.5463 - val_accuracy: 0.9806\n",
            "Epoch 619/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0086 - accuracy: 0.9983 - val_loss: 0.8948 - val_accuracy: 0.9763\n",
            "Epoch 620/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0185 - accuracy: 0.9970 - val_loss: 0.3591 - val_accuracy: 0.9775\n",
            "Epoch 621/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0363 - accuracy: 0.9967 - val_loss: 0.2700 - val_accuracy: 0.9848\n",
            "Epoch 622/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0103 - accuracy: 0.9979 - val_loss: 0.4334 - val_accuracy: 0.9794\n",
            "Epoch 623/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0116 - accuracy: 0.9983 - val_loss: 0.5243 - val_accuracy: 0.9818\n",
            "Epoch 624/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0092 - accuracy: 0.9989 - val_loss: 0.5105 - val_accuracy: 0.9812\n",
            "Epoch 625/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0123 - accuracy: 0.9985 - val_loss: 0.5136 - val_accuracy: 0.9794\n",
            "Epoch 626/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0119 - accuracy: 0.9982 - val_loss: 0.5598 - val_accuracy: 0.9769\n",
            "Epoch 627/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0074 - accuracy: 0.9985 - val_loss: 0.5489 - val_accuracy: 0.9794\n",
            "Epoch 628/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0126 - accuracy: 0.9983 - val_loss: 0.5078 - val_accuracy: 0.9788\n",
            "Epoch 629/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0329 - accuracy: 0.9954 - val_loss: 0.2355 - val_accuracy: 0.9794\n",
            "Epoch 630/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0259 - accuracy: 0.9948 - val_loss: 0.7726 - val_accuracy: 0.9703\n",
            "Epoch 631/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0066 - accuracy: 0.9986 - val_loss: 0.3788 - val_accuracy: 0.9830\n",
            "Epoch 632/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0204 - accuracy: 0.9967 - val_loss: 0.2581 - val_accuracy: 0.9806\n",
            "Epoch 633/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0167 - accuracy: 0.9971 - val_loss: 0.3281 - val_accuracy: 0.9812\n",
            "Epoch 634/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0097 - accuracy: 0.9980 - val_loss: 0.4444 - val_accuracy: 0.9769\n",
            "Epoch 635/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0181 - accuracy: 0.9973 - val_loss: 0.3520 - val_accuracy: 0.9769\n",
            "Epoch 636/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0080 - accuracy: 0.9983 - val_loss: 0.3619 - val_accuracy: 0.9848\n",
            "Epoch 637/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0094 - accuracy: 0.9986 - val_loss: 0.3791 - val_accuracy: 0.9806\n",
            "Epoch 638/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0202 - accuracy: 0.9980 - val_loss: 0.4076 - val_accuracy: 0.9782\n",
            "Epoch 639/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0039 - accuracy: 0.9991 - val_loss: 0.3998 - val_accuracy: 0.9824\n",
            "Epoch 640/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0052 - accuracy: 0.9991 - val_loss: 0.4226 - val_accuracy: 0.9818\n",
            "Epoch 641/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0090 - accuracy: 0.9982 - val_loss: 0.5958 - val_accuracy: 0.9818\n",
            "Epoch 642/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0120 - accuracy: 0.9977 - val_loss: 0.5242 - val_accuracy: 0.9800\n",
            "Epoch 643/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0111 - accuracy: 0.9976 - val_loss: 0.3384 - val_accuracy: 0.9782\n",
            "Epoch 644/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0085 - accuracy: 0.9982 - val_loss: 0.6509 - val_accuracy: 0.9775\n",
            "Epoch 645/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0089 - accuracy: 0.9983 - val_loss: 0.3293 - val_accuracy: 0.9818\n",
            "Epoch 646/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0067 - accuracy: 0.9988 - val_loss: 0.3550 - val_accuracy: 0.9818\n",
            "Epoch 647/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0079 - accuracy: 0.9983 - val_loss: 0.4778 - val_accuracy: 0.9812\n",
            "Epoch 648/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0047 - accuracy: 0.9991 - val_loss: 0.4729 - val_accuracy: 0.9818\n",
            "Epoch 649/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0170 - accuracy: 0.9980 - val_loss: 0.6814 - val_accuracy: 0.9782\n",
            "Epoch 650/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0125 - accuracy: 0.9977 - val_loss: 0.8735 - val_accuracy: 0.9788\n",
            "Epoch 651/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0111 - accuracy: 0.9979 - val_loss: 0.6432 - val_accuracy: 0.9788\n",
            "Epoch 652/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0120 - accuracy: 0.9977 - val_loss: 0.4361 - val_accuracy: 0.9806\n",
            "Epoch 653/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0047 - accuracy: 0.9991 - val_loss: 0.5134 - val_accuracy: 0.9806\n",
            "Epoch 654/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0110 - accuracy: 0.9979 - val_loss: 0.4611 - val_accuracy: 0.9739\n",
            "Epoch 655/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0065 - accuracy: 0.9988 - val_loss: 0.2535 - val_accuracy: 0.9860\n",
            "Epoch 656/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0057 - accuracy: 0.9988 - val_loss: 0.2468 - val_accuracy: 0.9854\n",
            "Epoch 657/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0085 - accuracy: 0.9988 - val_loss: 0.9120 - val_accuracy: 0.9775\n",
            "Epoch 658/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0134 - accuracy: 0.9983 - val_loss: 0.3286 - val_accuracy: 0.9818\n",
            "Epoch 659/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0231 - accuracy: 0.9961 - val_loss: 0.2810 - val_accuracy: 0.9818\n",
            "Epoch 660/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0084 - accuracy: 0.9983 - val_loss: 0.4510 - val_accuracy: 0.9800\n",
            "Epoch 661/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0048 - accuracy: 0.9991 - val_loss: 0.3820 - val_accuracy: 0.9824\n",
            "Epoch 662/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0108 - accuracy: 0.9983 - val_loss: 0.4564 - val_accuracy: 0.9806\n",
            "Epoch 663/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0054 - accuracy: 0.9989 - val_loss: 0.4582 - val_accuracy: 0.9848\n",
            "Epoch 664/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0111 - accuracy: 0.9983 - val_loss: 0.4068 - val_accuracy: 0.9812\n",
            "Epoch 665/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0045 - accuracy: 0.9992 - val_loss: 0.5212 - val_accuracy: 0.9812\n",
            "Epoch 666/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0052 - accuracy: 0.9991 - val_loss: 0.4394 - val_accuracy: 0.9836\n",
            "Epoch 667/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0060 - accuracy: 0.9988 - val_loss: 0.4582 - val_accuracy: 0.9842\n",
            "Epoch 668/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0103 - accuracy: 0.9979 - val_loss: 0.6818 - val_accuracy: 0.9709\n",
            "Epoch 669/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0040 - accuracy: 0.9992 - val_loss: 0.6580 - val_accuracy: 0.9782\n",
            "Epoch 670/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0052 - accuracy: 0.9988 - val_loss: 0.9861 - val_accuracy: 0.9733\n",
            "Epoch 671/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0214 - accuracy: 0.9974 - val_loss: 0.5531 - val_accuracy: 0.9800\n",
            "Epoch 672/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0208 - accuracy: 0.9979 - val_loss: 0.3110 - val_accuracy: 0.9806\n",
            "Epoch 673/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0093 - accuracy: 0.9977 - val_loss: 0.3019 - val_accuracy: 0.9842\n",
            "Epoch 674/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0127 - accuracy: 0.9982 - val_loss: 0.3942 - val_accuracy: 0.9830\n",
            "Epoch 675/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0062 - accuracy: 0.9988 - val_loss: 1.0448 - val_accuracy: 0.9733\n",
            "Epoch 676/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0040 - accuracy: 0.9994 - val_loss: 0.8485 - val_accuracy: 0.9782\n",
            "Epoch 677/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0042 - accuracy: 0.9992 - val_loss: 1.2927 - val_accuracy: 0.9727\n",
            "Epoch 678/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0051 - accuracy: 0.9988 - val_loss: 0.8311 - val_accuracy: 0.9800\n",
            "Epoch 679/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0220 - accuracy: 0.9974 - val_loss: 0.5348 - val_accuracy: 0.9824\n",
            "Epoch 680/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0052 - accuracy: 0.9992 - val_loss: 0.5899 - val_accuracy: 0.9800\n",
            "Epoch 681/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0097 - accuracy: 0.9988 - val_loss: 0.4975 - val_accuracy: 0.9836\n",
            "Epoch 682/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0267 - accuracy: 0.9974 - val_loss: 0.9451 - val_accuracy: 0.9769\n",
            "Epoch 683/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0417 - accuracy: 0.9976 - val_loss: 1.0564 - val_accuracy: 0.9763\n",
            "Epoch 684/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0576 - accuracy: 0.9944 - val_loss: 0.4253 - val_accuracy: 0.9800\n",
            "Epoch 685/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0150 - accuracy: 0.9962 - val_loss: 1.2891 - val_accuracy: 0.9709\n",
            "Epoch 686/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0164 - accuracy: 0.9973 - val_loss: 0.4895 - val_accuracy: 0.9812\n",
            "Epoch 687/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0236 - accuracy: 0.9973 - val_loss: 0.5017 - val_accuracy: 0.9836\n",
            "Epoch 688/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0095 - accuracy: 0.9982 - val_loss: 0.4484 - val_accuracy: 0.9824\n",
            "Epoch 689/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0099 - accuracy: 0.9983 - val_loss: 0.7251 - val_accuracy: 0.9836\n",
            "Epoch 690/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0052 - accuracy: 0.9991 - val_loss: 0.5122 - val_accuracy: 0.9836\n",
            "Epoch 691/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0072 - accuracy: 0.9986 - val_loss: 1.7944 - val_accuracy: 0.9691\n",
            "Epoch 692/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0098 - accuracy: 0.9983 - val_loss: 0.9517 - val_accuracy: 0.9800\n",
            "Epoch 693/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0089 - accuracy: 0.9992 - val_loss: 1.3311 - val_accuracy: 0.9739\n",
            "Epoch 694/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0082 - accuracy: 0.9992 - val_loss: 0.9392 - val_accuracy: 0.9806\n",
            "Epoch 695/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0065 - accuracy: 0.9988 - val_loss: 0.9269 - val_accuracy: 0.9763\n",
            "Epoch 696/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0059 - accuracy: 0.9989 - val_loss: 0.8381 - val_accuracy: 0.9824\n",
            "Epoch 697/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0166 - accuracy: 0.9979 - val_loss: 0.3615 - val_accuracy: 0.9830\n",
            "Epoch 698/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0279 - accuracy: 0.9965 - val_loss: 0.5524 - val_accuracy: 0.9806\n",
            "Epoch 699/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0232 - accuracy: 0.9968 - val_loss: 0.5434 - val_accuracy: 0.9788\n",
            "Epoch 700/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0115 - accuracy: 0.9977 - val_loss: 0.7026 - val_accuracy: 0.9763\n",
            "Epoch 701/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0058 - accuracy: 0.9988 - val_loss: 0.8983 - val_accuracy: 0.9727\n",
            "Epoch 702/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0098 - accuracy: 0.9979 - val_loss: 0.9243 - val_accuracy: 0.9794\n",
            "Epoch 703/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0052 - accuracy: 0.9992 - val_loss: 0.5073 - val_accuracy: 0.9842\n",
            "Epoch 704/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0088 - accuracy: 0.9983 - val_loss: 0.4484 - val_accuracy: 0.9824\n",
            "Epoch 705/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0135 - accuracy: 0.9974 - val_loss: 0.5996 - val_accuracy: 0.9763\n",
            "Epoch 706/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0121 - accuracy: 0.9976 - val_loss: 0.3639 - val_accuracy: 0.9848\n",
            "Epoch 707/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0045 - accuracy: 0.9991 - val_loss: 0.6699 - val_accuracy: 0.9836\n",
            "Epoch 708/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0038 - accuracy: 0.9994 - val_loss: 0.6462 - val_accuracy: 0.9842\n",
            "Epoch 709/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0051 - accuracy: 0.9991 - val_loss: 0.5949 - val_accuracy: 0.9824\n",
            "Epoch 710/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0042 - accuracy: 0.9994 - val_loss: 0.7033 - val_accuracy: 0.9812\n",
            "Epoch 711/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0171 - accuracy: 0.9973 - val_loss: 0.5123 - val_accuracy: 0.9769\n",
            "Epoch 712/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0056 - accuracy: 0.9988 - val_loss: 0.4471 - val_accuracy: 0.9812\n",
            "Epoch 713/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0119 - accuracy: 0.9988 - val_loss: 0.9651 - val_accuracy: 0.9788\n",
            "Epoch 714/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0057 - accuracy: 0.9988 - val_loss: 0.5361 - val_accuracy: 0.9818\n",
            "Epoch 715/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0038 - accuracy: 0.9994 - val_loss: 0.6111 - val_accuracy: 0.9830\n",
            "Epoch 716/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0040 - accuracy: 0.9992 - val_loss: 0.7121 - val_accuracy: 0.9824\n",
            "Epoch 717/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0157 - accuracy: 0.9979 - val_loss: 0.9464 - val_accuracy: 0.9709\n",
            "Epoch 718/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0123 - accuracy: 0.9980 - val_loss: 1.0120 - val_accuracy: 0.9727\n",
            "Epoch 719/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0068 - accuracy: 0.9985 - val_loss: 0.8113 - val_accuracy: 0.9769\n",
            "Epoch 720/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0111 - accuracy: 0.9980 - val_loss: 0.9206 - val_accuracy: 0.9818\n",
            "Epoch 721/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0066 - accuracy: 0.9985 - val_loss: 1.1268 - val_accuracy: 0.9800\n",
            "Epoch 722/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0154 - accuracy: 0.9973 - val_loss: 0.4815 - val_accuracy: 0.9775\n",
            "Epoch 723/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0050 - accuracy: 0.9991 - val_loss: 0.7054 - val_accuracy: 0.9818\n",
            "Epoch 724/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0103 - accuracy: 0.9982 - val_loss: 2.0109 - val_accuracy: 0.9630\n",
            "Epoch 725/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0069 - accuracy: 0.9985 - val_loss: 0.7762 - val_accuracy: 0.9812\n",
            "Epoch 726/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0060 - accuracy: 0.9989 - val_loss: 0.7431 - val_accuracy: 0.9812\n",
            "Epoch 727/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0377 - accuracy: 0.9974 - val_loss: 0.5502 - val_accuracy: 0.9836\n",
            "Epoch 728/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0120 - accuracy: 0.9971 - val_loss: 0.7616 - val_accuracy: 0.9800\n",
            "Epoch 729/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0122 - accuracy: 0.9974 - val_loss: 0.9506 - val_accuracy: 0.9769\n",
            "Epoch 730/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0104 - accuracy: 0.9986 - val_loss: 0.8017 - val_accuracy: 0.9800\n",
            "Epoch 731/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0069 - accuracy: 0.9988 - val_loss: 0.9254 - val_accuracy: 0.9800\n",
            "Epoch 732/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0156 - accuracy: 0.9973 - val_loss: 0.7644 - val_accuracy: 0.9800\n",
            "Epoch 733/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0101 - accuracy: 0.9977 - val_loss: 0.2882 - val_accuracy: 0.9788\n",
            "Epoch 734/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0107 - accuracy: 0.9983 - val_loss: 0.3636 - val_accuracy: 0.9794\n",
            "Epoch 735/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0082 - accuracy: 0.9982 - val_loss: 0.6100 - val_accuracy: 0.9745\n",
            "Epoch 736/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0154 - accuracy: 0.9982 - val_loss: 0.4601 - val_accuracy: 0.9800\n",
            "Epoch 737/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0111 - accuracy: 0.9979 - val_loss: 0.4682 - val_accuracy: 0.9824\n",
            "Epoch 738/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0070 - accuracy: 0.9985 - val_loss: 0.7888 - val_accuracy: 0.9800\n",
            "Epoch 739/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0035 - accuracy: 0.9994 - val_loss: 0.6682 - val_accuracy: 0.9824\n",
            "Epoch 740/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0043 - accuracy: 0.9991 - val_loss: 0.7663 - val_accuracy: 0.9794\n",
            "Epoch 741/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0171 - accuracy: 0.9962 - val_loss: 0.2884 - val_accuracy: 0.9806\n",
            "Epoch 742/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0142 - accuracy: 0.9977 - val_loss: 0.9492 - val_accuracy: 0.9600\n",
            "Epoch 743/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0095 - accuracy: 0.9979 - val_loss: 0.2972 - val_accuracy: 0.9848\n",
            "Epoch 744/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0094 - accuracy: 0.9982 - val_loss: 0.5977 - val_accuracy: 0.9769\n",
            "Epoch 745/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0063 - accuracy: 0.9985 - val_loss: 0.9663 - val_accuracy: 0.9763\n",
            "Epoch 746/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0065 - accuracy: 0.9988 - val_loss: 1.0559 - val_accuracy: 0.9715\n",
            "Epoch 747/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0131 - accuracy: 0.9982 - val_loss: 0.6321 - val_accuracy: 0.9782\n",
            "Epoch 748/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0084 - accuracy: 0.9985 - val_loss: 0.4043 - val_accuracy: 0.9775\n",
            "Epoch 749/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0070 - accuracy: 0.9989 - val_loss: 0.8360 - val_accuracy: 0.9763\n",
            "Epoch 750/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0061 - accuracy: 0.9988 - val_loss: 0.5948 - val_accuracy: 0.9763\n",
            "Epoch 751/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0041 - accuracy: 0.9991 - val_loss: 0.6382 - val_accuracy: 0.9782\n",
            "Epoch 752/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.5213 - val_accuracy: 0.9806\n",
            "Epoch 753/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0099 - accuracy: 0.9986 - val_loss: 0.3777 - val_accuracy: 0.9794\n",
            "Epoch 754/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0024 - accuracy: 0.9997 - val_loss: 0.6821 - val_accuracy: 0.9812\n",
            "Epoch 755/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0044 - accuracy: 0.9992 - val_loss: 0.9552 - val_accuracy: 0.9788\n",
            "Epoch 756/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0090 - accuracy: 0.9986 - val_loss: 3.5241 - val_accuracy: 0.9654\n",
            "Epoch 757/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0136 - accuracy: 0.9988 - val_loss: 0.9283 - val_accuracy: 0.9782\n",
            "Epoch 758/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0153 - accuracy: 0.9971 - val_loss: 1.3972 - val_accuracy: 0.9727\n",
            "Epoch 759/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0116 - accuracy: 0.9974 - val_loss: 0.5024 - val_accuracy: 0.9794\n",
            "Epoch 760/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0152 - accuracy: 0.9977 - val_loss: 0.7522 - val_accuracy: 0.9800\n",
            "Epoch 761/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0127 - accuracy: 0.9983 - val_loss: 0.6603 - val_accuracy: 0.9824\n",
            "Epoch 762/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0066 - accuracy: 0.9988 - val_loss: 0.6820 - val_accuracy: 0.9818\n",
            "Epoch 763/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0037 - accuracy: 0.9994 - val_loss: 0.8288 - val_accuracy: 0.9818\n",
            "Epoch 764/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0050 - accuracy: 0.9992 - val_loss: 0.8032 - val_accuracy: 0.9824\n",
            "Epoch 765/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0090 - accuracy: 0.9991 - val_loss: 0.9381 - val_accuracy: 0.9794\n",
            "Epoch 766/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0094 - accuracy: 0.9983 - val_loss: 0.4818 - val_accuracy: 0.9782\n",
            "Epoch 767/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0103 - accuracy: 0.9983 - val_loss: 0.4291 - val_accuracy: 0.9775\n",
            "Epoch 768/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0528 - accuracy: 0.9971 - val_loss: 1.3086 - val_accuracy: 0.9715\n",
            "Epoch 769/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0083 - accuracy: 0.9986 - val_loss: 0.7388 - val_accuracy: 0.9794\n",
            "Epoch 770/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 0.7949 - val_accuracy: 0.9782\n",
            "Epoch 771/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0071 - accuracy: 0.9986 - val_loss: 0.7569 - val_accuracy: 0.9751\n",
            "Epoch 772/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0092 - accuracy: 0.9976 - val_loss: 0.7558 - val_accuracy: 0.9769\n",
            "Epoch 773/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0098 - accuracy: 0.9985 - val_loss: 0.4686 - val_accuracy: 0.9788\n",
            "Epoch 774/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0119 - accuracy: 0.9979 - val_loss: 0.5179 - val_accuracy: 0.9775\n",
            "Epoch 775/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0052 - accuracy: 0.9989 - val_loss: 0.4210 - val_accuracy: 0.9836\n",
            "Epoch 776/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0062 - accuracy: 0.9988 - val_loss: 0.7277 - val_accuracy: 0.9788\n",
            "Epoch 777/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0127 - accuracy: 0.9982 - val_loss: 0.7791 - val_accuracy: 0.9715\n",
            "Epoch 778/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0120 - accuracy: 0.9980 - val_loss: 0.5071 - val_accuracy: 0.9800\n",
            "Epoch 779/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0070 - accuracy: 0.9988 - val_loss: 0.6062 - val_accuracy: 0.9800\n",
            "Epoch 780/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0091 - accuracy: 0.9980 - val_loss: 0.3628 - val_accuracy: 0.9848\n",
            "Epoch 781/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 0.4709 - val_accuracy: 0.9806\n",
            "Epoch 782/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0077 - accuracy: 0.9985 - val_loss: 0.3783 - val_accuracy: 0.9818\n",
            "Epoch 783/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0176 - accuracy: 0.9982 - val_loss: 0.5309 - val_accuracy: 0.9818\n",
            "Epoch 784/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0054 - accuracy: 0.9991 - val_loss: 0.4377 - val_accuracy: 0.9830\n",
            "Epoch 785/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0057 - accuracy: 0.9988 - val_loss: 0.7664 - val_accuracy: 0.9782\n",
            "Epoch 786/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0028 - accuracy: 0.9995 - val_loss: 0.6898 - val_accuracy: 0.9794\n",
            "Epoch 787/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0035 - accuracy: 0.9994 - val_loss: 0.7261 - val_accuracy: 0.9800\n",
            "Epoch 788/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0067 - accuracy: 0.9989 - val_loss: 0.4972 - val_accuracy: 0.9830\n",
            "Epoch 789/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0239 - accuracy: 0.9983 - val_loss: 2.5925 - val_accuracy: 0.9630\n",
            "Epoch 790/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0240 - accuracy: 0.9982 - val_loss: 0.5601 - val_accuracy: 0.9830\n",
            "Epoch 791/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0108 - accuracy: 0.9983 - val_loss: 0.6849 - val_accuracy: 0.9818\n",
            "Epoch 792/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0235 - accuracy: 0.9985 - val_loss: 2.0273 - val_accuracy: 0.9581\n",
            "Epoch 793/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0138 - accuracy: 0.9976 - val_loss: 0.5676 - val_accuracy: 0.9800\n",
            "Epoch 794/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0113 - accuracy: 0.9977 - val_loss: 0.6575 - val_accuracy: 0.9757\n",
            "Epoch 795/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0063 - accuracy: 0.9986 - val_loss: 0.6310 - val_accuracy: 0.9824\n",
            "Epoch 796/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0064 - accuracy: 0.9985 - val_loss: 1.0417 - val_accuracy: 0.9775\n",
            "Epoch 797/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0054 - accuracy: 0.9991 - val_loss: 1.0630 - val_accuracy: 0.9782\n",
            "Epoch 798/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0082 - accuracy: 0.9986 - val_loss: 0.4531 - val_accuracy: 0.9800\n",
            "Epoch 799/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0063 - accuracy: 0.9989 - val_loss: 0.2961 - val_accuracy: 0.9818\n",
            "Epoch 800/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0120 - accuracy: 0.9974 - val_loss: 0.4774 - val_accuracy: 0.9842\n",
            "Epoch 801/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0090 - accuracy: 0.9982 - val_loss: 0.3244 - val_accuracy: 0.9788\n",
            "Epoch 802/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0034 - accuracy: 0.9994 - val_loss: 0.4816 - val_accuracy: 0.9769\n",
            "Epoch 803/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0089 - accuracy: 0.9985 - val_loss: 0.6554 - val_accuracy: 0.9745\n",
            "Epoch 804/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0057 - accuracy: 0.9988 - val_loss: 0.5899 - val_accuracy: 0.9788\n",
            "Epoch 805/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0049 - accuracy: 0.9989 - val_loss: 0.3989 - val_accuracy: 0.9751\n",
            "Epoch 806/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0051 - accuracy: 0.9991 - val_loss: 0.3503 - val_accuracy: 0.9794\n",
            "Epoch 807/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0043 - accuracy: 0.9992 - val_loss: 0.3910 - val_accuracy: 0.9788\n",
            "Epoch 808/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0054 - accuracy: 0.9989 - val_loss: 0.8150 - val_accuracy: 0.9763\n",
            "Epoch 809/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0051 - accuracy: 0.9991 - val_loss: 0.3671 - val_accuracy: 0.9806\n",
            "Epoch 810/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0038 - accuracy: 0.9992 - val_loss: 0.4547 - val_accuracy: 0.9794\n",
            "Epoch 811/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0053 - accuracy: 0.9989 - val_loss: 0.6851 - val_accuracy: 0.9800\n",
            "Epoch 812/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0046 - accuracy: 0.9992 - val_loss: 0.6360 - val_accuracy: 0.9782\n",
            "Epoch 813/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 7.5391e-04 - accuracy: 1.0000 - val_loss: 0.7558 - val_accuracy: 0.9812\n",
            "Epoch 814/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0022 - accuracy: 0.9997 - val_loss: 0.7680 - val_accuracy: 0.9812\n",
            "Epoch 815/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 0.7804 - val_accuracy: 0.9806\n",
            "Epoch 816/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0191 - accuracy: 0.9985 - val_loss: 0.3428 - val_accuracy: 0.9848\n",
            "Epoch 817/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0102 - accuracy: 0.9982 - val_loss: 0.7293 - val_accuracy: 0.9818\n",
            "Epoch 818/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0039 - accuracy: 0.9992 - val_loss: 0.3933 - val_accuracy: 0.9812\n",
            "Epoch 819/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0102 - accuracy: 0.9979 - val_loss: 0.2182 - val_accuracy: 0.9812\n",
            "Epoch 820/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0165 - accuracy: 0.9976 - val_loss: 0.3226 - val_accuracy: 0.9842\n",
            "Epoch 821/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0085 - accuracy: 0.9982 - val_loss: 0.5172 - val_accuracy: 0.9794\n",
            "Epoch 822/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0102 - accuracy: 0.9980 - val_loss: 0.4304 - val_accuracy: 0.9836\n",
            "Epoch 823/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0186 - accuracy: 0.9980 - val_loss: 3.8823 - val_accuracy: 0.9502\n",
            "Epoch 824/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1254 - accuracy: 0.9962 - val_loss: 0.3642 - val_accuracy: 0.9757\n",
            "Epoch 825/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0079 - accuracy: 0.9983 - val_loss: 0.3086 - val_accuracy: 0.9788\n",
            "Epoch 826/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0098 - accuracy: 0.9982 - val_loss: 0.7334 - val_accuracy: 0.9800\n",
            "Epoch 827/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0052 - accuracy: 0.9991 - val_loss: 0.8832 - val_accuracy: 0.9806\n",
            "Epoch 828/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0061 - accuracy: 0.9986 - val_loss: 0.7752 - val_accuracy: 0.9806\n",
            "Epoch 829/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0069 - accuracy: 0.9988 - val_loss: 0.7844 - val_accuracy: 0.9836\n",
            "Epoch 830/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0038 - accuracy: 0.9992 - val_loss: 0.8311 - val_accuracy: 0.9830\n",
            "Epoch 831/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0037 - accuracy: 0.9994 - val_loss: 0.8743 - val_accuracy: 0.9836\n",
            "Epoch 832/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0025 - accuracy: 0.9995 - val_loss: 0.6751 - val_accuracy: 0.9824\n",
            "Epoch 833/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0047 - accuracy: 0.9989 - val_loss: 1.2441 - val_accuracy: 0.9769\n",
            "Epoch 834/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0065 - accuracy: 0.9989 - val_loss: 0.8407 - val_accuracy: 0.9824\n",
            "Epoch 835/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0104 - accuracy: 0.9985 - val_loss: 0.4476 - val_accuracy: 0.9842\n",
            "Epoch 836/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0059 - accuracy: 0.9988 - val_loss: 0.6628 - val_accuracy: 0.9860\n",
            "Epoch 837/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0035 - accuracy: 0.9994 - val_loss: 0.7732 - val_accuracy: 0.9848\n",
            "Epoch 838/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0062 - accuracy: 0.9994 - val_loss: 0.9897 - val_accuracy: 0.9800\n",
            "Epoch 839/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0045 - accuracy: 0.9994 - val_loss: 0.5210 - val_accuracy: 0.9854\n",
            "Epoch 840/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0076 - accuracy: 0.9994 - val_loss: 0.5560 - val_accuracy: 0.9830\n",
            "Epoch 841/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0163 - accuracy: 0.9989 - val_loss: 0.6452 - val_accuracy: 0.9800\n",
            "Epoch 842/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0184 - accuracy: 0.9983 - val_loss: 0.6710 - val_accuracy: 0.9818\n",
            "Epoch 843/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0098 - accuracy: 0.9983 - val_loss: 0.9150 - val_accuracy: 0.9782\n",
            "Epoch 844/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0254 - accuracy: 0.9968 - val_loss: 0.1675 - val_accuracy: 0.9769\n",
            "Epoch 845/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0118 - accuracy: 0.9971 - val_loss: 0.6518 - val_accuracy: 0.9800\n",
            "Epoch 846/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.6398 - val_accuracy: 0.9782\n",
            "Epoch 847/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0041 - accuracy: 0.9992 - val_loss: 0.3413 - val_accuracy: 0.9830\n",
            "Epoch 848/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0106 - accuracy: 0.9979 - val_loss: 0.4150 - val_accuracy: 0.9769\n",
            "Epoch 849/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0095 - accuracy: 0.9982 - val_loss: 0.4839 - val_accuracy: 0.9800\n",
            "Epoch 850/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0083 - accuracy: 0.9986 - val_loss: 0.4004 - val_accuracy: 0.9818\n",
            "Epoch 851/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0066 - accuracy: 0.9988 - val_loss: 0.5217 - val_accuracy: 0.9812\n",
            "Epoch 852/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0283 - accuracy: 0.9967 - val_loss: 0.5821 - val_accuracy: 0.9794\n",
            "Epoch 853/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0071 - accuracy: 0.9986 - val_loss: 0.3944 - val_accuracy: 0.9873\n",
            "Epoch 854/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0068 - accuracy: 0.9985 - val_loss: 0.8231 - val_accuracy: 0.9782\n",
            "Epoch 855/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0077 - accuracy: 0.9985 - val_loss: 0.7890 - val_accuracy: 0.9800\n",
            "Epoch 856/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0038 - accuracy: 0.9991 - val_loss: 1.0576 - val_accuracy: 0.9818\n",
            "Epoch 857/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0198 - accuracy: 0.9973 - val_loss: 0.6391 - val_accuracy: 0.9818\n",
            "Epoch 858/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0146 - accuracy: 0.9977 - val_loss: 0.7094 - val_accuracy: 0.9830\n",
            "Epoch 859/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0033 - accuracy: 0.9997 - val_loss: 0.5575 - val_accuracy: 0.9830\n",
            "Epoch 860/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0090 - accuracy: 0.9983 - val_loss: 0.4189 - val_accuracy: 0.9842\n",
            "Epoch 861/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0050 - accuracy: 0.9988 - val_loss: 2.3167 - val_accuracy: 0.9654\n",
            "Epoch 862/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0061 - accuracy: 0.9988 - val_loss: 0.4600 - val_accuracy: 0.9830\n",
            "Epoch 863/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0066 - accuracy: 0.9985 - val_loss: 0.7344 - val_accuracy: 0.9818\n",
            "Epoch 864/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0040 - accuracy: 0.9992 - val_loss: 0.6288 - val_accuracy: 0.9812\n",
            "Epoch 865/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 0.6975 - val_accuracy: 0.9824\n",
            "Epoch 866/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0039 - accuracy: 0.9992 - val_loss: 1.3766 - val_accuracy: 0.9751\n",
            "Epoch 867/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0028 - accuracy: 0.9995 - val_loss: 0.5999 - val_accuracy: 0.9836\n",
            "Epoch 868/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0041 - accuracy: 0.9991 - val_loss: 0.7805 - val_accuracy: 0.9836\n",
            "Epoch 869/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0347 - accuracy: 0.9965 - val_loss: 0.4026 - val_accuracy: 0.9751\n",
            "Epoch 870/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0244 - accuracy: 0.9959 - val_loss: 0.3461 - val_accuracy: 0.9830\n",
            "Epoch 871/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0161 - accuracy: 0.9967 - val_loss: 0.4474 - val_accuracy: 0.9830\n",
            "Epoch 872/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0088 - accuracy: 0.9983 - val_loss: 0.5308 - val_accuracy: 0.9824\n",
            "Epoch 873/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0072 - accuracy: 0.9988 - val_loss: 0.5266 - val_accuracy: 0.9818\n",
            "Epoch 874/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0037 - accuracy: 0.9992 - val_loss: 1.4801 - val_accuracy: 0.9630\n",
            "Epoch 875/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0079 - accuracy: 0.9983 - val_loss: 0.5355 - val_accuracy: 0.9806\n",
            "Epoch 876/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0068 - accuracy: 0.9988 - val_loss: 0.5448 - val_accuracy: 0.9818\n",
            "Epoch 877/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0050 - accuracy: 0.9991 - val_loss: 0.7620 - val_accuracy: 0.9788\n",
            "Epoch 878/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0022 - accuracy: 0.9997 - val_loss: 0.7534 - val_accuracy: 0.9788\n",
            "Epoch 879/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0042 - accuracy: 0.9992 - val_loss: 1.0766 - val_accuracy: 0.9788\n",
            "Epoch 880/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0334 - accuracy: 0.9982 - val_loss: 1.6724 - val_accuracy: 0.9782\n",
            "Epoch 881/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0235 - accuracy: 0.9988 - val_loss: 0.9796 - val_accuracy: 0.9800\n",
            "Epoch 882/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0044 - accuracy: 0.9991 - val_loss: 0.6878 - val_accuracy: 0.9763\n",
            "Epoch 883/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0074 - accuracy: 0.9986 - val_loss: 0.4673 - val_accuracy: 0.9836\n",
            "Epoch 884/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0025 - accuracy: 0.9997 - val_loss: 0.6540 - val_accuracy: 0.9812\n",
            "Epoch 885/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0037 - accuracy: 0.9994 - val_loss: 0.6035 - val_accuracy: 0.9830\n",
            "Epoch 886/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0055 - accuracy: 0.9992 - val_loss: 0.8026 - val_accuracy: 0.9775\n",
            "Epoch 887/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0041 - accuracy: 0.9991 - val_loss: 0.9390 - val_accuracy: 0.9751\n",
            "Epoch 888/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0200 - accuracy: 0.9980 - val_loss: 0.5695 - val_accuracy: 0.9818\n",
            "Epoch 889/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0135 - accuracy: 0.9986 - val_loss: 4.7328 - val_accuracy: 0.9484\n",
            "Epoch 890/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0145 - accuracy: 0.9974 - val_loss: 0.6932 - val_accuracy: 0.9775\n",
            "Epoch 891/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0066 - accuracy: 0.9986 - val_loss: 0.4537 - val_accuracy: 0.9806\n",
            "Epoch 892/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0046 - accuracy: 0.9992 - val_loss: 0.5128 - val_accuracy: 0.9800\n",
            "Epoch 893/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0047 - accuracy: 0.9994 - val_loss: 0.4856 - val_accuracy: 0.9782\n",
            "Epoch 894/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0119 - accuracy: 0.9977 - val_loss: 0.4345 - val_accuracy: 0.9824\n",
            "Epoch 895/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0126 - accuracy: 0.9983 - val_loss: 0.3612 - val_accuracy: 0.9824\n",
            "Epoch 896/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0081 - accuracy: 0.9985 - val_loss: 0.7974 - val_accuracy: 0.9757\n",
            "Epoch 897/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0059 - accuracy: 0.9989 - val_loss: 1.4538 - val_accuracy: 0.9757\n",
            "Epoch 898/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0073 - accuracy: 0.9983 - val_loss: 0.7492 - val_accuracy: 0.9806\n",
            "Epoch 899/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0317 - accuracy: 0.9956 - val_loss: 0.3078 - val_accuracy: 0.9830\n",
            "Epoch 900/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0048 - accuracy: 0.9991 - val_loss: 0.4750 - val_accuracy: 0.9818\n",
            "Epoch 901/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0026 - accuracy: 0.9995 - val_loss: 0.5048 - val_accuracy: 0.9824\n",
            "Epoch 902/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0038 - accuracy: 0.9994 - val_loss: 0.5055 - val_accuracy: 0.9824\n",
            "Epoch 903/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0034 - accuracy: 0.9994 - val_loss: 0.9003 - val_accuracy: 0.9763\n",
            "Epoch 904/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0177 - accuracy: 0.9970 - val_loss: 0.6489 - val_accuracy: 0.9775\n",
            "Epoch 905/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0086 - accuracy: 0.9986 - val_loss: 0.3807 - val_accuracy: 0.9812\n",
            "Epoch 906/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0052 - accuracy: 0.9991 - val_loss: 0.6372 - val_accuracy: 0.9794\n",
            "Epoch 907/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0068 - accuracy: 0.9991 - val_loss: 0.7396 - val_accuracy: 0.9763\n",
            "Epoch 908/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0080 - accuracy: 0.9983 - val_loss: 0.5376 - val_accuracy: 0.9818\n",
            "Epoch 909/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0044 - accuracy: 0.9989 - val_loss: 0.5901 - val_accuracy: 0.9830\n",
            "Epoch 910/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0051 - accuracy: 0.9991 - val_loss: 7.4418 - val_accuracy: 0.9393\n",
            "Epoch 911/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0066 - accuracy: 0.9989 - val_loss: 0.7721 - val_accuracy: 0.9769\n",
            "Epoch 912/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0349 - accuracy: 0.9959 - val_loss: 0.3160 - val_accuracy: 0.9788\n",
            "Epoch 913/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0185 - accuracy: 0.9956 - val_loss: 0.5466 - val_accuracy: 0.9782\n",
            "Epoch 914/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0088 - accuracy: 0.9985 - val_loss: 0.3836 - val_accuracy: 0.9842\n",
            "Epoch 915/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0052 - accuracy: 0.9989 - val_loss: 0.6427 - val_accuracy: 0.9860\n",
            "Epoch 916/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0117 - accuracy: 0.9983 - val_loss: 0.5865 - val_accuracy: 0.9848\n",
            "Epoch 917/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.7547 - val_accuracy: 0.9824\n",
            "Epoch 918/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0035 - accuracy: 0.9992 - val_loss: 0.5225 - val_accuracy: 0.9848\n",
            "Epoch 919/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0060 - accuracy: 0.9988 - val_loss: 0.9400 - val_accuracy: 0.9769\n",
            "Epoch 920/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0121 - accuracy: 0.9986 - val_loss: 0.3426 - val_accuracy: 0.9848\n",
            "Epoch 921/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0096 - accuracy: 0.9980 - val_loss: 0.4425 - val_accuracy: 0.9854\n",
            "Epoch 922/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0159 - accuracy: 0.9979 - val_loss: 0.2875 - val_accuracy: 0.9812\n",
            "Epoch 923/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0110 - accuracy: 0.9983 - val_loss: 0.3719 - val_accuracy: 0.9854\n",
            "Epoch 924/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0059 - accuracy: 0.9992 - val_loss: 0.4288 - val_accuracy: 0.9854\n",
            "Epoch 925/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0066 - accuracy: 0.9991 - val_loss: 0.3508 - val_accuracy: 0.9860\n",
            "Epoch 926/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0054 - accuracy: 0.9986 - val_loss: 0.4260 - val_accuracy: 0.9860\n",
            "Epoch 927/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0077 - accuracy: 0.9983 - val_loss: 0.3507 - val_accuracy: 0.9873\n",
            "Epoch 928/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0065 - accuracy: 0.9989 - val_loss: 0.3678 - val_accuracy: 0.9867\n",
            "Epoch 929/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0048 - accuracy: 0.9991 - val_loss: 0.3724 - val_accuracy: 0.9873\n",
            "Epoch 930/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0031 - accuracy: 0.9995 - val_loss: 0.3724 - val_accuracy: 0.9879\n",
            "Epoch 931/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0063 - accuracy: 0.9991 - val_loss: 0.8549 - val_accuracy: 0.9794\n",
            "Epoch 932/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0106 - accuracy: 0.9982 - val_loss: 1.9280 - val_accuracy: 0.9660\n",
            "Epoch 933/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0071 - accuracy: 0.9986 - val_loss: 0.4325 - val_accuracy: 0.9860\n",
            "Epoch 934/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0072 - accuracy: 0.9985 - val_loss: 0.8058 - val_accuracy: 0.9824\n",
            "Epoch 935/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0050 - accuracy: 0.9989 - val_loss: 0.8678 - val_accuracy: 0.9788\n",
            "Epoch 936/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0024 - accuracy: 0.9997 - val_loss: 0.4498 - val_accuracy: 0.9806\n",
            "Epoch 937/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0054 - accuracy: 0.9989 - val_loss: 0.4340 - val_accuracy: 0.9800\n",
            "Epoch 938/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0140 - accuracy: 0.9982 - val_loss: 0.8653 - val_accuracy: 0.9709\n",
            "Epoch 939/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0098 - accuracy: 0.9982 - val_loss: 0.6798 - val_accuracy: 0.9733\n",
            "Epoch 940/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0078 - accuracy: 0.9983 - val_loss: 0.5602 - val_accuracy: 0.9745\n",
            "Epoch 941/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0055 - accuracy: 0.9988 - val_loss: 0.5476 - val_accuracy: 0.9763\n",
            "Epoch 942/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0130 - accuracy: 0.9979 - val_loss: 0.7897 - val_accuracy: 0.9751\n",
            "Epoch 943/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0157 - accuracy: 0.9977 - val_loss: 0.4274 - val_accuracy: 0.9800\n",
            "Epoch 944/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0046 - accuracy: 0.9991 - val_loss: 0.8707 - val_accuracy: 0.9751\n",
            "Epoch 945/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0205 - accuracy: 0.9991 - val_loss: 1.1593 - val_accuracy: 0.9775\n",
            "Epoch 946/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0090 - accuracy: 0.9982 - val_loss: 0.4542 - val_accuracy: 0.9794\n",
            "Epoch 947/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0108 - accuracy: 0.9976 - val_loss: 0.6231 - val_accuracy: 0.9806\n",
            "Epoch 948/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0072 - accuracy: 0.9985 - val_loss: 1.1260 - val_accuracy: 0.9769\n",
            "Epoch 949/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0172 - accuracy: 0.9983 - val_loss: 0.7579 - val_accuracy: 0.9812\n",
            "Epoch 950/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.7804 - val_accuracy: 0.9812\n",
            "Epoch 951/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0036 - accuracy: 0.9992 - val_loss: 0.8104 - val_accuracy: 0.9782\n",
            "Epoch 952/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0403 - accuracy: 0.9973 - val_loss: 0.9514 - val_accuracy: 0.9806\n",
            "Epoch 953/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0105 - accuracy: 0.9980 - val_loss: 0.7944 - val_accuracy: 0.9806\n",
            "Epoch 954/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0102 - accuracy: 0.9985 - val_loss: 0.4455 - val_accuracy: 0.9842\n",
            "Epoch 955/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0068 - accuracy: 0.9994 - val_loss: 0.5069 - val_accuracy: 0.9848\n",
            "Epoch 956/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0031 - accuracy: 0.9992 - val_loss: 0.9082 - val_accuracy: 0.9812\n",
            "Epoch 957/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0046 - accuracy: 0.9989 - val_loss: 0.9380 - val_accuracy: 0.9775\n",
            "Epoch 958/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0053 - accuracy: 0.9992 - val_loss: 0.7185 - val_accuracy: 0.9812\n",
            "Epoch 959/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0039 - accuracy: 0.9991 - val_loss: 0.9712 - val_accuracy: 0.9800\n",
            "Epoch 960/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0181 - accuracy: 0.9991 - val_loss: 0.9062 - val_accuracy: 0.9794\n",
            "Epoch 961/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0019 - accuracy: 0.9997 - val_loss: 0.9333 - val_accuracy: 0.9794\n",
            "Epoch 962/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0031 - accuracy: 0.9995 - val_loss: 0.9689 - val_accuracy: 0.9788\n",
            "Epoch 963/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0089 - accuracy: 0.9980 - val_loss: 0.5903 - val_accuracy: 0.9824\n",
            "Epoch 964/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0022 - accuracy: 0.9997 - val_loss: 0.6667 - val_accuracy: 0.9812\n",
            "Epoch 965/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0016 - accuracy: 0.9998 - val_loss: 0.7081 - val_accuracy: 0.9824\n",
            "Epoch 966/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 0.8106 - val_accuracy: 0.9818\n",
            "Epoch 967/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.7099 - val_accuracy: 0.9824\n",
            "Epoch 968/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 1.1999 - val_accuracy: 0.9794\n",
            "Epoch 969/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0239 - accuracy: 0.9973 - val_loss: 0.5648 - val_accuracy: 0.9788\n",
            "Epoch 970/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0060 - accuracy: 0.9986 - val_loss: 0.5613 - val_accuracy: 0.9812\n",
            "Epoch 971/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.4573 - val_accuracy: 0.9824\n",
            "Epoch 972/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0097 - accuracy: 0.9983 - val_loss: 1.7061 - val_accuracy: 0.9624\n",
            "Epoch 973/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0540 - accuracy: 0.9962 - val_loss: 0.3780 - val_accuracy: 0.9794\n",
            "Epoch 974/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0344 - accuracy: 0.9947 - val_loss: 0.2976 - val_accuracy: 0.9812\n",
            "Epoch 975/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0056 - accuracy: 0.9986 - val_loss: 0.3883 - val_accuracy: 0.9794\n",
            "Epoch 976/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0034 - accuracy: 0.9994 - val_loss: 0.5225 - val_accuracy: 0.9800\n",
            "Epoch 977/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0086 - accuracy: 0.9986 - val_loss: 0.3748 - val_accuracy: 0.9830\n",
            "Epoch 978/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0039 - accuracy: 0.9992 - val_loss: 0.4220 - val_accuracy: 0.9818\n",
            "Epoch 979/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.5273 - val_accuracy: 0.9806\n",
            "Epoch 980/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0042 - accuracy: 0.9991 - val_loss: 0.6095 - val_accuracy: 0.9806\n",
            "Epoch 981/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0111 - accuracy: 0.9979 - val_loss: 0.5885 - val_accuracy: 0.9812\n",
            "Epoch 982/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0173 - accuracy: 0.9974 - val_loss: 0.5286 - val_accuracy: 0.9794\n",
            "Epoch 983/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0069 - accuracy: 0.9985 - val_loss: 1.1411 - val_accuracy: 0.9715\n",
            "Epoch 984/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0158 - accuracy: 0.9979 - val_loss: 0.7367 - val_accuracy: 0.9812\n",
            "Epoch 985/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0321 - accuracy: 0.9953 - val_loss: 0.5314 - val_accuracy: 0.9818\n",
            "Epoch 986/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0164 - accuracy: 0.9965 - val_loss: 0.3323 - val_accuracy: 0.9745\n",
            "Epoch 987/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0101 - accuracy: 0.9982 - val_loss: 0.7500 - val_accuracy: 0.9806\n",
            "Epoch 988/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0072 - accuracy: 0.9985 - val_loss: 0.8517 - val_accuracy: 0.9806\n",
            "Epoch 989/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0127 - accuracy: 0.9991 - val_loss: 0.8403 - val_accuracy: 0.9794\n",
            "Epoch 990/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.7508 - val_accuracy: 0.9788\n",
            "Epoch 991/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0025 - accuracy: 0.9995 - val_loss: 0.8571 - val_accuracy: 0.9782\n",
            "Epoch 992/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0150 - accuracy: 0.9989 - val_loss: 0.7160 - val_accuracy: 0.9788\n",
            "Epoch 993/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0055 - accuracy: 0.9988 - val_loss: 0.5115 - val_accuracy: 0.9818\n",
            "Epoch 994/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0046 - accuracy: 0.9991 - val_loss: 0.8055 - val_accuracy: 0.9782\n",
            "Epoch 995/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0089 - accuracy: 0.9986 - val_loss: 0.7942 - val_accuracy: 0.9788\n",
            "Epoch 996/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 1.0539 - val_accuracy: 0.9782\n",
            "Epoch 997/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0072 - accuracy: 0.9986 - val_loss: 0.4441 - val_accuracy: 0.9818\n",
            "Epoch 998/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0073 - accuracy: 0.9985 - val_loss: 1.0874 - val_accuracy: 0.9715\n",
            "Epoch 999/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0183 - accuracy: 0.9974 - val_loss: 0.7044 - val_accuracy: 0.9769\n",
            "Epoch 1000/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0101 - accuracy: 0.9979 - val_loss: 0.5652 - val_accuracy: 0.9800\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1200x400 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "206/206 [==============================] - 12s 46ms/step - loss: 3.5716 - accuracy: 0.8584 - val_loss: 0.2889 - val_accuracy: 0.8689\n",
            "Epoch 2/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.2944 - accuracy: 0.8806 - val_loss: 0.1969 - val_accuracy: 0.8695\n",
            "Epoch 3/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.2758 - accuracy: 0.8807 - val_loss: 0.1867 - val_accuracy: 0.8677\n",
            "Epoch 4/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.2261 - accuracy: 0.8821 - val_loss: 0.1872 - val_accuracy: 0.8701\n",
            "Epoch 5/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.2168 - accuracy: 0.8822 - val_loss: 0.1615 - val_accuracy: 0.8726\n",
            "Epoch 6/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1922 - accuracy: 0.8895 - val_loss: 0.1353 - val_accuracy: 0.9029\n",
            "Epoch 7/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1682 - accuracy: 0.8954 - val_loss: 0.1372 - val_accuracy: 0.8938\n",
            "Epoch 8/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.2825 - accuracy: 0.8892 - val_loss: 0.3314 - val_accuracy: 0.8635\n",
            "Epoch 9/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.2326 - accuracy: 0.8813 - val_loss: 0.2191 - val_accuracy: 0.8714\n",
            "Epoch 10/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1969 - accuracy: 0.8985 - val_loss: 0.1416 - val_accuracy: 0.9521\n",
            "Epoch 11/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1669 - accuracy: 0.9302 - val_loss: 0.1836 - val_accuracy: 0.9314\n",
            "Epoch 12/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1706 - accuracy: 0.9282 - val_loss: 0.3043 - val_accuracy: 0.8841\n",
            "Epoch 13/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1623 - accuracy: 0.9275 - val_loss: 0.1364 - val_accuracy: 0.9733\n",
            "Epoch 14/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1641 - accuracy: 0.9340 - val_loss: 0.1200 - val_accuracy: 0.9697\n",
            "Epoch 15/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1520 - accuracy: 0.9373 - val_loss: 0.1199 - val_accuracy: 0.9636\n",
            "Epoch 16/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1526 - accuracy: 0.9373 - val_loss: 0.1527 - val_accuracy: 0.9575\n",
            "Epoch 17/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1372 - accuracy: 0.9457 - val_loss: 0.1086 - val_accuracy: 0.9775\n",
            "Epoch 18/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1417 - accuracy: 0.9425 - val_loss: 0.1056 - val_accuracy: 0.9775\n",
            "Epoch 19/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1473 - accuracy: 0.9429 - val_loss: 0.1984 - val_accuracy: 0.9430\n",
            "Epoch 20/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1469 - accuracy: 0.9440 - val_loss: 0.6070 - val_accuracy: 0.9490\n",
            "Epoch 21/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1898 - accuracy: 0.9226 - val_loss: 0.1638 - val_accuracy: 0.9527\n",
            "Epoch 22/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1592 - accuracy: 0.9203 - val_loss: 0.1038 - val_accuracy: 0.9606\n",
            "Epoch 23/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1440 - accuracy: 0.9357 - val_loss: 0.0890 - val_accuracy: 0.9812\n",
            "Epoch 24/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1199 - accuracy: 0.9478 - val_loss: 0.0900 - val_accuracy: 0.9769\n",
            "Epoch 25/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1264 - accuracy: 0.9472 - val_loss: 0.1749 - val_accuracy: 0.9636\n",
            "Epoch 26/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1166 - accuracy: 0.9490 - val_loss: 0.0902 - val_accuracy: 0.9800\n",
            "Epoch 27/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1009 - accuracy: 0.9610 - val_loss: 0.1350 - val_accuracy: 0.9751\n",
            "Epoch 28/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1071 - accuracy: 0.9598 - val_loss: 0.0823 - val_accuracy: 0.9727\n",
            "Epoch 29/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1266 - accuracy: 0.9560 - val_loss: 0.1127 - val_accuracy: 0.9751\n",
            "Epoch 30/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0943 - accuracy: 0.9592 - val_loss: 0.1131 - val_accuracy: 0.9636\n",
            "Epoch 31/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1038 - accuracy: 0.9590 - val_loss: 1.0082 - val_accuracy: 0.8944\n",
            "Epoch 32/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0954 - accuracy: 0.9627 - val_loss: 0.0721 - val_accuracy: 0.9818\n",
            "Epoch 33/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0870 - accuracy: 0.9639 - val_loss: 0.0787 - val_accuracy: 0.9836\n",
            "Epoch 34/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0788 - accuracy: 0.9700 - val_loss: 0.1369 - val_accuracy: 0.9739\n",
            "Epoch 35/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0729 - accuracy: 0.9731 - val_loss: 0.1267 - val_accuracy: 0.9800\n",
            "Epoch 36/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0865 - accuracy: 0.9721 - val_loss: 0.2639 - val_accuracy: 0.9490\n",
            "Epoch 37/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1116 - accuracy: 0.9710 - val_loss: 3.6752 - val_accuracy: 0.9120\n",
            "Epoch 38/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0859 - accuracy: 0.9654 - val_loss: 9.4044 - val_accuracy: 0.8993\n",
            "Epoch 39/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0763 - accuracy: 0.9712 - val_loss: 0.2197 - val_accuracy: 0.9769\n",
            "Epoch 40/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0774 - accuracy: 0.9719 - val_loss: 0.0713 - val_accuracy: 0.9885\n",
            "Epoch 41/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0633 - accuracy: 0.9781 - val_loss: 0.0994 - val_accuracy: 0.9824\n",
            "Epoch 42/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0901 - accuracy: 0.9734 - val_loss: 0.2457 - val_accuracy: 0.9654\n",
            "Epoch 43/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0908 - accuracy: 0.9683 - val_loss: 0.0729 - val_accuracy: 0.9775\n",
            "Epoch 44/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0607 - accuracy: 0.9795 - val_loss: 0.0586 - val_accuracy: 0.9860\n",
            "Epoch 45/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0527 - accuracy: 0.9825 - val_loss: 0.1129 - val_accuracy: 0.9842\n",
            "Epoch 46/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0593 - accuracy: 0.9803 - val_loss: 0.1061 - val_accuracy: 0.9818\n",
            "Epoch 47/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0511 - accuracy: 0.9833 - val_loss: 0.0751 - val_accuracy: 0.9885\n",
            "Epoch 48/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0477 - accuracy: 0.9839 - val_loss: 0.1140 - val_accuracy: 0.9800\n",
            "Epoch 49/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0703 - accuracy: 0.9785 - val_loss: 2.0927 - val_accuracy: 0.9248\n",
            "Epoch 50/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0582 - accuracy: 0.9786 - val_loss: 0.1556 - val_accuracy: 0.9800\n",
            "Epoch 51/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0493 - accuracy: 0.9841 - val_loss: 0.1875 - val_accuracy: 0.9745\n",
            "Epoch 52/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1129 - accuracy: 0.9707 - val_loss: 0.1140 - val_accuracy: 0.9800\n",
            "Epoch 53/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0719 - accuracy: 0.9728 - val_loss: 0.0496 - val_accuracy: 0.9885\n",
            "Epoch 54/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0440 - accuracy: 0.9865 - val_loss: 0.1187 - val_accuracy: 0.9751\n",
            "Epoch 55/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0918 - accuracy: 0.9731 - val_loss: 0.0837 - val_accuracy: 0.9678\n",
            "Epoch 56/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0727 - accuracy: 0.9736 - val_loss: 0.1227 - val_accuracy: 0.9812\n",
            "Epoch 57/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0500 - accuracy: 0.9803 - val_loss: 1.9531 - val_accuracy: 0.9618\n",
            "Epoch 58/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0492 - accuracy: 0.9847 - val_loss: 0.1397 - val_accuracy: 0.9727\n",
            "Epoch 59/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0436 - accuracy: 0.9853 - val_loss: 0.0934 - val_accuracy: 0.9848\n",
            "Epoch 60/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0500 - accuracy: 0.9839 - val_loss: 0.1909 - val_accuracy: 0.9715\n",
            "Epoch 61/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0514 - accuracy: 0.9847 - val_loss: 0.5152 - val_accuracy: 0.9697\n",
            "Epoch 62/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0575 - accuracy: 0.9783 - val_loss: 0.0703 - val_accuracy: 0.9867\n",
            "Epoch 63/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0395 - accuracy: 0.9868 - val_loss: 0.2280 - val_accuracy: 0.9800\n",
            "Epoch 64/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0442 - accuracy: 0.9850 - val_loss: 0.0901 - val_accuracy: 0.9909\n",
            "Epoch 65/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0393 - accuracy: 0.9889 - val_loss: 4.0160 - val_accuracy: 0.9563\n",
            "Epoch 66/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0446 - accuracy: 0.9869 - val_loss: 0.1275 - val_accuracy: 0.9854\n",
            "Epoch 67/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0389 - accuracy: 0.9876 - val_loss: 0.1278 - val_accuracy: 0.9873\n",
            "Epoch 68/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0417 - accuracy: 0.9876 - val_loss: 0.1488 - val_accuracy: 0.9818\n",
            "Epoch 69/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0366 - accuracy: 0.9888 - val_loss: 0.0487 - val_accuracy: 0.9927\n",
            "Epoch 70/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0281 - accuracy: 0.9914 - val_loss: 0.0725 - val_accuracy: 0.9933\n",
            "Epoch 71/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0326 - accuracy: 0.9906 - val_loss: 0.2124 - val_accuracy: 0.9788\n",
            "Epoch 72/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0419 - accuracy: 0.9876 - val_loss: 0.1960 - val_accuracy: 0.9782\n",
            "Epoch 73/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0588 - accuracy: 0.9841 - val_loss: 0.3877 - val_accuracy: 0.9666\n",
            "Epoch 74/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0716 - accuracy: 0.9810 - val_loss: 0.2444 - val_accuracy: 0.9684\n",
            "Epoch 75/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0401 - accuracy: 0.9885 - val_loss: 0.0899 - val_accuracy: 0.9848\n",
            "Epoch 76/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0409 - accuracy: 0.9869 - val_loss: 0.1590 - val_accuracy: 0.9830\n",
            "Epoch 77/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0289 - accuracy: 0.9909 - val_loss: 0.1278 - val_accuracy: 0.9879\n",
            "Epoch 78/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0330 - accuracy: 0.9889 - val_loss: 0.1049 - val_accuracy: 0.9867\n",
            "Epoch 79/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0393 - accuracy: 0.9907 - val_loss: 0.1595 - val_accuracy: 0.9842\n",
            "Epoch 80/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0329 - accuracy: 0.9901 - val_loss: 0.0886 - val_accuracy: 0.9860\n",
            "Epoch 81/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0227 - accuracy: 0.9942 - val_loss: 0.1552 - val_accuracy: 0.9818\n",
            "Epoch 82/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0289 - accuracy: 0.9910 - val_loss: 0.2607 - val_accuracy: 0.9788\n",
            "Epoch 83/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0376 - accuracy: 0.9891 - val_loss: 0.0691 - val_accuracy: 0.9800\n",
            "Epoch 84/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0267 - accuracy: 0.9929 - val_loss: 0.1004 - val_accuracy: 0.9848\n",
            "Epoch 85/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0329 - accuracy: 0.9894 - val_loss: 0.1450 - val_accuracy: 0.9854\n",
            "Epoch 86/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0266 - accuracy: 0.9918 - val_loss: 0.1598 - val_accuracy: 0.9818\n",
            "Epoch 87/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0293 - accuracy: 0.9914 - val_loss: 0.0849 - val_accuracy: 0.9879\n",
            "Epoch 88/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0290 - accuracy: 0.9926 - val_loss: 0.1015 - val_accuracy: 0.9873\n",
            "Epoch 89/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0223 - accuracy: 0.9933 - val_loss: 0.2618 - val_accuracy: 0.9806\n",
            "Epoch 90/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0452 - accuracy: 0.9886 - val_loss: 0.0507 - val_accuracy: 0.9812\n",
            "Epoch 91/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0326 - accuracy: 0.9910 - val_loss: 0.1654 - val_accuracy: 0.9891\n",
            "Epoch 92/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0209 - accuracy: 0.9938 - val_loss: 0.2945 - val_accuracy: 0.9666\n",
            "Epoch 93/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0251 - accuracy: 0.9932 - val_loss: 0.1428 - val_accuracy: 0.9824\n",
            "Epoch 94/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0253 - accuracy: 0.9924 - val_loss: 0.0643 - val_accuracy: 0.9921\n",
            "Epoch 95/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0214 - accuracy: 0.9939 - val_loss: 0.2750 - val_accuracy: 0.9782\n",
            "Epoch 96/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0259 - accuracy: 0.9929 - val_loss: 0.4842 - val_accuracy: 0.9678\n",
            "Epoch 97/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0386 - accuracy: 0.9907 - val_loss: 0.2714 - val_accuracy: 0.9703\n",
            "Epoch 98/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0279 - accuracy: 0.9917 - val_loss: 0.0930 - val_accuracy: 0.9891\n",
            "Epoch 99/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0255 - accuracy: 0.9935 - val_loss: 0.0779 - val_accuracy: 0.9915\n",
            "Epoch 100/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0244 - accuracy: 0.9948 - val_loss: 0.1336 - val_accuracy: 0.9879\n",
            "Epoch 101/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0322 - accuracy: 0.9901 - val_loss: 0.0934 - val_accuracy: 0.9915\n",
            "Epoch 102/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0169 - accuracy: 0.9959 - val_loss: 0.1794 - val_accuracy: 0.9842\n",
            "Epoch 103/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0152 - accuracy: 0.9961 - val_loss: 0.0997 - val_accuracy: 0.9909\n",
            "Epoch 104/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0420 - accuracy: 0.9924 - val_loss: 0.4045 - val_accuracy: 0.9587\n",
            "Epoch 105/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0383 - accuracy: 0.9895 - val_loss: 0.1138 - val_accuracy: 0.9891\n",
            "Epoch 106/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0196 - accuracy: 0.9954 - val_loss: 0.0711 - val_accuracy: 0.9909\n",
            "Epoch 107/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0242 - accuracy: 0.9933 - val_loss: 0.0773 - val_accuracy: 0.9897\n",
            "Epoch 108/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0169 - accuracy: 0.9953 - val_loss: 0.1915 - val_accuracy: 0.9860\n",
            "Epoch 109/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0285 - accuracy: 0.9920 - val_loss: 0.0918 - val_accuracy: 0.9891\n",
            "Epoch 110/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0198 - accuracy: 0.9939 - val_loss: 0.0732 - val_accuracy: 0.9909\n",
            "Epoch 111/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0175 - accuracy: 0.9947 - val_loss: 0.1107 - val_accuracy: 0.9891\n",
            "Epoch 112/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0175 - accuracy: 0.9953 - val_loss: 0.1089 - val_accuracy: 0.9909\n",
            "Epoch 113/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0304 - accuracy: 0.9935 - val_loss: 0.1651 - val_accuracy: 0.9612\n",
            "Epoch 114/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0642 - accuracy: 0.9859 - val_loss: 0.1080 - val_accuracy: 0.9836\n",
            "Epoch 115/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0262 - accuracy: 0.9939 - val_loss: 0.0692 - val_accuracy: 0.9897\n",
            "Epoch 116/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0388 - accuracy: 0.9924 - val_loss: 0.1397 - val_accuracy: 0.9854\n",
            "Epoch 117/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0313 - accuracy: 0.9929 - val_loss: 0.0721 - val_accuracy: 0.9873\n",
            "Epoch 118/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0342 - accuracy: 0.9927 - val_loss: 0.1551 - val_accuracy: 0.9818\n",
            "Epoch 119/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0264 - accuracy: 0.9929 - val_loss: 0.1140 - val_accuracy: 0.9885\n",
            "Epoch 120/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0355 - accuracy: 0.9933 - val_loss: 0.1228 - val_accuracy: 0.9842\n",
            "Epoch 121/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0340 - accuracy: 0.9907 - val_loss: 0.0703 - val_accuracy: 0.9903\n",
            "Epoch 122/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0224 - accuracy: 0.9932 - val_loss: 0.3716 - val_accuracy: 0.9745\n",
            "Epoch 123/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0357 - accuracy: 0.9933 - val_loss: 0.5460 - val_accuracy: 0.9800\n",
            "Epoch 124/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0260 - accuracy: 0.9930 - val_loss: 0.1106 - val_accuracy: 0.9915\n",
            "Epoch 125/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0207 - accuracy: 0.9944 - val_loss: 0.1424 - val_accuracy: 0.9885\n",
            "Epoch 126/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0194 - accuracy: 0.9948 - val_loss: 0.1470 - val_accuracy: 0.9879\n",
            "Epoch 127/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0171 - accuracy: 0.9961 - val_loss: 0.2573 - val_accuracy: 0.9848\n",
            "Epoch 128/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0178 - accuracy: 0.9953 - val_loss: 0.1600 - val_accuracy: 0.9885\n",
            "Epoch 129/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0221 - accuracy: 0.9942 - val_loss: 0.6737 - val_accuracy: 0.9733\n",
            "Epoch 130/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0283 - accuracy: 0.9945 - val_loss: 0.1610 - val_accuracy: 0.9854\n",
            "Epoch 131/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0186 - accuracy: 0.9967 - val_loss: 0.1092 - val_accuracy: 0.9842\n",
            "Epoch 132/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0145 - accuracy: 0.9962 - val_loss: 0.1254 - val_accuracy: 0.9903\n",
            "Epoch 133/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0148 - accuracy: 0.9967 - val_loss: 0.1041 - val_accuracy: 0.9927\n",
            "Epoch 134/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0269 - accuracy: 0.9938 - val_loss: 0.1460 - val_accuracy: 0.9854\n",
            "Epoch 135/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0259 - accuracy: 0.9938 - val_loss: 0.1518 - val_accuracy: 0.9842\n",
            "Epoch 136/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0265 - accuracy: 0.9921 - val_loss: 0.3499 - val_accuracy: 0.9727\n",
            "Epoch 137/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0222 - accuracy: 0.9936 - val_loss: 0.1074 - val_accuracy: 0.9903\n",
            "Epoch 138/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0130 - accuracy: 0.9968 - val_loss: 0.1330 - val_accuracy: 0.9903\n",
            "Epoch 139/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0153 - accuracy: 0.9964 - val_loss: 0.1798 - val_accuracy: 0.9885\n",
            "Epoch 140/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0243 - accuracy: 0.9944 - val_loss: 0.0887 - val_accuracy: 0.9891\n",
            "Epoch 141/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0205 - accuracy: 0.9945 - val_loss: 0.2047 - val_accuracy: 0.9854\n",
            "Epoch 142/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0175 - accuracy: 0.9956 - val_loss: 0.2122 - val_accuracy: 0.9885\n",
            "Epoch 143/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0191 - accuracy: 0.9959 - val_loss: 0.2347 - val_accuracy: 0.9867\n",
            "Epoch 144/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0205 - accuracy: 0.9948 - val_loss: 0.3595 - val_accuracy: 0.9854\n",
            "Epoch 145/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0146 - accuracy: 0.9967 - val_loss: 0.8553 - val_accuracy: 0.9727\n",
            "Epoch 146/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0502 - accuracy: 0.9926 - val_loss: 0.1471 - val_accuracy: 0.9757\n",
            "Epoch 147/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0832 - accuracy: 0.9845 - val_loss: 1.0067 - val_accuracy: 0.9375\n",
            "Epoch 148/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0405 - accuracy: 0.9886 - val_loss: 0.2092 - val_accuracy: 0.9830\n",
            "Epoch 149/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0184 - accuracy: 0.9950 - val_loss: 0.1396 - val_accuracy: 0.9927\n",
            "Epoch 150/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0130 - accuracy: 0.9970 - val_loss: 0.1680 - val_accuracy: 0.9903\n",
            "Epoch 151/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0184 - accuracy: 0.9959 - val_loss: 0.1425 - val_accuracy: 0.9891\n",
            "Epoch 152/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0351 - accuracy: 0.9933 - val_loss: 0.2637 - val_accuracy: 0.9891\n",
            "Epoch 153/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0223 - accuracy: 0.9951 - val_loss: 0.1927 - val_accuracy: 0.9873\n",
            "Epoch 154/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0199 - accuracy: 0.9951 - val_loss: 0.2527 - val_accuracy: 0.9873\n",
            "Epoch 155/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0161 - accuracy: 0.9965 - val_loss: 0.1378 - val_accuracy: 0.9909\n",
            "Epoch 156/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0186 - accuracy: 0.9945 - val_loss: 0.2199 - val_accuracy: 0.9812\n",
            "Epoch 157/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0222 - accuracy: 0.9950 - val_loss: 0.1378 - val_accuracy: 0.9909\n",
            "Epoch 158/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0319 - accuracy: 0.9958 - val_loss: 0.2064 - val_accuracy: 0.9885\n",
            "Epoch 159/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0179 - accuracy: 0.9964 - val_loss: 0.1974 - val_accuracy: 0.9897\n",
            "Epoch 160/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0193 - accuracy: 0.9954 - val_loss: 0.2180 - val_accuracy: 0.9873\n",
            "Epoch 161/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0190 - accuracy: 0.9954 - val_loss: 0.2054 - val_accuracy: 0.9903\n",
            "Epoch 162/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0144 - accuracy: 0.9964 - val_loss: 0.1961 - val_accuracy: 0.9921\n",
            "Epoch 163/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0227 - accuracy: 0.9961 - val_loss: 0.5063 - val_accuracy: 0.9818\n",
            "Epoch 164/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0307 - accuracy: 0.9950 - val_loss: 0.1050 - val_accuracy: 0.9867\n",
            "Epoch 165/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0222 - accuracy: 0.9953 - val_loss: 0.7475 - val_accuracy: 0.9727\n",
            "Epoch 166/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0132 - accuracy: 0.9968 - val_loss: 0.1977 - val_accuracy: 0.9867\n",
            "Epoch 167/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0121 - accuracy: 0.9970 - val_loss: 0.1843 - val_accuracy: 0.9909\n",
            "Epoch 168/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0208 - accuracy: 0.9951 - val_loss: 0.1693 - val_accuracy: 0.9860\n",
            "Epoch 169/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0164 - accuracy: 0.9958 - val_loss: 0.7001 - val_accuracy: 0.9666\n",
            "Epoch 170/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0174 - accuracy: 0.9959 - val_loss: 0.1780 - val_accuracy: 0.9915\n",
            "Epoch 171/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0163 - accuracy: 0.9958 - val_loss: 0.0763 - val_accuracy: 0.9939\n",
            "Epoch 172/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0129 - accuracy: 0.9967 - val_loss: 0.1793 - val_accuracy: 0.9867\n",
            "Epoch 173/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0128 - accuracy: 0.9970 - val_loss: 0.2177 - val_accuracy: 0.9879\n",
            "Epoch 174/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0328 - accuracy: 0.9939 - val_loss: 0.1081 - val_accuracy: 0.9897\n",
            "Epoch 175/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0134 - accuracy: 0.9971 - val_loss: 0.1262 - val_accuracy: 0.9903\n",
            "Epoch 176/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0072 - accuracy: 0.9986 - val_loss: 0.0708 - val_accuracy: 0.9915\n",
            "Epoch 177/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0109 - accuracy: 0.9976 - val_loss: 0.0743 - val_accuracy: 0.9927\n",
            "Epoch 178/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0128 - accuracy: 0.9973 - val_loss: 0.1015 - val_accuracy: 0.9903\n",
            "Epoch 179/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0124 - accuracy: 0.9968 - val_loss: 0.1086 - val_accuracy: 0.9921\n",
            "Epoch 180/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0171 - accuracy: 0.9968 - val_loss: 0.1576 - val_accuracy: 0.9891\n",
            "Epoch 181/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0283 - accuracy: 0.9951 - val_loss: 0.2799 - val_accuracy: 0.9800\n",
            "Epoch 182/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0136 - accuracy: 0.9965 - val_loss: 0.1683 - val_accuracy: 0.9915\n",
            "Epoch 183/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0299 - accuracy: 0.9950 - val_loss: 0.1140 - val_accuracy: 0.9854\n",
            "Epoch 184/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0343 - accuracy: 0.9930 - val_loss: 0.1085 - val_accuracy: 0.9897\n",
            "Epoch 185/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0171 - accuracy: 0.9965 - val_loss: 0.1256 - val_accuracy: 0.9897\n",
            "Epoch 186/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0167 - accuracy: 0.9961 - val_loss: 0.1677 - val_accuracy: 0.9879\n",
            "Epoch 187/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0173 - accuracy: 0.9965 - val_loss: 0.1877 - val_accuracy: 0.9903\n",
            "Epoch 188/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0141 - accuracy: 0.9965 - val_loss: 0.1519 - val_accuracy: 0.9909\n",
            "Epoch 189/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0085 - accuracy: 0.9982 - val_loss: 0.1129 - val_accuracy: 0.9915\n",
            "Epoch 190/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0156 - accuracy: 0.9971 - val_loss: 0.0687 - val_accuracy: 0.9915\n",
            "Epoch 191/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0323 - accuracy: 0.9954 - val_loss: 0.6528 - val_accuracy: 0.9733\n",
            "Epoch 192/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0160 - accuracy: 0.9967 - val_loss: 0.1989 - val_accuracy: 0.9873\n",
            "Epoch 193/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0194 - accuracy: 0.9964 - val_loss: 0.5130 - val_accuracy: 0.9824\n",
            "Epoch 194/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0175 - accuracy: 0.9961 - val_loss: 4.7652 - val_accuracy: 0.9587\n",
            "Epoch 195/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0197 - accuracy: 0.9958 - val_loss: 0.1783 - val_accuracy: 0.9879\n",
            "Epoch 196/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0115 - accuracy: 0.9977 - val_loss: 0.1611 - val_accuracy: 0.9885\n",
            "Epoch 197/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0136 - accuracy: 0.9970 - val_loss: 0.3064 - val_accuracy: 0.9873\n",
            "Epoch 198/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0078 - accuracy: 0.9985 - val_loss: 0.1862 - val_accuracy: 0.9891\n",
            "Epoch 199/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0161 - accuracy: 0.9965 - val_loss: 0.2017 - val_accuracy: 0.9867\n",
            "Epoch 200/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0161 - accuracy: 0.9959 - val_loss: 0.1792 - val_accuracy: 0.9933\n",
            "Epoch 201/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0199 - accuracy: 0.9956 - val_loss: 0.0502 - val_accuracy: 0.9915\n",
            "Epoch 202/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0170 - accuracy: 0.9959 - val_loss: 0.0781 - val_accuracy: 0.9939\n",
            "Epoch 203/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0142 - accuracy: 0.9970 - val_loss: 0.0850 - val_accuracy: 0.9933\n",
            "Epoch 204/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0105 - accuracy: 0.9974 - val_loss: 0.1357 - val_accuracy: 0.9927\n",
            "Epoch 205/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0099 - accuracy: 0.9976 - val_loss: 0.1538 - val_accuracy: 0.9903\n",
            "Epoch 206/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0094 - accuracy: 0.9982 - val_loss: 0.1345 - val_accuracy: 0.9897\n",
            "Epoch 207/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0129 - accuracy: 0.9976 - val_loss: 0.1051 - val_accuracy: 0.9860\n",
            "Epoch 208/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0155 - accuracy: 0.9959 - val_loss: 0.2776 - val_accuracy: 0.9854\n",
            "Epoch 209/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0116 - accuracy: 0.9971 - val_loss: 0.1535 - val_accuracy: 0.9879\n",
            "Epoch 210/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0103 - accuracy: 0.9976 - val_loss: 0.1795 - val_accuracy: 0.9867\n",
            "Epoch 211/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0120 - accuracy: 0.9971 - val_loss: 0.0910 - val_accuracy: 0.9915\n",
            "Epoch 212/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0097 - accuracy: 0.9976 - val_loss: 0.1856 - val_accuracy: 0.9848\n",
            "Epoch 213/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0126 - accuracy: 0.9970 - val_loss: 0.1532 - val_accuracy: 0.9891\n",
            "Epoch 214/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0394 - accuracy: 0.9954 - val_loss: 0.1501 - val_accuracy: 0.9879\n",
            "Epoch 215/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0467 - accuracy: 0.9945 - val_loss: 0.4446 - val_accuracy: 0.9788\n",
            "Epoch 216/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0162 - accuracy: 0.9967 - val_loss: 0.2050 - val_accuracy: 0.9867\n",
            "Epoch 217/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0169 - accuracy: 0.9970 - val_loss: 0.1618 - val_accuracy: 0.9885\n",
            "Epoch 218/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0110 - accuracy: 0.9977 - val_loss: 0.3807 - val_accuracy: 0.9806\n",
            "Epoch 219/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0124 - accuracy: 0.9974 - val_loss: 0.1960 - val_accuracy: 0.9915\n",
            "Epoch 220/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0114 - accuracy: 0.9968 - val_loss: 0.1425 - val_accuracy: 0.9909\n",
            "Epoch 221/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0218 - accuracy: 0.9947 - val_loss: 0.2253 - val_accuracy: 0.9885\n",
            "Epoch 222/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0190 - accuracy: 0.9956 - val_loss: 0.1235 - val_accuracy: 0.9891\n",
            "Epoch 223/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0117 - accuracy: 0.9974 - val_loss: 0.1734 - val_accuracy: 0.9897\n",
            "Epoch 224/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0169 - accuracy: 0.9974 - val_loss: 0.4320 - val_accuracy: 0.9836\n",
            "Epoch 225/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0348 - accuracy: 0.9956 - val_loss: 0.2166 - val_accuracy: 0.9879\n",
            "Epoch 226/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0174 - accuracy: 0.9974 - val_loss: 0.1358 - val_accuracy: 0.9921\n",
            "Epoch 227/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0187 - accuracy: 0.9977 - val_loss: 0.1831 - val_accuracy: 0.9909\n",
            "Epoch 228/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0102 - accuracy: 0.9977 - val_loss: 0.1568 - val_accuracy: 0.9867\n",
            "Epoch 229/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0299 - accuracy: 0.9961 - val_loss: 0.1711 - val_accuracy: 0.9860\n",
            "Epoch 230/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0158 - accuracy: 0.9962 - val_loss: 0.1747 - val_accuracy: 0.9885\n",
            "Epoch 231/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0156 - accuracy: 0.9962 - val_loss: 0.2122 - val_accuracy: 0.9848\n",
            "Epoch 232/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0151 - accuracy: 0.9968 - val_loss: 0.2057 - val_accuracy: 0.9873\n",
            "Epoch 233/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0092 - accuracy: 0.9982 - val_loss: 0.1337 - val_accuracy: 0.9909\n",
            "Epoch 234/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0138 - accuracy: 0.9970 - val_loss: 0.1460 - val_accuracy: 0.9879\n",
            "Epoch 235/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0178 - accuracy: 0.9962 - val_loss: 0.2546 - val_accuracy: 0.9848\n",
            "Epoch 236/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0129 - accuracy: 0.9965 - val_loss: 0.2361 - val_accuracy: 0.9879\n",
            "Epoch 237/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0117 - accuracy: 0.9976 - val_loss: 0.2242 - val_accuracy: 0.9891\n",
            "Epoch 238/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0078 - accuracy: 0.9983 - val_loss: 0.0973 - val_accuracy: 0.9921\n",
            "Epoch 239/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0262 - accuracy: 0.9968 - val_loss: 0.0775 - val_accuracy: 0.9921\n",
            "Epoch 240/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0119 - accuracy: 0.9973 - val_loss: 0.1348 - val_accuracy: 0.9879\n",
            "Epoch 241/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0117 - accuracy: 0.9974 - val_loss: 0.1829 - val_accuracy: 0.9903\n",
            "Epoch 242/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0195 - accuracy: 0.9954 - val_loss: 0.3726 - val_accuracy: 0.9782\n",
            "Epoch 243/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0111 - accuracy: 0.9974 - val_loss: 0.1666 - val_accuracy: 0.9867\n",
            "Epoch 244/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0076 - accuracy: 0.9988 - val_loss: 0.1859 - val_accuracy: 0.9867\n",
            "Epoch 245/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0100 - accuracy: 0.9977 - val_loss: 0.1457 - val_accuracy: 0.9885\n",
            "Epoch 246/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0092 - accuracy: 0.9980 - val_loss: 0.2287 - val_accuracy: 0.9891\n",
            "Epoch 247/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0089 - accuracy: 0.9980 - val_loss: 0.2797 - val_accuracy: 0.9873\n",
            "Epoch 248/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0083 - accuracy: 0.9982 - val_loss: 0.1432 - val_accuracy: 0.9897\n",
            "Epoch 249/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0235 - accuracy: 0.9967 - val_loss: 0.1336 - val_accuracy: 0.9873\n",
            "Epoch 250/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0100 - accuracy: 0.9976 - val_loss: 0.1599 - val_accuracy: 0.9879\n",
            "Epoch 251/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0103 - accuracy: 0.9977 - val_loss: 0.1395 - val_accuracy: 0.9909\n",
            "Epoch 252/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0053 - accuracy: 0.9989 - val_loss: 0.3423 - val_accuracy: 0.9824\n",
            "Epoch 253/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0392 - accuracy: 0.9938 - val_loss: 0.6531 - val_accuracy: 0.9545\n",
            "Epoch 254/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0371 - accuracy: 0.9942 - val_loss: 0.1669 - val_accuracy: 0.9909\n",
            "Epoch 255/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0185 - accuracy: 0.9964 - val_loss: 0.1146 - val_accuracy: 0.9879\n",
            "Epoch 256/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0116 - accuracy: 0.9973 - val_loss: 0.1189 - val_accuracy: 0.9903\n",
            "Epoch 257/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0151 - accuracy: 0.9962 - val_loss: 0.1738 - val_accuracy: 0.9867\n",
            "Epoch 258/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0112 - accuracy: 0.9982 - val_loss: 0.2019 - val_accuracy: 0.9867\n",
            "Epoch 259/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0141 - accuracy: 0.9967 - val_loss: 0.1451 - val_accuracy: 0.9885\n",
            "Epoch 260/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0251 - accuracy: 0.9979 - val_loss: 0.1331 - val_accuracy: 0.9909\n",
            "Epoch 261/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0124 - accuracy: 0.9971 - val_loss: 0.1292 - val_accuracy: 0.9909\n",
            "Epoch 262/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0116 - accuracy: 0.9974 - val_loss: 0.1202 - val_accuracy: 0.9915\n",
            "Epoch 263/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0112 - accuracy: 0.9977 - val_loss: 0.0910 - val_accuracy: 0.9885\n",
            "Epoch 264/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0088 - accuracy: 0.9980 - val_loss: 0.1130 - val_accuracy: 0.9891\n",
            "Epoch 265/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0063 - accuracy: 0.9988 - val_loss: 0.2204 - val_accuracy: 0.9842\n",
            "Epoch 266/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0128 - accuracy: 0.9971 - val_loss: 0.1280 - val_accuracy: 0.9854\n",
            "Epoch 267/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0138 - accuracy: 0.9974 - val_loss: 0.2667 - val_accuracy: 0.9879\n",
            "Epoch 268/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0148 - accuracy: 0.9967 - val_loss: 0.1426 - val_accuracy: 0.9873\n",
            "Epoch 269/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0115 - accuracy: 0.9974 - val_loss: 0.1471 - val_accuracy: 0.9885\n",
            "Epoch 270/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0117 - accuracy: 0.9973 - val_loss: 0.2275 - val_accuracy: 0.9867\n",
            "Epoch 271/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0109 - accuracy: 0.9977 - val_loss: 0.3548 - val_accuracy: 0.9873\n",
            "Epoch 272/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0100 - accuracy: 0.9977 - val_loss: 0.1427 - val_accuracy: 0.9860\n",
            "Epoch 273/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0088 - accuracy: 0.9988 - val_loss: 0.2058 - val_accuracy: 0.9873\n",
            "Epoch 274/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0438 - accuracy: 0.9948 - val_loss: 0.0898 - val_accuracy: 0.9879\n",
            "Epoch 275/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0112 - accuracy: 0.9976 - val_loss: 0.2039 - val_accuracy: 0.9885\n",
            "Epoch 276/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0131 - accuracy: 0.9976 - val_loss: 0.3237 - val_accuracy: 0.9818\n",
            "Epoch 277/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0113 - accuracy: 0.9976 - val_loss: 0.2056 - val_accuracy: 0.9909\n",
            "Epoch 278/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0325 - accuracy: 0.9962 - val_loss: 0.0885 - val_accuracy: 0.9903\n",
            "Epoch 279/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0140 - accuracy: 0.9965 - val_loss: 0.2675 - val_accuracy: 0.9873\n",
            "Epoch 280/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0119 - accuracy: 0.9977 - val_loss: 0.2076 - val_accuracy: 0.9897\n",
            "Epoch 281/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0092 - accuracy: 0.9979 - val_loss: 0.2070 - val_accuracy: 0.9897\n",
            "Epoch 282/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0065 - accuracy: 0.9986 - val_loss: 0.1166 - val_accuracy: 0.9909\n",
            "Epoch 283/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0128 - accuracy: 0.9971 - val_loss: 0.1531 - val_accuracy: 0.9879\n",
            "Epoch 284/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0292 - accuracy: 0.9945 - val_loss: 0.2669 - val_accuracy: 0.9873\n",
            "Epoch 285/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0171 - accuracy: 0.9962 - val_loss: 0.1349 - val_accuracy: 0.9897\n",
            "Epoch 286/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0314 - accuracy: 0.9970 - val_loss: 0.1172 - val_accuracy: 0.9885\n",
            "Epoch 287/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0137 - accuracy: 0.9973 - val_loss: 0.1707 - val_accuracy: 0.9885\n",
            "Epoch 288/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0051 - accuracy: 0.9992 - val_loss: 0.1968 - val_accuracy: 0.9873\n",
            "Epoch 289/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0083 - accuracy: 0.9983 - val_loss: 0.1835 - val_accuracy: 0.9873\n",
            "Epoch 290/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0064 - accuracy: 0.9986 - val_loss: 0.2002 - val_accuracy: 0.9885\n",
            "Epoch 291/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0188 - accuracy: 0.9982 - val_loss: 0.2740 - val_accuracy: 0.9860\n",
            "Epoch 292/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0279 - accuracy: 0.9954 - val_loss: 0.1339 - val_accuracy: 0.9903\n",
            "Epoch 293/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0269 - accuracy: 0.9948 - val_loss: 0.2181 - val_accuracy: 0.9836\n",
            "Epoch 294/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0122 - accuracy: 0.9973 - val_loss: 0.1729 - val_accuracy: 0.9897\n",
            "Epoch 295/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0368 - accuracy: 0.9950 - val_loss: 0.1145 - val_accuracy: 0.9897\n",
            "Epoch 296/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0192 - accuracy: 0.9956 - val_loss: 0.1064 - val_accuracy: 0.9885\n",
            "Epoch 297/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0109 - accuracy: 0.9976 - val_loss: 0.1108 - val_accuracy: 0.9921\n",
            "Epoch 298/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0066 - accuracy: 0.9988 - val_loss: 0.1361 - val_accuracy: 0.9909\n",
            "Epoch 299/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0129 - accuracy: 0.9974 - val_loss: 0.2162 - val_accuracy: 0.9879\n",
            "Epoch 300/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0261 - accuracy: 0.9951 - val_loss: 0.3566 - val_accuracy: 0.9830\n",
            "Epoch 301/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0141 - accuracy: 0.9970 - val_loss: 0.1647 - val_accuracy: 0.9897\n",
            "Epoch 302/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0207 - accuracy: 0.9962 - val_loss: 0.1267 - val_accuracy: 0.9867\n",
            "Epoch 303/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0176 - accuracy: 0.9964 - val_loss: 0.0893 - val_accuracy: 0.9897\n",
            "Epoch 304/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0049 - accuracy: 0.9992 - val_loss: 0.0836 - val_accuracy: 0.9909\n",
            "Epoch 305/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0136 - accuracy: 0.9964 - val_loss: 0.0922 - val_accuracy: 0.9921\n",
            "Epoch 306/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0051 - accuracy: 0.9991 - val_loss: 0.1787 - val_accuracy: 0.9897\n",
            "Epoch 307/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0057 - accuracy: 0.9991 - val_loss: 0.2114 - val_accuracy: 0.9854\n",
            "Epoch 308/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0118 - accuracy: 0.9976 - val_loss: 0.4633 - val_accuracy: 0.9769\n",
            "Epoch 309/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0259 - accuracy: 0.9956 - val_loss: 0.4548 - val_accuracy: 0.9775\n",
            "Epoch 310/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0173 - accuracy: 0.9958 - val_loss: 0.1438 - val_accuracy: 0.9897\n",
            "Epoch 311/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0066 - accuracy: 0.9988 - val_loss: 0.1618 - val_accuracy: 0.9885\n",
            "Epoch 312/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0066 - accuracy: 0.9986 - val_loss: 0.1489 - val_accuracy: 0.9903\n",
            "Epoch 313/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0125 - accuracy: 0.9974 - val_loss: 0.3936 - val_accuracy: 0.9842\n",
            "Epoch 314/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0311 - accuracy: 0.9951 - val_loss: 0.0997 - val_accuracy: 0.9879\n",
            "Epoch 315/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0220 - accuracy: 0.9954 - val_loss: 0.2030 - val_accuracy: 0.9830\n",
            "Epoch 316/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0075 - accuracy: 0.9983 - val_loss: 0.2210 - val_accuracy: 0.9879\n",
            "Epoch 317/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0098 - accuracy: 0.9979 - val_loss: 0.4123 - val_accuracy: 0.9873\n",
            "Epoch 318/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0076 - accuracy: 0.9985 - val_loss: 0.2702 - val_accuracy: 0.9885\n",
            "Epoch 319/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0102 - accuracy: 0.9983 - val_loss: 0.2584 - val_accuracy: 0.9867\n",
            "Epoch 320/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0075 - accuracy: 0.9986 - val_loss: 0.2512 - val_accuracy: 0.9873\n",
            "Epoch 321/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0101 - accuracy: 0.9977 - val_loss: 0.1739 - val_accuracy: 0.9897\n",
            "Epoch 322/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0101 - accuracy: 0.9979 - val_loss: 0.1432 - val_accuracy: 0.9885\n",
            "Epoch 323/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0127 - accuracy: 0.9968 - val_loss: 0.1578 - val_accuracy: 0.9891\n",
            "Epoch 324/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0068 - accuracy: 0.9986 - val_loss: 0.1617 - val_accuracy: 0.9927\n",
            "Epoch 325/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0041 - accuracy: 0.9992 - val_loss: 0.1368 - val_accuracy: 0.9933\n",
            "Epoch 326/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0130 - accuracy: 0.9979 - val_loss: 0.1317 - val_accuracy: 0.9885\n",
            "Epoch 327/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0090 - accuracy: 0.9980 - val_loss: 0.1438 - val_accuracy: 0.9897\n",
            "Epoch 328/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0105 - accuracy: 0.9979 - val_loss: 0.1726 - val_accuracy: 0.9873\n",
            "Epoch 329/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0097 - accuracy: 0.9983 - val_loss: 0.2388 - val_accuracy: 0.9873\n",
            "Epoch 330/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0086 - accuracy: 0.9995 - val_loss: 0.1233 - val_accuracy: 0.9897\n",
            "Epoch 331/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0085 - accuracy: 0.9985 - val_loss: 0.1745 - val_accuracy: 0.9897\n",
            "Epoch 332/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0063 - accuracy: 0.9986 - val_loss: 0.1985 - val_accuracy: 0.9885\n",
            "Epoch 333/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0067 - accuracy: 0.9985 - val_loss: 0.1478 - val_accuracy: 0.9921\n",
            "Epoch 334/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0054 - accuracy: 0.9991 - val_loss: 0.1821 - val_accuracy: 0.9927\n",
            "Epoch 335/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0073 - accuracy: 0.9988 - val_loss: 0.1821 - val_accuracy: 0.9897\n",
            "Epoch 336/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0113 - accuracy: 0.9973 - val_loss: 0.2718 - val_accuracy: 0.9867\n",
            "Epoch 337/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0102 - accuracy: 0.9982 - val_loss: 0.1899 - val_accuracy: 0.9897\n",
            "Epoch 338/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0109 - accuracy: 0.9979 - val_loss: 0.2403 - val_accuracy: 0.9885\n",
            "Epoch 339/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0102 - accuracy: 0.9979 - val_loss: 0.2886 - val_accuracy: 0.9873\n",
            "Epoch 340/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0157 - accuracy: 0.9970 - val_loss: 0.1019 - val_accuracy: 0.9933\n",
            "Epoch 341/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0128 - accuracy: 0.9977 - val_loss: 0.5605 - val_accuracy: 0.9782\n",
            "Epoch 342/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0104 - accuracy: 0.9976 - val_loss: 0.2035 - val_accuracy: 0.9879\n",
            "Epoch 343/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0060 - accuracy: 0.9986 - val_loss: 0.0742 - val_accuracy: 0.9921\n",
            "Epoch 344/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0093 - accuracy: 0.9983 - val_loss: 0.1972 - val_accuracy: 0.9867\n",
            "Epoch 345/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0150 - accuracy: 0.9973 - val_loss: 0.1729 - val_accuracy: 0.9885\n",
            "Epoch 346/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0103 - accuracy: 0.9979 - val_loss: 0.2056 - val_accuracy: 0.9867\n",
            "Epoch 347/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0128 - accuracy: 0.9973 - val_loss: 0.1618 - val_accuracy: 0.9873\n",
            "Epoch 348/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0255 - accuracy: 0.9964 - val_loss: 0.2484 - val_accuracy: 0.9879\n",
            "Epoch 349/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0088 - accuracy: 0.9976 - val_loss: 0.2871 - val_accuracy: 0.9897\n",
            "Epoch 350/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0087 - accuracy: 0.9976 - val_loss: 0.2714 - val_accuracy: 0.9885\n",
            "Epoch 351/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0130 - accuracy: 0.9974 - val_loss: 0.2306 - val_accuracy: 0.9897\n",
            "Epoch 352/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0056 - accuracy: 0.9986 - val_loss: 0.3422 - val_accuracy: 0.9873\n",
            "Epoch 353/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0294 - accuracy: 0.9970 - val_loss: 0.1946 - val_accuracy: 0.9903\n",
            "Epoch 354/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0040 - accuracy: 0.9991 - val_loss: 0.2624 - val_accuracy: 0.9879\n",
            "Epoch 355/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0235 - accuracy: 0.9980 - val_loss: 0.2695 - val_accuracy: 0.9848\n",
            "Epoch 356/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0093 - accuracy: 0.9979 - val_loss: 0.3291 - val_accuracy: 0.9897\n",
            "Epoch 357/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0054 - accuracy: 0.9991 - val_loss: 0.3692 - val_accuracy: 0.9860\n",
            "Epoch 358/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0113 - accuracy: 0.9982 - val_loss: 0.1660 - val_accuracy: 0.9903\n",
            "Epoch 359/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0081 - accuracy: 0.9982 - val_loss: 0.2591 - val_accuracy: 0.9891\n",
            "Epoch 360/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0127 - accuracy: 0.9976 - val_loss: 0.1453 - val_accuracy: 0.9921\n",
            "Epoch 361/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0059 - accuracy: 0.9988 - val_loss: 0.2415 - val_accuracy: 0.9915\n",
            "Epoch 362/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0065 - accuracy: 0.9988 - val_loss: 0.3672 - val_accuracy: 0.9885\n",
            "Epoch 363/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0064 - accuracy: 0.9985 - val_loss: 0.2952 - val_accuracy: 0.9873\n",
            "Epoch 364/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0076 - accuracy: 0.9988 - val_loss: 0.3971 - val_accuracy: 0.9867\n",
            "Epoch 365/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0082 - accuracy: 0.9983 - val_loss: 0.2379 - val_accuracy: 0.9903\n",
            "Epoch 366/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0203 - accuracy: 0.9968 - val_loss: 0.0634 - val_accuracy: 0.9915\n",
            "Epoch 367/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0101 - accuracy: 0.9974 - val_loss: 0.1786 - val_accuracy: 0.9915\n",
            "Epoch 368/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0109 - accuracy: 0.9980 - val_loss: 0.0968 - val_accuracy: 0.9909\n",
            "Epoch 369/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0076 - accuracy: 0.9985 - val_loss: 0.2125 - val_accuracy: 0.9891\n",
            "Epoch 370/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0077 - accuracy: 0.9982 - val_loss: 0.1907 - val_accuracy: 0.9885\n",
            "Epoch 371/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0095 - accuracy: 0.9977 - val_loss: 0.1107 - val_accuracy: 0.9927\n",
            "Epoch 372/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0261 - accuracy: 0.9976 - val_loss: 0.2709 - val_accuracy: 0.9854\n",
            "Epoch 373/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0116 - accuracy: 0.9977 - val_loss: 0.2464 - val_accuracy: 0.9873\n",
            "Epoch 374/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0179 - accuracy: 0.9968 - val_loss: 0.2510 - val_accuracy: 0.9854\n",
            "Epoch 375/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0087 - accuracy: 0.9982 - val_loss: 0.1364 - val_accuracy: 0.9927\n",
            "Epoch 376/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0072 - accuracy: 0.9983 - val_loss: 0.1277 - val_accuracy: 0.9933\n",
            "Epoch 377/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0094 - accuracy: 0.9980 - val_loss: 0.2347 - val_accuracy: 0.9860\n",
            "Epoch 378/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0157 - accuracy: 0.9974 - val_loss: 0.1434 - val_accuracy: 0.9879\n",
            "Epoch 379/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0068 - accuracy: 0.9986 - val_loss: 0.1127 - val_accuracy: 0.9921\n",
            "Epoch 380/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0091 - accuracy: 0.9980 - val_loss: 0.0766 - val_accuracy: 0.9897\n",
            "Epoch 381/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0092 - accuracy: 0.9985 - val_loss: 0.1493 - val_accuracy: 0.9921\n",
            "Epoch 382/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0088 - accuracy: 0.9980 - val_loss: 0.1572 - val_accuracy: 0.9915\n",
            "Epoch 383/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0083 - accuracy: 0.9982 - val_loss: 0.1764 - val_accuracy: 0.9915\n",
            "Epoch 384/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0081 - accuracy: 0.9985 - val_loss: 0.2527 - val_accuracy: 0.9891\n",
            "Epoch 385/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0083 - accuracy: 0.9985 - val_loss: 0.2557 - val_accuracy: 0.9903\n",
            "Epoch 386/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0055 - accuracy: 0.9989 - val_loss: 0.1766 - val_accuracy: 0.9885\n",
            "Epoch 387/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0123 - accuracy: 0.9989 - val_loss: 0.2103 - val_accuracy: 0.9909\n",
            "Epoch 388/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0138 - accuracy: 0.9979 - val_loss: 0.0914 - val_accuracy: 0.9921\n",
            "Epoch 389/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0093 - accuracy: 0.9979 - val_loss: 0.2521 - val_accuracy: 0.9867\n",
            "Epoch 390/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0081 - accuracy: 0.9983 - val_loss: 0.2140 - val_accuracy: 0.9891\n",
            "Epoch 391/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0048 - accuracy: 0.9989 - val_loss: 0.2267 - val_accuracy: 0.9897\n",
            "Epoch 392/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0124 - accuracy: 0.9977 - val_loss: 0.1555 - val_accuracy: 0.9897\n",
            "Epoch 393/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0108 - accuracy: 0.9976 - val_loss: 0.3000 - val_accuracy: 0.9860\n",
            "Epoch 394/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0362 - accuracy: 0.9991 - val_loss: 0.2533 - val_accuracy: 0.9848\n",
            "Epoch 395/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0152 - accuracy: 0.9967 - val_loss: 0.2916 - val_accuracy: 0.9788\n",
            "Epoch 396/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0100 - accuracy: 0.9979 - val_loss: 0.1252 - val_accuracy: 0.9897\n",
            "Epoch 397/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0062 - accuracy: 0.9985 - val_loss: 0.1523 - val_accuracy: 0.9885\n",
            "Epoch 398/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0039 - accuracy: 0.9991 - val_loss: 0.1367 - val_accuracy: 0.9915\n",
            "Epoch 399/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0035 - accuracy: 0.9992 - val_loss: 0.1858 - val_accuracy: 0.9903\n",
            "Epoch 400/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0026 - accuracy: 0.9992 - val_loss: 0.6559 - val_accuracy: 0.9806\n",
            "Epoch 401/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0071 - accuracy: 0.9991 - val_loss: 0.2323 - val_accuracy: 0.9903\n",
            "Epoch 402/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0040 - accuracy: 0.9992 - val_loss: 0.2556 - val_accuracy: 0.9879\n",
            "Epoch 403/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0104 - accuracy: 0.9977 - val_loss: 0.8063 - val_accuracy: 0.9769\n",
            "Epoch 404/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0087 - accuracy: 0.9985 - val_loss: 0.2745 - val_accuracy: 0.9854\n",
            "Epoch 405/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0241 - accuracy: 0.9977 - val_loss: 0.1433 - val_accuracy: 0.9879\n",
            "Epoch 406/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0144 - accuracy: 0.9970 - val_loss: 0.0824 - val_accuracy: 0.9915\n",
            "Epoch 407/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0076 - accuracy: 0.9985 - val_loss: 0.1973 - val_accuracy: 0.9909\n",
            "Epoch 408/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0150 - accuracy: 0.9970 - val_loss: 0.2604 - val_accuracy: 0.9891\n",
            "Epoch 409/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0112 - accuracy: 0.9980 - val_loss: 0.2079 - val_accuracy: 0.9897\n",
            "Epoch 410/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0112 - accuracy: 0.9983 - val_loss: 0.3672 - val_accuracy: 0.9691\n",
            "Epoch 411/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0092 - accuracy: 0.9979 - val_loss: 0.1420 - val_accuracy: 0.9933\n",
            "Epoch 412/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0070 - accuracy: 0.9986 - val_loss: 0.1027 - val_accuracy: 0.9951\n",
            "Epoch 413/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0110 - accuracy: 0.9976 - val_loss: 0.2373 - val_accuracy: 0.9897\n",
            "Epoch 414/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0040 - accuracy: 0.9994 - val_loss: 0.1305 - val_accuracy: 0.9933\n",
            "Epoch 415/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0083 - accuracy: 0.9983 - val_loss: 0.3047 - val_accuracy: 0.9854\n",
            "Epoch 416/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0061 - accuracy: 0.9988 - val_loss: 0.1914 - val_accuracy: 0.9915\n",
            "Epoch 417/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 0.1666 - val_accuracy: 0.9897\n",
            "Epoch 418/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0022 - accuracy: 0.9997 - val_loss: 0.1194 - val_accuracy: 0.9939\n",
            "Epoch 419/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0079 - accuracy: 0.9983 - val_loss: 0.1310 - val_accuracy: 0.9921\n",
            "Epoch 420/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0036 - accuracy: 0.9991 - val_loss: 0.2426 - val_accuracy: 0.9921\n",
            "Epoch 421/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0076 - accuracy: 0.9991 - val_loss: 0.3488 - val_accuracy: 0.9848\n",
            "Epoch 422/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0058 - accuracy: 0.9988 - val_loss: 0.2964 - val_accuracy: 0.9885\n",
            "Epoch 423/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0127 - accuracy: 0.9982 - val_loss: 0.3364 - val_accuracy: 0.9897\n",
            "Epoch 424/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0143 - accuracy: 0.9983 - val_loss: 0.1812 - val_accuracy: 0.9860\n",
            "Epoch 425/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0277 - accuracy: 0.9958 - val_loss: 0.4399 - val_accuracy: 0.9854\n",
            "Epoch 426/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0063 - accuracy: 0.9989 - val_loss: 0.2220 - val_accuracy: 0.9903\n",
            "Epoch 427/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0181 - accuracy: 0.9988 - val_loss: 0.5833 - val_accuracy: 0.9800\n",
            "Epoch 428/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0103 - accuracy: 0.9979 - val_loss: 0.1662 - val_accuracy: 0.9915\n",
            "Epoch 429/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0036 - accuracy: 0.9994 - val_loss: 0.2641 - val_accuracy: 0.9909\n",
            "Epoch 430/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0068 - accuracy: 0.9988 - val_loss: 0.2480 - val_accuracy: 0.9939\n",
            "Epoch 431/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0052 - accuracy: 0.9991 - val_loss: 0.2736 - val_accuracy: 0.9915\n",
            "Epoch 432/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0042 - accuracy: 0.9992 - val_loss: 0.2324 - val_accuracy: 0.9921\n",
            "Epoch 433/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0102 - accuracy: 0.9980 - val_loss: 1.0218 - val_accuracy: 0.9612\n",
            "Epoch 434/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0108 - accuracy: 0.9983 - val_loss: 0.4475 - val_accuracy: 0.9830\n",
            "Epoch 435/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0151 - accuracy: 0.9983 - val_loss: 0.2795 - val_accuracy: 0.9897\n",
            "Epoch 436/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0102 - accuracy: 0.9977 - val_loss: 0.2860 - val_accuracy: 0.9897\n",
            "Epoch 437/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0034 - accuracy: 0.9995 - val_loss: 0.3359 - val_accuracy: 0.9891\n",
            "Epoch 438/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0044 - accuracy: 0.9991 - val_loss: 0.2685 - val_accuracy: 0.9897\n",
            "Epoch 439/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0050 - accuracy: 0.9992 - val_loss: 0.3121 - val_accuracy: 0.9891\n",
            "Epoch 440/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0055 - accuracy: 0.9986 - val_loss: 0.3420 - val_accuracy: 0.9885\n",
            "Epoch 441/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0041 - accuracy: 0.9994 - val_loss: 0.3658 - val_accuracy: 0.9879\n",
            "Epoch 442/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0038 - accuracy: 0.9994 - val_loss: 0.4140 - val_accuracy: 0.9860\n",
            "Epoch 443/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0129 - accuracy: 0.9986 - val_loss: 0.2660 - val_accuracy: 0.9921\n",
            "Epoch 444/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0062 - accuracy: 0.9988 - val_loss: 0.1356 - val_accuracy: 0.9915\n",
            "Epoch 445/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0140 - accuracy: 0.9979 - val_loss: 0.1238 - val_accuracy: 0.9933\n",
            "Epoch 446/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0171 - accuracy: 0.9974 - val_loss: 0.2616 - val_accuracy: 0.9915\n",
            "Epoch 447/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0092 - accuracy: 0.9986 - val_loss: 0.2456 - val_accuracy: 0.9927\n",
            "Epoch 448/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.2568 - val_accuracy: 0.9903\n",
            "Epoch 449/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0097 - accuracy: 0.9983 - val_loss: 0.1465 - val_accuracy: 0.9921\n",
            "Epoch 450/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0048 - accuracy: 0.9988 - val_loss: 0.3718 - val_accuracy: 0.9879\n",
            "Epoch 451/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0075 - accuracy: 0.9983 - val_loss: 0.2833 - val_accuracy: 0.9897\n",
            "Epoch 452/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0092 - accuracy: 0.9988 - val_loss: 0.2824 - val_accuracy: 0.9915\n",
            "Epoch 453/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0176 - accuracy: 0.9992 - val_loss: 0.1644 - val_accuracy: 0.9927\n",
            "Epoch 454/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0122 - accuracy: 0.9973 - val_loss: 0.2500 - val_accuracy: 0.9903\n",
            "Epoch 455/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0075 - accuracy: 0.9989 - val_loss: 0.1566 - val_accuracy: 0.9921\n",
            "Epoch 456/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0140 - accuracy: 0.9968 - val_loss: 0.1323 - val_accuracy: 0.9897\n",
            "Epoch 457/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0081 - accuracy: 0.9983 - val_loss: 0.3834 - val_accuracy: 0.9848\n",
            "Epoch 458/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0034 - accuracy: 0.9994 - val_loss: 0.2164 - val_accuracy: 0.9885\n",
            "Epoch 459/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0082 - accuracy: 0.9985 - val_loss: 0.2486 - val_accuracy: 0.9873\n",
            "Epoch 460/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0039 - accuracy: 0.9992 - val_loss: 0.3334 - val_accuracy: 0.9891\n",
            "Epoch 461/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0041 - accuracy: 0.9992 - val_loss: 0.3421 - val_accuracy: 0.9860\n",
            "Epoch 462/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0060 - accuracy: 0.9986 - val_loss: 0.3481 - val_accuracy: 0.9800\n",
            "Epoch 463/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0090 - accuracy: 0.9979 - val_loss: 0.1833 - val_accuracy: 0.9879\n",
            "Epoch 464/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.2052 - val_accuracy: 0.9903\n",
            "Epoch 465/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0042 - accuracy: 0.9994 - val_loss: 0.2370 - val_accuracy: 0.9891\n",
            "Epoch 466/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0047 - accuracy: 0.9991 - val_loss: 0.2645 - val_accuracy: 0.9879\n",
            "Epoch 467/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0041 - accuracy: 0.9992 - val_loss: 0.1186 - val_accuracy: 0.9915\n",
            "Epoch 468/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0055 - accuracy: 0.9989 - val_loss: 0.2270 - val_accuracy: 0.9927\n",
            "Epoch 469/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0058 - accuracy: 0.9986 - val_loss: 0.1991 - val_accuracy: 0.9939\n",
            "Epoch 470/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0160 - accuracy: 0.9970 - val_loss: 0.0575 - val_accuracy: 0.9927\n",
            "Epoch 471/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0188 - accuracy: 0.9970 - val_loss: 0.3169 - val_accuracy: 0.9830\n",
            "Epoch 472/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0128 - accuracy: 0.9971 - val_loss: 0.2033 - val_accuracy: 0.9903\n",
            "Epoch 473/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0064 - accuracy: 0.9986 - val_loss: 0.2395 - val_accuracy: 0.9903\n",
            "Epoch 474/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0116 - accuracy: 0.9985 - val_loss: 0.1445 - val_accuracy: 0.9945\n",
            "Epoch 475/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0170 - accuracy: 0.9965 - val_loss: 0.2725 - val_accuracy: 0.9867\n",
            "Epoch 476/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0054 - accuracy: 0.9989 - val_loss: 0.2118 - val_accuracy: 0.9921\n",
            "Epoch 477/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.1063 - val_accuracy: 0.9915\n",
            "Epoch 478/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0038 - accuracy: 0.9989 - val_loss: 0.2412 - val_accuracy: 0.9915\n",
            "Epoch 479/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0056 - accuracy: 0.9989 - val_loss: 0.1057 - val_accuracy: 0.9939\n",
            "Epoch 480/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0044 - accuracy: 0.9992 - val_loss: 0.2082 - val_accuracy: 0.9915\n",
            "Epoch 481/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0053 - accuracy: 0.9986 - val_loss: 0.3202 - val_accuracy: 0.9891\n",
            "Epoch 482/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 0.2085 - val_accuracy: 0.9915\n",
            "Epoch 483/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0068 - accuracy: 0.9983 - val_loss: 0.1855 - val_accuracy: 0.9848\n",
            "Epoch 484/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0050 - accuracy: 0.9986 - val_loss: 0.4989 - val_accuracy: 0.9860\n",
            "Epoch 485/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0040 - accuracy: 0.9991 - val_loss: 0.1543 - val_accuracy: 0.9909\n",
            "Epoch 486/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0079 - accuracy: 0.9994 - val_loss: 0.2240 - val_accuracy: 0.9891\n",
            "Epoch 487/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0076 - accuracy: 0.9988 - val_loss: 0.1446 - val_accuracy: 0.9939\n",
            "Epoch 488/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0086 - accuracy: 0.9985 - val_loss: 0.3884 - val_accuracy: 0.9806\n",
            "Epoch 489/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0079 - accuracy: 0.9988 - val_loss: 0.1913 - val_accuracy: 0.9897\n",
            "Epoch 490/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0085 - accuracy: 0.9988 - val_loss: 0.1704 - val_accuracy: 0.9879\n",
            "Epoch 491/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0129 - accuracy: 0.9983 - val_loss: 0.1554 - val_accuracy: 0.9915\n",
            "Epoch 492/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0094 - accuracy: 0.9980 - val_loss: 0.1382 - val_accuracy: 0.9891\n",
            "Epoch 493/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0036 - accuracy: 0.9994 - val_loss: 0.0859 - val_accuracy: 0.9915\n",
            "Epoch 494/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0062 - accuracy: 0.9989 - val_loss: 0.1454 - val_accuracy: 0.9909\n",
            "Epoch 495/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0038 - accuracy: 0.9994 - val_loss: 0.1270 - val_accuracy: 0.9933\n",
            "Epoch 496/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0056 - accuracy: 0.9989 - val_loss: 0.1562 - val_accuracy: 0.9915\n",
            "Epoch 497/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0037 - accuracy: 0.9994 - val_loss: 0.1996 - val_accuracy: 0.9873\n",
            "Epoch 498/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0066 - accuracy: 0.9988 - val_loss: 0.2161 - val_accuracy: 0.9891\n",
            "Epoch 499/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0100 - accuracy: 0.9983 - val_loss: 0.0999 - val_accuracy: 0.9921\n",
            "Epoch 500/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0054 - accuracy: 0.9989 - val_loss: 0.1570 - val_accuracy: 0.9915\n",
            "Epoch 501/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0015 - accuracy: 0.9998 - val_loss: 0.1397 - val_accuracy: 0.9921\n",
            "Epoch 502/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0041 - accuracy: 0.9995 - val_loss: 0.0744 - val_accuracy: 0.9951\n",
            "Epoch 503/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0329 - accuracy: 0.9992 - val_loss: 0.1321 - val_accuracy: 0.9909\n",
            "Epoch 504/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0036 - accuracy: 0.9995 - val_loss: 0.0574 - val_accuracy: 0.9921\n",
            "Epoch 505/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0204 - accuracy: 0.9977 - val_loss: 0.0638 - val_accuracy: 0.9921\n",
            "Epoch 506/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0373 - accuracy: 0.9948 - val_loss: 0.2104 - val_accuracy: 0.9873\n",
            "Epoch 507/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0188 - accuracy: 0.9967 - val_loss: 0.0776 - val_accuracy: 0.9933\n",
            "Epoch 508/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0156 - accuracy: 0.9973 - val_loss: 0.1584 - val_accuracy: 0.9909\n",
            "Epoch 509/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0055 - accuracy: 0.9986 - val_loss: 0.3840 - val_accuracy: 0.9903\n",
            "Epoch 510/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0051 - accuracy: 0.9991 - val_loss: 0.2578 - val_accuracy: 0.9921\n",
            "Epoch 511/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0040 - accuracy: 0.9991 - val_loss: 0.4221 - val_accuracy: 0.9891\n",
            "Epoch 512/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0099 - accuracy: 0.9983 - val_loss: 0.2582 - val_accuracy: 0.9897\n",
            "Epoch 513/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0044 - accuracy: 0.9991 - val_loss: 0.2789 - val_accuracy: 0.9879\n",
            "Epoch 514/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0054 - accuracy: 0.9988 - val_loss: 0.1980 - val_accuracy: 0.9915\n",
            "Epoch 515/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0015 - accuracy: 0.9998 - val_loss: 0.1894 - val_accuracy: 0.9921\n",
            "Epoch 516/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0036 - accuracy: 0.9992 - val_loss: 0.3124 - val_accuracy: 0.9873\n",
            "Epoch 517/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 5.4946e-04 - accuracy: 1.0000 - val_loss: 0.2372 - val_accuracy: 0.9903\n",
            "Epoch 518/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0075 - accuracy: 0.9985 - val_loss: 0.2304 - val_accuracy: 0.9897\n",
            "Epoch 519/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0107 - accuracy: 0.9988 - val_loss: 0.1590 - val_accuracy: 0.9933\n",
            "Epoch 520/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0065 - accuracy: 0.9988 - val_loss: 0.2351 - val_accuracy: 0.9909\n",
            "Epoch 521/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0107 - accuracy: 0.9982 - val_loss: 0.3376 - val_accuracy: 0.9848\n",
            "Epoch 522/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0094 - accuracy: 0.9982 - val_loss: 0.1905 - val_accuracy: 0.9885\n",
            "Epoch 523/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.2760 - val_accuracy: 0.9867\n",
            "Epoch 524/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0018 - accuracy: 0.9997 - val_loss: 0.3758 - val_accuracy: 0.9848\n",
            "Epoch 525/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 0.2354 - val_accuracy: 0.9885\n",
            "Epoch 526/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0112 - accuracy: 0.9983 - val_loss: 0.1585 - val_accuracy: 0.9921\n",
            "Epoch 527/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0062 - accuracy: 0.9986 - val_loss: 0.1490 - val_accuracy: 0.9915\n",
            "Epoch 528/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0092 - accuracy: 0.9980 - val_loss: 0.1995 - val_accuracy: 0.9897\n",
            "Epoch 529/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0034 - accuracy: 0.9992 - val_loss: 0.1935 - val_accuracy: 0.9891\n",
            "Epoch 530/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0022 - accuracy: 0.9997 - val_loss: 0.1633 - val_accuracy: 0.9903\n",
            "Epoch 531/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0024 - accuracy: 0.9997 - val_loss: 0.1924 - val_accuracy: 0.9903\n",
            "Epoch 532/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0122 - accuracy: 0.9991 - val_loss: 0.1899 - val_accuracy: 0.9909\n",
            "Epoch 533/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0238 - accuracy: 0.9976 - val_loss: 1.9072 - val_accuracy: 0.9017\n",
            "Epoch 534/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0103 - accuracy: 0.9980 - val_loss: 0.1403 - val_accuracy: 0.9873\n",
            "Epoch 535/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0043 - accuracy: 0.9989 - val_loss: 0.2032 - val_accuracy: 0.9915\n",
            "Epoch 536/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0184 - accuracy: 0.9979 - val_loss: 0.1089 - val_accuracy: 0.9885\n",
            "Epoch 537/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0066 - accuracy: 0.9985 - val_loss: 0.1589 - val_accuracy: 0.9879\n",
            "Epoch 538/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0035 - accuracy: 0.9992 - val_loss: 0.1540 - val_accuracy: 0.9885\n",
            "Epoch 539/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0247 - accuracy: 0.9967 - val_loss: 0.1739 - val_accuracy: 0.9897\n",
            "Epoch 540/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0029 - accuracy: 0.9992 - val_loss: 0.1990 - val_accuracy: 0.9909\n",
            "Epoch 541/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.1527 - val_accuracy: 0.9897\n",
            "Epoch 542/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0022 - accuracy: 0.9997 - val_loss: 0.1549 - val_accuracy: 0.9897\n",
            "Epoch 543/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0080 - accuracy: 0.9985 - val_loss: 0.1518 - val_accuracy: 0.9897\n",
            "Epoch 544/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0050 - accuracy: 0.9989 - val_loss: 0.1315 - val_accuracy: 0.9897\n",
            "Epoch 545/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0070 - accuracy: 0.9983 - val_loss: 0.1331 - val_accuracy: 0.9927\n",
            "Epoch 546/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0053 - accuracy: 0.9991 - val_loss: 0.2410 - val_accuracy: 0.9903\n",
            "Epoch 547/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0022 - accuracy: 0.9997 - val_loss: 0.2308 - val_accuracy: 0.9903\n",
            "Epoch 548/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0022 - accuracy: 0.9997 - val_loss: 0.2053 - val_accuracy: 0.9909\n",
            "Epoch 549/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0104 - accuracy: 0.9988 - val_loss: 0.2068 - val_accuracy: 0.9921\n",
            "Epoch 550/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0064 - accuracy: 0.9988 - val_loss: 0.2258 - val_accuracy: 0.9891\n",
            "Epoch 551/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0197 - accuracy: 0.9974 - val_loss: 0.3512 - val_accuracy: 0.9836\n",
            "Epoch 552/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0068 - accuracy: 0.9989 - val_loss: 0.2035 - val_accuracy: 0.9903\n",
            "Epoch 553/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0021 - accuracy: 0.9992 - val_loss: 0.2697 - val_accuracy: 0.9921\n",
            "Epoch 554/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 7.8894e-04 - accuracy: 0.9998 - val_loss: 0.2894 - val_accuracy: 0.9927\n",
            "Epoch 555/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 0.3115 - val_accuracy: 0.9927\n",
            "Epoch 556/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0042 - accuracy: 0.9992 - val_loss: 0.2709 - val_accuracy: 0.9927\n",
            "Epoch 557/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0058 - accuracy: 0.9989 - val_loss: 0.2797 - val_accuracy: 0.9915\n",
            "Epoch 558/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0040 - accuracy: 0.9994 - val_loss: 0.3595 - val_accuracy: 0.9909\n",
            "Epoch 559/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0025 - accuracy: 0.9995 - val_loss: 0.3770 - val_accuracy: 0.9903\n",
            "Epoch 560/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 5.3626e-04 - accuracy: 1.0000 - val_loss: 0.3583 - val_accuracy: 0.9915\n",
            "Epoch 561/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 6.1435e-04 - accuracy: 1.0000 - val_loss: 0.4763 - val_accuracy: 0.9879\n",
            "Epoch 562/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.3642 - val_accuracy: 0.9903\n",
            "Epoch 563/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 0.3266 - val_accuracy: 0.9903\n",
            "Epoch 564/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0021 - accuracy: 0.9997 - val_loss: 0.3480 - val_accuracy: 0.9897\n",
            "Epoch 565/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0039 - accuracy: 0.9989 - val_loss: 0.4453 - val_accuracy: 0.9885\n",
            "Epoch 566/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0061 - accuracy: 0.9991 - val_loss: 0.2137 - val_accuracy: 0.9909\n",
            "Epoch 567/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.3145 - val_accuracy: 0.9897\n",
            "Epoch 568/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0087 - accuracy: 0.9986 - val_loss: 0.0794 - val_accuracy: 0.9945\n",
            "Epoch 569/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0062 - accuracy: 0.9988 - val_loss: 0.1160 - val_accuracy: 0.9951\n",
            "Epoch 570/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0048 - accuracy: 0.9991 - val_loss: 0.0896 - val_accuracy: 0.9951\n",
            "Epoch 571/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0130 - accuracy: 0.9977 - val_loss: 0.1374 - val_accuracy: 0.9933\n",
            "Epoch 572/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0073 - accuracy: 0.9989 - val_loss: 0.1710 - val_accuracy: 0.9933\n",
            "Epoch 573/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0041 - accuracy: 0.9991 - val_loss: 0.2015 - val_accuracy: 0.9933\n",
            "Epoch 574/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0033 - accuracy: 0.9992 - val_loss: 0.2407 - val_accuracy: 0.9933\n",
            "Epoch 575/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0039 - accuracy: 0.9992 - val_loss: 0.3626 - val_accuracy: 0.9873\n",
            "Epoch 576/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0073 - accuracy: 0.9986 - val_loss: 0.2254 - val_accuracy: 0.9927\n",
            "Epoch 577/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0065 - accuracy: 0.9988 - val_loss: 0.4397 - val_accuracy: 0.9873\n",
            "Epoch 578/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0090 - accuracy: 0.9988 - val_loss: 0.3024 - val_accuracy: 0.9891\n",
            "Epoch 579/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0081 - accuracy: 0.9991 - val_loss: 1.0438 - val_accuracy: 0.9502\n",
            "Epoch 580/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0073 - accuracy: 0.9989 - val_loss: 0.2065 - val_accuracy: 0.9939\n",
            "Epoch 581/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0376 - accuracy: 0.9980 - val_loss: 0.3078 - val_accuracy: 0.9915\n",
            "Epoch 582/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0206 - accuracy: 0.9974 - val_loss: 0.2510 - val_accuracy: 0.9945\n",
            "Epoch 583/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.1595 - val_accuracy: 0.9915\n",
            "Epoch 584/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0081 - accuracy: 0.9983 - val_loss: 0.3542 - val_accuracy: 0.9812\n",
            "Epoch 585/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0107 - accuracy: 0.9985 - val_loss: 0.2122 - val_accuracy: 0.9927\n",
            "Epoch 586/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0099 - accuracy: 0.9985 - val_loss: 0.1510 - val_accuracy: 0.9939\n",
            "Epoch 587/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0085 - accuracy: 0.9980 - val_loss: 0.2489 - val_accuracy: 0.9909\n",
            "Epoch 588/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0067 - accuracy: 0.9989 - val_loss: 0.3346 - val_accuracy: 0.9909\n",
            "Epoch 589/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0032 - accuracy: 0.9991 - val_loss: 0.1534 - val_accuracy: 0.9921\n",
            "Epoch 590/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0083 - accuracy: 0.9992 - val_loss: 0.1892 - val_accuracy: 0.9885\n",
            "Epoch 591/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0058 - accuracy: 0.9991 - val_loss: 0.1360 - val_accuracy: 0.9897\n",
            "Epoch 592/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 0.2160 - val_accuracy: 0.9891\n",
            "Epoch 593/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0065 - accuracy: 0.9989 - val_loss: 0.1615 - val_accuracy: 0.9897\n",
            "Epoch 594/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0060 - accuracy: 0.9988 - val_loss: 0.1379 - val_accuracy: 0.9915\n",
            "Epoch 595/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.1436 - val_accuracy: 0.9909\n",
            "Epoch 596/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0040 - accuracy: 0.9992 - val_loss: 0.2075 - val_accuracy: 0.9891\n",
            "Epoch 597/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0086 - accuracy: 0.9983 - val_loss: 0.2340 - val_accuracy: 0.9909\n",
            "Epoch 598/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0063 - accuracy: 0.9989 - val_loss: 0.2493 - val_accuracy: 0.9879\n",
            "Epoch 599/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0086 - accuracy: 0.9982 - val_loss: 0.1136 - val_accuracy: 0.9903\n",
            "Epoch 600/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0068 - accuracy: 0.9988 - val_loss: 0.2128 - val_accuracy: 0.9897\n",
            "Epoch 601/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0050 - accuracy: 0.9988 - val_loss: 0.3651 - val_accuracy: 0.9854\n",
            "Epoch 602/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0041 - accuracy: 0.9994 - val_loss: 0.3517 - val_accuracy: 0.9860\n",
            "Epoch 603/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0025 - accuracy: 0.9995 - val_loss: 0.2339 - val_accuracy: 0.9921\n",
            "Epoch 604/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0104 - accuracy: 0.9988 - val_loss: 0.6703 - val_accuracy: 0.9818\n",
            "Epoch 605/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0059 - accuracy: 0.9991 - val_loss: 0.2345 - val_accuracy: 0.9867\n",
            "Epoch 606/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0160 - accuracy: 0.9976 - val_loss: 0.1330 - val_accuracy: 0.9903\n",
            "Epoch 607/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0030 - accuracy: 0.9992 - val_loss: 0.1061 - val_accuracy: 0.9915\n",
            "Epoch 608/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0046 - accuracy: 0.9989 - val_loss: 0.2955 - val_accuracy: 0.9848\n",
            "Epoch 609/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0113 - accuracy: 0.9989 - val_loss: 0.3687 - val_accuracy: 0.9812\n",
            "Epoch 610/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0122 - accuracy: 0.9989 - val_loss: 0.4648 - val_accuracy: 0.9873\n",
            "Epoch 611/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0078 - accuracy: 0.9988 - val_loss: 0.3249 - val_accuracy: 0.9885\n",
            "Epoch 612/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.4305 - val_accuracy: 0.9867\n",
            "Epoch 613/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 8.6508e-04 - accuracy: 0.9998 - val_loss: 0.3200 - val_accuracy: 0.9885\n",
            "Epoch 614/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.3102 - val_accuracy: 0.9885\n",
            "Epoch 615/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.1689 - val_accuracy: 0.9909\n",
            "Epoch 616/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 0.1622 - val_accuracy: 0.9909\n",
            "Epoch 617/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0040 - accuracy: 0.9994 - val_loss: 0.5919 - val_accuracy: 0.9860\n",
            "Epoch 618/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.2548 - val_accuracy: 0.9897\n",
            "Epoch 619/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0016 - accuracy: 0.9997 - val_loss: 0.3031 - val_accuracy: 0.9860\n",
            "Epoch 620/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 0.1869 - val_accuracy: 0.9885\n",
            "Epoch 621/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0036 - accuracy: 0.9994 - val_loss: 0.3582 - val_accuracy: 0.9879\n",
            "Epoch 622/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0098 - accuracy: 0.9991 - val_loss: 0.2105 - val_accuracy: 0.9830\n",
            "Epoch 623/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0029 - accuracy: 0.9991 - val_loss: 0.2102 - val_accuracy: 0.9879\n",
            "Epoch 624/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0683 - accuracy: 0.9965 - val_loss: 0.2719 - val_accuracy: 0.9806\n",
            "Epoch 625/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0190 - accuracy: 0.9982 - val_loss: 0.2262 - val_accuracy: 0.9842\n",
            "Epoch 626/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0144 - accuracy: 0.9970 - val_loss: 0.3649 - val_accuracy: 0.9891\n",
            "Epoch 627/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0059 - accuracy: 0.9991 - val_loss: 0.2416 - val_accuracy: 0.9927\n",
            "Epoch 628/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0040 - accuracy: 0.9992 - val_loss: 0.2395 - val_accuracy: 0.9903\n",
            "Epoch 629/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0016 - accuracy: 0.9997 - val_loss: 0.1132 - val_accuracy: 0.9927\n",
            "Epoch 630/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0113 - accuracy: 0.9983 - val_loss: 0.2564 - val_accuracy: 0.9867\n",
            "Epoch 631/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0023 - accuracy: 0.9992 - val_loss: 0.1591 - val_accuracy: 0.9897\n",
            "Epoch 632/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 7.2807e-04 - accuracy: 0.9998 - val_loss: 0.3320 - val_accuracy: 0.9854\n",
            "Epoch 633/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0077 - accuracy: 0.9988 - val_loss: 0.1475 - val_accuracy: 0.9873\n",
            "Epoch 634/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.2301 - val_accuracy: 0.9854\n",
            "Epoch 635/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0049 - accuracy: 0.9994 - val_loss: 0.2729 - val_accuracy: 0.9873\n",
            "Epoch 636/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0035 - accuracy: 0.9992 - val_loss: 0.1232 - val_accuracy: 0.9891\n",
            "Epoch 637/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0100 - accuracy: 0.9985 - val_loss: 0.2454 - val_accuracy: 0.9873\n",
            "Epoch 638/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0056 - accuracy: 0.9991 - val_loss: 1.0314 - val_accuracy: 0.9569\n",
            "Epoch 639/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0151 - accuracy: 0.9985 - val_loss: 0.1392 - val_accuracy: 0.9921\n",
            "Epoch 640/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0078 - accuracy: 0.9992 - val_loss: 0.1279 - val_accuracy: 0.9903\n",
            "Epoch 641/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0043 - accuracy: 0.9991 - val_loss: 0.0786 - val_accuracy: 0.9921\n",
            "Epoch 642/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0026 - accuracy: 0.9995 - val_loss: 0.1583 - val_accuracy: 0.9891\n",
            "Epoch 643/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0066 - accuracy: 0.9989 - val_loss: 0.1497 - val_accuracy: 0.9885\n",
            "Epoch 644/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0026 - accuracy: 0.9997 - val_loss: 0.2020 - val_accuracy: 0.9873\n",
            "Epoch 645/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 0.1704 - val_accuracy: 0.9897\n",
            "Epoch 646/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0039 - accuracy: 0.9994 - val_loss: 0.6434 - val_accuracy: 0.9794\n",
            "Epoch 647/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0133 - accuracy: 0.9985 - val_loss: 0.2540 - val_accuracy: 0.9891\n",
            "Epoch 648/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0181 - accuracy: 0.9980 - val_loss: 0.1373 - val_accuracy: 0.9897\n",
            "Epoch 649/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0127 - accuracy: 0.9988 - val_loss: 5.4962 - val_accuracy: 0.9812\n",
            "Epoch 650/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0075 - accuracy: 0.9988 - val_loss: 0.1899 - val_accuracy: 0.9897\n",
            "Epoch 651/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0035 - accuracy: 0.9991 - val_loss: 0.1355 - val_accuracy: 0.9939\n",
            "Epoch 652/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0035 - accuracy: 0.9994 - val_loss: 0.1726 - val_accuracy: 0.9915\n",
            "Epoch 653/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0039 - accuracy: 0.9994 - val_loss: 0.1937 - val_accuracy: 0.9915\n",
            "Epoch 654/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0037 - accuracy: 0.9992 - val_loss: 0.1735 - val_accuracy: 0.9927\n",
            "Epoch 655/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0022 - accuracy: 0.9997 - val_loss: 0.1239 - val_accuracy: 0.9933\n",
            "Epoch 656/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0058 - accuracy: 0.9988 - val_loss: 0.2798 - val_accuracy: 0.9909\n",
            "Epoch 657/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 0.1724 - val_accuracy: 0.9933\n",
            "Epoch 658/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0069 - accuracy: 0.9986 - val_loss: 0.1688 - val_accuracy: 0.9903\n",
            "Epoch 659/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0023 - accuracy: 0.9997 - val_loss: 0.1972 - val_accuracy: 0.9879\n",
            "Epoch 660/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0099 - accuracy: 0.9991 - val_loss: 0.1815 - val_accuracy: 0.9909\n",
            "Epoch 661/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0058 - accuracy: 0.9992 - val_loss: 0.0663 - val_accuracy: 0.9927\n",
            "Epoch 662/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0032 - accuracy: 0.9992 - val_loss: 0.4256 - val_accuracy: 0.9806\n",
            "Epoch 663/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.1163 - val_accuracy: 0.9921\n",
            "Epoch 664/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0034 - accuracy: 0.9994 - val_loss: 0.1910 - val_accuracy: 0.9897\n",
            "Epoch 665/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0016 - accuracy: 0.9997 - val_loss: 0.1391 - val_accuracy: 0.9927\n",
            "Epoch 666/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.1100 - val_accuracy: 0.9933\n",
            "Epoch 667/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0027 - accuracy: 0.9992 - val_loss: 0.1410 - val_accuracy: 0.9927\n",
            "Epoch 668/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0021 - accuracy: 0.9997 - val_loss: 0.1485 - val_accuracy: 0.9927\n",
            "Epoch 669/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.1744 - val_accuracy: 0.9915\n",
            "Epoch 670/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0144 - accuracy: 0.9989 - val_loss: 0.0899 - val_accuracy: 0.9909\n",
            "Epoch 671/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0075 - accuracy: 0.9986 - val_loss: 0.4383 - val_accuracy: 0.9830\n",
            "Epoch 672/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0068 - accuracy: 0.9989 - val_loss: 0.3540 - val_accuracy: 0.9885\n",
            "Epoch 673/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0074 - accuracy: 0.9985 - val_loss: 0.1123 - val_accuracy: 0.9933\n",
            "Epoch 674/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0056 - accuracy: 0.9991 - val_loss: 1.0453 - val_accuracy: 0.9812\n",
            "Epoch 675/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0265 - accuracy: 0.9959 - val_loss: 0.1228 - val_accuracy: 0.9909\n",
            "Epoch 676/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0044 - accuracy: 0.9991 - val_loss: 0.2318 - val_accuracy: 0.9909\n",
            "Epoch 677/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0037 - accuracy: 0.9994 - val_loss: 0.2609 - val_accuracy: 0.9909\n",
            "Epoch 678/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0045 - accuracy: 0.9992 - val_loss: 0.1491 - val_accuracy: 0.9915\n",
            "Epoch 679/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0034 - accuracy: 0.9994 - val_loss: 0.1401 - val_accuracy: 0.9921\n",
            "Epoch 680/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0055 - accuracy: 0.9989 - val_loss: 0.2882 - val_accuracy: 0.9939\n",
            "Epoch 681/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0078 - accuracy: 0.9988 - val_loss: 0.3058 - val_accuracy: 0.9927\n",
            "Epoch 682/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.3267 - val_accuracy: 0.9915\n",
            "Epoch 683/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0034 - accuracy: 0.9994 - val_loss: 0.3239 - val_accuracy: 0.9909\n",
            "Epoch 684/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0070 - accuracy: 0.9992 - val_loss: 0.3427 - val_accuracy: 0.9909\n",
            "Epoch 685/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0051 - accuracy: 0.9994 - val_loss: 0.2061 - val_accuracy: 0.9897\n",
            "Epoch 686/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 0.3286 - val_accuracy: 0.9879\n",
            "Epoch 687/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0011 - accuracy: 0.9995 - val_loss: 0.2532 - val_accuracy: 0.9909\n",
            "Epoch 688/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.3166 - val_accuracy: 0.9903\n",
            "Epoch 689/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0021 - accuracy: 0.9997 - val_loss: 0.3646 - val_accuracy: 0.9903\n",
            "Epoch 690/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0044 - accuracy: 0.9992 - val_loss: 0.4729 - val_accuracy: 0.9897\n",
            "Epoch 691/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0020 - accuracy: 0.9997 - val_loss: 0.2506 - val_accuracy: 0.9915\n",
            "Epoch 692/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0044 - accuracy: 0.9998 - val_loss: 0.3352 - val_accuracy: 0.9885\n",
            "Epoch 693/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0056 - accuracy: 0.9991 - val_loss: 0.2536 - val_accuracy: 0.9921\n",
            "Epoch 694/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0087 - accuracy: 0.9989 - val_loss: 0.2463 - val_accuracy: 0.9891\n",
            "Epoch 695/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0047 - accuracy: 0.9994 - val_loss: 0.3274 - val_accuracy: 0.9903\n",
            "Epoch 696/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.1722 - val_accuracy: 0.9933\n",
            "Epoch 697/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0047 - accuracy: 0.9992 - val_loss: 0.1597 - val_accuracy: 0.9927\n",
            "Epoch 698/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 0.1833 - val_accuracy: 0.9921\n",
            "Epoch 699/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0047 - accuracy: 0.9992 - val_loss: 0.1490 - val_accuracy: 0.9921\n",
            "Epoch 700/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0084 - accuracy: 0.9986 - val_loss: 0.4685 - val_accuracy: 0.9830\n",
            "Epoch 701/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.2730 - val_accuracy: 0.9903\n",
            "Epoch 702/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0117 - accuracy: 0.9988 - val_loss: 0.2291 - val_accuracy: 0.9806\n",
            "Epoch 703/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0050 - accuracy: 0.9992 - val_loss: 0.3746 - val_accuracy: 0.9885\n",
            "Epoch 704/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0021 - accuracy: 0.9997 - val_loss: 0.4201 - val_accuracy: 0.9879\n",
            "Epoch 705/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0033 - accuracy: 0.9989 - val_loss: 0.3274 - val_accuracy: 0.9909\n",
            "Epoch 706/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0086 - accuracy: 0.9989 - val_loss: 0.6227 - val_accuracy: 0.9794\n",
            "Epoch 707/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0127 - accuracy: 0.9989 - val_loss: 0.1689 - val_accuracy: 0.9891\n",
            "Epoch 708/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0047 - accuracy: 0.9991 - val_loss: 0.6729 - val_accuracy: 0.9842\n",
            "Epoch 709/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0093 - accuracy: 0.9986 - val_loss: 0.3194 - val_accuracy: 0.9897\n",
            "Epoch 710/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0098 - accuracy: 0.9989 - val_loss: 0.2616 - val_accuracy: 0.9873\n",
            "Epoch 711/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0106 - accuracy: 0.9985 - val_loss: 0.1455 - val_accuracy: 0.9897\n",
            "Epoch 712/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0187 - accuracy: 0.9994 - val_loss: 0.2110 - val_accuracy: 0.9891\n",
            "Epoch 713/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0090 - accuracy: 0.9991 - val_loss: 0.1792 - val_accuracy: 0.9903\n",
            "Epoch 714/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0502 - accuracy: 0.9973 - val_loss: 0.6426 - val_accuracy: 0.9806\n",
            "Epoch 715/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0123 - accuracy: 0.9983 - val_loss: 0.0842 - val_accuracy: 0.9927\n",
            "Epoch 716/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0077 - accuracy: 0.9986 - val_loss: 0.2240 - val_accuracy: 0.9885\n",
            "Epoch 717/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.1866 - val_accuracy: 0.9891\n",
            "Epoch 718/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0067 - accuracy: 0.9991 - val_loss: 0.6283 - val_accuracy: 0.9818\n",
            "Epoch 719/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0092 - accuracy: 0.9991 - val_loss: 0.2582 - val_accuracy: 0.9867\n",
            "Epoch 720/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0054 - accuracy: 0.9989 - val_loss: 0.1936 - val_accuracy: 0.9854\n",
            "Epoch 721/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0057 - accuracy: 0.9992 - val_loss: 0.1275 - val_accuracy: 0.9885\n",
            "Epoch 722/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0037 - accuracy: 0.9994 - val_loss: 0.1642 - val_accuracy: 0.9879\n",
            "Epoch 723/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0035 - accuracy: 0.9994 - val_loss: 0.3164 - val_accuracy: 0.9885\n",
            "Epoch 724/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 4.1908e-04 - accuracy: 1.0000 - val_loss: 0.2719 - val_accuracy: 0.9891\n",
            "Epoch 725/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 7.3375e-04 - accuracy: 0.9998 - val_loss: 0.1083 - val_accuracy: 0.9921\n",
            "Epoch 726/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 0.1104 - val_accuracy: 0.9915\n",
            "Epoch 727/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.1563 - val_accuracy: 0.9879\n",
            "Epoch 728/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0050 - accuracy: 0.9991 - val_loss: 0.1633 - val_accuracy: 0.9921\n",
            "Epoch 729/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0384 - accuracy: 0.9976 - val_loss: 0.7929 - val_accuracy: 0.9830\n",
            "Epoch 730/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0127 - accuracy: 0.9992 - val_loss: 0.7719 - val_accuracy: 0.9830\n",
            "Epoch 731/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0227 - accuracy: 0.9988 - val_loss: 0.9106 - val_accuracy: 0.9806\n",
            "Epoch 732/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0091 - accuracy: 0.9985 - val_loss: 0.4530 - val_accuracy: 0.9903\n",
            "Epoch 733/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0028 - accuracy: 0.9995 - val_loss: 0.6691 - val_accuracy: 0.9867\n",
            "Epoch 734/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0023 - accuracy: 0.9995 - val_loss: 0.5171 - val_accuracy: 0.9891\n",
            "Epoch 735/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.5278 - val_accuracy: 0.9891\n",
            "Epoch 736/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0110 - accuracy: 0.9986 - val_loss: 0.7606 - val_accuracy: 0.9824\n",
            "Epoch 737/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0049 - accuracy: 0.9991 - val_loss: 0.2885 - val_accuracy: 0.9897\n",
            "Epoch 738/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.2825 - val_accuracy: 0.9933\n",
            "Epoch 739/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 5.0448e-04 - accuracy: 1.0000 - val_loss: 0.3575 - val_accuracy: 0.9915\n",
            "Epoch 740/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0049 - accuracy: 0.9992 - val_loss: 0.3675 - val_accuracy: 0.9915\n",
            "Epoch 741/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0043 - accuracy: 0.9994 - val_loss: 0.2563 - val_accuracy: 0.9921\n",
            "Epoch 742/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 0.5789 - val_accuracy: 0.9885\n",
            "Epoch 743/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.5188 - val_accuracy: 0.9885\n",
            "Epoch 744/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0021 - accuracy: 0.9997 - val_loss: 0.5571 - val_accuracy: 0.9885\n",
            "Epoch 745/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 4.9516e-04 - accuracy: 0.9998 - val_loss: 0.6871 - val_accuracy: 0.9867\n",
            "Epoch 746/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.5510 - val_accuracy: 0.9897\n",
            "Epoch 747/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 4.4249e-04 - accuracy: 0.9998 - val_loss: 0.3793 - val_accuracy: 0.9915\n",
            "Epoch 748/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0045 - accuracy: 0.9991 - val_loss: 0.3378 - val_accuracy: 0.9933\n",
            "Epoch 749/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0315 - accuracy: 0.9985 - val_loss: 0.7634 - val_accuracy: 0.9873\n",
            "Epoch 750/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0054 - accuracy: 0.9991 - val_loss: 0.4461 - val_accuracy: 0.9860\n",
            "Epoch 751/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0082 - accuracy: 0.9992 - val_loss: 0.1658 - val_accuracy: 0.9897\n",
            "Epoch 752/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0075 - accuracy: 0.9995 - val_loss: 0.2731 - val_accuracy: 0.9903\n",
            "Epoch 753/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0076 - accuracy: 0.9992 - val_loss: 0.4132 - val_accuracy: 0.9909\n",
            "Epoch 754/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0050 - accuracy: 0.9989 - val_loss: 0.4300 - val_accuracy: 0.9885\n",
            "Epoch 755/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0073 - accuracy: 0.9989 - val_loss: 0.2587 - val_accuracy: 0.9927\n",
            "Epoch 756/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0037 - accuracy: 0.9994 - val_loss: 0.7040 - val_accuracy: 0.9879\n",
            "Epoch 757/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0143 - accuracy: 0.9991 - val_loss: 0.4816 - val_accuracy: 0.9885\n",
            "Epoch 758/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0037 - accuracy: 0.9992 - val_loss: 0.5065 - val_accuracy: 0.9903\n",
            "Epoch 759/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0049 - accuracy: 0.9989 - val_loss: 0.5621 - val_accuracy: 0.9921\n",
            "Epoch 760/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0045 - accuracy: 0.9992 - val_loss: 1.0887 - val_accuracy: 0.9897\n",
            "Epoch 761/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0020 - accuracy: 0.9998 - val_loss: 0.6878 - val_accuracy: 0.9891\n",
            "Epoch 762/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0149 - accuracy: 0.9995 - val_loss: 0.5492 - val_accuracy: 0.9903\n",
            "Epoch 763/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0028 - accuracy: 0.9995 - val_loss: 0.9325 - val_accuracy: 0.9897\n",
            "Epoch 764/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0018 - accuracy: 0.9997 - val_loss: 0.7535 - val_accuracy: 0.9909\n",
            "Epoch 765/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0037 - accuracy: 0.9992 - val_loss: 0.4270 - val_accuracy: 0.9903\n",
            "Epoch 766/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0216 - accuracy: 0.9983 - val_loss: 0.1916 - val_accuracy: 0.9909\n",
            "Epoch 767/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0096 - accuracy: 0.9989 - val_loss: 0.3691 - val_accuracy: 0.9867\n",
            "Epoch 768/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0089 - accuracy: 0.9991 - val_loss: 0.4174 - val_accuracy: 0.9891\n",
            "Epoch 769/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0056 - accuracy: 0.9991 - val_loss: 0.3765 - val_accuracy: 0.9903\n",
            "Epoch 770/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0065 - accuracy: 0.9988 - val_loss: 0.4589 - val_accuracy: 0.9873\n",
            "Epoch 771/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0040 - accuracy: 0.9994 - val_loss: 0.2587 - val_accuracy: 0.9897\n",
            "Epoch 772/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0037 - accuracy: 0.9991 - val_loss: 0.5053 - val_accuracy: 0.9860\n",
            "Epoch 773/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0043 - accuracy: 0.9997 - val_loss: 0.2910 - val_accuracy: 0.9897\n",
            "Epoch 774/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0040 - accuracy: 0.9994 - val_loss: 0.2425 - val_accuracy: 0.9891\n",
            "Epoch 775/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.1907 - val_accuracy: 0.9909\n",
            "Epoch 776/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0021 - accuracy: 0.9997 - val_loss: 0.2138 - val_accuracy: 0.9903\n",
            "Epoch 777/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0049 - accuracy: 0.9991 - val_loss: 0.3080 - val_accuracy: 0.9891\n",
            "Epoch 778/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0063 - accuracy: 0.9994 - val_loss: 0.4695 - val_accuracy: 0.9879\n",
            "Epoch 779/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.4631 - val_accuracy: 0.9860\n",
            "Epoch 780/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.2214 - val_accuracy: 0.9909\n",
            "Epoch 781/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0035 - accuracy: 0.9994 - val_loss: 0.2382 - val_accuracy: 0.9897\n",
            "Epoch 782/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0040 - accuracy: 0.9995 - val_loss: 0.2284 - val_accuracy: 0.9909\n",
            "Epoch 783/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0027 - accuracy: 0.9992 - val_loss: 0.1109 - val_accuracy: 0.9933\n",
            "Epoch 784/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.0904 - val_accuracy: 0.9939\n",
            "Epoch 785/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0066 - accuracy: 0.9991 - val_loss: 0.3887 - val_accuracy: 0.9909\n",
            "Epoch 786/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0022 - accuracy: 0.9997 - val_loss: 0.2281 - val_accuracy: 0.9927\n",
            "Epoch 787/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.1379 - val_accuracy: 0.9939\n",
            "Epoch 788/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0039 - accuracy: 0.9995 - val_loss: 0.1127 - val_accuracy: 0.9933\n",
            "Epoch 789/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.0912 - val_accuracy: 0.9945\n",
            "Epoch 790/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0041 - accuracy: 0.9992 - val_loss: 0.2692 - val_accuracy: 0.9909\n",
            "Epoch 791/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0137 - accuracy: 0.9989 - val_loss: 0.3613 - val_accuracy: 0.9860\n",
            "Epoch 792/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0086 - accuracy: 0.9985 - val_loss: 0.1651 - val_accuracy: 0.9915\n",
            "Epoch 793/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0068 - accuracy: 0.9992 - val_loss: 0.4616 - val_accuracy: 0.9860\n",
            "Epoch 794/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0257 - accuracy: 0.9971 - val_loss: 0.5396 - val_accuracy: 0.9806\n",
            "Epoch 795/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0103 - accuracy: 0.9980 - val_loss: 0.3497 - val_accuracy: 0.9824\n",
            "Epoch 796/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0037 - accuracy: 0.9994 - val_loss: 0.2636 - val_accuracy: 0.9897\n",
            "Epoch 797/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0038 - accuracy: 0.9994 - val_loss: 0.1847 - val_accuracy: 0.9903\n",
            "Epoch 798/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 0.1684 - val_accuracy: 0.9915\n",
            "Epoch 799/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0036 - accuracy: 0.9994 - val_loss: 0.2526 - val_accuracy: 0.9891\n",
            "Epoch 800/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0025 - accuracy: 0.9995 - val_loss: 0.3060 - val_accuracy: 0.9891\n",
            "Epoch 801/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.1437 - val_accuracy: 0.9903\n",
            "Epoch 802/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0044 - accuracy: 0.9991 - val_loss: 0.2524 - val_accuracy: 0.9897\n",
            "Epoch 803/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0048 - accuracy: 0.9991 - val_loss: 0.1655 - val_accuracy: 0.9867\n",
            "Epoch 804/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0110 - accuracy: 0.9988 - val_loss: 0.1765 - val_accuracy: 0.9915\n",
            "Epoch 805/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0038 - accuracy: 0.9992 - val_loss: 0.3100 - val_accuracy: 0.9854\n",
            "Epoch 806/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.2449 - val_accuracy: 0.9891\n",
            "Epoch 807/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 3.2198e-04 - accuracy: 1.0000 - val_loss: 0.2413 - val_accuracy: 0.9897\n",
            "Epoch 808/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0105 - accuracy: 0.9994 - val_loss: 0.2680 - val_accuracy: 0.9860\n",
            "Epoch 809/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.1888 - val_accuracy: 0.9903\n",
            "Epoch 810/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.2601 - val_accuracy: 0.9885\n",
            "Epoch 811/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0077 - accuracy: 0.9983 - val_loss: 0.1826 - val_accuracy: 0.9897\n",
            "Epoch 812/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0069 - accuracy: 0.9986 - val_loss: 0.0703 - val_accuracy: 0.9927\n",
            "Epoch 813/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0048 - accuracy: 0.9989 - val_loss: 0.0912 - val_accuracy: 0.9921\n",
            "Epoch 814/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0049 - accuracy: 0.9991 - val_loss: 0.1301 - val_accuracy: 0.9921\n",
            "Epoch 815/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 9.8542e-04 - accuracy: 0.9998 - val_loss: 0.2066 - val_accuracy: 0.9909\n",
            "Epoch 816/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 3.2622e-04 - accuracy: 1.0000 - val_loss: 0.1917 - val_accuracy: 0.9915\n",
            "Epoch 817/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 0.0862 - val_accuracy: 0.9921\n",
            "Epoch 818/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0047 - accuracy: 0.9992 - val_loss: 0.1290 - val_accuracy: 0.9933\n",
            "Epoch 819/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0053 - accuracy: 0.9995 - val_loss: 0.2152 - val_accuracy: 0.9897\n",
            "Epoch 820/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0021 - accuracy: 0.9997 - val_loss: 0.2054 - val_accuracy: 0.9903\n",
            "Epoch 821/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0023 - accuracy: 0.9995 - val_loss: 0.5745 - val_accuracy: 0.9818\n",
            "Epoch 822/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.2420 - val_accuracy: 0.9891\n",
            "Epoch 823/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 0.2776 - val_accuracy: 0.9885\n",
            "Epoch 824/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0042 - accuracy: 0.9994 - val_loss: 0.2569 - val_accuracy: 0.9873\n",
            "Epoch 825/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0144 - accuracy: 0.9986 - val_loss: 0.1616 - val_accuracy: 0.9891\n",
            "Epoch 826/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0038 - accuracy: 0.9991 - val_loss: 0.1859 - val_accuracy: 0.9879\n",
            "Epoch 827/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0076 - accuracy: 0.9980 - val_loss: 0.2138 - val_accuracy: 0.9860\n",
            "Epoch 828/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0137 - accuracy: 0.9985 - val_loss: 0.7273 - val_accuracy: 0.9806\n",
            "Epoch 829/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.1513 - val_accuracy: 0.9915\n",
            "Epoch 830/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0226 - accuracy: 0.9980 - val_loss: 0.3067 - val_accuracy: 0.9879\n",
            "Epoch 831/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0045 - accuracy: 0.9991 - val_loss: 0.1307 - val_accuracy: 0.9909\n",
            "Epoch 832/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0218 - accuracy: 0.9976 - val_loss: 0.1595 - val_accuracy: 0.9927\n",
            "Epoch 833/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0152 - accuracy: 0.9983 - val_loss: 0.0890 - val_accuracy: 0.9939\n",
            "Epoch 834/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0308 - accuracy: 0.9982 - val_loss: 0.2899 - val_accuracy: 0.9830\n",
            "Epoch 835/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0064 - accuracy: 0.9986 - val_loss: 0.1826 - val_accuracy: 0.9927\n",
            "Epoch 836/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0048 - accuracy: 0.9991 - val_loss: 0.2588 - val_accuracy: 0.9897\n",
            "Epoch 837/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0051 - accuracy: 0.9988 - val_loss: 0.3030 - val_accuracy: 0.9897\n",
            "Epoch 838/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0016 - accuracy: 0.9997 - val_loss: 0.3083 - val_accuracy: 0.9879\n",
            "Epoch 839/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0016 - accuracy: 0.9997 - val_loss: 0.2412 - val_accuracy: 0.9885\n",
            "Epoch 840/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0122 - accuracy: 0.9992 - val_loss: 0.3200 - val_accuracy: 0.9873\n",
            "Epoch 841/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 4.6144e-04 - accuracy: 1.0000 - val_loss: 0.3617 - val_accuracy: 0.9885\n",
            "Epoch 842/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0038 - accuracy: 0.9995 - val_loss: 0.3177 - val_accuracy: 0.9891\n",
            "Epoch 843/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0061 - accuracy: 0.9991 - val_loss: 0.2593 - val_accuracy: 0.9879\n",
            "Epoch 844/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.2253 - val_accuracy: 0.9891\n",
            "Epoch 845/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0033 - accuracy: 0.9992 - val_loss: 0.1349 - val_accuracy: 0.9897\n",
            "Epoch 846/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.2265 - val_accuracy: 0.9885\n",
            "Epoch 847/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0046 - accuracy: 0.9992 - val_loss: 0.1512 - val_accuracy: 0.9891\n",
            "Epoch 848/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0023 - accuracy: 0.9995 - val_loss: 0.2957 - val_accuracy: 0.9891\n",
            "Epoch 849/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 3.4188e-04 - accuracy: 1.0000 - val_loss: 0.3295 - val_accuracy: 0.9879\n",
            "Epoch 850/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0017 - accuracy: 0.9997 - val_loss: 0.4119 - val_accuracy: 0.9873\n",
            "Epoch 851/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0133 - accuracy: 0.9995 - val_loss: 0.2735 - val_accuracy: 0.9903\n",
            "Epoch 852/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0022 - accuracy: 0.9997 - val_loss: 0.3416 - val_accuracy: 0.9891\n",
            "Epoch 853/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0023 - accuracy: 0.9995 - val_loss: 0.2607 - val_accuracy: 0.9903\n",
            "Epoch 854/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0042 - accuracy: 0.9991 - val_loss: 0.0932 - val_accuracy: 0.9933\n",
            "Epoch 855/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0062 - accuracy: 0.9988 - val_loss: 0.2332 - val_accuracy: 0.9909\n",
            "Epoch 856/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.2911 - val_accuracy: 0.9897\n",
            "Epoch 857/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 8.8793e-04 - accuracy: 0.9998 - val_loss: 0.2951 - val_accuracy: 0.9897\n",
            "Epoch 858/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0024 - accuracy: 0.9997 - val_loss: 0.1274 - val_accuracy: 0.9927\n",
            "Epoch 859/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0021 - accuracy: 0.9997 - val_loss: 0.1559 - val_accuracy: 0.9915\n",
            "Epoch 860/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0234 - accuracy: 0.9986 - val_loss: 1.6784 - val_accuracy: 0.9775\n",
            "Epoch 861/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0835 - accuracy: 0.9951 - val_loss: 0.0509 - val_accuracy: 0.9945\n",
            "Epoch 862/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.0905 - val_accuracy: 0.9915\n",
            "Epoch 863/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0083 - accuracy: 0.9994 - val_loss: 0.1590 - val_accuracy: 0.9927\n",
            "Epoch 864/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0130 - accuracy: 0.9995 - val_loss: 0.2185 - val_accuracy: 0.9879\n",
            "Epoch 865/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0026 - accuracy: 0.9995 - val_loss: 0.1670 - val_accuracy: 0.9921\n",
            "Epoch 866/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 2.9999e-04 - accuracy: 1.0000 - val_loss: 0.1781 - val_accuracy: 0.9921\n",
            "Epoch 867/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0075 - accuracy: 0.9994 - val_loss: 0.1679 - val_accuracy: 0.9903\n",
            "Epoch 868/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0040 - accuracy: 0.9992 - val_loss: 0.1450 - val_accuracy: 0.9921\n",
            "Epoch 869/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0070 - accuracy: 0.9994 - val_loss: 0.1974 - val_accuracy: 0.9927\n",
            "Epoch 870/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 3.4545e-04 - accuracy: 1.0000 - val_loss: 0.1794 - val_accuracy: 0.9927\n",
            "Epoch 871/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0021 - accuracy: 0.9997 - val_loss: 0.1682 - val_accuracy: 0.9927\n",
            "Epoch 872/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 2.8171e-04 - accuracy: 1.0000 - val_loss: 0.1677 - val_accuracy: 0.9927\n",
            "Epoch 873/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.1673 - val_accuracy: 0.9927\n",
            "Epoch 874/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0039 - accuracy: 0.9995 - val_loss: 0.2087 - val_accuracy: 0.9927\n",
            "Epoch 875/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0038 - accuracy: 0.9994 - val_loss: 0.2681 - val_accuracy: 0.9897\n",
            "Epoch 876/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0076 - accuracy: 0.9991 - val_loss: 0.1379 - val_accuracy: 0.9927\n",
            "Epoch 877/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0074 - accuracy: 0.9983 - val_loss: 0.1466 - val_accuracy: 0.9903\n",
            "Epoch 878/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 5.9841e-04 - accuracy: 0.9998 - val_loss: 0.0905 - val_accuracy: 0.9939\n",
            "Epoch 879/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.0881 - val_accuracy: 0.9945\n",
            "Epoch 880/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0039 - accuracy: 0.9995 - val_loss: 0.1316 - val_accuracy: 0.9921\n",
            "Epoch 881/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 0.0776 - val_accuracy: 0.9927\n",
            "Epoch 882/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.1281 - val_accuracy: 0.9909\n",
            "Epoch 883/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0025 - accuracy: 0.9997 - val_loss: 0.0698 - val_accuracy: 0.9951\n",
            "Epoch 884/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0049 - accuracy: 0.9992 - val_loss: 0.0978 - val_accuracy: 0.9933\n",
            "Epoch 885/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0044 - accuracy: 0.9992 - val_loss: 0.2015 - val_accuracy: 0.9897\n",
            "Epoch 886/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0019 - accuracy: 0.9997 - val_loss: 0.2556 - val_accuracy: 0.9885\n",
            "Epoch 887/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.2142 - val_accuracy: 0.9909\n",
            "Epoch 888/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.1703 - val_accuracy: 0.9915\n",
            "Epoch 889/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 3.0786e-04 - accuracy: 1.0000 - val_loss: 0.1636 - val_accuracy: 0.9915\n",
            "Epoch 890/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0021 - accuracy: 0.9997 - val_loss: 0.1598 - val_accuracy: 0.9915\n",
            "Epoch 891/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.1557 - val_accuracy: 0.9915\n",
            "Epoch 892/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0055 - accuracy: 0.9989 - val_loss: 0.1001 - val_accuracy: 0.9945\n",
            "Epoch 893/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0022 - accuracy: 0.9997 - val_loss: 0.0944 - val_accuracy: 0.9933\n",
            "Epoch 894/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0074 - accuracy: 0.9992 - val_loss: 0.3492 - val_accuracy: 0.9873\n",
            "Epoch 895/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0023 - accuracy: 0.9995 - val_loss: 0.2036 - val_accuracy: 0.9933\n",
            "Epoch 896/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0057 - accuracy: 0.9988 - val_loss: 0.2386 - val_accuracy: 0.9921\n",
            "Epoch 897/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.0779 - val_accuracy: 0.9933\n",
            "Epoch 898/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.2566 - val_accuracy: 0.9891\n",
            "Epoch 899/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0069 - accuracy: 0.9989 - val_loss: 0.0708 - val_accuracy: 0.9939\n",
            "Epoch 900/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0107 - accuracy: 0.9989 - val_loss: 0.1695 - val_accuracy: 0.9915\n",
            "Epoch 901/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0053 - accuracy: 0.9992 - val_loss: 0.1058 - val_accuracy: 0.9921\n",
            "Epoch 902/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0065 - accuracy: 0.9988 - val_loss: 0.1696 - val_accuracy: 0.9909\n",
            "Epoch 903/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.1692 - val_accuracy: 0.9921\n",
            "Epoch 904/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 6.0663e-04 - accuracy: 0.9998 - val_loss: 0.4293 - val_accuracy: 0.9830\n",
            "Epoch 905/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0033 - accuracy: 0.9997 - val_loss: 0.1928 - val_accuracy: 0.9927\n",
            "Epoch 906/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0114 - accuracy: 0.9988 - val_loss: 0.2694 - val_accuracy: 0.9873\n",
            "Epoch 907/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0114 - accuracy: 0.9986 - val_loss: 0.0999 - val_accuracy: 0.9933\n",
            "Epoch 908/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0042 - accuracy: 0.9992 - val_loss: 0.0790 - val_accuracy: 0.9933\n",
            "Epoch 909/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0049 - accuracy: 0.9992 - val_loss: 0.1728 - val_accuracy: 0.9897\n",
            "Epoch 910/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0052 - accuracy: 0.9994 - val_loss: 0.1706 - val_accuracy: 0.9903\n",
            "Epoch 911/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0021 - accuracy: 0.9997 - val_loss: 0.1605 - val_accuracy: 0.9909\n",
            "Epoch 912/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.1599 - val_accuracy: 0.9909\n",
            "Epoch 913/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 2.8928e-04 - accuracy: 1.0000 - val_loss: 0.1546 - val_accuracy: 0.9909\n",
            "Epoch 914/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0068 - accuracy: 0.9988 - val_loss: 0.2434 - val_accuracy: 0.9897\n",
            "Epoch 915/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0040 - accuracy: 0.9994 - val_loss: 0.0726 - val_accuracy: 0.9939\n",
            "Epoch 916/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.0773 - val_accuracy: 0.9939\n",
            "Epoch 917/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0070 - accuracy: 0.9995 - val_loss: 0.1374 - val_accuracy: 0.9933\n",
            "Epoch 918/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0155 - accuracy: 0.9986 - val_loss: 0.0966 - val_accuracy: 0.9891\n",
            "Epoch 919/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0072 - accuracy: 0.9994 - val_loss: 0.5342 - val_accuracy: 0.9812\n",
            "Epoch 920/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0042 - accuracy: 0.9992 - val_loss: 0.2766 - val_accuracy: 0.9897\n",
            "Epoch 921/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0150 - accuracy: 0.9977 - val_loss: 0.1948 - val_accuracy: 0.9860\n",
            "Epoch 922/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0120 - accuracy: 0.9985 - val_loss: 0.0324 - val_accuracy: 0.9958\n",
            "Epoch 923/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0031 - accuracy: 0.9995 - val_loss: 0.0446 - val_accuracy: 0.9945\n",
            "Epoch 924/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0022 - accuracy: 0.9997 - val_loss: 0.0612 - val_accuracy: 0.9927\n",
            "Epoch 925/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0058 - accuracy: 0.9991 - val_loss: 0.0994 - val_accuracy: 0.9909\n",
            "Epoch 926/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 7.7043e-04 - accuracy: 0.9998 - val_loss: 0.2857 - val_accuracy: 0.9867\n",
            "Epoch 927/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0031 - accuracy: 0.9995 - val_loss: 0.1347 - val_accuracy: 0.9909\n",
            "Epoch 928/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0059 - accuracy: 0.9988 - val_loss: 0.0358 - val_accuracy: 0.9945\n",
            "Epoch 929/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0039 - accuracy: 0.9994 - val_loss: 0.0924 - val_accuracy: 0.9903\n",
            "Epoch 930/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.3059 - val_accuracy: 0.9854\n",
            "Epoch 931/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0047 - accuracy: 0.9992 - val_loss: 0.4071 - val_accuracy: 0.9848\n",
            "Epoch 932/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 3.4432e-04 - accuracy: 1.0000 - val_loss: 0.1970 - val_accuracy: 0.9897\n",
            "Epoch 933/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0021 - accuracy: 0.9997 - val_loss: 0.1923 - val_accuracy: 0.9903\n",
            "Epoch 934/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0081 - accuracy: 0.9991 - val_loss: 0.1296 - val_accuracy: 0.9891\n",
            "Epoch 935/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0279 - accuracy: 0.9983 - val_loss: 0.1202 - val_accuracy: 0.9909\n",
            "Epoch 936/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0036 - accuracy: 0.9992 - val_loss: 0.2200 - val_accuracy: 0.9854\n",
            "Epoch 937/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0046 - accuracy: 0.9994 - val_loss: 0.1283 - val_accuracy: 0.9897\n",
            "Epoch 938/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0041 - accuracy: 0.9994 - val_loss: 0.1901 - val_accuracy: 0.9885\n",
            "Epoch 939/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0095 - accuracy: 0.9991 - val_loss: 0.0790 - val_accuracy: 0.9915\n",
            "Epoch 940/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0038 - accuracy: 0.9994 - val_loss: 0.1335 - val_accuracy: 0.9903\n",
            "Epoch 941/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.1563 - val_accuracy: 0.9897\n",
            "Epoch 942/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0039 - accuracy: 0.9994 - val_loss: 0.1415 - val_accuracy: 0.9891\n",
            "Epoch 943/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0061 - accuracy: 0.9989 - val_loss: 0.1429 - val_accuracy: 0.9903\n",
            "Epoch 944/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.2047 - val_accuracy: 0.9879\n",
            "Epoch 945/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.1970 - val_accuracy: 0.9873\n",
            "Epoch 946/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0049 - accuracy: 0.9992 - val_loss: 0.2495 - val_accuracy: 0.9867\n",
            "Epoch 947/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0028 - accuracy: 0.9995 - val_loss: 0.2812 - val_accuracy: 0.9860\n",
            "Epoch 948/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0022 - accuracy: 0.9997 - val_loss: 0.2098 - val_accuracy: 0.9879\n",
            "Epoch 949/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 4.4780e-04 - accuracy: 0.9998 - val_loss: 0.2650 - val_accuracy: 0.9879\n",
            "Epoch 950/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0068 - accuracy: 0.9991 - val_loss: 0.1891 - val_accuracy: 0.9891\n",
            "Epoch 951/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0142 - accuracy: 0.9988 - val_loss: 0.0759 - val_accuracy: 0.9939\n",
            "Epoch 952/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0040 - accuracy: 0.9994 - val_loss: 0.0846 - val_accuracy: 0.9915\n",
            "Epoch 953/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 8.2351e-04 - accuracy: 0.9998 - val_loss: 0.1027 - val_accuracy: 0.9915\n",
            "Epoch 954/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 0.0704 - val_accuracy: 0.9951\n",
            "Epoch 955/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.1046 - val_accuracy: 0.9915\n",
            "Epoch 956/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0025 - accuracy: 0.9992 - val_loss: 0.1967 - val_accuracy: 0.9903\n",
            "Epoch 957/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 3.8615e-04 - accuracy: 1.0000 - val_loss: 0.2809 - val_accuracy: 0.9891\n",
            "Epoch 958/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0043 - accuracy: 0.9991 - val_loss: 0.1394 - val_accuracy: 0.9903\n",
            "Epoch 959/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.2045 - val_accuracy: 0.9903\n",
            "Epoch 960/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.3245 - val_accuracy: 0.9860\n",
            "Epoch 961/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 1.3595 - val_accuracy: 0.9217\n",
            "Epoch 962/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0054 - accuracy: 0.9991 - val_loss: 0.0969 - val_accuracy: 0.9921\n",
            "Epoch 963/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0020 - accuracy: 0.9997 - val_loss: 0.1673 - val_accuracy: 0.9909\n",
            "Epoch 964/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 7.6350e-04 - accuracy: 0.9998 - val_loss: 0.1508 - val_accuracy: 0.9909\n",
            "Epoch 965/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.1612 - val_accuracy: 0.9909\n",
            "Epoch 966/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.1715 - val_accuracy: 0.9891\n",
            "Epoch 967/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 0.1200 - val_accuracy: 0.9903\n",
            "Epoch 968/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0022 - accuracy: 0.9997 - val_loss: 0.0547 - val_accuracy: 0.9921\n",
            "Epoch 969/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0029 - accuracy: 0.9995 - val_loss: 0.0958 - val_accuracy: 0.9897\n",
            "Epoch 970/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0038 - accuracy: 0.9994 - val_loss: 0.1633 - val_accuracy: 0.9867\n",
            "Epoch 971/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0016 - accuracy: 0.9997 - val_loss: 0.1176 - val_accuracy: 0.9915\n",
            "Epoch 972/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0108 - accuracy: 0.9988 - val_loss: 0.3517 - val_accuracy: 0.9836\n",
            "Epoch 973/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0034 - accuracy: 0.9992 - val_loss: 0.1344 - val_accuracy: 0.9915\n",
            "Epoch 974/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 7.5087e-04 - accuracy: 0.9997 - val_loss: 0.1242 - val_accuracy: 0.9921\n",
            "Epoch 975/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0075 - accuracy: 0.9997 - val_loss: 0.3051 - val_accuracy: 0.9848\n",
            "Epoch 976/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0071 - accuracy: 0.9989 - val_loss: 0.0652 - val_accuracy: 0.9927\n",
            "Epoch 977/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0055 - accuracy: 0.9995 - val_loss: 0.1682 - val_accuracy: 0.9897\n",
            "Epoch 978/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.1365 - val_accuracy: 0.9915\n",
            "Epoch 979/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.1745 - val_accuracy: 0.9903\n",
            "Epoch 980/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0041 - accuracy: 0.9991 - val_loss: 0.2058 - val_accuracy: 0.9897\n",
            "Epoch 981/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0017 - accuracy: 0.9997 - val_loss: 0.0857 - val_accuracy: 0.9939\n",
            "Epoch 982/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0025 - accuracy: 0.9995 - val_loss: 0.2015 - val_accuracy: 0.9915\n",
            "Epoch 983/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 3.0075e-04 - accuracy: 1.0000 - val_loss: 0.2174 - val_accuracy: 0.9915\n",
            "Epoch 984/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0041 - accuracy: 0.9994 - val_loss: 0.0932 - val_accuracy: 0.9915\n",
            "Epoch 985/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0041 - accuracy: 0.9994 - val_loss: 0.0905 - val_accuracy: 0.9921\n",
            "Epoch 986/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0031 - accuracy: 0.9995 - val_loss: 0.1058 - val_accuracy: 0.9915\n",
            "Epoch 987/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.1140 - val_accuracy: 0.9915\n",
            "Epoch 988/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.1166 - val_accuracy: 0.9915\n",
            "Epoch 989/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 2.4895e-04 - accuracy: 1.0000 - val_loss: 0.1179 - val_accuracy: 0.9915\n",
            "Epoch 990/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0021 - accuracy: 0.9997 - val_loss: 0.1182 - val_accuracy: 0.9915\n",
            "Epoch 991/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0065 - accuracy: 0.9992 - val_loss: 0.1756 - val_accuracy: 0.9897\n",
            "Epoch 992/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0184 - accuracy: 0.9977 - val_loss: 0.1305 - val_accuracy: 0.9927\n",
            "Epoch 993/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0068 - accuracy: 0.9997 - val_loss: 0.1932 - val_accuracy: 0.9903\n",
            "Epoch 994/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0050 - accuracy: 0.9989 - val_loss: 0.2134 - val_accuracy: 0.9891\n",
            "Epoch 995/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 0.0103 - accuracy: 0.9989 - val_loss: 0.2024 - val_accuracy: 0.9903\n",
            "Epoch 996/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0047 - accuracy: 0.9991 - val_loss: 0.2541 - val_accuracy: 0.9909\n",
            "Epoch 997/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0034 - accuracy: 0.9995 - val_loss: 0.2835 - val_accuracy: 0.9885\n",
            "Epoch 998/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0031 - accuracy: 0.9995 - val_loss: 0.2490 - val_accuracy: 0.9897\n",
            "Epoch 999/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0021 - accuracy: 0.9997 - val_loss: 0.4590 - val_accuracy: 0.9873\n",
            "Epoch 1000/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0018 - accuracy: 0.9997 - val_loss: 0.1193 - val_accuracy: 0.9915\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1200x400 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "206/206 [==============================] - 12s 46ms/step - loss: 1.6063 - accuracy: 0.9219 - val_loss: 8.4239 - val_accuracy: 0.9059\n",
            "Epoch 2/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.1016 - accuracy: 0.9580 - val_loss: 0.1608 - val_accuracy: 0.9739\n",
            "Epoch 3/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.1218 - accuracy: 0.9596 - val_loss: 0.0179 - val_accuracy: 0.9939\n",
            "Epoch 4/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0787 - accuracy: 0.9663 - val_loss: 0.2585 - val_accuracy: 0.9569\n",
            "Epoch 5/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0573 - accuracy: 0.9745 - val_loss: 0.1669 - val_accuracy: 0.9800\n",
            "Epoch 6/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0640 - accuracy: 0.9762 - val_loss: 0.0184 - val_accuracy: 0.9921\n",
            "Epoch 7/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0511 - accuracy: 0.9716 - val_loss: 0.0062 - val_accuracy: 0.9994\n",
            "Epoch 8/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.9458 - accuracy: 0.9387 - val_loss: 67.6137 - val_accuracy: 0.8817\n",
            "Epoch 9/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.3146 - accuracy: 0.8971 - val_loss: 0.1258 - val_accuracy: 0.9023\n",
            "Epoch 10/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.1212 - accuracy: 0.9299 - val_loss: 0.0794 - val_accuracy: 0.9757\n",
            "Epoch 11/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0908 - accuracy: 0.9520 - val_loss: 20.8327 - val_accuracy: 0.9314\n",
            "Epoch 12/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0756 - accuracy: 0.9593 - val_loss: 0.0225 - val_accuracy: 0.9915\n",
            "Epoch 13/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0591 - accuracy: 0.9631 - val_loss: 0.0165 - val_accuracy: 0.9939\n",
            "Epoch 14/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0630 - accuracy: 0.9684 - val_loss: 0.0104 - val_accuracy: 0.9958\n",
            "Epoch 15/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0370 - accuracy: 0.9859 - val_loss: 0.0128 - val_accuracy: 0.9970\n",
            "Epoch 16/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0300 - accuracy: 0.9865 - val_loss: 0.0142 - val_accuracy: 0.9958\n",
            "Epoch 17/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0264 - accuracy: 0.9888 - val_loss: 0.0534 - val_accuracy: 0.9927\n",
            "Epoch 18/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0282 - accuracy: 0.9874 - val_loss: 0.0068 - val_accuracy: 0.9982\n",
            "Epoch 19/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0237 - accuracy: 0.9897 - val_loss: 0.0158 - val_accuracy: 0.9958\n",
            "Epoch 20/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0250 - accuracy: 0.9900 - val_loss: 0.0052 - val_accuracy: 0.9988\n",
            "Epoch 21/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0384 - accuracy: 0.9879 - val_loss: 0.0645 - val_accuracy: 0.9697\n",
            "Epoch 22/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0511 - accuracy: 0.9825 - val_loss: 0.1572 - val_accuracy: 0.9915\n",
            "Epoch 23/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0407 - accuracy: 0.9889 - val_loss: 0.0080 - val_accuracy: 0.9976\n",
            "Epoch 24/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0622 - accuracy: 0.9847 - val_loss: 533.0579 - val_accuracy: 0.8805\n",
            "Epoch 25/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0358 - accuracy: 0.9865 - val_loss: 0.0420 - val_accuracy: 0.9982\n",
            "Epoch 26/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0539 - accuracy: 0.9851 - val_loss: 0.4136 - val_accuracy: 0.9733\n",
            "Epoch 27/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0602 - accuracy: 0.9756 - val_loss: 0.0287 - val_accuracy: 0.9836\n",
            "Epoch 28/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0427 - accuracy: 0.9838 - val_loss: 0.0248 - val_accuracy: 0.9958\n",
            "Epoch 29/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0362 - accuracy: 0.9866 - val_loss: 0.0189 - val_accuracy: 0.9970\n",
            "Epoch 30/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0364 - accuracy: 0.9915 - val_loss: 0.0083 - val_accuracy: 0.9976\n",
            "Epoch 31/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0434 - accuracy: 0.9842 - val_loss: 0.0316 - val_accuracy: 0.9860\n",
            "Epoch 32/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0522 - accuracy: 0.9812 - val_loss: 0.0104 - val_accuracy: 0.9982\n",
            "Epoch 33/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0231 - accuracy: 0.9939 - val_loss: 0.0078 - val_accuracy: 0.9994\n",
            "Epoch 34/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0166 - accuracy: 0.9964 - val_loss: 0.0059 - val_accuracy: 0.9994\n",
            "Epoch 35/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.2428 - accuracy: 0.9788 - val_loss: 0.2418 - val_accuracy: 0.8610\n",
            "Epoch 36/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.1582 - accuracy: 0.9419 - val_loss: 0.4662 - val_accuracy: 0.9800\n",
            "Epoch 37/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0873 - accuracy: 0.9721 - val_loss: 0.0103 - val_accuracy: 0.9970\n",
            "Epoch 38/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0428 - accuracy: 0.9839 - val_loss: 0.0135 - val_accuracy: 0.9958\n",
            "Epoch 39/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0307 - accuracy: 0.9900 - val_loss: 0.0195 - val_accuracy: 0.9964\n",
            "Epoch 40/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0469 - accuracy: 0.9895 - val_loss: 0.0089 - val_accuracy: 0.9982\n",
            "Epoch 41/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0381 - accuracy: 0.9891 - val_loss: 1.3294 - val_accuracy: 0.9915\n",
            "Epoch 42/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0287 - accuracy: 0.9882 - val_loss: 0.0135 - val_accuracy: 0.9982\n",
            "Epoch 43/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0304 - accuracy: 0.9900 - val_loss: 0.0213 - val_accuracy: 0.9976\n",
            "Epoch 44/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0361 - accuracy: 0.9914 - val_loss: 0.0092 - val_accuracy: 0.9988\n",
            "Epoch 45/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0215 - accuracy: 0.9951 - val_loss: 0.0329 - val_accuracy: 0.9970\n",
            "Epoch 46/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0229 - accuracy: 0.9936 - val_loss: 6.2564 - val_accuracy: 0.9260\n",
            "Epoch 47/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0608 - accuracy: 0.9863 - val_loss: 0.1394 - val_accuracy: 0.9891\n",
            "Epoch 48/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0443 - accuracy: 0.9848 - val_loss: 0.0076 - val_accuracy: 0.9988\n",
            "Epoch 49/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0408 - accuracy: 0.9862 - val_loss: 0.0364 - val_accuracy: 0.9933\n",
            "Epoch 50/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0235 - accuracy: 0.9930 - val_loss: 0.0111 - val_accuracy: 0.9988\n",
            "Epoch 51/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0186 - accuracy: 0.9914 - val_loss: 0.0193 - val_accuracy: 0.9988\n",
            "Epoch 52/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0510 - accuracy: 0.9924 - val_loss: 32.1772 - val_accuracy: 0.9181\n",
            "Epoch 53/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0245 - accuracy: 0.9924 - val_loss: 0.0130 - val_accuracy: 0.9976\n",
            "Epoch 54/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0173 - accuracy: 0.9941 - val_loss: 0.0092 - val_accuracy: 0.9982\n",
            "Epoch 55/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0293 - accuracy: 0.9918 - val_loss: 0.0125 - val_accuracy: 0.9964\n",
            "Epoch 56/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0187 - accuracy: 0.9923 - val_loss: 0.0202 - val_accuracy: 0.9909\n",
            "Epoch 57/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0296 - accuracy: 0.9910 - val_loss: 0.0182 - val_accuracy: 0.9994\n",
            "Epoch 58/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0320 - accuracy: 0.9964 - val_loss: 0.0126 - val_accuracy: 0.9994\n",
            "Epoch 59/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0441 - accuracy: 0.9907 - val_loss: 0.1273 - val_accuracy: 0.9806\n",
            "Epoch 60/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0191 - accuracy: 0.9951 - val_loss: 0.0140 - val_accuracy: 0.9982\n",
            "Epoch 61/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0146 - accuracy: 0.9977 - val_loss: 0.0060 - val_accuracy: 0.9994\n",
            "Epoch 62/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0075 - accuracy: 0.9982 - val_loss: 0.0098 - val_accuracy: 0.9994\n",
            "Epoch 63/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0046 - accuracy: 0.9995 - val_loss: 0.0110 - val_accuracy: 0.9994\n",
            "Epoch 64/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0138 - accuracy: 0.9970 - val_loss: 0.0133 - val_accuracy: 0.9988\n",
            "Epoch 65/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0138 - accuracy: 0.9979 - val_loss: 0.0287 - val_accuracy: 0.9988\n",
            "Epoch 66/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0475 - accuracy: 0.9948 - val_loss: 0.1012 - val_accuracy: 0.9915\n",
            "Epoch 67/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0170 - accuracy: 0.9948 - val_loss: 0.0022 - val_accuracy: 0.9994\n",
            "Epoch 68/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0151 - accuracy: 0.9964 - val_loss: 0.0016 - val_accuracy: 0.9994\n",
            "Epoch 69/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0145 - accuracy: 0.9970 - val_loss: 1.4945e-06 - val_accuracy: 1.0000\n",
            "Epoch 70/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0165 - accuracy: 0.9968 - val_loss: 0.0031 - val_accuracy: 0.9994\n",
            "Epoch 71/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0094 - accuracy: 0.9986 - val_loss: 0.0010 - val_accuracy: 0.9994\n",
            "Epoch 72/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0041 - accuracy: 0.9995 - val_loss: 7.6581e-04 - val_accuracy: 0.9994\n",
            "Epoch 73/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0031 - accuracy: 0.9997 - val_loss: 1.0244e-04 - val_accuracy: 1.0000\n",
            "Epoch 74/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0045 - accuracy: 0.9989 - val_loss: 1.2810e-05 - val_accuracy: 1.0000\n",
            "Epoch 75/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0329 - accuracy: 0.9971 - val_loss: 0.0155 - val_accuracy: 0.9988\n",
            "Epoch 76/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0109 - accuracy: 0.9977 - val_loss: 0.0165 - val_accuracy: 0.9982\n",
            "Epoch 77/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0109 - accuracy: 0.9961 - val_loss: 9.1985e-06 - val_accuracy: 1.0000\n",
            "Epoch 78/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0606 - accuracy: 0.9954 - val_loss: 0.0117 - val_accuracy: 0.9988\n",
            "Epoch 79/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0070 - accuracy: 0.9979 - val_loss: 5.6209e-04 - val_accuracy: 1.0000\n",
            "Epoch 80/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0090 - accuracy: 0.9980 - val_loss: 8.8634e-04 - val_accuracy: 0.9994\n",
            "Epoch 81/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0340 - accuracy: 0.9959 - val_loss: 0.0677 - val_accuracy: 0.9915\n",
            "Epoch 82/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0209 - accuracy: 0.9974 - val_loss: 1.5459e-04 - val_accuracy: 1.0000\n",
            "Epoch 83/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0599 - accuracy: 0.9964 - val_loss: 0.0741 - val_accuracy: 0.9945\n",
            "Epoch 84/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0084 - accuracy: 0.9977 - val_loss: 0.0083 - val_accuracy: 0.9988\n",
            "Epoch 85/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0208 - accuracy: 0.9965 - val_loss: 0.0037 - val_accuracy: 0.9994\n",
            "Epoch 86/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0048 - accuracy: 0.9994 - val_loss: 0.0024 - val_accuracy: 0.9994\n",
            "Epoch 87/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0048 - accuracy: 0.9991 - val_loss: 0.0022 - val_accuracy: 0.9994\n",
            "Epoch 88/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 0.0038 - val_accuracy: 0.9994\n",
            "Epoch 89/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0037 - accuracy: 0.9989 - val_loss: 0.0023 - val_accuracy: 0.9994\n",
            "Epoch 90/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0373 - accuracy: 0.9974 - val_loss: 0.0153 - val_accuracy: 0.9982\n",
            "Epoch 91/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0094 - accuracy: 0.9977 - val_loss: 0.0067 - val_accuracy: 0.9982\n",
            "Epoch 92/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0099 - accuracy: 0.9971 - val_loss: 0.0012 - val_accuracy: 0.9994\n",
            "Epoch 93/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0098 - accuracy: 0.9983 - val_loss: 0.0110 - val_accuracy: 0.9994\n",
            "Epoch 94/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0025 - accuracy: 0.9995 - val_loss: 0.0097 - val_accuracy: 0.9994\n",
            "Epoch 95/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 6.5805e-04 - val_accuracy: 0.9994\n",
            "Epoch 96/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0045 - accuracy: 0.9988 - val_loss: 0.0032 - val_accuracy: 0.9988\n",
            "Epoch 97/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0032 - accuracy: 0.9995 - val_loss: 0.0036 - val_accuracy: 0.9994\n",
            "Epoch 98/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0076 - accuracy: 0.9989 - val_loss: 2.1439e-04 - val_accuracy: 1.0000\n",
            "Epoch 99/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0016 - accuracy: 0.9998 - val_loss: 5.1032e-06 - val_accuracy: 1.0000\n",
            "Epoch 100/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0051 - accuracy: 0.9986 - val_loss: 0.0022 - val_accuracy: 0.9994\n",
            "Epoch 101/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0033 - accuracy: 0.9991 - val_loss: 0.0040 - val_accuracy: 0.9994\n",
            "Epoch 102/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0037 - accuracy: 0.9989 - val_loss: 3.3644e-06 - val_accuracy: 1.0000\n",
            "Epoch 103/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0381 - accuracy: 0.9947 - val_loss: 0.0207 - val_accuracy: 0.9970\n",
            "Epoch 104/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0529 - accuracy: 0.9976 - val_loss: 0.0030 - val_accuracy: 0.9994\n",
            "Epoch 105/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0075 - accuracy: 0.9985 - val_loss: 0.0056 - val_accuracy: 0.9994\n",
            "Epoch 106/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.0047 - val_accuracy: 0.9994\n",
            "Epoch 107/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0015 - accuracy: 0.9998 - val_loss: 0.0071 - val_accuracy: 0.9994\n",
            "Epoch 108/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0022 - accuracy: 0.9997 - val_loss: 0.0142 - val_accuracy: 0.9994\n",
            "Epoch 109/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0052 - accuracy: 0.9991 - val_loss: 0.0105 - val_accuracy: 0.9994\n",
            "Epoch 110/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0051 - accuracy: 0.9991 - val_loss: 0.0041 - val_accuracy: 0.9994\n",
            "Epoch 111/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0068 - accuracy: 0.9989 - val_loss: 0.0107 - val_accuracy: 0.9994\n",
            "Epoch 112/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0032 - accuracy: 0.9991 - val_loss: 0.0093 - val_accuracy: 0.9994\n",
            "Epoch 113/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0067 - accuracy: 0.9992 - val_loss: 0.0136 - val_accuracy: 0.9994\n",
            "Epoch 114/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0497 - accuracy: 0.9970 - val_loss: 0.0399 - val_accuracy: 0.9951\n",
            "Epoch 115/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0130 - accuracy: 0.9983 - val_loss: 0.0032 - val_accuracy: 0.9994\n",
            "Epoch 116/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0088 - accuracy: 0.9986 - val_loss: 0.0080 - val_accuracy: 0.9994\n",
            "Epoch 117/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 9.1847e-04 - accuracy: 1.0000 - val_loss: 0.0094 - val_accuracy: 0.9994\n",
            "Epoch 118/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 0.0114 - val_accuracy: 0.9994\n",
            "Epoch 119/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.0077 - val_accuracy: 0.9994\n",
            "Epoch 120/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0084 - accuracy: 0.9992 - val_loss: 0.0368 - val_accuracy: 0.9964\n",
            "Epoch 121/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0158 - accuracy: 0.9982 - val_loss: 0.0024 - val_accuracy: 0.9994\n",
            "Epoch 122/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0299 - accuracy: 0.9985 - val_loss: 0.1959 - val_accuracy: 0.9885\n",
            "Epoch 123/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0168 - accuracy: 0.9988 - val_loss: 0.8541 - val_accuracy: 0.9848\n",
            "Epoch 124/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1138 - accuracy: 0.9962 - val_loss: 0.0696 - val_accuracy: 0.9988\n",
            "Epoch 125/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0166 - accuracy: 0.9983 - val_loss: 0.0027 - val_accuracy: 0.9988\n",
            "Epoch 126/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0044 - accuracy: 0.9995 - val_loss: 0.0020 - val_accuracy: 0.9994\n",
            "Epoch 127/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0106 - accuracy: 0.9986 - val_loss: 0.0020 - val_accuracy: 0.9994\n",
            "Epoch 128/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0026 - accuracy: 0.9995 - val_loss: 0.0020 - val_accuracy: 0.9994\n",
            "Epoch 129/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0063 - accuracy: 0.9988 - val_loss: 0.0085 - val_accuracy: 0.9982\n",
            "Epoch 130/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0074 - accuracy: 0.9983 - val_loss: 0.0030 - val_accuracy: 0.9994\n",
            "Epoch 131/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0033 - accuracy: 0.9992 - val_loss: 0.0020 - val_accuracy: 0.9994\n",
            "Epoch 132/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0015 - accuracy: 0.9998 - val_loss: 0.0019 - val_accuracy: 0.9994\n",
            "Epoch 133/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.0032 - val_accuracy: 0.9994\n",
            "Epoch 134/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.0059 - val_accuracy: 0.9994\n",
            "Epoch 135/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0069 - accuracy: 0.9995 - val_loss: 8.6048e-05 - val_accuracy: 1.0000\n",
            "Epoch 136/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.0097 - val_accuracy: 0.9994\n",
            "Epoch 137/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 4.4433e-04 - accuracy: 1.0000 - val_loss: 0.0133 - val_accuracy: 0.9994\n",
            "Epoch 138/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0095 - accuracy: 0.9992 - val_loss: 0.0374 - val_accuracy: 0.9988\n",
            "Epoch 139/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0195 - accuracy: 0.9985 - val_loss: 0.0478 - val_accuracy: 0.9994\n",
            "Epoch 140/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0082 - accuracy: 0.9994 - val_loss: 0.0348 - val_accuracy: 0.9994\n",
            "Epoch 141/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0232 - accuracy: 0.9983 - val_loss: 0.0047 - val_accuracy: 0.9994\n",
            "Epoch 142/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0150 - accuracy: 0.9991 - val_loss: 0.0214 - val_accuracy: 0.9994\n",
            "Epoch 143/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0099 - accuracy: 0.9992 - val_loss: 0.0136 - val_accuracy: 0.9994\n",
            "Epoch 144/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0031 - accuracy: 0.9992 - val_loss: 0.0127 - val_accuracy: 0.9994\n",
            "Epoch 145/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 0.0142 - val_accuracy: 0.9994\n",
            "Epoch 146/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0083 - accuracy: 0.9985 - val_loss: 0.0220 - val_accuracy: 0.9988\n",
            "Epoch 147/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0112 - accuracy: 0.9986 - val_loss: 0.0477 - val_accuracy: 0.9976\n",
            "Epoch 148/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0113 - accuracy: 0.9989 - val_loss: 0.0131 - val_accuracy: 0.9988\n",
            "Epoch 149/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0047 - accuracy: 0.9989 - val_loss: 0.0155 - val_accuracy: 0.9988\n",
            "Epoch 150/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0027 - accuracy: 0.9997 - val_loss: 0.0080 - val_accuracy: 0.9994\n",
            "Epoch 151/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.0033 - val_accuracy: 0.9994\n",
            "Epoch 152/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0050 - accuracy: 0.9992 - val_loss: 0.0199 - val_accuracy: 0.9982\n",
            "Epoch 153/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0159 - accuracy: 0.9980 - val_loss: 0.0705 - val_accuracy: 0.9939\n",
            "Epoch 154/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0044 - accuracy: 0.9988 - val_loss: 0.0099 - val_accuracy: 0.9988\n",
            "Epoch 155/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0032 - accuracy: 0.9992 - val_loss: 0.0112 - val_accuracy: 0.9994\n",
            "Epoch 156/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.0105 - val_accuracy: 0.9994\n",
            "Epoch 157/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 4.1438e-04 - accuracy: 1.0000 - val_loss: 0.0105 - val_accuracy: 0.9994\n",
            "Epoch 158/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0010 - accuracy: 0.9998 - val_loss: 0.0139 - val_accuracy: 0.9994\n",
            "Epoch 159/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 7.7882e-04 - accuracy: 0.9998 - val_loss: 0.0140 - val_accuracy: 0.9994\n",
            "Epoch 160/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.0164 - val_accuracy: 0.9994\n",
            "Epoch 161/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 2.8597e-04 - accuracy: 1.0000 - val_loss: 0.0189 - val_accuracy: 0.9994\n",
            "Epoch 162/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0335 - accuracy: 0.9986 - val_loss: 26.6501 - val_accuracy: 0.9430\n",
            "Epoch 163/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0071 - accuracy: 0.9983 - val_loss: 1.4846e-04 - val_accuracy: 1.0000\n",
            "Epoch 164/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0125 - accuracy: 0.9982 - val_loss: 3.3509e-05 - val_accuracy: 1.0000\n",
            "Epoch 165/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0027 - accuracy: 0.9995 - val_loss: 3.3611e-05 - val_accuracy: 1.0000\n",
            "Epoch 166/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0046 - accuracy: 0.9989 - val_loss: 0.0038 - val_accuracy: 0.9994\n",
            "Epoch 167/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0152 - accuracy: 0.9988 - val_loss: 0.0021 - val_accuracy: 0.9994\n",
            "Epoch 168/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0065 - accuracy: 0.9988 - val_loss: 0.0020 - val_accuracy: 0.9994\n",
            "Epoch 169/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0046 - accuracy: 0.9992 - val_loss: 0.0020 - val_accuracy: 0.9994\n",
            "Epoch 170/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.0019 - val_accuracy: 0.9994\n",
            "Epoch 171/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.0167 - val_accuracy: 0.9988\n",
            "Epoch 172/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.0118 - val_accuracy: 0.9994\n",
            "Epoch 173/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0066 - accuracy: 0.9989 - val_loss: 0.0034 - val_accuracy: 0.9994\n",
            "Epoch 174/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0040 - accuracy: 0.9989 - val_loss: 5.8743e-04 - val_accuracy: 0.9994\n",
            "Epoch 175/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.0024 - val_accuracy: 0.9994\n",
            "Epoch 176/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 2.2565e-04 - val_accuracy: 1.0000\n",
            "Epoch 177/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0049 - accuracy: 0.9992 - val_loss: 0.0020 - val_accuracy: 0.9994\n",
            "Epoch 178/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 3.2627e-04 - val_accuracy: 1.0000\n",
            "Epoch 179/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 7.3470e-05 - val_accuracy: 1.0000\n",
            "Epoch 180/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 1.2917e-04 - val_accuracy: 1.0000\n",
            "Epoch 181/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 9.0423e-04 - accuracy: 0.9997 - val_loss: 2.2098e-05 - val_accuracy: 1.0000\n",
            "Epoch 182/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 1.0685e-05 - val_accuracy: 1.0000\n",
            "Epoch 183/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 7.3811e-06 - val_accuracy: 1.0000\n",
            "Epoch 184/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 3.4737e-06 - val_accuracy: 1.0000\n",
            "Epoch 185/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 4.0750e-04 - accuracy: 1.0000 - val_loss: 1.1007e-05 - val_accuracy: 1.0000\n",
            "Epoch 186/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 4.5247e-04 - accuracy: 1.0000 - val_loss: 1.1533e-05 - val_accuracy: 1.0000\n",
            "Epoch 187/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 3.4798e-04 - accuracy: 1.0000 - val_loss: 1.9717e-05 - val_accuracy: 1.0000\n",
            "Epoch 188/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 4.0538e-04 - val_accuracy: 1.0000\n",
            "Epoch 189/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 5.5909e-04 - accuracy: 0.9998 - val_loss: 1.8684e-07 - val_accuracy: 1.0000\n",
            "Epoch 190/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 7.2456e-04 - accuracy: 0.9998 - val_loss: 9.7324e-08 - val_accuracy: 1.0000\n",
            "Epoch 191/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.0834e-04 - accuracy: 1.0000 - val_loss: 1.7352e-05 - val_accuracy: 1.0000\n",
            "Epoch 192/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.1238e-04 - accuracy: 1.0000 - val_loss: 4.4666e-05 - val_accuracy: 1.0000\n",
            "Epoch 193/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 6.3923e-04 - accuracy: 0.9998 - val_loss: 1.0619e-04 - val_accuracy: 1.0000\n",
            "Epoch 194/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0189 - accuracy: 0.9994 - val_loss: 9.4388 - val_accuracy: 0.9223\n",
            "Epoch 195/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0136 - accuracy: 0.9985 - val_loss: 0.0200 - val_accuracy: 0.9994\n",
            "Epoch 196/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 1.9555e-05 - val_accuracy: 1.0000\n",
            "Epoch 197/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 9.1807e-04 - accuracy: 0.9998 - val_loss: 0.0420 - val_accuracy: 0.9988\n",
            "Epoch 198/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0405 - accuracy: 0.9983 - val_loss: 0.0196 - val_accuracy: 0.9988\n",
            "Epoch 199/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0089 - accuracy: 0.9991 - val_loss: 0.0435 - val_accuracy: 0.9982\n",
            "Epoch 200/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.0040 - val_accuracy: 0.9994\n",
            "Epoch 201/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0048 - val_accuracy: 0.9994\n",
            "Epoch 202/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 8.0731e-04 - accuracy: 0.9998 - val_loss: 0.0073 - val_accuracy: 0.9994\n",
            "Epoch 203/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 1.3779e-04 - accuracy: 1.0000 - val_loss: 0.0104 - val_accuracy: 0.9994\n",
            "Epoch 204/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 6.9960e-04 - accuracy: 0.9998 - val_loss: 0.0112 - val_accuracy: 0.9994\n",
            "Epoch 205/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.5701e-04 - accuracy: 1.0000 - val_loss: 0.0128 - val_accuracy: 0.9994\n",
            "Epoch 206/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0209 - accuracy: 0.9994 - val_loss: 0.0236 - val_accuracy: 0.9994\n",
            "Epoch 207/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0096 - accuracy: 0.9997 - val_loss: 0.0057 - val_accuracy: 0.9988\n",
            "Epoch 208/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0041 - accuracy: 0.9994 - val_loss: 0.0033 - val_accuracy: 0.9994\n",
            "Epoch 209/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 8.3982e-04 - accuracy: 0.9997 - val_loss: 0.0032 - val_accuracy: 0.9994\n",
            "Epoch 210/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 2.8708e-04 - accuracy: 0.9998 - val_loss: 2.7366e-07 - val_accuracy: 1.0000\n",
            "Epoch 211/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 9.2514e-05 - accuracy: 1.0000 - val_loss: 1.2818e-07 - val_accuracy: 1.0000\n",
            "Epoch 212/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0087 - accuracy: 0.9997 - val_loss: 3.1746e-06 - val_accuracy: 1.0000\n",
            "Epoch 213/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.5209e-04 - accuracy: 1.0000 - val_loss: 1.5501e-08 - val_accuracy: 1.0000\n",
            "Epoch 214/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0076 - accuracy: 0.9994 - val_loss: 9.0969e-07 - val_accuracy: 1.0000\n",
            "Epoch 215/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 1.4716e-05 - val_accuracy: 1.0000\n",
            "Epoch 216/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 9.0058e-04 - accuracy: 0.9998 - val_loss: 1.4520e-05 - val_accuracy: 1.0000\n",
            "Epoch 217/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 1.4521e-05 - val_accuracy: 1.0000\n",
            "Epoch 218/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 2.2001e-04 - accuracy: 1.0000 - val_loss: 7.6076e-06 - val_accuracy: 1.0000\n",
            "Epoch 219/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0091 - accuracy: 0.9994 - val_loss: 2.5541e-04 - val_accuracy: 1.0000\n",
            "Epoch 220/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 4.0459e-04 - accuracy: 1.0000 - val_loss: 8.1047e-06 - val_accuracy: 1.0000\n",
            "Epoch 221/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 0.0035 - val_accuracy: 0.9994\n",
            "Epoch 222/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 2.8873e-04 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 0.9994\n",
            "Epoch 223/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 2.7722e-04 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9994\n",
            "Epoch 224/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 2.2072e-04 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9994\n",
            "Epoch 225/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0121 - accuracy: 0.9992 - val_loss: 5.7449e-06 - val_accuracy: 1.0000\n",
            "Epoch 226/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0057 - accuracy: 0.9995 - val_loss: 2.7425e-04 - val_accuracy: 1.0000\n",
            "Epoch 227/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0169 - accuracy: 0.9991 - val_loss: 0.0035 - val_accuracy: 0.9994\n",
            "Epoch 228/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0051 - accuracy: 0.9991 - val_loss: 0.0031 - val_accuracy: 0.9988\n",
            "Epoch 229/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.0025 - val_accuracy: 0.9994\n",
            "Epoch 230/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 4.2035e-04 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 0.9994\n",
            "Epoch 231/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0079 - accuracy: 0.9989 - val_loss: 7.7789e-05 - val_accuracy: 1.0000\n",
            "Epoch 232/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0132 - accuracy: 0.9991 - val_loss: 0.0397 - val_accuracy: 0.9982\n",
            "Epoch 233/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0119 - accuracy: 0.9994 - val_loss: 5.0696e-06 - val_accuracy: 1.0000\n",
            "Epoch 234/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 8.0043e-04 - accuracy: 0.9998 - val_loss: 5.8421e-06 - val_accuracy: 1.0000\n",
            "Epoch 235/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 2.0016e-04 - accuracy: 1.0000 - val_loss: 5.3055e-06 - val_accuracy: 1.0000\n",
            "Epoch 236/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 4.5990e-04 - accuracy: 0.9998 - val_loss: 3.7310e-06 - val_accuracy: 1.0000\n",
            "Epoch 237/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 7.9144e-04 - accuracy: 0.9997 - val_loss: 0.0236 - val_accuracy: 0.9994\n",
            "Epoch 238/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0053 - accuracy: 0.9995 - val_loss: 1.2732e-09 - val_accuracy: 1.0000\n",
            "Epoch 239/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 9.7053e-12 - val_accuracy: 1.0000\n",
            "Epoch 240/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 8.9153e-04 - accuracy: 0.9998 - val_loss: 2.9385e-11 - val_accuracy: 1.0000\n",
            "Epoch 241/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 1.5678e-08 - val_accuracy: 1.0000\n",
            "Epoch 242/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0044 - accuracy: 0.9994 - val_loss: 2.5407e-08 - val_accuracy: 1.0000\n",
            "Epoch 243/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0026 - accuracy: 0.9997 - val_loss: 0.0057 - val_accuracy: 0.9994\n",
            "Epoch 244/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 1.5693e-04 - accuracy: 1.0000 - val_loss: 1.0240e-05 - val_accuracy: 1.0000\n",
            "Epoch 245/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 5.1011e-04 - accuracy: 0.9998 - val_loss: 8.5867e-06 - val_accuracy: 1.0000\n",
            "Epoch 246/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 9.9424e-05 - accuracy: 1.0000 - val_loss: 7.9453e-07 - val_accuracy: 1.0000\n",
            "Epoch 247/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 4.8027e-05 - accuracy: 1.0000 - val_loss: 2.1139e-07 - val_accuracy: 1.0000\n",
            "Epoch 248/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0117 - accuracy: 0.9994 - val_loss: 2.7532e-05 - val_accuracy: 1.0000\n",
            "Epoch 249/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 2.3388e-04 - accuracy: 1.0000 - val_loss: 2.2474e-05 - val_accuracy: 1.0000\n",
            "Epoch 250/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 2.1532e-04 - accuracy: 1.0000 - val_loss: 7.2212e-06 - val_accuracy: 1.0000\n",
            "Epoch 251/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 7.4242e-06 - val_accuracy: 1.0000\n",
            "Epoch 252/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 7.3363e-04 - accuracy: 0.9998 - val_loss: 0.0207 - val_accuracy: 0.9988\n",
            "Epoch 253/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0291 - accuracy: 0.9986 - val_loss: 1.2489e-05 - val_accuracy: 1.0000\n",
            "Epoch 254/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.0010 - val_accuracy: 0.9994\n",
            "Epoch 255/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.0322 - val_accuracy: 0.9994\n",
            "Epoch 256/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0109 - accuracy: 0.9992 - val_loss: 0.0092 - val_accuracy: 0.9988\n",
            "Epoch 257/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 4.0274e-04 - accuracy: 0.9997 - val_loss: 0.0240 - val_accuracy: 0.9994\n",
            "Epoch 258/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 6.1415e-04 - accuracy: 0.9998 - val_loss: 0.0425 - val_accuracy: 0.9994\n",
            "Epoch 259/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0077 - accuracy: 0.9995 - val_loss: 1.6409e-17 - val_accuracy: 1.0000\n",
            "Epoch 260/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 2.4113e-04 - accuracy: 0.9998 - val_loss: 0.0097 - val_accuracy: 0.9994\n",
            "Epoch 261/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0648 - accuracy: 0.9982 - val_loss: 0.0042 - val_accuracy: 0.9994\n",
            "Epoch 262/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0114 - accuracy: 0.9994 - val_loss: 0.0095 - val_accuracy: 0.9994\n",
            "Epoch 263/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.0060 - val_accuracy: 0.9994\n",
            "Epoch 264/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 4.8205e-04 - accuracy: 0.9998 - val_loss: 0.0069 - val_accuracy: 0.9994\n",
            "Epoch 265/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0010 - accuracy: 0.9998 - val_loss: 0.0167 - val_accuracy: 0.9994\n",
            "Epoch 266/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 9.3196e-05 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 0.9994\n",
            "Epoch 267/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 6.4396e-05 - accuracy: 1.0000 - val_loss: 0.0102 - val_accuracy: 0.9994\n",
            "Epoch 268/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 7.1636e-04 - accuracy: 0.9998 - val_loss: 0.0098 - val_accuracy: 0.9994\n",
            "Epoch 269/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 7.9776e-04 - accuracy: 0.9997 - val_loss: 5.9367e-07 - val_accuracy: 1.0000\n",
            "Epoch 270/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 3.1885e-04 - accuracy: 0.9998 - val_loss: 0.0041 - val_accuracy: 0.9994\n",
            "Epoch 271/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 5.0892e-05 - accuracy: 1.0000 - val_loss: 0.0066 - val_accuracy: 0.9994\n",
            "Epoch 272/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 3.5640e-05 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 0.9994\n",
            "Epoch 273/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 5.2270e-05 - accuracy: 1.0000 - val_loss: 0.0076 - val_accuracy: 0.9994\n",
            "Epoch 274/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 4.3599e-05 - accuracy: 1.0000 - val_loss: 0.0078 - val_accuracy: 0.9994\n",
            "Epoch 275/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 4.5248e-05 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 0.9994\n",
            "Epoch 276/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 5.2670e-05 - accuracy: 1.0000 - val_loss: 0.0055 - val_accuracy: 0.9994\n",
            "Epoch 277/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 3.9775e-04 - accuracy: 0.9998 - val_loss: 0.0014 - val_accuracy: 0.9994\n",
            "Epoch 278/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 2.6090e-05 - accuracy: 1.0000 - val_loss: 6.3765e-05 - val_accuracy: 1.0000\n",
            "Epoch 279/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.0390 - val_accuracy: 0.9988\n",
            "Epoch 280/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 6.1824e-05 - accuracy: 1.0000 - val_loss: 0.0216 - val_accuracy: 0.9994\n",
            "Epoch 281/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 6.5048e-05 - accuracy: 1.0000 - val_loss: 0.0168 - val_accuracy: 0.9994\n",
            "Epoch 282/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 4.7036e-05 - accuracy: 1.0000 - val_loss: 0.0153 - val_accuracy: 0.9994\n",
            "Epoch 283/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.0156 - val_accuracy: 0.9994\n",
            "Epoch 284/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 4.7056e-05 - accuracy: 1.0000 - val_loss: 0.0132 - val_accuracy: 0.9994\n",
            "Epoch 285/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 3.6678e-05 - accuracy: 1.0000 - val_loss: 0.0160 - val_accuracy: 0.9994\n",
            "Epoch 286/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 0.0155 - val_accuracy: 0.9994\n",
            "Epoch 287/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 2.9589e-05 - accuracy: 1.0000 - val_loss: 0.0200 - val_accuracy: 0.9994\n",
            "Epoch 288/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0259 - accuracy: 0.9989 - val_loss: 7.6221e-13 - val_accuracy: 1.0000\n",
            "Epoch 289/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0031 - accuracy: 0.9997 - val_loss: 5.4518e-23 - val_accuracy: 1.0000\n",
            "Epoch 290/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0054 - accuracy: 0.9995 - val_loss: 0.0636 - val_accuracy: 0.9988\n",
            "Epoch 291/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0135 - accuracy: 0.9989 - val_loss: 0.0274 - val_accuracy: 0.9994\n",
            "Epoch 292/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0019 - accuracy: 0.9998 - val_loss: 0.0352 - val_accuracy: 0.9994\n",
            "Epoch 293/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.6550e-04 - accuracy: 0.9998 - val_loss: 0.0295 - val_accuracy: 0.9994\n",
            "Epoch 294/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0016 - accuracy: 0.9997 - val_loss: 0.0273 - val_accuracy: 0.9994\n",
            "Epoch 295/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 3.9043e-05 - accuracy: 1.0000 - val_loss: 0.0273 - val_accuracy: 0.9994\n",
            "Epoch 296/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 5.3167e-05 - accuracy: 1.0000 - val_loss: 0.0271 - val_accuracy: 0.9994\n",
            "Epoch 297/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 4.6203e-05 - accuracy: 1.0000 - val_loss: 0.0273 - val_accuracy: 0.9994\n",
            "Epoch 298/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0054 - accuracy: 0.9991 - val_loss: 0.0337 - val_accuracy: 0.9994\n",
            "Epoch 299/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 1.8221e-05 - accuracy: 1.0000 - val_loss: 0.0405 - val_accuracy: 0.9994\n",
            "Epoch 300/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 1.1739e-05 - accuracy: 1.0000 - val_loss: 0.0412 - val_accuracy: 0.9994\n",
            "Epoch 301/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 9.9058e-06 - accuracy: 1.0000 - val_loss: 0.0422 - val_accuracy: 0.9994\n",
            "Epoch 302/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.0283 - val_accuracy: 0.9994\n",
            "Epoch 303/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 2.2099e-05 - accuracy: 1.0000 - val_loss: 0.0136 - val_accuracy: 0.9994\n",
            "Epoch 304/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 6.6980e-04 - accuracy: 0.9998 - val_loss: 0.0109 - val_accuracy: 0.9994\n",
            "Epoch 305/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 1.1551e-05 - accuracy: 1.0000 - val_loss: 0.0107 - val_accuracy: 0.9994\n",
            "Epoch 306/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.0147 - val_accuracy: 0.9994\n",
            "Epoch 307/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 8.0837e-06 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 0.9994\n",
            "Epoch 308/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0170 - accuracy: 0.9995 - val_loss: 2.3337e-06 - val_accuracy: 1.0000\n",
            "Epoch 309/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 6.4301e-04 - accuracy: 0.9998 - val_loss: 6.2300e-10 - val_accuracy: 1.0000\n",
            "Epoch 310/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.1900e-05 - accuracy: 1.0000 - val_loss: 1.0562e-08 - val_accuracy: 1.0000\n",
            "Epoch 311/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 1.0362e-05 - accuracy: 1.0000 - val_loss: 3.3628e-06 - val_accuracy: 1.0000\n",
            "Epoch 312/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.0089 - val_accuracy: 0.9994\n",
            "Epoch 313/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 1.0550e-05 - accuracy: 1.0000 - val_loss: 0.0094 - val_accuracy: 0.9994\n",
            "Epoch 314/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 1.7318e-05 - accuracy: 1.0000 - val_loss: 0.0109 - val_accuracy: 0.9994\n",
            "Epoch 315/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 5.0828e-06 - accuracy: 1.0000 - val_loss: 0.0096 - val_accuracy: 0.9994\n",
            "Epoch 316/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0250 - accuracy: 0.9992 - val_loss: 0.1256 - val_accuracy: 0.9988\n",
            "Epoch 317/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.1751 - accuracy: 0.9991 - val_loss: 0.0525 - val_accuracy: 0.9994\n",
            "Epoch 318/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0565 - accuracy: 0.9994 - val_loss: 0.1014 - val_accuracy: 0.9994\n",
            "Epoch 319/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0113 - accuracy: 0.9994 - val_loss: 0.1323 - val_accuracy: 0.9994\n",
            "Epoch 320/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0024 - accuracy: 0.9998 - val_loss: 0.1113 - val_accuracy: 0.9994\n",
            "Epoch 321/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0111 - accuracy: 0.9995 - val_loss: 0.1139 - val_accuracy: 0.9994\n",
            "Epoch 322/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0136 - accuracy: 0.9997 - val_loss: 0.0803 - val_accuracy: 0.9994\n",
            "Epoch 323/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0040 - accuracy: 0.9997 - val_loss: 0.0869 - val_accuracy: 0.9994\n",
            "Epoch 324/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.8704e-05 - accuracy: 1.0000 - val_loss: 0.0877 - val_accuracy: 0.9994\n",
            "Epoch 325/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 1.3656e-05 - accuracy: 1.0000 - val_loss: 0.0880 - val_accuracy: 0.9994\n",
            "Epoch 326/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0050 - accuracy: 0.9997 - val_loss: 0.0401 - val_accuracy: 0.9994\n",
            "Epoch 327/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 5.9614e-06 - accuracy: 1.0000 - val_loss: 0.0438 - val_accuracy: 0.9994\n",
            "Epoch 328/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0026 - accuracy: 0.9998 - val_loss: 0.0448 - val_accuracy: 0.9994\n",
            "Epoch 329/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0017 - accuracy: 0.9998 - val_loss: 0.1164 - val_accuracy: 0.9994\n",
            "Epoch 330/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 7.5934e-06 - accuracy: 1.0000 - val_loss: 0.1003 - val_accuracy: 0.9994\n",
            "Epoch 331/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 3.8053e-06 - accuracy: 1.0000 - val_loss: 0.0972 - val_accuracy: 0.9994\n",
            "Epoch 332/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 5.6860e-06 - accuracy: 1.0000 - val_loss: 0.0976 - val_accuracy: 0.9994\n",
            "Epoch 333/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 7.5718e-06 - accuracy: 1.0000 - val_loss: 0.0971 - val_accuracy: 0.9994\n",
            "Epoch 334/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0021 - accuracy: 0.9997 - val_loss: 0.0149 - val_accuracy: 0.9994\n",
            "Epoch 335/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 9.5601e-06 - accuracy: 1.0000 - val_loss: 0.0414 - val_accuracy: 0.9994\n",
            "Epoch 336/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 6.3250e-06 - accuracy: 1.0000 - val_loss: 0.0439 - val_accuracy: 0.9994\n",
            "Epoch 337/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 1.9959e-06 - accuracy: 1.0000 - val_loss: 0.0427 - val_accuracy: 0.9994\n",
            "Epoch 338/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0157 - accuracy: 0.9997 - val_loss: 3.2622e-34 - val_accuracy: 1.0000\n",
            "Epoch 339/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 5.1775e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 340/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 6.5935e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 341/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 5.6482e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 342/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 5.6501e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 343/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 5.6418e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 344/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 5.6328e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 345/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0243 - accuracy: 0.9998 - val_loss: 0.9877 - val_accuracy: 0.9891\n",
            "Epoch 346/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 3.0433e-04 - accuracy: 0.9998 - val_loss: 1.8616e-34 - val_accuracy: 1.0000\n",
            "Epoch 347/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0051 - accuracy: 0.9998 - val_loss: 0.0203 - val_accuracy: 0.9994\n",
            "Epoch 348/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 349/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0373 - accuracy: 0.9997 - val_loss: 1.6544e-08 - val_accuracy: 1.0000\n",
            "Epoch 350/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 1.6890e-07 - accuracy: 1.0000 - val_loss: 1.1902e-34 - val_accuracy: 1.0000\n",
            "Epoch 351/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 4.8356e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 352/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 3.9193e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 353/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.2395e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 354/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 2.4567e-16 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 355/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0091 - accuracy: 0.9997 - val_loss: 1.2009e-30 - val_accuracy: 1.0000\n",
            "Epoch 356/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0081 - accuracy: 0.9998 - val_loss: 3.0243e-31 - val_accuracy: 1.0000\n",
            "Epoch 357/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 2.5134e-06 - accuracy: 1.0000 - val_loss: 1.9399e-32 - val_accuracy: 1.0000\n",
            "Epoch 358/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 5.7468e-09 - accuracy: 1.0000 - val_loss: 1.9114e-32 - val_accuracy: 1.0000\n",
            "Epoch 359/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 4.7915e-06 - accuracy: 1.0000 - val_loss: 3.2300e-32 - val_accuracy: 1.0000\n",
            "Epoch 360/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.8306e-06 - accuracy: 1.0000 - val_loss: 1.1059e-32 - val_accuracy: 1.0000\n",
            "Epoch 361/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 2.3832e-08 - accuracy: 1.0000 - val_loss: 3.7841e-32 - val_accuracy: 1.0000\n",
            "Epoch 362/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0180 - accuracy: 0.9995 - val_loss: 0.0158 - val_accuracy: 0.9994\n",
            "Epoch 363/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0016 - accuracy: 0.9997 - val_loss: 0.0216 - val_accuracy: 0.9988\n",
            "Epoch 364/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 3.1011e-04 - accuracy: 0.9998 - val_loss: 0.0046 - val_accuracy: 0.9994\n",
            "Epoch 365/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 1.0953e-06 - accuracy: 1.0000 - val_loss: 1.1936e-04 - val_accuracy: 1.0000\n",
            "Epoch 366/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 2.5253e-06 - accuracy: 1.0000 - val_loss: 4.9414e-07 - val_accuracy: 1.0000\n",
            "Epoch 367/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.1266e-07 - accuracy: 1.0000 - val_loss: 4.4971e-07 - val_accuracy: 1.0000\n",
            "Epoch 368/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.5392e-07 - accuracy: 1.0000 - val_loss: 3.4406e-07 - val_accuracy: 1.0000\n",
            "Epoch 369/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 2.5308e-06 - accuracy: 1.0000 - val_loss: 1.6698e-07 - val_accuracy: 1.0000\n",
            "Epoch 370/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 2.0426e-06 - accuracy: 1.0000 - val_loss: 2.7571e-07 - val_accuracy: 1.0000\n",
            "Epoch 371/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 3.1974e-04 - accuracy: 0.9998 - val_loss: 1.4547e-10 - val_accuracy: 1.0000\n",
            "Epoch 372/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0019 - accuracy: 0.9998 - val_loss: 1.7393e-16 - val_accuracy: 1.0000\n",
            "Epoch 373/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 3.7022e-06 - accuracy: 1.0000 - val_loss: 9.6378e-18 - val_accuracy: 1.0000\n",
            "Epoch 374/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.9135e-06 - accuracy: 1.0000 - val_loss: 8.0908e-18 - val_accuracy: 1.0000\n",
            "Epoch 375/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 2.0375e-06 - accuracy: 1.0000 - val_loss: 7.3598e-18 - val_accuracy: 1.0000\n",
            "Epoch 376/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 6.7201e-06 - accuracy: 1.0000 - val_loss: 4.5282e-19 - val_accuracy: 1.0000\n",
            "Epoch 377/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0040 - accuracy: 0.9998 - val_loss: 0.0317 - val_accuracy: 0.9994\n",
            "Epoch 378/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1033 - accuracy: 0.9989 - val_loss: 0.0023 - val_accuracy: 0.9994\n",
            "Epoch 379/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.7382e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 380/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0152 - accuracy: 0.9997 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 381/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0036 - accuracy: 0.9998 - val_loss: 2.2895e-12 - val_accuracy: 1.0000\n",
            "Epoch 382/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0105 - accuracy: 0.9995 - val_loss: 0.1089 - val_accuracy: 0.9988\n",
            "Epoch 383/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 6.4795e-06 - accuracy: 1.0000 - val_loss: 0.0911 - val_accuracy: 0.9994\n",
            "Epoch 384/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 1.0025e-13 - accuracy: 1.0000 - val_loss: 0.0897 - val_accuracy: 0.9994\n",
            "Epoch 385/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 4.1637e-14 - accuracy: 1.0000 - val_loss: 0.0892 - val_accuracy: 0.9994\n",
            "Epoch 386/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 2.7936e-06 - accuracy: 1.0000 - val_loss: 0.0877 - val_accuracy: 0.9994\n",
            "Epoch 387/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 1.8737e-06 - accuracy: 1.0000 - val_loss: 0.0884 - val_accuracy: 0.9994\n",
            "Epoch 388/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0366 - accuracy: 0.9997 - val_loss: 0.0901 - val_accuracy: 0.9994\n",
            "Epoch 389/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0269 - accuracy: 0.9995 - val_loss: 0.0633 - val_accuracy: 0.9994\n",
            "Epoch 390/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 4.7489e-07 - accuracy: 1.0000 - val_loss: 0.0636 - val_accuracy: 0.9994\n",
            "Epoch 391/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.2238e-15 - accuracy: 1.0000 - val_loss: 0.0631 - val_accuracy: 0.9994\n",
            "Epoch 392/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0020 - accuracy: 0.9997 - val_loss: 0.1286 - val_accuracy: 0.9994\n",
            "Epoch 393/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0069 - accuracy: 0.9998 - val_loss: 0.0166 - val_accuracy: 0.9994\n",
            "Epoch 394/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 6.0094e-06 - accuracy: 1.0000 - val_loss: 0.0334 - val_accuracy: 0.9994\n",
            "Epoch 395/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0049 - accuracy: 0.9997 - val_loss: 0.1688 - val_accuracy: 0.9994\n",
            "Epoch 396/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.8090e-09 - accuracy: 1.0000 - val_loss: 0.1426 - val_accuracy: 0.9994\n",
            "Epoch 397/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.7074e-06 - accuracy: 1.0000 - val_loss: 0.1369 - val_accuracy: 0.9994\n",
            "Epoch 398/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0010 - accuracy: 0.9998 - val_loss: 0.0770 - val_accuracy: 0.9994\n",
            "Epoch 399/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0052 - accuracy: 0.9998 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 400/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 2.1066e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 401/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 2.6730e-13 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 402/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 2.3797e-14 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 403/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0052 - accuracy: 0.9998 - val_loss: 4.9558e-37 - val_accuracy: 1.0000\n",
            "Epoch 404/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0090 - accuracy: 0.9998 - val_loss: 8.0611e-21 - val_accuracy: 1.0000\n",
            "Epoch 405/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 3.4328e-04 - accuracy: 0.9998 - val_loss: 0.0377 - val_accuracy: 0.9994\n",
            "Epoch 406/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.6728e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 407/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0128 - accuracy: 0.9998 - val_loss: 15.8832 - val_accuracy: 0.9466\n",
            "Epoch 408/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0065 - accuracy: 0.9998 - val_loss: 0.0469 - val_accuracy: 0.9994\n",
            "Epoch 409/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0032 - accuracy: 0.9998 - val_loss: 0.0725 - val_accuracy: 0.9994\n",
            "Epoch 410/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.6472e-06 - accuracy: 1.0000 - val_loss: 0.0937 - val_accuracy: 0.9994\n",
            "Epoch 411/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0030 - accuracy: 0.9998 - val_loss: 0.2730 - val_accuracy: 0.9976\n",
            "Epoch 412/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 8.1354e-17 - accuracy: 1.0000 - val_loss: 0.1692 - val_accuracy: 0.9988\n",
            "Epoch 413/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0028 - accuracy: 0.9997 - val_loss: 0.1387 - val_accuracy: 0.9994\n",
            "Epoch 414/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 2.5231e-22 - accuracy: 1.0000 - val_loss: 0.3159 - val_accuracy: 0.9988\n",
            "Epoch 415/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0337 - accuracy: 0.9997 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 416/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0482 - accuracy: 0.9995 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 417/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 8.6308e-29 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 418/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.7650e-18 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 419/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.5148e-17 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 420/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.3111e-22 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 421/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 2.4368e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 422/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0058 - accuracy: 0.9998 - val_loss: 1.1803e-09 - val_accuracy: 1.0000\n",
            "Epoch 423/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 2.2167e-07 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 0.9994\n",
            "Epoch 424/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 4.1291e-11 - accuracy: 1.0000 - val_loss: 8.4585e-04 - val_accuracy: 0.9994\n",
            "Epoch 425/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.3678e-32 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 0.9994\n",
            "Epoch 426/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.5675e-06 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 0.9994\n",
            "Epoch 427/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.9869e-20 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9994\n",
            "Epoch 428/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 5.6134e-27 - accuracy: 1.0000 - val_loss: 2.8998e-06 - val_accuracy: 1.0000\n",
            "Epoch 429/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 2.0084e-17 - accuracy: 1.0000 - val_loss: 7.2848e-06 - val_accuracy: 1.0000\n",
            "Epoch 430/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 2.9995e-18 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 0.9994\n",
            "Epoch 431/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0020 - accuracy: 0.9998 - val_loss: 4.5269e-28 - val_accuracy: 1.0000\n",
            "Epoch 432/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 2.9593e-09 - accuracy: 1.0000 - val_loss: 2.3304e-08 - val_accuracy: 1.0000\n",
            "Epoch 433/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1983 - accuracy: 0.9989 - val_loss: 0.0430 - val_accuracy: 0.9994\n",
            "Epoch 434/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1357 - accuracy: 0.9998 - val_loss: 3.3770e-23 - val_accuracy: 1.0000\n",
            "Epoch 435/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0035 - accuracy: 0.9995 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 436/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0233 - accuracy: 0.9995 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 437/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0095 - accuracy: 0.9995 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 438/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 2.0503e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 439/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.0420e-08 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 440/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0065 - accuracy: 0.9997 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 441/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0089 - accuracy: 0.9998 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 442/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.6615e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 443/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0069 - accuracy: 0.9998 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 444/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0105 - accuracy: 0.9997 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 445/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 6.4072e-08 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 446/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.6386e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 447/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 2.4129e-04 - accuracy: 0.9998 - val_loss: 0.1172 - val_accuracy: 0.9982\n",
            "Epoch 448/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 4.1657e-08 - accuracy: 1.0000 - val_loss: 1.3156e-07 - val_accuracy: 1.0000\n",
            "Epoch 449/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 7.7953e-15 - accuracy: 1.0000 - val_loss: 3.7104e-17 - val_accuracy: 1.0000\n",
            "Epoch 450/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 2.3132e-09 - accuracy: 1.0000 - val_loss: 1.9162e-17 - val_accuracy: 1.0000\n",
            "Epoch 451/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.4234e-06 - accuracy: 1.0000 - val_loss: 5.6487e-19 - val_accuracy: 1.0000\n",
            "Epoch 452/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0338 - accuracy: 0.9997 - val_loss: 4.8076e-10 - val_accuracy: 1.0000\n",
            "Epoch 453/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 2.4231e-20 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 454/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 7.1794e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 455/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.4537e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 456/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0042 - accuracy: 0.9998 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 457/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0032 - accuracy: 0.9998 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 458/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 2.5805e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 459/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0016 - accuracy: 0.9998 - val_loss: 1.5415e-27 - val_accuracy: 1.0000\n",
            "Epoch 460/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 9.3194e-22 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 461/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.3808e-30 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 462/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0299 - accuracy: 0.9995 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 463/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0371 - accuracy: 0.9995 - val_loss: 0.1012 - val_accuracy: 0.9988\n",
            "Epoch 464/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0130 - accuracy: 0.9998 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 465/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.7705e-10 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 466/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 7.1133e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 467/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 5.9445e-16 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 468/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0439 - accuracy: 0.9998 - val_loss: 2.3796e-38 - val_accuracy: 1.0000\n",
            "Epoch 469/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 5.9440e-04 - accuracy: 0.9998 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 470/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.3286e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 471/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 4.6065e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 472/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0039 - accuracy: 0.9998 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 473/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.3524e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 474/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.0256e-10 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 475/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0021 - accuracy: 0.9997 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 476/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 4.0741e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 477/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.3667e-15 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 478/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 4.6826e-08 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 479/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 3.8940e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 480/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 2.4452e-08 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 481/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.3211e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 482/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 3.3402e-16 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 483/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 5.0258e-08 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 484/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 3.3586e-08 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 485/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 3.4893e-13 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 486/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 6.8231e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 487/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.3023e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 488/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 2.1112e-12 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 489/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 8.7777e-15 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 490/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 5.0485e-13 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 491/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.1966e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 492/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 6.0179e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 493/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 3.6751e-16 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 494/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 9.4471e-33 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 495/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 2.5078e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 496/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 3.6513e-29 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 497/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 3.4622e-20 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 498/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 3.0103e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 499/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.4344e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 500/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 7.2806e-04 - accuracy: 0.9998 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 501/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.3032e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 502/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0076 - accuracy: 0.9997 - val_loss: 0.0652 - val_accuracy: 0.9994\n",
            "Epoch 503/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 2.0458e-10 - accuracy: 1.0000 - val_loss: 0.0996 - val_accuracy: 0.9994\n",
            "Epoch 504/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.2942e-09 - accuracy: 1.0000 - val_loss: 0.1022 - val_accuracy: 0.9994\n",
            "Epoch 505/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0093 - accuracy: 0.9998 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 506/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 3.2613e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 507/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0010 - accuracy: 0.9998 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 508/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0382 - accuracy: 0.9995 - val_loss: 0.0561 - val_accuracy: 0.9988\n",
            "Epoch 509/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0234 - accuracy: 0.9992 - val_loss: 0.0661 - val_accuracy: 0.9994\n",
            "Epoch 510/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 6.9620e-08 - accuracy: 1.0000 - val_loss: 1.7764e-04 - val_accuracy: 1.0000\n",
            "Epoch 511/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0195 - accuracy: 0.9997 - val_loss: 4.0325e-32 - val_accuracy: 1.0000\n",
            "Epoch 512/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0375 - accuracy: 0.9995 - val_loss: 0.6527 - val_accuracy: 0.9988\n",
            "Epoch 513/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0696 - accuracy: 0.9995 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 514/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 2.5445e-04 - accuracy: 0.9998 - val_loss: 3.9971e-27 - val_accuracy: 1.0000\n",
            "Epoch 515/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 3.4639e-05 - accuracy: 1.0000 - val_loss: 5.4146e-27 - val_accuracy: 1.0000\n",
            "Epoch 516/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0065 - accuracy: 0.9998 - val_loss: 0.0474 - val_accuracy: 0.9994\n",
            "Epoch 517/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 2.6616e-06 - accuracy: 1.0000 - val_loss: 0.0418 - val_accuracy: 0.9994\n",
            "Epoch 518/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.3159e-05 - accuracy: 1.0000 - val_loss: 0.0218 - val_accuracy: 0.9994\n",
            "Epoch 519/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 2.6054e-06 - accuracy: 1.0000 - val_loss: 0.0220 - val_accuracy: 0.9994\n",
            "Epoch 520/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0038 - accuracy: 0.9998 - val_loss: 1.1318e-34 - val_accuracy: 1.0000\n",
            "Epoch 521/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.2512e-06 - accuracy: 1.0000 - val_loss: 1.5866e-32 - val_accuracy: 1.0000\n",
            "Epoch 522/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.2574e-06 - accuracy: 1.0000 - val_loss: 5.8175e-32 - val_accuracy: 1.0000\n",
            "Epoch 523/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 7.1360e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 524/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 3.7718e-12 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 525/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.2405e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 526/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 9.2476e-05 - accuracy: 1.0000 - val_loss: 1.2360e-33 - val_accuracy: 1.0000\n",
            "Epoch 527/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.6787e-11 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 528/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.9973e-18 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 529/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 2.2093e-14 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 530/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.3838e-18 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 531/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 2.1331e-13 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 532/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0015 - accuracy: 0.9998 - val_loss: 8.0832e-31 - val_accuracy: 1.0000\n",
            "Epoch 533/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 4.0224e-06 - accuracy: 1.0000 - val_loss: 2.9122e-29 - val_accuracy: 1.0000\n",
            "Epoch 534/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 3.7834e-06 - accuracy: 1.0000 - val_loss: 9.3336e-29 - val_accuracy: 1.0000\n",
            "Epoch 535/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0025 - accuracy: 0.9998 - val_loss: 1.8273e-06 - val_accuracy: 1.0000\n",
            "Epoch 536/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.2254e-06 - accuracy: 1.0000 - val_loss: 4.7865e-14 - val_accuracy: 1.0000\n",
            "Epoch 537/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 6.9229e-04 - accuracy: 0.9998 - val_loss: 0.1169 - val_accuracy: 0.9994\n",
            "Epoch 538/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0071 - accuracy: 0.9997 - val_loss: 0.0380 - val_accuracy: 0.9988\n",
            "Epoch 539/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.2494e-06 - accuracy: 1.0000 - val_loss: 6.0916e-07 - val_accuracy: 1.0000\n",
            "Epoch 540/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0022 - accuracy: 0.9998 - val_loss: 4.4489e-17 - val_accuracy: 1.0000\n",
            "Epoch 541/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 2.7265e-06 - accuracy: 1.0000 - val_loss: 3.3838e-20 - val_accuracy: 1.0000\n",
            "Epoch 542/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 5.0852e-06 - accuracy: 1.0000 - val_loss: 3.3022e-20 - val_accuracy: 1.0000\n",
            "Epoch 543/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 2.5386e-06 - accuracy: 1.0000 - val_loss: 1.6996e-20 - val_accuracy: 1.0000\n",
            "Epoch 544/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 8.2781e-06 - accuracy: 1.0000 - val_loss: 9.9385e-19 - val_accuracy: 1.0000\n",
            "Epoch 545/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 2.6502e-11 - val_accuracy: 1.0000\n",
            "Epoch 546/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0048 - accuracy: 0.9997 - val_loss: 1.2051e-32 - val_accuracy: 1.0000\n",
            "Epoch 547/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0146 - accuracy: 0.9997 - val_loss: 0.2561 - val_accuracy: 0.9988\n",
            "Epoch 548/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0017 - accuracy: 0.9998 - val_loss: 0.0488 - val_accuracy: 0.9994\n",
            "Epoch 549/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 9.6034e-04 - accuracy: 0.9998 - val_loss: 0.0358 - val_accuracy: 0.9994\n",
            "Epoch 550/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 2.7333e-07 - accuracy: 1.0000 - val_loss: 0.0403 - val_accuracy: 0.9994\n",
            "Epoch 551/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 8.2192e-16 - accuracy: 1.0000 - val_loss: 0.0424 - val_accuracy: 0.9994\n",
            "Epoch 552/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 2.4851e-08 - accuracy: 1.0000 - val_loss: 0.0426 - val_accuracy: 0.9994\n",
            "Epoch 553/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0441 - accuracy: 0.9997 - val_loss: 8.4054e-32 - val_accuracy: 1.0000\n",
            "Epoch 554/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.2682e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 555/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 3.0837e-04 - accuracy: 0.9998 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 556/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 8.4605e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 557/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.2614e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 558/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 5.3832e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 559/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.2489e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 560/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.2494e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 561/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 1.5346e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 562/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.0074e-12 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 563/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 2.7054e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 564/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 8.3197e-16 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 565/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.3602e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 566/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 2.4937e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 567/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.9214e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 568/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.7309e-08 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 569/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 6.5434e-11 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 570/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 6.3033e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 571/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.2451e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 572/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 8.5993e-16 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 573/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.2443e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 574/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 9.0358e-12 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 575/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.2433e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 576/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 2.8527e-10 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 577/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.2419e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 578/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.0505e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 579/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.8088e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 580/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 4.8235e-10 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 581/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 2.1031e-14 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 582/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 9.1113e-10 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 583/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 5.5579e-11 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 584/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.2385e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 585/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.2425e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 586/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0135 - accuracy: 0.9995 - val_loss: 0.0403 - val_accuracy: 0.9988\n",
            "Epoch 587/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.2352e-06 - accuracy: 1.0000 - val_loss: 5.4985e-04 - val_accuracy: 0.9994\n",
            "Epoch 588/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 3.2075e-10 - accuracy: 1.0000 - val_loss: 6.1347e-08 - val_accuracy: 1.0000\n",
            "Epoch 589/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0260 - accuracy: 0.9997 - val_loss: 0.0691 - val_accuracy: 0.9994\n",
            "Epoch 590/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0060 - accuracy: 0.9998 - val_loss: 1.9372e-05 - val_accuracy: 1.0000\n",
            "Epoch 591/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.5797e-13 - accuracy: 1.0000 - val_loss: 7.7347e-13 - val_accuracy: 1.0000\n",
            "Epoch 592/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 6.8460e-23 - accuracy: 1.0000 - val_loss: 5.6936e-14 - val_accuracy: 1.0000\n",
            "Epoch 593/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.2176e-06 - accuracy: 1.0000 - val_loss: 5.2983e-14 - val_accuracy: 1.0000\n",
            "Epoch 594/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 2.1545e-17 - accuracy: 1.0000 - val_loss: 4.6714e-14 - val_accuracy: 1.0000\n",
            "Epoch 595/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 2.5005e-23 - accuracy: 1.0000 - val_loss: 7.5498e-14 - val_accuracy: 1.0000\n",
            "Epoch 596/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 3.5770e-09 - accuracy: 1.0000 - val_loss: 3.4955e-14 - val_accuracy: 1.0000\n",
            "Epoch 597/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0032 - accuracy: 0.9998 - val_loss: 0.1098 - val_accuracy: 0.9988\n",
            "Epoch 598/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.2156e-06 - accuracy: 1.0000 - val_loss: 0.0746 - val_accuracy: 0.9988\n",
            "Epoch 599/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.7197e-04 - accuracy: 0.9998 - val_loss: 0.0848 - val_accuracy: 0.9988\n",
            "Epoch 600/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.2038e-06 - accuracy: 1.0000 - val_loss: 0.1240 - val_accuracy: 0.9988\n",
            "Epoch 601/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0415 - accuracy: 0.9995 - val_loss: 7.8969e-38 - val_accuracy: 1.0000\n",
            "Epoch 602/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 3.9869e-04 - accuracy: 0.9998 - val_loss: 1.4364e-08 - val_accuracy: 1.0000\n",
            "Epoch 603/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 3.8704e-11 - accuracy: 1.0000 - val_loss: 0.0102 - val_accuracy: 0.9988\n",
            "Epoch 604/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0020 - accuracy: 0.9998 - val_loss: 1.9434e-13 - val_accuracy: 1.0000\n",
            "Epoch 605/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.6690e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 606/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0043 - accuracy: 0.9998 - val_loss: 4.8693e-04 - val_accuracy: 0.9994\n",
            "Epoch 607/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0309 - accuracy: 0.9998 - val_loss: 0.1405 - val_accuracy: 0.9994\n",
            "Epoch 608/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0189 - accuracy: 0.9997 - val_loss: 0.1209 - val_accuracy: 0.9994\n",
            "Epoch 609/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0078 - accuracy: 0.9997 - val_loss: 0.1798 - val_accuracy: 0.9994\n",
            "Epoch 610/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 5.5653e-07 - accuracy: 1.0000 - val_loss: 0.1466 - val_accuracy: 0.9994\n",
            "Epoch 611/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.2615e-06 - accuracy: 1.0000 - val_loss: 0.1477 - val_accuracy: 0.9994\n",
            "Epoch 612/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0045 - accuracy: 0.9998 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 613/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.2806e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 614/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 3.1656e-04 - accuracy: 0.9998 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 615/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.3741e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 616/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 8.2213e-04 - accuracy: 0.9998 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 617/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 5.7774e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 618/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.3197e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 619/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.4249e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 620/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.3196e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 621/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 3.8507e-14 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 622/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.3189e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 623/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.5826e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 624/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 2.2884e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 625/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 4.8478e-11 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 626/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 2.6348e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 627/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 3.5591e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 628/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 7.2570e-16 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 629/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0067 - accuracy: 0.9997 - val_loss: 0.6422 - val_accuracy: 0.9964\n",
            "Epoch 630/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0074 - accuracy: 0.9997 - val_loss: 0.0272 - val_accuracy: 0.9994\n",
            "Epoch 631/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 6.3857e-09 - accuracy: 1.0000 - val_loss: 0.0375 - val_accuracy: 0.9994\n",
            "Epoch 632/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.2650e-06 - accuracy: 1.0000 - val_loss: 0.0390 - val_accuracy: 0.9994\n",
            "Epoch 633/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.4360e-07 - accuracy: 1.0000 - val_loss: 0.0400 - val_accuracy: 0.9994\n",
            "Epoch 634/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.2647e-06 - accuracy: 1.0000 - val_loss: 0.0409 - val_accuracy: 0.9994\n",
            "Epoch 635/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 3.5319e-07 - accuracy: 1.0000 - val_loss: 0.0402 - val_accuracy: 0.9994\n",
            "Epoch 636/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 2.3207e-08 - accuracy: 1.0000 - val_loss: 0.0370 - val_accuracy: 0.9994\n",
            "Epoch 637/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 2.5285e-06 - accuracy: 1.0000 - val_loss: 0.0398 - val_accuracy: 0.9994\n",
            "Epoch 638/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0054 - accuracy: 0.9998 - val_loss: 0.0643 - val_accuracy: 0.9994\n",
            "Epoch 639/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 3.8700e-06 - accuracy: 1.0000 - val_loss: 0.0602 - val_accuracy: 0.9994\n",
            "Epoch 640/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.5949e-06 - accuracy: 1.0000 - val_loss: 0.0607 - val_accuracy: 0.9994\n",
            "Epoch 641/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0182 - accuracy: 0.9998 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 642/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0045 - accuracy: 0.9997 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 643/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 7.3841e-04 - accuracy: 0.9998 - val_loss: 0.0323 - val_accuracy: 0.9994\n",
            "Epoch 644/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0084 - accuracy: 0.9998 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 645/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0068 - accuracy: 0.9998 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 646/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 647/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0022 - accuracy: 0.9998 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 648/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 2.3898e-10 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 649/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.2320e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 650/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 9.8921e-04 - accuracy: 0.9998 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 651/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.8880e-12 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 652/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 3.6712e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 653/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.2115e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 654/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 655/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.3278e-11 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 656/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 657/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.2912e-21 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 658/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 2.1205e-36 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 659/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.2133e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 660/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 4.7227e-25 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 661/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.1873e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 662/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0041 - accuracy: 0.9998 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 663/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.2592e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 664/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 2.3499e-04 - accuracy: 0.9998 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 665/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.0550e-12 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 666/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0030 - accuracy: 0.9998 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 667/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 3.5042e-18 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 668/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 5.0807e-20 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 669/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0089 - accuracy: 0.9998 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 670/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.1863e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 671/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 3.4827e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 672/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 5.4200e-04 - accuracy: 0.9998 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 673/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 2.3226e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 674/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.6497e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 675/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 2.6670e-19 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 676/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 677/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.1443 - val_accuracy: 0.9988\n",
            "Epoch 678/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0047 - accuracy: 0.9997 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 679/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0152 - accuracy: 0.9998 - val_loss: 1.3864e-07 - val_accuracy: 1.0000\n",
            "Epoch 680/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 681/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0031 - accuracy: 0.9998 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 682/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.0287e-30 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 683/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 9.9921e-26 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 684/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 685/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 2.0563e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 686/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 2.0781e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 687/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 9.4559e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 688/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.9475e-10 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 689/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 690/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 2.7547e-20 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 691/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 7.4536e-04 - accuracy: 0.9998 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 692/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0037 - accuracy: 0.9998 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 693/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0048 - accuracy: 0.9998 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 694/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.0790e-10 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 695/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0124 - accuracy: 0.9997 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 696/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.9917e-12 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 697/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0251 - accuracy: 0.9998 - val_loss: 0.2790 - val_accuracy: 0.9988\n",
            "Epoch 698/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0226 - accuracy: 0.9995 - val_loss: 0.0651 - val_accuracy: 0.9994\n",
            "Epoch 699/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 9.8213e-29 - accuracy: 1.0000 - val_loss: 0.0172 - val_accuracy: 0.9994\n",
            "Epoch 700/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.1591e-06 - accuracy: 1.0000 - val_loss: 0.0115 - val_accuracy: 0.9994\n",
            "Epoch 701/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.3605e-05 - accuracy: 1.0000 - val_loss: 0.0180 - val_accuracy: 0.9994\n",
            "Epoch 702/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 2.3193e-06 - accuracy: 1.0000 - val_loss: 0.0163 - val_accuracy: 0.9994\n",
            "Epoch 703/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 2.3508e-06 - accuracy: 1.0000 - val_loss: 0.0142 - val_accuracy: 0.9994\n",
            "Epoch 704/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 4.4776e-13 - accuracy: 1.0000 - val_loss: 0.0153 - val_accuracy: 0.9994\n",
            "Epoch 705/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 5.1294e-13 - accuracy: 1.0000 - val_loss: 0.0140 - val_accuracy: 0.9994\n",
            "Epoch 706/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0010 - accuracy: 0.9998 - val_loss: 0.0254 - val_accuracy: 0.9994\n",
            "Epoch 707/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 7.2891e-15 - accuracy: 1.0000 - val_loss: 0.0324 - val_accuracy: 0.9994\n",
            "Epoch 708/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 2.1437e-17 - accuracy: 1.0000 - val_loss: 0.0360 - val_accuracy: 0.9994\n",
            "Epoch 709/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.1348e-06 - accuracy: 1.0000 - val_loss: 0.0346 - val_accuracy: 0.9994\n",
            "Epoch 710/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 7.4351e-04 - accuracy: 0.9998 - val_loss: 0.0358 - val_accuracy: 0.9994\n",
            "Epoch 711/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0058 - accuracy: 0.9998 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 712/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0047 - accuracy: 0.9998 - val_loss: 1.0673e-19 - val_accuracy: 1.0000\n",
            "Epoch 713/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0016 - accuracy: 0.9998 - val_loss: 0.0922 - val_accuracy: 0.9994\n",
            "Epoch 714/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0110 - accuracy: 0.9998 - val_loss: 5.6858e-30 - val_accuracy: 1.0000\n",
            "Epoch 715/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0225 - accuracy: 0.9998 - val_loss: 5.0841e-37 - val_accuracy: 1.0000\n",
            "Epoch 716/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 2.7200e-06 - accuracy: 1.0000 - val_loss: 1.6071e-15 - val_accuracy: 1.0000\n",
            "Epoch 717/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 8.9147e-26 - accuracy: 1.0000 - val_loss: 4.5513e-13 - val_accuracy: 1.0000\n",
            "Epoch 718/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 4.7776e-15 - accuracy: 1.0000 - val_loss: 2.5756e-12 - val_accuracy: 1.0000\n",
            "Epoch 719/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 2.3125e-29 - accuracy: 1.0000 - val_loss: 7.6272e-13 - val_accuracy: 1.0000\n",
            "Epoch 720/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.7790e-18 - accuracy: 1.0000 - val_loss: 4.2585e-11 - val_accuracy: 1.0000\n",
            "Epoch 721/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 2.0187e-07 - accuracy: 1.0000 - val_loss: 4.3769e-11 - val_accuracy: 1.0000\n",
            "Epoch 722/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.1693e-13 - accuracy: 1.0000 - val_loss: 3.8037e-12 - val_accuracy: 1.0000\n",
            "Epoch 723/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.1465e-06 - accuracy: 1.0000 - val_loss: 7.8014e-14 - val_accuracy: 1.0000\n",
            "Epoch 724/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.1751e-09 - accuracy: 1.0000 - val_loss: 2.0960e-13 - val_accuracy: 1.0000\n",
            "Epoch 725/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 2.6086e-25 - accuracy: 1.0000 - val_loss: 1.7660e-13 - val_accuracy: 1.0000\n",
            "Epoch 726/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 8.3467e-11 - accuracy: 1.0000 - val_loss: 2.1911e-13 - val_accuracy: 1.0000\n",
            "Epoch 727/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 2.0480e-17 - accuracy: 1.0000 - val_loss: 7.6294e-13 - val_accuracy: 1.0000\n",
            "Epoch 728/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 3.0150e-18 - accuracy: 1.0000 - val_loss: 4.0808e-12 - val_accuracy: 1.0000\n",
            "Epoch 729/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 3.2008e-19 - accuracy: 1.0000 - val_loss: 2.7763e-11 - val_accuracy: 1.0000\n",
            "Epoch 730/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.0344e-11 - accuracy: 1.0000 - val_loss: 3.3533e-13 - val_accuracy: 1.0000\n",
            "Epoch 731/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.9377e-13 - val_accuracy: 1.0000\n",
            "Epoch 732/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.1987e-21 - accuracy: 1.0000 - val_loss: 1.3772e-12 - val_accuracy: 1.0000\n",
            "Epoch 733/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 7.4197e-04 - accuracy: 0.9998 - val_loss: 4.0427e-10 - val_accuracy: 1.0000\n",
            "Epoch 734/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 7.6165e-19 - accuracy: 1.0000 - val_loss: 7.2917e-13 - val_accuracy: 1.0000\n",
            "Epoch 735/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 7.3817e-29 - accuracy: 1.0000 - val_loss: 3.1626e-11 - val_accuracy: 1.0000\n",
            "Epoch 736/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0031 - accuracy: 0.9998 - val_loss: 0.5152 - val_accuracy: 0.9927\n",
            "Epoch 737/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 2.5301e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 738/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 9.3651e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 739/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0045 - accuracy: 0.9998 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 740/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.4726e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 741/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.2342e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 742/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.2339e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 743/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.2336e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 744/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 3.1906e-12 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 745/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 7.1236e-22 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 746/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.2332e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 747/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 9.3905e-17 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 748/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.1210e-31 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 749/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 2.9523e-13 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 750/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.2328e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 751/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.2722e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 752/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 753/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 2.4617e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 754/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 2.3820e-13 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 755/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 4.9124e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 756/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 2.5577e-11 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 757/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.2248e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 758/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.3944e-14 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 759/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 2.7061e-10 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 760/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 6.6464e-12 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 761/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 7.3210e-04 - accuracy: 0.9998 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 762/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0022 - accuracy: 0.9997 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 763/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0069 - accuracy: 0.9997 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 764/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.5755e-30 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 765/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0034 - accuracy: 0.9998 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 766/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.1726 - accuracy: 0.9997 - val_loss: 0.0538 - val_accuracy: 0.9994\n",
            "Epoch 767/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0117 - accuracy: 0.9997 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 768/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.1899e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 769/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.6490e-18 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 770/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 771/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 6.0014e-24 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 772/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0030 - accuracy: 0.9998 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 773/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0038 - accuracy: 0.9998 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 774/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 775/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 9.6756e-11 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 776/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.1890e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 777/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.1887e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 778/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 3.7272e-30 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 779/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.3496e-21 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 780/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 7.4342e-08 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 781/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0018 - accuracy: 0.9998 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 782/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0158 - accuracy: 0.9998 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 783/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 2.3666e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 784/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 2.0295e-10 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 785/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0027 - accuracy: 0.9998 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 786/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.5396e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 787/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 3.4594e-29 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 788/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.1588e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 789/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0030 - accuracy: 0.9997 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 790/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0564 - accuracy: 0.9994 - val_loss: 0.0569 - val_accuracy: 0.9994\n",
            "Epoch 791/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.1228e-06 - accuracy: 1.0000 - val_loss: 4.6469e-34 - val_accuracy: 1.0000\n",
            "Epoch 792/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0044 - accuracy: 0.9995 - val_loss: 0.0550 - val_accuracy: 0.9994\n",
            "Epoch 793/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.1648e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 794/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0220 - accuracy: 0.9998 - val_loss: 0.4055 - val_accuracy: 0.9988\n",
            "Epoch 795/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 7.1557e-26 - accuracy: 1.0000 - val_loss: 0.0965 - val_accuracy: 0.9988\n",
            "Epoch 796/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0041 - accuracy: 0.9998 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 797/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0039 - accuracy: 0.9997 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 798/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 2.1143e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 799/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 4.5385e-14 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 800/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 3.8833e-04 - accuracy: 0.9998 - val_loss: 0.1011 - val_accuracy: 0.9988\n",
            "Epoch 801/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 3.9191e-17 - accuracy: 1.0000 - val_loss: 0.0075 - val_accuracy: 0.9994\n",
            "Epoch 802/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 3.8726e-07 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 0.9994\n",
            "Epoch 803/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0227 - accuracy: 0.9998 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 804/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0018 - accuracy: 0.9998 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 805/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 5.0808e-04 - accuracy: 0.9998 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 806/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 2.2228e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 807/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.1112e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 808/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 2.2218e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 809/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.1107e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 810/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.1105e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 811/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 6.4499e-20 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 812/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0053 - accuracy: 0.9997 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 813/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 6.6772e-26 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 814/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.2814e-21 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 815/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.0878e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 816/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 6.0678e-08 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 817/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 3.0849e-25 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 818/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 2.8097e-16 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 819/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 2.1276e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 820/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0020 - accuracy: 0.9998 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 821/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 7.3286e-04 - accuracy: 0.9998 - val_loss: 1.6023e-36 - val_accuracy: 1.0000\n",
            "Epoch 822/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0114 - accuracy: 0.9997 - val_loss: 0.0088 - val_accuracy: 0.9994\n",
            "Epoch 823/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 7.0785e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 824/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 1.1635e-10 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 825/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 826/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 827/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.4825e-30 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 828/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.0695e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 829/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 3.7721e-13 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 830/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 1.0693e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 831/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 2.1954e-10 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 832/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.6752e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 833/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 6.8405e-04 - accuracy: 0.9998 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 834/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 3.2679e-18 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 835/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0071 - accuracy: 0.9998 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 836/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 6.6289e-12 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 837/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0565 - accuracy: 0.9994 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 838/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.0465e-18 - accuracy: 1.0000 - val_loss: 5.2512e-37 - val_accuracy: 1.0000\n",
            "Epoch 839/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.9870e-06 - accuracy: 1.0000 - val_loss: 1.3362e-29 - val_accuracy: 1.0000\n",
            "Epoch 840/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0089 - accuracy: 0.9998 - val_loss: 4.9935e-37 - val_accuracy: 1.0000\n",
            "Epoch 841/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 2.3713e-10 - accuracy: 1.0000 - val_loss: 4.2891e-35 - val_accuracy: 1.0000\n",
            "Epoch 842/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0058 - accuracy: 0.9998 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 843/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.9734e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 844/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.9774e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 845/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 9.8580e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 846/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.9699e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 847/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 4.9221e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 848/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 9.8391e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 849/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0362 - accuracy: 0.9997 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 850/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0259 - accuracy: 0.9997 - val_loss: 5.3917e-12 - val_accuracy: 1.0000\n",
            "Epoch 851/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 6.4506e-14 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 852/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.9510e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 853/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.7326e-16 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 854/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.9500e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 855/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 9.7765e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 856/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 9.7624e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 857/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0105 - accuracy: 0.9998 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 858/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.4789e-18 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 859/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.8452e-37 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 860/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.1672e-11 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 861/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.9071e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 862/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0114 - accuracy: 0.9997 - val_loss: 3.6479e-20 - val_accuracy: 1.0000\n",
            "Epoch 863/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 2.8464e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 864/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 3.8784e-20 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 865/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 2.6144e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 866/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 2.5558e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 867/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 9.4765e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 868/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 9.4746e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 869/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.8943e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 870/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 8.0955e-04 - accuracy: 0.9998 - val_loss: 0.1321 - val_accuracy: 0.9982\n",
            "Epoch 871/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 2.9110e-06 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 0.9994\n",
            "Epoch 872/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 9.5589e-04 - accuracy: 0.9998 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 873/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 2.2880e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 874/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 7.7198e-04 - accuracy: 0.9998 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 875/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 8.0267e-13 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 876/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.9436e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 877/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 2.8922e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 878/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.9429e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 879/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 2.8458e-11 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 880/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 3.8823e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 881/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 7.7006e-04 - accuracy: 0.9998 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 882/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 3.4033e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 883/1000\n",
            "206/206 [==============================] - 9s 42ms/step - loss: 2.9821e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 884/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.0177 - val_accuracy: 0.9994\n",
            "Epoch 885/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 7.5111e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 886/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 9.7024e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 887/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 2.0260e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 888/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 889/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0358 - accuracy: 0.9995 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 890/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0309 - accuracy: 0.9998 - val_loss: 0.5146 - val_accuracy: 0.9964\n",
            "Epoch 891/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0081 - accuracy: 0.9998 - val_loss: 0.0947 - val_accuracy: 0.9994\n",
            "Epoch 892/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0024 - accuracy: 0.9998 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 893/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0020 - accuracy: 0.9998 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 894/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 895/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 9.9821e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 896/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 6.0791e-32 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 897/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 898/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.0252e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 899/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.4436e-13 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 900/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 5.1037e-11 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 901/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0203 - accuracy: 0.9998 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 902/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.2538e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 903/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.0212e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 904/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 5.0562e-10 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 905/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.0210e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 906/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 8.0194e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 907/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 2.2138e-18 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 908/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 8.2899e-20 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 909/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 2.6771e-12 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 910/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.0207e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 911/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.4181e-16 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 912/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0099 - accuracy: 0.9997 - val_loss: 0.0436 - val_accuracy: 0.9994\n",
            "Epoch 913/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0116 - accuracy: 0.9998 - val_loss: 0.0754 - val_accuracy: 0.9994\n",
            "Epoch 914/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 9.9401e-07 - accuracy: 1.0000 - val_loss: 0.1134 - val_accuracy: 0.9994\n",
            "Epoch 915/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.1298 - val_accuracy: 0.9994\n",
            "Epoch 916/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.9878e-06 - accuracy: 1.0000 - val_loss: 0.1311 - val_accuracy: 0.9994\n",
            "Epoch 917/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0031 - accuracy: 0.9998 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 918/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 5.2675e-21 - accuracy: 1.0000 - val_loss: 7.7485e-30 - val_accuracy: 1.0000\n",
            "Epoch 919/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 4.5911e-13 - accuracy: 1.0000 - val_loss: 6.9339e-21 - val_accuracy: 1.0000\n",
            "Epoch 920/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 6.6422e-21 - accuracy: 1.0000 - val_loss: 5.3420e-27 - val_accuracy: 1.0000\n",
            "Epoch 921/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 4.4007e-12 - accuracy: 1.0000 - val_loss: 1.8025e-31 - val_accuracy: 1.0000\n",
            "Epoch 922/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 2.0292e-06 - accuracy: 1.0000 - val_loss: 1.2110e-22 - val_accuracy: 1.0000\n",
            "Epoch 923/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.0142e-06 - accuracy: 1.0000 - val_loss: 5.8164e-19 - val_accuracy: 1.0000\n",
            "Epoch 924/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.8266e-07 - accuracy: 1.0000 - val_loss: 1.4303e-17 - val_accuracy: 1.0000\n",
            "Epoch 925/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 9.9372e-05 - accuracy: 1.0000 - val_loss: 0.6756 - val_accuracy: 0.9951\n",
            "Epoch 926/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0143 - accuracy: 0.9995 - val_loss: 0.0680 - val_accuracy: 0.9994\n",
            "Epoch 927/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.4285e-18 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 928/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 9.7765e-21 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 929/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0056 - accuracy: 0.9998 - val_loss: 0.0766 - val_accuracy: 0.9994\n",
            "Epoch 930/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0024 - accuracy: 0.9998 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 931/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 3.7903e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 932/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0189 - accuracy: 0.9997 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 933/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0028 - accuracy: 0.9998 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 934/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 935/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 936/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0103 - accuracy: 0.9995 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 937/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 7.4173e-23 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 938/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 2.3590e-20 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 939/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0025 - accuracy: 0.9998 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 940/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 941/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 5.0446e-18 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 942/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 943/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 944/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 2.2349e-20 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 945/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 946/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 6.5199e-10 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 947/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 948/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 4.8263e-14 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 949/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.8942e-11 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 950/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 951/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 952/1000\n",
            "206/206 [==============================] - 9s 41ms/step - loss: 9.2660e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 953/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0060 - accuracy: 0.9998 - val_loss: 0.0030 - val_accuracy: 0.9994\n",
            "Epoch 954/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0313 - val_accuracy: 0.9994\n",
            "Epoch 955/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 2.1245e-29 - accuracy: 1.0000 - val_loss: 2.1692e-10 - val_accuracy: 1.0000\n",
            "Epoch 956/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 4.9913e-10 - accuracy: 1.0000 - val_loss: 8.7096e-15 - val_accuracy: 1.0000\n",
            "Epoch 957/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 6.9165e-13 - accuracy: 1.0000 - val_loss: 3.6842e-16 - val_accuracy: 1.0000\n",
            "Epoch 958/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 8.9982e-07 - accuracy: 1.0000 - val_loss: 1.4087e-19 - val_accuracy: 1.0000\n",
            "Epoch 959/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 5.1875e-28 - accuracy: 1.0000 - val_loss: 9.4670e-15 - val_accuracy: 1.0000\n",
            "Epoch 960/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 3.5318e-26 - accuracy: 1.0000 - val_loss: 1.0916e-14 - val_accuracy: 1.0000\n",
            "Epoch 961/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0040 - accuracy: 0.9998 - val_loss: 4.5257e-37 - val_accuracy: 1.0000\n",
            "Epoch 962/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.3236e-19 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 963/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 9.3178e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 964/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 5.0974e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 965/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.8648e-20 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 966/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 9.1562e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 967/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 4.8108e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 968/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 969/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 970/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.5717e-22 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 971/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0523 - accuracy: 0.9997 - val_loss: 0.3371 - val_accuracy: 0.9970\n",
            "Epoch 972/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 973/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 974/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 9.2192e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 975/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 7.8317e-17 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 976/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 8.4825e-05 - accuracy: 1.0000 - val_loss: 0.0405 - val_accuracy: 0.9994\n",
            "Epoch 977/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 2.7237e-35 - accuracy: 1.0000 - val_loss: 0.0113 - val_accuracy: 0.9994\n",
            "Epoch 978/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 2.1400e-04 - accuracy: 0.9998 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 979/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 8.8957e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 980/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 2.6765e-10 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 981/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 8.8940e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 982/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.8535e-28 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 983/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 5.3826e-26 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 984/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 985/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 986/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 987/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0176 - accuracy: 0.9998 - val_loss: 0.0098 - val_accuracy: 0.9994\n",
            "Epoch 988/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0145 - accuracy: 0.9998 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 989/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.7659e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 990/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.0834e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 991/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.4048e-27 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 992/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 8.8259e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 993/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0361 - accuracy: 0.9997 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 994/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.1804e-32 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 995/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 9.4952e-22 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 996/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 0.0043 - accuracy: 0.9998 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 997/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 1.8242e-34 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 998/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 8.6082e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 999/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 7.4433e-24 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 1000/1000\n",
            "206/206 [==============================] - 8s 41ms/step - loss: 7.6932e-10 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Iterate through the test dataset, predict with each trained model, and collect predictions and true labels."
      ],
      "metadata": {
        "id": "LSvDjB_HiwfL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "predicted_labels = []\n",
        "true_labels = []\n",
        "\n",
        "# New base directory for output\n",
        "base_dir = '/content/drive/MyDrive/output/'\n",
        "\n",
        "# Directories for models and metrics within the base directory\n",
        "models_dir = os.path.join(base_dir, 'models')\n",
        "# metrics_dir = os.path.join(base_dir, 'metrics') # Uncomment if you need to access metrics\n",
        "\n",
        "# Initialize a dictionary to cache the loaded models\n",
        "model_cache = {}\n",
        "\n",
        "# Loop through each family name and attempt to load the corresponding model\n",
        "for family_id, family_name in label_map.items():\n",
        "    if family_id == 9:\n",
        "        continue\n",
        "\n",
        "    # Construct the path to the model file within Google Drive\n",
        "    model_path = os.path.join(models_dir, f'family_{family_name}_classifier.h5')\n",
        "\n",
        "    # Check if the model file exists at the specified path\n",
        "    if os.path.exists(model_path):\n",
        "        # Load the model and store it in the cache\n",
        "        model_cache[family_name] = load_model(model_path)\n",
        "    else:\n",
        "        print(f\"Model for {family_name} not found at {model_path}\")\n",
        "# At this point, model_cache will contain all successfully loaded models\n",
        "\n",
        "# for example in nsynth_test.take(100):  # Example modification for quick testing\n",
        "for example in nsynth_test:\n",
        "    audio_sample = example['audio'].numpy()\n",
        "\n",
        "    spectrogram = audio_to_spectrogram(audio_sample)\n",
        "    spectrogram = np.expand_dims(np.expand_dims(spectrogram, 0), -1)  # Correctly reshape\n",
        "\n",
        "    true_label = example['instrument']['family'].numpy()\n",
        "\n",
        "    if true_label == 9:\n",
        "        continue\n",
        "\n",
        "    true_labels.append(true_label)\n",
        "\n",
        "    # Store predictions with their probabilities\n",
        "    prediction_probs = {}\n",
        "    for family_id, family_name in label_map.items():\n",
        "\n",
        "        if family_id == 9:\n",
        "            continue  # Skip this family ID\n",
        "\n",
        "        model = model_cache[family_name]\n",
        "\n",
        "        # Get prediction probability for the positive class\n",
        "        prob = model.predict(spectrogram)[0]\n",
        "        prediction_probs[family_id] = prob\n",
        "\n",
        "    # Select the class with the highest probability\n",
        "    if prediction_probs:\n",
        "        predicted_label = max(prediction_probs, key=prediction_probs.get)\n",
        "    else:\n",
        "        predicted_label = None  # Handle case with no predictions\n",
        "\n",
        "    predicted_labels.append(predicted_label)\n",
        "\n",
        "# Convert lists to arrays for easier handling\n",
        "true_labels = np.array(true_labels)\n",
        "predicted_labels = np.array(predicted_labels)\n",
        "\n",
        "\n",
        "# Define the base directory in Google Drive where you want to save the test results\n",
        "test_results_dir = '/content/drive/MyDrive/output/tests/'\n",
        "\n",
        "# Ensure the directory exists\n",
        "os.makedirs(test_results_dir, exist_ok=True)\n",
        "\n",
        "# Define the full path for the files to save\n",
        "true_label_path = os.path.join(test_results_dir, 'true_label.txt')\n",
        "predicted_labels_path = os.path.join(test_results_dir, 'predicted_labels.txt')\n",
        "\n",
        "# Save true and predicted labels for further analysis\n",
        "np.savetxt(true_label_path, true_labels, fmt='%d')\n",
        "np.savetxt(predicted_labels_path, predicted_labels, fmt='%d')\n",
        "\n",
        "print(f\"True labels saved to: {true_label_path}\")\n",
        "print(f\"Predicted labels saved to: {predicted_labels_path}\")\n"
      ],
      "metadata": {
        "id": "F8o2FGp6iyHQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0673724-1255-42cd-892c-e8ff71c23775"
      },
      "execution_count": 10,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 271ms/step\n",
            "1/1 [==============================] - 0s 104ms/step\n",
            "1/1 [==============================] - 0s 102ms/step\n",
            "1/1 [==============================] - 0s 104ms/step\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7a547e5a8940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 104ms/step\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7a547ff2acb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "True labels saved to: /content/drive/MyDrive/output/tests/true_label.txt\n",
            "Predicted labels saved to: /content/drive/MyDrive/output/tests/predicted_labels.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "get blanced test set:"
      ],
      "metadata": {
        "id": "EkztRfoZXmyL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "import random\n",
        "\n",
        "# Function to preprocess and extract a balanced dataset\n",
        "def build_balanced_dataset(nsynth_train, nsynth_valid, nsynth_test, target_samples=100):\n",
        "    # Combine datasets to pool samples from\n",
        "    combined_dataset = nsynth_train.concatenate(nsynth_valid).concatenate(nsynth_test)\n",
        "\n",
        "    # Initialize a dictionary to store examples by class\n",
        "    class_samples = defaultdict(list)\n",
        "\n",
        "    # Iterate over the combined dataset to classify examples by instrument family\n",
        "    for example in tfds.as_numpy(combined_dataset):\n",
        "        label = example['instrument']['family']\n",
        "        # Skip class 9 as per requirement\n",
        "        if label != 9:\n",
        "            class_samples[label].append(example)\n",
        "\n",
        "    # Initialize list for balanced dataset\n",
        "    balanced_dataset = []\n",
        "\n",
        "    # Iterate over each class to select samples\n",
        "    for label, examples in class_samples.items():\n",
        "        # Ensure each class has exactly target_samples examples\n",
        "        if len(examples) >= target_samples:\n",
        "            # Randomly sample target_samples examples\n",
        "            balanced_samples = random.sample(examples, target_samples)\n",
        "        else:\n",
        "            # If not enough samples, use what's available (shouldn't happen with correct setup)\n",
        "            balanced_samples = examples\n",
        "        balanced_dataset.extend(balanced_samples)\n",
        "\n",
        "    # Return the balanced dataset\n",
        "    return balanced_dataset\n",
        "\n",
        "# Build a balanced dataset\n",
        "balanced_dataset = build_balanced_dataset(nsynth_train, nsynth_valid, nsynth_test)\n",
        "\n",
        "predicted_labels_blc = []\n",
        "true_labels_blc = []\n",
        "\n",
        "for example in balanced_dataset:\n",
        "    audio_sample = example['audio']  # Already a NumPy array, no need for .numpy()\n",
        "\n",
        "    spectrogram = audio_to_spectrogram(audio_sample)\n",
        "    spectrogram = np.expand_dims(np.expand_dims(spectrogram, 0), -1)  # Correctly reshape\n",
        "\n",
        "    true_label = example['instrument']['family']  # Already a NumPy value, no need for .numpy()\n",
        "    if true_label == 9:\n",
        "        continue\n",
        "\n",
        "    true_labels_blc.append(true_label)\n",
        "\n",
        "    # Store predictions with their probabilities\n",
        "    prediction_probs = {}\n",
        "    for family_id, family_name in label_map.items():\n",
        "\n",
        "        if family_id == 9:\n",
        "            continue  # Skip this family ID\n",
        "\n",
        "        model = model_cache[family_name]\n",
        "\n",
        "        # Get prediction probability for the positive class\n",
        "        prob = model.predict(spectrogram)[0]\n",
        "        prediction_probs[family_id] = prob\n",
        "\n",
        "    # Select the class with the highest probability\n",
        "    if prediction_probs:\n",
        "        predicted_label = max(prediction_probs, key=prediction_probs.get)\n",
        "    else:\n",
        "        predicted_label = None  # Handle case with no predictions\n",
        "\n",
        "    predicted_labels_blc.append(predicted_label)\n",
        "\n",
        "# Convert lists to arrays for easier handling\n",
        "true_labels = np.array(predicted_labels_blc)\n",
        "predicted_labels = np.array(predicted_labels_blc)\n",
        "\n",
        "\n",
        "# Define the base directory in Google Drive where you want to save the test results\n",
        "test_results_dir = '/content/drive/MyDrive/output/tests_blc/'\n",
        "\n",
        "# Ensure the directory exists\n",
        "os.makedirs(test_results_dir, exist_ok=True)\n",
        "\n",
        "# Define the full path for the files to save\n",
        "true_label_path_blc = os.path.join(test_results_dir, 'true_label_blc.txt')\n",
        "predicted_labels_path_blc = os.path.join(test_results_dir, 'predicted_labels_blc.txt')\n",
        "\n",
        "# Save true and predicted labels for further analysis\n",
        "np.savetxt(true_label_path_blc, true_labels_blc, fmt='%d')\n",
        "np.savetxt(predicted_labels_path_blc, predicted_labels_blc, fmt='%d')\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "label_map_no_syn_blc = {\n",
        "    0: 'bass',\n",
        "    1: 'brass',\n",
        "    2: 'flute',\n",
        "    3: 'guitar',\n",
        "    4: 'keyboard',\n",
        "    5: 'mallet',\n",
        "    6: 'organ',\n",
        "    7: 'reed',\n",
        "    8: 'string',\n",
        "    # 9: 'synth_lead',\n",
        "    10: 'vocal',\n",
        "}\n",
        "\n",
        "# Compute metrics for each class\n",
        "print(classification_report(true_labels_blc, predicted_labels_blc, target_names=label_map_no_syn_blc.values()))\n",
        "\n",
        "# Compute confusion matrix\n",
        "conf_matrix_blc = confusion_matrix(true_labels_blc, predicted_labels_blc)\n",
        "print(conf_matrix_blc)\n",
        "\n",
        "# Additional metrics like TP, TN, FP, FN can be derived from the confusion matrix if needed."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WZ_JvXMVXpgp",
        "outputId": "1a0fcaf9-27d8-4417-9d6c-f2629b937c28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After collecting predictions and true labels, compute and print evaluation metrics for each class.\n",
        "\n"
      ],
      "metadata": {
        "id": "-GJA4dEAizCi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "label_map_no_syn = {\n",
        "    0: 'bass',\n",
        "    1: 'brass',\n",
        "    2: 'flute',\n",
        "    3: 'guitar',\n",
        "    4: 'keyboard',\n",
        "    5: 'mallet',\n",
        "    6: 'organ',\n",
        "    7: 'reed',\n",
        "    8: 'string',\n",
        "    # 9: 'synth_lead',\n",
        "    10: 'vocal',\n",
        "}\n",
        "\n",
        "# Compute metrics for each class\n",
        "print(classification_report(true_labels, predicted_labels, target_names=label_map_no_syn.values()))\n",
        "\n",
        "# Compute confusion matrix\n",
        "conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
        "print(conf_matrix)\n",
        "\n",
        "# Additional metrics like TP, TN, FP, FN can be derived from the confusion matrix if needed."
      ],
      "metadata": {
        "id": "CEfPw1lTi1aa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Overlay example\n"
      ],
      "metadata": {
        "id": "Bf3EhMB3GuaO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import librosa\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import librosa.display\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "\n",
        "# Load one sample from the NSynth dataset\n",
        "nsynth_test_sample = next(iter(tfds.load('nsynth/gansynth_subset', split='test', shuffle_files=False).take(1)))\n",
        "nsynth_audio = nsynth_test_sample['audio'].numpy()\n",
        "nsynth_sr = 16000  # NSynth sample rate\n",
        "\n",
        "# Generate random noise with the same length as the NSynth audio\n",
        "noise = np.random.normal(0, 1, nsynth_audio.shape)\n",
        "\n",
        "# Adjust the amplitude of the noise to be lower\n",
        "noise_amplitude = 0.05  # Lower this value to reduce the noise level further if necessary\n",
        "noise = noise * noise_amplitude\n",
        "\n",
        "# Overlay the audio by adding the noise to the NSynth audio\n",
        "overlayed_audio = nsynth_audio + noise\n",
        "\n",
        "# Plotting and saving the waveforms and spectrograms\n",
        "# Ensure the plots directory exists\n",
        "os.makedirs('./plots', exist_ok=True)\n",
        "\n",
        "# Plotting the original NSynth audio, the generated noise, and the overlayed audio\n",
        "plt.figure(figsize=(15, 9))\n",
        "plt.subplot(3, 1, 1)\n",
        "plt.plot(nsynth_audio)\n",
        "plt.title('Original NSynth Audio')\n",
        "plt.xlabel('Sample')\n",
        "plt.ylabel('Amplitude')\n",
        "\n",
        "plt.subplot(3, 1, 2)\n",
        "plt.plot(noise)\n",
        "plt.title('Generated Noise')\n",
        "plt.xlabel('Sample')\n",
        "plt.ylabel('Amplitude')\n",
        "\n",
        "plt.subplot(3, 1, 3)\n",
        "plt.plot(overlayed_audio)\n",
        "plt.title('Overlayed Audio')\n",
        "plt.xlabel('Sample')\n",
        "plt.ylabel('Amplitude')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('./plots/waveforms_with_quiet_noise.png')\n",
        "plt.show()\n",
        "\n",
        "# Plotting spectrograms\n",
        "plt.figure(figsize=(15, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "D_original = librosa.amplitude_to_db(np.abs(librosa.stft(nsynth_audio)), ref=np.max)\n",
        "librosa.display.specshow(D_original, sr=nsynth_sr, x_axis='time', y_axis='log')\n",
        "plt.colorbar(format='%+2.0f dB')\n",
        "plt.title('Original NSynth Spectrogram')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "D_overlayed = librosa.amplitude_to_db(np.abs(librosa.stft(overlayed_audio)), ref=np.max)\n",
        "librosa.display.specshow(D_overlayed, sr=nsynth_sr, x_axis='time', y_axis='log')\n",
        "plt.colorbar(format='%+2.0f dB')\n",
        "plt.title('Overlayed Audio Spectrogram')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('./plots/spectrograms_with_quiet_noise.png')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 926
        },
        "id": "-gwXyOmdGwHb",
        "outputId": "e5c9c2c0-bded-48d6-d475-5811eea26f7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x900 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x600 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "multiple label classification\n"
      ],
      "metadata": {
        "id": "k55_feGDmE0a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from math import comb\n",
        "\n",
        "# Redefining the number of samples per class to 10\n",
        "samples_per_class = 10\n",
        "\n",
        "# Solo instruments and combinations\n",
        "solo_samples = 10 * 10  # 10 solo instruments\n",
        "duo_samples = comb(10, 2) * samples_per_class  # Combinations of 2 from 10 instruments\n",
        "trio_samples = comb(10, 3) * samples_per_class  # Combinations of 3 from 10 instruments\n",
        "quartet_samples = comb(10, 4) * samples_per_class  # Combinations of 4 from 10 instruments\n",
        "quintet_samples = comb(10, 5) * samples_per_class  # Combinations of 5 from 10 instruments\n",
        "sextet_samples = comb(10, 6) * samples_per_class  # Combinations of 6 from 10 instruments\n",
        "septet_samples = comb(10, 7) * samples_per_class  # Combinations of 7 from 10 instruments\n",
        "octet_samples = comb(10, 8) * samples_per_class  # Combinations of 8 from 10 instruments\n",
        "nonet_samples = comb(10, 9) * samples_per_class  # Combinations of 9 from 10 instruments\n",
        "all_instruments_samples = samples_per_class  # All 10 instruments together\n",
        "\n",
        "# Adding no instrument samples\n",
        "no_instrument_samples = samples_per_class\n",
        "\n",
        "# Calculating total number of samples with reduced sample size per class\n",
        "total_samples_reduced = (solo_samples + duo_samples + trio_samples + quartet_samples + quintet_samples +\n",
        "                         sextet_samples + septet_samples + octet_samples + nonet_samples + all_instruments_samples +\n",
        "                         no_instrument_samples)\n",
        "\n",
        "total_samples_reduced\n"
      ],
      "metadata": {
        "id": "N0psiOnvmHxm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "generate samples"
      ],
      "metadata": {
        "id": "qHy4Ei6NmItG"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "30rDjXgimK5l"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}